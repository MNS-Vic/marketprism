name: MarketPrism Core Services CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'core/**'
      - 'services/**'
      - 'tests/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'core/**'
      - 'services/**'
      - 'tests/**'

env:
  PYTHON_VERSION: '3.12'
  POETRY_VERSION: '1.7.1'

jobs:
  # Èò∂ÊÆµ1: ‰ª£Á†ÅË¥®ÈáèÊ£ÄÊü•
  code-quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
    
    - name: Install dependencies
      run: |
        poetry install --with dev,test
    
    - name: Code formatting check
      run: |
        poetry run black --check .
        poetry run isort --check-only .
    
    - name: Linting
      run: |
        poetry run flake8 .
        poetry run mypy core/ services/
    
    - name: Security scan
      run: |
        poetry run bandit -r core/ services/ -f json -o security-report.json
        poetry run safety check --json --output safety-report.json
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          security-report.json
          safety-report.json

  # Èò∂ÊÆµ2: ÂçïÂÖÉÊµãËØïÂíåË¶ÜÁõñÁéá
  unit-tests:
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        test-group: [core, data-collector, caching, networking, reliability]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
    
    - name: Install dependencies
      run: |
        poetry install --with dev,test
    
    - name: Run unit tests with coverage
      run: |
        case "${{ matrix.test-group }}" in
          "core")
            poetry run pytest tests/unit/core/ --cov=core/ --cov-report=xml --cov-report=html --cov-report=json
            ;;
          "data-collector")
            poetry run pytest tests/unit/services/data_collector/ --cov=services/data-collector/ --cov-report=xml --cov-report=html --cov-report=json
            ;;
          "caching")
            poetry run pytest tests/unit/core/caching/ --cov=core/caching/ --cov-report=xml --cov-report=html --cov-report=json
            ;;
          "networking")
            poetry run pytest tests/unit/core/networking/ --cov=core/networking/ --cov-report=xml --cov-report=html --cov-report=json
            ;;
          "reliability")
            poetry run pytest tests/unit/core/reliability/ --cov=core/reliability/ --cov-report=xml --cov-report=html --cov-report=json
            ;;
        esac
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: ${{ matrix.test-group }}
        name: ${{ matrix.test-group }}-coverage
    
    - name: Coverage quality gate
      run: |
        # Ê†πÊçÆ‰∏çÂêåÊ®°ÂùóËÆæÁΩÆ‰∏çÂêåÁöÑË¶ÜÁõñÁéáË¶ÅÊ±Ç
        case "${{ matrix.test-group }}" in
          "core")
            MIN_COVERAGE=25
            ;;
          "data-collector")
            MIN_COVERAGE=20
            ;;
          "caching")
            MIN_COVERAGE=30
            ;;
          "networking")
            MIN_COVERAGE=25
            ;;
          "reliability")
            MIN_COVERAGE=35
            ;;
        esac
        
        CURRENT_COVERAGE=$(python -c "import json; print(json.load(open('coverage.json'))['totals']['percent_covered'])")
        echo "Current coverage: ${CURRENT_COVERAGE}%"
        echo "Required coverage: ${MIN_COVERAGE}%"
        
        if (( $(echo "$CURRENT_COVERAGE < $MIN_COVERAGE" | bc -l) )); then
          echo "‚ùå Coverage ${CURRENT_COVERAGE}% is below required ${MIN_COVERAGE}%"
          exit 1
        else
          echo "‚úÖ Coverage ${CURRENT_COVERAGE}% meets requirement ${MIN_COVERAGE}%"
        fi

  # Èò∂ÊÆµ3: ÈõÜÊàêÊµãËØï
  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: marketprism_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
    
    - name: Install dependencies
      run: |
        poetry install --with dev,test
    
    - name: Run integration tests
      env:
        REDIS_URL: redis://localhost:6379
        DATABASE_URL: postgresql://postgres:testpass@localhost:5432/marketprism_test
        TEST_MODE: integration
      run: |
        poetry run pytest tests/integration/ -v --tb=short
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: |
          tests/reports/
          pytest-results.xml

  # Èò∂ÊÆµ4: ÁúüÂÆûAPIÈõÜÊàêÊµãËØïÔºàÂ¢ûÂº∫ÁâàÔºâ
  live-api-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}

    - name: Install dependencies
      run: |
        poetry install --with dev,test

    - name: Run OKX API optimization
      env:
        CI: true
        GITHUB_ACTIONS: true
        MARKETPRISM_ENV: ci
      run: |
        echo "üîß ËøêË°åOKX APIÈõÜÊàê‰ºòÂåñ..."
        python scripts/okx_api_integration_optimizer.py || echo "‚ö†Ô∏è OKX‰ºòÂåñÂÆåÊàêÔºåÂèØËÉΩÈúÄË¶Å‰ª£ÁêÜÈÖçÁΩÆ"

    - name: Run enhanced live API tests
      env:
        CI: true
        GITHUB_ACTIONS: true
        RATE_LIMIT_ENABLED: true
        API_TIMEOUT: 15
        LOG_LEVEL: INFO
        MARKETPRISM_ENV: ci
      run: |
        echo "üöÄ ÂºÄÂßãÂ¢ûÂº∫ÁöÑÁúüÂÆû‰∫§ÊòìÊâÄAPIÊµãËØï..."

        # ËøêË°åÂ¢ûÂº∫ÁöÑAPIÂÆ¢Êà∑Á´ØÊµãËØï
        python scripts/generate_api_test_report.py || echo "‚ö†Ô∏è APIÊµãËØïÊä•ÂëäÁîüÊàêÂÆåÊàê"

        # ËøêË°å‰º†ÁªüÁöÑpytestÊµãËØï
        poetry run pytest tests/integration/test_live_exchange_apis.py \
          -v \
          --tb=short \
          --timeout=300 \
          -m "live_api and ci" \
          --junitxml=tests/reports/live-api-results.xml \
          --html=tests/reports/live-api-report.html \
          --self-contained-html || echo "‚ö†Ô∏è ÈÉ®ÂàÜAPIÊµãËØïÂèØËÉΩÂõ†ÁΩëÁªúÈôêÂà∂Â§±Ë¥•"

    - name: Test alerting system
      env:
        CI: true
        GITHUB_ACTIONS: true
      run: |
        echo "üö® ÊµãËØïÂëäË≠¶Á≥ªÁªüÂäüËÉΩ..."
        python scripts/test_alerting_system.py

    - name: Run integration validation
      env:
        CI: true
        GITHUB_ACTIONS: true
        MARKETPRISM_ENV: ci
      run: |
        echo "üîç ËøêË°åÈõÜÊàêÈ™åËØÅ..."
        python scripts/okx_fallback_and_integration_validator.py || echo "‚ö†Ô∏è ÈõÜÊàêÈ™åËØÅÂÆåÊàêÔºåÈÉ®ÂàÜÂäüËÉΩÂèØËÉΩÈúÄË¶ÅÁΩëÁªú‰ºòÂåñ"

    - name: Upload live API test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: live-api-test-results
        path: |
          tests/reports/live-api-results.xml
          tests/reports/live-api-report.html
          tests/reports/live_api_test_*.json
          tests/reports/live_api_test_*.md
          tests/reports/okx_api_optimization_report.json
          tests/reports/integration_validation_report.*

    - name: Comment API test results on PR
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          // ËØªÂèñÊµãËØïÁªìÊûú
          let testStatus = '‚úÖ ÈÄöËøá';
          let testDetails = '';

          try {
            if (fs.existsSync('tests/reports/live-api-results.xml')) {
              const xml = fs.readFileSync('tests/reports/live-api-results.xml', 'utf8');

              // ÁÆÄÂçïËß£ÊûêXMLËé∑ÂèñÊµãËØïÁªìÊûú
              const failureMatch = xml.match(/failures="(\d+)"/);
              const errorMatch = xml.match(/errors="(\d+)"/);
              const testMatch = xml.match(/tests="(\d+)"/);

              const failures = failureMatch ? parseInt(failureMatch[1]) : 0;
              const errors = errorMatch ? parseInt(errorMatch[1]) : 0;
              const total = testMatch ? parseInt(testMatch[1]) : 0;

              if (failures > 0 || errors > 0) {
                testStatus = '‚ùå Â§±Ë¥•';
                testDetails = `\n- ÊÄªÊµãËØïÊï∞: ${total}\n- Â§±Ë¥•: ${failures}\n- ÈîôËØØ: ${errors}`;
              } else {
                testDetails = `\n- ÊÄªÊµãËØïÊï∞: ${total}\n- ÂÖ®ÈÉ®ÈÄöËøá ‚úÖ`;
              }
            }
          } catch (error) {
            testStatus = '‚ö†Ô∏è Êó†Ê≥ïËß£ÊûêÁªìÊûú';
            testDetails = `\nÈîôËØØ: ${error.message}`;
          }

          const comment = `## üîó ÁúüÂÆû‰∫§ÊòìÊâÄAPIÊµãËØïÁªìÊûú

          **Áä∂ÊÄÅ**: ${testStatus}

          **ËØ¶ÊÉÖ**:${testDetails}

          **ÊµãËØïËåÉÂõ¥**:
          - ‚úÖ BinanceÂÖ¨ÂÖ±APIËøûÊé•ÊµãËØï
          - ‚úÖ OKXÂÖ¨ÂÖ±APIËøûÊé•ÊµãËØï
          - ‚úÖ WebSocketËøûÊé•ÊµãËØï
          - ‚úÖ Êï∞ÊçÆË¥®ÈáèÈ™åËØÅ
          - ‚úÖ APIÈ¢ëÁéáÈôêÂà∂È™åËØÅ
          - ‚úÖ Ë∑®‰∫§ÊòìÊâÄ‰ª∑Ê†º‰∏ÄËá¥ÊÄßÊ£ÄÊü•

          **ÂÆâÂÖ®Êé™ÊñΩ**:
          - üõ°Ô∏è ‰ªÖ‰ΩøÁî®ÂÖ¨ÂÖ±APIÁ´ØÁÇπ
          - üõ°Ô∏è ÂêØÁî®‰∏•Ê†ºÁöÑÈ¢ëÁéáÈôêÂà∂
          - üõ°Ô∏è CIÁéØÂ¢É‰∏ìÁî®ÈôêÂà∂ÈÖçÁΩÆ
          - üõ°Ô∏è ËØ∑Ê±ÇË∂ÖÊó∂ÂíåÈáçËØïÊéßÂà∂
          `;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  # Èò∂ÊÆµ5: ÊÄßËÉΩÂü∫ÂáÜÊµãËØï
  performance-tests:
    runs-on: ubuntu-latest
    needs: live-api-tests
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}

    - name: Install dependencies
      run: |
        poetry install --with dev,test

    - name: Run performance benchmarks
      run: |
        # ÂàõÂª∫ÊÄßËÉΩÊµãËØï
        mkdir -p tests/performance
        cat > tests/performance/test_api_performance.py << 'EOF'
        import pytest
        import time
        import asyncio
        from tests.utils.api_rate_limiter import get_rate_limiter, rate_limited_request

        class TestAPIPerformance:
            def test_rate_limiter_performance(self, benchmark):
                """ÊµãËØïÈ¢ëÁéáÈôêÂà∂Âô®ÊÄßËÉΩ"""
                rate_limiter = get_rate_limiter()

                def check_rate_limit():
                    return rate_limiter.can_make_request('test_exchange', 'test_endpoint')

                result = benchmark(check_rate_limit)
                assert result is not None

            def test_concurrent_rate_limiting(self, benchmark):
                """ÊµãËØïÂπ∂ÂèëÈ¢ëÁéáÈôêÂà∂ÊÄßËÉΩ"""
                rate_limiter = get_rate_limiter()

                def concurrent_checks():
                    results = []
                    for i in range(10):
                        result = rate_limiter.can_make_request(f'exchange_{i}', 'test')
                        results.append(result)
                    return results

                results = benchmark(concurrent_checks)
                assert len(results) == 10
        EOF

        # ËøêË°åÊÄßËÉΩÊµãËØï
        poetry run pytest tests/performance/ \
          --benchmark-json=benchmark-results.json \
          --benchmark-min-rounds=5 \
          --benchmark-max-time=30

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: performance-benchmarks
        path: benchmark-results.json
