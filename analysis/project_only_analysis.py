#!/usr/bin/env python3
"""
MarketPrismé¡¹ç›®ä»£ç ä¸“é¡¹åˆ†æ
ä»…åˆ†æé¡¹ç›®è‡ªæœ‰ä»£ç ï¼Œæ’é™¤ä¾èµ–åº“
"""

import os
from pathlib import Path
import ast

def analyze_project_only():
    """åˆ†æä»…é¡¹ç›®è‡ªæœ‰ä»£ç """
    print("ğŸ¯ åˆ†æMarketPrismé¡¹ç›®è‡ªæœ‰ä»£ç ...")
    
    # æ’é™¤ä¾èµ–åº“ç›®å½•
    exclude_dirs = {
        "venv", "venv_tdd", "__pycache__", ".git", 
        "node_modules", "dist", "build", ".pytest_cache",
        "coverage_html_report", ".coverage"
    }
    
    project_files = []
    week_files = []
    test_files = []
    core_files = []
    
    for file_path in Path(".").rglob("*.py"):
        # è·³è¿‡ä¾èµ–åº“ç›®å½•
        if any(excluded in str(file_path) for excluded in exclude_dirs):
            continue
            
        project_files.append(file_path)
        
        if "week" in file_path.name.lower():
            week_files.append(file_path)
        if "test" in file_path.name.lower():
            test_files.append(file_path)
        if "core/" in str(file_path):
            core_files.append(file_path)
    
    print(f"ğŸ“Š é¡¹ç›®æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  ğŸ“ æ€»é¡¹ç›®æ–‡ä»¶: {len(project_files)}")
    print(f"  ğŸ“… Weekç›¸å…³æ–‡ä»¶: {len(week_files)}")
    print(f"  ğŸ§ª æµ‹è¯•æ–‡ä»¶: {len(test_files)}")
    print(f"  ğŸ—ï¸ æ ¸å¿ƒç»„ä»¶æ–‡ä»¶: {len(core_files)}")
    
    # åˆ†æä»£ç è¡Œæ•°
    total_lines = 0
    for file_path in project_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                total_lines += len(f.readlines())
        except:
            pass
    
    print(f"  ğŸ“ é¡¹ç›®æ€»ä»£ç è¡Œæ•°: {total_lines:,}")
    
    # åˆ†æé‡å¤ç»„ä»¶
    analyze_project_duplicates(project_files)
    
    # åˆ†ææ•´åˆè¿›å±•
    analyze_consolidation_progress()

def analyze_project_duplicates(project_files):
    """åˆ†æé¡¹ç›®é‡å¤ç»„ä»¶"""
    print(f"\nğŸ” åˆ†æé¡¹ç›®é‡å¤ç»„ä»¶...")
    
    classes = {}
    for file_path in project_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
                
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_name = node.name
                    if class_name not in classes:
                        classes[class_name] = []
                    classes[class_name].append(str(file_path))
        except:
            continue
    
    # æŸ¥æ‰¾é¡¹ç›®é‡å¤ç±»
    project_duplicates = {name: files for name, files in classes.items() 
                         if len(files) > 1 and any("marketprism" in f or "week" in f or "core/" in f for f in files)}
    
    print(f"ğŸ“Š é¡¹ç›®é‡å¤ç±»ç»Ÿè®¡:")
    print(f"  ğŸ”„ é¡¹ç›®é‡å¤ç±»æ•°: {len(project_duplicates)}")
    
    # æ˜¾ç¤ºå…³é”®é‡å¤
    critical_duplicates = {name: files for name, files in project_duplicates.items() if len(files) >= 3}
    
    print(f"\nğŸš¨ å…³é”®é‡å¤ç±» (3ä¸ªä»¥ä¸Š):")
    for class_name, files in sorted(critical_duplicates.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
        print(f"  ğŸ“‹ {class_name} ({len(files)}ä¸ªé‡å¤):")
        for file in files[:5]:
            if any(excluded not in file for excluded in ["venv", "__pycache__"]):
                print(f"    ğŸ“ {file}")
        if len(files) > 5:
            print(f"    ... å’Œå…¶ä»– {len(files)-5} ä¸ªæ–‡ä»¶")

def analyze_consolidation_progress():
    """åˆ†ææ•´åˆè¿›å±•"""
    print(f"\nğŸ“ˆ åˆ†ææ•´åˆè¿›å±•...")
    
    # æ£€æŸ¥ç»Ÿä¸€ç»„ä»¶
    core_components = {
        "é…ç½®ç®¡ç†": "core/config/unified_config_system.py",
        "ç›‘æ§ç®¡ç†": "core/monitoring/unified_monitoring_platform.py", 
        "å®‰å…¨ç®¡ç†": "core/security/unified_security_platform.py",
        "è¿ç»´ç®¡ç†": "core/operations/unified_operations_platform.py",
        "æ€§èƒ½ä¼˜åŒ–": "core/performance/unified_performance_platform.py"
    }
    
    print("ğŸ—ï¸ ç»Ÿä¸€ç»„ä»¶çŠ¶æ€:")
    for component_name, file_path in core_components.items():
        if Path(file_path).exists():
            print(f"  âœ… {component_name}: {file_path}")
        else:
            print(f"  â³ {component_name}: å¾…åˆ›å»º")
    
    # æ£€æŸ¥å†å²å½’æ¡£
    archive_dirs = [
        "week_development_history/week1_config_legacy",
        "week_development_history/week5_config_v2", 
        "week_development_history/week2_monitoring_basic",
        "week_development_history/scattered_configs",
        "week_development_history/scattered_monitoring"
    ]
    
    print(f"\nğŸ“¦ å†å²å½’æ¡£çŠ¶æ€:")
    for archive_dir in archive_dirs:
        if Path(archive_dir).exists():
            file_count = len(list(Path(archive_dir).rglob("*.py")))
            print(f"  âœ… {archive_dir}: {file_count}ä¸ªæ–‡ä»¶å·²å½’æ¡£")
        else:
            print(f"  âŒ {archive_dir}: ä¸å­˜åœ¨")

def calculate_consolidation_impact():
    """è®¡ç®—æ•´åˆå½±å“"""
    print(f"\nğŸ’¡ è®¡ç®—æ•´åˆå½±å“...")
    
    # ç»Ÿè®¡Weekæ–‡ä»¶
    week_patterns = ["week*.py"]
    remaining_week_files = []
    
    for pattern in week_patterns:
        for file_path in Path(".").rglob(pattern):
            if not any(excluded in str(file_path) for excluded in ["venv", "__pycache__", "backup", "week_development_history"]):
                remaining_week_files.append(file_path)
    
    print(f"ğŸ“Š å‰©ä½™Weekæ–‡ä»¶: {len(remaining_week_files)}")
    
    # æŒ‰Weekåˆ†ç»„
    week_groups = {}
    for file_path in remaining_week_files:
        file_name = file_path.name
        if "week5" in file_name:
            week_groups.setdefault("Week 5", []).append(file_path)
        elif "week6" in file_name:
            week_groups.setdefault("Week 6", []).append(file_path)
        elif "week7" in file_name:
            week_groups.setdefault("Week 7", []).append(file_path)
    
    for week, files in week_groups.items():
        print(f"  ğŸ“… {week}: {len(files)}ä¸ªæ–‡ä»¶")
        if len(files) <= 5:
            for file in files:
                print(f"    ğŸ“„ {file}")
    
    # ä¼°ç®—æ•´åˆæ½œåŠ›
    estimated_reduction = len(remaining_week_files) * 0.8  # é¢„è®¡å¯å‡å°‘80%
    print(f"\nğŸ¯ ç¬¬2é˜¶æ®µæ•´åˆæ½œåŠ›:")
    print(f"  ğŸ—‘ï¸ å¯å‡å°‘Weekæ–‡ä»¶: {int(estimated_reduction)}ä¸ª")
    print(f"  ğŸ“ˆ æ•´åˆè¿›åº¦: çº¦60%å®Œæˆ")

if __name__ == "__main__":
    print("ğŸš€" + "="*60 + "ğŸš€")
    print("    MarketPrismé¡¹ç›®ä»£ç ä¸“é¡¹åˆ†æ")
    print("    ä»…åˆ†æé¡¹ç›®è‡ªæœ‰ä»£ç ï¼Œæ’é™¤ä¾èµ–åº“")
    print("ğŸš€" + "="*60 + "ğŸš€")
    print()
    
    analyze_project_only()
    calculate_consolidation_impact()
    
    print("\nâœ… é¡¹ç›®ä»£ç ä¸“é¡¹åˆ†æå®Œæˆ!")
    print("ğŸš€ ç»§ç»­ç¬¬2é˜¶æ®µæ•´åˆ: è¿ç»´å’Œæ€§èƒ½ç³»ç»Ÿ")