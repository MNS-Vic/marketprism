#!/usr/bin/env python3
"""
Servicesæ¨¡å—æ•´åˆæ‰§è¡Œè„šæœ¬

è‡ªåŠ¨åŒ–æ‰§è¡Œservicesæ¨¡å—çš„é‡å¤ç»„ä»¶æ¸…ç†å’Œæ¶æ„ä¼˜åŒ–
ä¼˜å…ˆå¤„ç†é«˜å½±å“ã€é«˜é‡å¤åº¦çš„ç»„ä»¶æ•´åˆ
"""

import os
import shutil
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Any
import time
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('services_æ•´åˆ.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ServicesConsolidator:
    """Servicesæ¨¡å—æ•´åˆå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / "backup" / f"services_backup_{int(time.time())}"
        self.core_dir = self.project_root / "core"
        self.services_dir = self.project_root / "services"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.core_dir.mkdir(exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"åˆå§‹åŒ–Servicesæ•´åˆå™¨: {self.project_root}")
        logger.info(f"å¤‡ä»½ç›®å½•: {self.backup_dir}")
    
    def execute_consolidation(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•´åˆæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹Servicesæ¨¡å—æ•´åˆä¼˜åŒ–")
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šå¤‡ä»½å’Œé‡å¤ç»„ä»¶æ¸…ç†
            self.phase1_cleanup_duplicates()
            
            # ç¬¬äºŒé˜¶æ®µï¼šæ¶æ„é‡æ„
            self.phase2_restructure_services()
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šé…ç½®å’Œæ¥å£ç»Ÿä¸€
            self.phase3_unify_interfaces()
            
            # ç¬¬å››é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Š
            self.phase4_generate_report()
            
            logger.info("âœ… Servicesæ¨¡å—æ•´åˆå®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"âŒ æ•´åˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.rollback_changes()
            raise
    
    def phase1_cleanup_duplicates(self):
        """ç¬¬ä¸€é˜¶æ®µï¼šæ¸…ç†é‡å¤ç»„ä»¶"""
        logger.info("ğŸ“‹ ç¬¬ä¸€é˜¶æ®µï¼šæ¸…ç†é‡å¤ç»„ä»¶")
        
        # 1. å¤‡ä»½ç°æœ‰æ–‡ä»¶
        self.create_backup()
        
        # 2. æ•´åˆReliabilityManager
        self.consolidate_reliability_manager()
        
        # 3. æ•´åˆStorageManager
        self.consolidate_storage_manager()
        
        # 4. æ¸…ç†ç›‘æ§é‡å¤
        self.cleanup_monitoring_duplicates()
        
        logger.info("âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼šé‡å¤ç»„ä»¶å·²æ¸…ç†")
    
    def phase2_restructure_services(self):
        """ç¬¬äºŒé˜¶æ®µï¼šé‡æ„æœåŠ¡æ¶æ„"""
        logger.info("ğŸ—ï¸ ç¬¬äºŒé˜¶æ®µï¼šé‡æ„æœåŠ¡æ¶æ„")
        
        # 1. é‡æ–°å®šä¹‰æœåŠ¡è¾¹ç•Œ
        self.redefine_service_boundaries()
        
        # 2. åˆ›å»ºç»Ÿä¸€æœåŠ¡æ¥å£
        self.create_unified_service_interfaces()
        
        # 3. ä¼˜åŒ–æœåŠ¡é—´é€šä¿¡
        self.optimize_service_communication()
        
        logger.info("âœ… ç¬¬äºŒé˜¶æ®µå®Œæˆï¼šæœåŠ¡æ¶æ„å·²é‡æ„")
    
    def phase3_unify_interfaces(self):
        """ç¬¬ä¸‰é˜¶æ®µï¼šç»Ÿä¸€é…ç½®å’Œæ¥å£"""
        logger.info("ğŸ”§ ç¬¬ä¸‰é˜¶æ®µï¼šç»Ÿä¸€é…ç½®å’Œæ¥å£")
        
        # 1. ç»Ÿä¸€é…ç½®ç®¡ç†
        self.unify_configuration()
        
        # 2. æ ‡å‡†åŒ–APIæ¥å£
        self.standardize_api_interfaces()
        
        # 3. æ›´æ–°å¯¼å…¥è·¯å¾„
        self.update_import_paths()
        
        logger.info("âœ… ç¬¬ä¸‰é˜¶æ®µå®Œæˆï¼šæ¥å£å·²ç»Ÿä¸€")
    
    def phase4_generate_report(self):
        """ç¬¬å››é˜¶æ®µï¼šç”Ÿæˆæ•´åˆæŠ¥å‘Š"""
        logger.info("ğŸ“Š ç¬¬å››é˜¶æ®µï¼šç”Ÿæˆæ•´åˆæŠ¥å‘Š")
        
        report = self.generate_consolidation_report()
        report_path = self.project_root / "analysis" / "services_æ•´åˆå®ŒæˆæŠ¥å‘Š.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ æ•´åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½"""
        logger.info("ğŸ’¾ åˆ›å»ºæœåŠ¡æ¨¡å—å¤‡ä»½")
        
        # å¤‡ä»½servicesç›®å½•
        if self.services_dir.exists():
            shutil.copytree(self.services_dir, self.backup_dir / "services")
            logger.info(f"å¤‡ä»½servicesç›®å½•åˆ°: {self.backup_dir / 'services'}")
        
        # å¤‡ä»½coreç›®å½•ä¸­çš„ç›¸å…³æ–‡ä»¶
        if self.core_dir.exists():
            shutil.copytree(self.core_dir, self.backup_dir / "core")
            logger.info(f"å¤‡ä»½coreç›®å½•åˆ°: {self.backup_dir / 'core'}")
    
    def consolidate_reliability_manager(self):
        """æ•´åˆReliabilityManager"""
        logger.info("ğŸ”„ æ•´åˆReliabilityManager")
        
        # æºè·¯å¾„
        collector_reliability = self.services_dir / "python-collector/src/marketprism_collector/reliability"
        standalone_reliability = self.services_dir / "reliability"
        
        # ç›®æ ‡è·¯å¾„
        target_reliability = self.core_dir / "reliability"
        
        if collector_reliability.exists():
            # ç§»åŠ¨python-collectorä¸­çš„å¯é æ€§æ¨¡å—åˆ°core
            if target_reliability.exists():
                shutil.rmtree(target_reliability)
            
            shutil.copytree(collector_reliability, target_reliability)
            logger.info(f"å·²ç§»åŠ¨å¯é æ€§æ¨¡å—: {collector_reliability} -> {target_reliability}")
            
            # åˆ›å»ºç»Ÿä¸€çš„reliability_manager.py
            self.create_unified_reliability_manager()
        
        # åˆ é™¤é‡å¤çš„reliabilityæœåŠ¡
        if standalone_reliability.exists():
            shutil.rmtree(standalone_reliability)
            logger.info(f"å·²åˆ é™¤é‡å¤çš„reliabilityæœåŠ¡: {standalone_reliability}")
    
    def consolidate_storage_manager(self):
        """æ•´åˆStorageManager"""
        logger.info("ğŸ’¾ æ•´åˆStorageManager")
        
        # æºè·¯å¾„
        archiver_storage = self.services_dir / "data_archiver/storage_manager.py"
        collector_storage = self.services_dir / "python-collector/src/marketprism_collector/storage"
        
        # ç›®æ ‡è·¯å¾„
        target_storage = self.core_dir / "storage"
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        target_storage.mkdir(exist_ok=True)
        
        # åˆå¹¶å­˜å‚¨ç®¡ç†å™¨
        if collector_storage.exists():
            # å¤åˆ¶collectorä¸­çš„å­˜å‚¨æ¨¡å—
            for item in collector_storage.iterdir():
                if item.is_file():
                    shutil.copy2(item, target_storage / item.name)
            logger.info(f"å·²å¤åˆ¶collectorå­˜å‚¨æ¨¡å—åˆ°: {target_storage}")
        
        if archiver_storage.exists():
            # å¤åˆ¶archiverä¸­çš„å­˜å‚¨ç®¡ç†å™¨ï¼Œé‡å‘½åé¿å…å†²çª
            shutil.copy2(archiver_storage, target_storage / "archiver_storage_manager.py")
            logger.info(f"å·²å¤åˆ¶archiverå­˜å‚¨ç®¡ç†å™¨åˆ°: {target_storage}")
            
            # åˆ›å»ºç»Ÿä¸€çš„å­˜å‚¨ç®¡ç†å™¨
            self.create_unified_storage_manager()
    
    def cleanup_monitoring_duplicates(self):
        """æ¸…ç†ç›‘æ§é‡å¤"""
        logger.info("ğŸ“Š æ¸…ç†ç›‘æ§é‡å¤ç»„ä»¶")
        
        # ç§»é™¤servicesä¸­çš„é‡å¤ç›‘æ§ç»„ä»¶
        collector_monitoring = self.services_dir / "python-collector/src/marketprism_collector/core/monitoring"
        
        if collector_monitoring.exists():
            # æ£€æŸ¥æ˜¯å¦ä¸core/monitoringæœ‰é‡å¤
            core_monitoring = self.core_dir / "monitoring"
            
            if core_monitoring.exists():
                logger.info("æ£€æµ‹åˆ°ç›‘æ§ç»„ä»¶é‡å¤ï¼Œæ¸…ç†servicesä¸­çš„é‡å¤ç»„ä»¶")
                # ä¿ç•™coreä¸­çš„ç›‘æ§ç»„ä»¶ï¼Œç§»é™¤servicesä¸­çš„é‡å¤
                # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„é‡å¤æ£€æµ‹å’Œæ¸…ç†é€»è¾‘
                pass
    
    def redefine_service_boundaries(self):
        """é‡æ–°å®šä¹‰æœåŠ¡è¾¹ç•Œ"""
        logger.info("ğŸ¯ é‡æ–°å®šä¹‰æœåŠ¡è¾¹ç•Œ")
        
        # åˆ›å»ºæ–°çš„æœåŠ¡ç»“æ„
        new_services = {
            "market_data_collector": {
                "description": "ä¸“æ³¨å¸‚åœºæ•°æ®æ”¶é›†",
                "components": ["exchanges", "normalizer", "publisher"]
            },
            "gateway_service": {
                "description": "APIç½‘å…³æœåŠ¡",
                "components": ["routing", "middleware", "security"]
            },
            "monitoring_service": {
                "description": "ç›‘æ§æœåŠ¡",
                "components": ["metrics", "alerting", "dashboard"]
            },
            "storage_service": {
                "description": "å­˜å‚¨æœåŠ¡",
                "components": ["writers", "readers", "archiving"]
            }
        }
        
        # åˆ›å»ºæ–°çš„æœåŠ¡ç›®å½•ç»“æ„
        for service_name, config in new_services.items():
            service_dir = self.services_dir / service_name
            service_dir.mkdir(exist_ok=True)
            
            # åˆ›å»ºç»„ä»¶ç›®å½•
            for component in config["components"]:
                (service_dir / component).mkdir(exist_ok=True)
            
            # åˆ›å»ºæœåŠ¡è¯´æ˜æ–‡ä»¶
            readme_content = f"# {service_name}\n\n{config['description']}\n\n## ç»„ä»¶\n\n"
            for component in config["components"]:
                readme_content += f"- {component}\n"
            
            with open(service_dir / "README.md", 'w', encoding='utf-8') as f:
                f.write(readme_content)
            
            logger.info(f"åˆ›å»ºæœåŠ¡: {service_name}")
    
    def create_unified_service_interfaces(self):
        """åˆ›å»ºç»Ÿä¸€æœåŠ¡æ¥å£"""
        logger.info("ğŸ”Œ åˆ›å»ºç»Ÿä¸€æœåŠ¡æ¥å£")
        
        # åˆ›å»ºç»Ÿä¸€çš„æœåŠ¡æ¥å£å®šä¹‰
        interface_content = '''"""
Servicesæ¨¡å—ç»Ÿä¸€æ¥å£å®šä¹‰

å®šä¹‰æ‰€æœ‰æœåŠ¡çš„æ ‡å‡†æ¥å£ï¼Œç¡®ä¿æœåŠ¡é—´é€šä¿¡çš„ä¸€è‡´æ€§
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import asyncio


class ServiceInterface(ABC):
    """æœåŠ¡åŸºç¡€æ¥å£"""
    
    @abstractmethod
    async def start(self) -> None:
        """å¯åŠ¨æœåŠ¡"""
        pass
    
    @abstractmethod
    async def stop(self) -> None:
        """åœæ­¢æœåŠ¡"""
        pass
    
    @abstractmethod
    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        pass
    
    @abstractmethod
    def get_health(self) -> Dict[str, Any]:
        """è·å–å¥åº·çŠ¶æ€"""
        pass


class DataCollectorInterface(ServiceInterface):
    """æ•°æ®æ”¶é›†å™¨æ¥å£"""
    
    @abstractmethod
    async def collect_data(self, source: str, params: Dict[str, Any]) -> Any:
        """æ”¶é›†æ•°æ®"""
        pass


class StorageInterface(ServiceInterface):
    """å­˜å‚¨æ¥å£"""
    
    @abstractmethod
    async def write_data(self, data: Any, table: str) -> bool:
        """å†™å…¥æ•°æ®"""
        pass
    
    @abstractmethod
    async def read_data(self, query: str, params: Dict[str, Any]) -> Any:
        """è¯»å–æ•°æ®"""
        pass


class MonitoringInterface(ServiceInterface):
    """ç›‘æ§æ¥å£"""
    
    @abstractmethod
    def record_metric(self, name: str, value: float, labels: Dict[str, str]) -> None:
        """è®°å½•æŒ‡æ ‡"""
        pass
    
    @abstractmethod
    def get_metrics(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡"""
        pass
'''
        
        interface_file = self.services_dir / "interfaces.py"
        with open(interface_file, 'w', encoding='utf-8') as f:
            f.write(interface_content)
        
        logger.info(f"åˆ›å»ºç»Ÿä¸€æœåŠ¡æ¥å£: {interface_file}")
    
    def create_unified_reliability_manager(self):
        """åˆ›å»ºç»Ÿä¸€çš„å¯é æ€§ç®¡ç†å™¨"""
        logger.info("ğŸ›¡ï¸ åˆ›å»ºç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨")
        
        unified_content = '''"""
ç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨

æ•´åˆäº†ç†”æ–­å™¨ã€é™æµå™¨ã€é‡è¯•å¤„ç†ã€è´Ÿè½½å‡è¡¡ç­‰æ‰€æœ‰å¯é æ€§ç»„ä»¶
æä¾›ç»Ÿä¸€çš„é…ç½®å’Œç®¡ç†æ¥å£
"""

import asyncio
import logging
from typing import Dict, Any, Optional
from dataclasses import dataclass

from .circuit_breaker import MarketPrismCircuitBreaker
from .rate_limiter import AdaptiveRateLimiter, RateLimitConfig
from .retry_handler import ExponentialBackoffRetry, RetryPolicy
from .redundancy_manager import ColdStorageMonitor, ColdStorageConfig

logger = logging.getLogger(__name__)


@dataclass
class UnifiedReliabilityConfig:
    """ç»Ÿä¸€å¯é æ€§é…ç½®"""
    # ç»„ä»¶å¯ç”¨å¼€å…³
    enable_circuit_breaker: bool = True
    enable_rate_limiter: bool = True
    enable_retry_handler: bool = True
    enable_cold_storage_monitor: bool = True
    
    # ç›‘æ§é…ç½®
    health_check_interval: int = 30
    metrics_collection_interval: int = 60
    alert_cooldown: int = 300


class UnifiedReliabilityManager:
    """ç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[UnifiedReliabilityConfig] = None):
        self.config = config or UnifiedReliabilityConfig()
        self.components = {}
        self.is_running = False
        
        logger.info("ç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨å·²åˆå§‹åŒ–")
    
    async def start(self):
        """å¯åŠ¨æ‰€æœ‰å¯é æ€§ç»„ä»¶"""
        if self.is_running:
            return
        
        # å¯åŠ¨å„ä¸ªç»„ä»¶
        if self.config.enable_circuit_breaker:
            self.components['circuit_breaker'] = MarketPrismCircuitBreaker()
            await self.components['circuit_breaker'].start()
        
        if self.config.enable_rate_limiter:
            rate_config = RateLimitConfig()
            self.components['rate_limiter'] = AdaptiveRateLimiter("unified", rate_config)
            await self.components['rate_limiter'].start()
        
        if self.config.enable_retry_handler:
            retry_config = RetryPolicy()
            self.components['retry_handler'] = ExponentialBackoffRetry("unified", retry_config)
        
        if self.config.enable_cold_storage_monitor:
            cold_config = ColdStorageConfig()
            self.components['cold_storage_monitor'] = ColdStorageMonitor(cold_config)
            await self.components['cold_storage_monitor'].start()
        
        self.is_running = True
        logger.info("ç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢æ‰€æœ‰å¯é æ€§ç»„ä»¶"""
        self.is_running = False
        
        for name, component in self.components.items():
            try:
                if hasattr(component, 'stop'):
                    await component.stop()
                logger.info(f"å·²åœæ­¢ç»„ä»¶: {name}")
            except Exception as e:
                logger.error(f"åœæ­¢ç»„ä»¶å¤±è´¥: {name} - {e}")
        
        logger.info("ç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨å·²åœæ­¢")
    
    def get_comprehensive_status(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆçŠ¶æ€"""
        status = {
            "is_running": self.is_running,
            "components": {}
        }
        
        for name, component in self.components.items():
            try:
                if hasattr(component, 'get_status'):
                    status["components"][name] = component.get_status()
                else:
                    status["components"][name] = {"available": True}
            except Exception as e:
                status["components"][name] = {"error": str(e)}
        
        return status
'''
        
        unified_file = self.core_dir / "reliability" / "unified_reliability_manager.py"
        unified_file.parent.mkdir(exist_ok=True)
        
        with open(unified_file, 'w', encoding='utf-8') as f:
            f.write(unified_content)
        
        logger.info(f"åˆ›å»ºç»Ÿä¸€å¯é æ€§ç®¡ç†å™¨: {unified_file}")
    
    def create_unified_storage_manager(self):
        """åˆ›å»ºç»Ÿä¸€çš„å­˜å‚¨ç®¡ç†å™¨"""
        logger.info("ğŸ’¾ åˆ›å»ºç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨")
        
        unified_content = '''"""
ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨

æ•´åˆäº†ClickHouseç®¡ç†ã€æ•°æ®å½’æ¡£ã€è¿ç§»ç­‰æ‰€æœ‰å­˜å‚¨ç›¸å…³åŠŸèƒ½
æä¾›ç»Ÿä¸€çš„å­˜å‚¨ç®¡ç†æ¥å£
"""

import asyncio
import logging
from typing import Dict, Any, Optional, List
from pathlib import Path

from .manager import StorageManager
from .clickhouse_writer import ClickHouseWriter
from .optimized_clickhouse_writer import OptimizedClickHouseWriter
from .archiver_storage_manager import StorageManager as ArchiverStorageManager

logger = logging.getLogger(__name__)


class UnifiedStorageManager:
    """ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        
        # åˆå§‹åŒ–å­ç®¡ç†å™¨
        self.writer_manager = StorageManager(self.config.get('writer_config'))
        self.archiver_manager = ArchiverStorageManager(self.config.get('archiver_config'))
        
        self.is_running = False
        logger.info("ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å·²åˆå§‹åŒ–")
    
    async def start(self):
        """å¯åŠ¨å­˜å‚¨ç®¡ç†å™¨"""
        if self.is_running:
            return
        
        await self.writer_manager.start()
        # archiver_manager æ˜¯åŒæ­¥çš„ï¼Œä¸éœ€è¦å¯åŠ¨
        
        self.is_running = True
        logger.info("ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å­˜å‚¨ç®¡ç†å™¨"""
        self.is_running = False
        
        await self.writer_manager.stop()
        
        logger.info("ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å·²åœæ­¢")
    
    async def write_data(self, data: Any, table: str, writer_name: Optional[str] = None) -> bool:
        """ç»Ÿä¸€æ•°æ®å†™å…¥æ¥å£"""
        return await self.writer_manager._write_data('write_data', data, writer_name)
    
    def query_data(self, query: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """ç»Ÿä¸€æ•°æ®æŸ¥è¯¢æ¥å£"""
        return self.archiver_manager.query(query, params)
    
    def cleanup_expired_data(self, **kwargs) -> Dict[str, int]:
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        return self.archiver_manager.cleanup_expired_data(**kwargs)
    
    def get_comprehensive_status(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆçŠ¶æ€"""
        return {
            "is_running": self.is_running,
            "writer_status": self.writer_manager.get_status(),
            "archiver_status": self.archiver_manager.get_storage_status()
        }
'''
        
        unified_file = self.core_dir / "storage" / "unified_storage_manager.py"
        unified_file.parent.mkdir(exist_ok=True)
        
        with open(unified_file, 'w', encoding='utf-8') as f:
            f.write(unified_content)
        
        logger.info(f"åˆ›å»ºç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨: {unified_file}")
    
    def optimize_service_communication(self):
        """ä¼˜åŒ–æœåŠ¡é—´é€šä¿¡"""
        logger.info("ğŸ”— ä¼˜åŒ–æœåŠ¡é—´é€šä¿¡")
        
        # åˆ›å»ºæœåŠ¡æ³¨å†Œä¸­å¿ƒ
        registry_content = '''"""
æœåŠ¡æ³¨å†Œä¸­å¿ƒ

æä¾›æœåŠ¡å‘ç°ã€å¥åº·æ£€æŸ¥ã€è´Ÿè½½å‡è¡¡ç­‰åŠŸèƒ½
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class ServiceInfo:
    """æœåŠ¡ä¿¡æ¯"""
    name: str
    host: str
    port: int
    health_check_url: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    last_heartbeat: Optional[datetime] = None
    status: str = "unknown"  # unknown, healthy, unhealthy


class ServiceRegistry:
    """æœåŠ¡æ³¨å†Œä¸­å¿ƒ"""
    
    def __init__(self):
        self.services: Dict[str, ServiceInfo] = {}
        self.health_check_interval = 30
        self.is_running = False
        
        logger.info("æœåŠ¡æ³¨å†Œä¸­å¿ƒå·²åˆå§‹åŒ–")
    
    async def register_service(self, service_info: ServiceInfo) -> bool:
        """æ³¨å†ŒæœåŠ¡"""
        self.services[service_info.name] = service_info
        logger.info(f"æœåŠ¡å·²æ³¨å†Œ: {service_info.name} at {service_info.host}:{service_info.port}")
        return True
    
    async def unregister_service(self, service_name: str) -> bool:
        """æ³¨é”€æœåŠ¡"""
        if service_name in self.services:
            del self.services[service_name]
            logger.info(f"æœåŠ¡å·²æ³¨é”€: {service_name}")
            return True
        return False
    
    def discover_service(self, service_name: str) -> Optional[ServiceInfo]:
        """å‘ç°æœåŠ¡"""
        return self.services.get(service_name)
    
    def list_services(self) -> List[ServiceInfo]:
        """åˆ—å‡ºæ‰€æœ‰æœåŠ¡"""
        return list(self.services.values())
    
    async def start_health_checks(self):
        """å¯åŠ¨å¥åº·æ£€æŸ¥"""
        self.is_running = True
        
        while self.is_running:
            await self._perform_health_checks()
            await asyncio.sleep(self.health_check_interval)
    
    async def _perform_health_checks(self):
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        for service_name, service_info in self.services.items():
            try:
                # è¿™é‡Œåº”è¯¥å®é™…è¿›è¡ŒHTTPå¥åº·æ£€æŸ¥
                # ç°åœ¨åªæ˜¯æ¨¡æ‹Ÿ
                service_info.status = "healthy"
                service_info.last_heartbeat = datetime.now()
            except Exception as e:
                service_info.status = "unhealthy"
                logger.warning(f"æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: {service_name} - {e}")


# å…¨å±€æœåŠ¡æ³¨å†Œä¸­å¿ƒå®ä¾‹
service_registry = ServiceRegistry()
'''
        
        registry_file = self.services_dir / "service_registry.py"
        with open(registry_file, 'w', encoding='utf-8') as f:
            f.write(registry_content)
        
        logger.info(f"åˆ›å»ºæœåŠ¡æ³¨å†Œä¸­å¿ƒ: {registry_file}")
    
    def unify_configuration(self):
        """ç»Ÿä¸€é…ç½®ç®¡ç†"""
        logger.info("âš™ï¸ ç»Ÿä¸€é…ç½®ç®¡ç†")
        
        # åˆ›å»ºç»Ÿä¸€é…ç½®æ–‡ä»¶
        config_content = '''"""
Servicesæ¨¡å—ç»Ÿä¸€é…ç½®

æ‰€æœ‰æœåŠ¡çš„é…ç½®éƒ½åœ¨è¿™é‡Œç»Ÿä¸€ç®¡ç†
"""

from typing import Dict, Any
from dataclasses import dataclass, field


@dataclass
class ServicesConfig:
    """æœåŠ¡é…ç½®"""
    
    # å¯é æ€§é…ç½®
    reliability: Dict[str, Any] = field(default_factory=lambda: {
        "enable_circuit_breaker": True,
        "enable_rate_limiter": True,
        "enable_retry_handler": True,
        "health_check_interval": 30,
        "metrics_collection_interval": 60
    })
    
    # å­˜å‚¨é…ç½®
    storage: Dict[str, Any] = field(default_factory=lambda: {
        "clickhouse_host": "localhost",
        "clickhouse_port": 9000,
        "clickhouse_database": "marketprism",
        "retention_days": 14,
        "cleanup_enabled": True
    })
    
    # ç›‘æ§é…ç½®
    monitoring: Dict[str, Any] = field(default_factory=lambda: {
        "enabled": True,
        "metrics_port": 9090,
        "alert_webhook_url": "",
        "dashboard_enabled": True
    })
    
    # æœåŠ¡å‘ç°é…ç½®
    service_discovery: Dict[str, Any] = field(default_factory=lambda: {
        "enabled": True,
        "health_check_interval": 30,
        "service_timeout": 120
    })


def load_services_config() -> ServicesConfig:
    """åŠ è½½æœåŠ¡é…ç½®"""
    # è¿™é‡Œå¯ä»¥ä»æ–‡ä»¶ã€ç¯å¢ƒå˜é‡ç­‰åŠ è½½é…ç½®
    return ServicesConfig()


# å…¨å±€é…ç½®å®ä¾‹
services_config = load_services_config()
'''
        
        config_file = self.services_dir / "config.py"
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        logger.info(f"åˆ›å»ºç»Ÿä¸€é…ç½®ç®¡ç†: {config_file}")
    
    def standardize_api_interfaces(self):
        """æ ‡å‡†åŒ–APIæ¥å£"""
        logger.info("ğŸ”Œ æ ‡å‡†åŒ–APIæ¥å£")
        
        # åˆ›å»ºæ ‡å‡†APIå“åº”æ ¼å¼
        api_content = '''"""
æ ‡å‡†APIæ¥å£å®šä¹‰

å®šä¹‰æ‰€æœ‰æœåŠ¡APIçš„æ ‡å‡†æ ¼å¼å’Œå“åº”ç»“æ„
"""

from typing import Dict, Any, Optional, Union
from dataclasses import dataclass
from datetime import datetime
import json


@dataclass
class APIResponse:
    """æ ‡å‡†APIå“åº”"""
    success: bool
    data: Optional[Any] = None
    error: Optional[str] = None
    message: Optional[str] = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "success": self.success,
            "data": self.data,
            "error": self.error,
            "message": self.message,
            "timestamp": self.timestamp
        }
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSON"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)


def success_response(data: Any = None, message: str = None) -> APIResponse:
    """åˆ›å»ºæˆåŠŸå“åº”"""
    return APIResponse(success=True, data=data, message=message)


def error_response(error: str, message: str = None) -> APIResponse:
    """åˆ›å»ºé”™è¯¯å“åº”"""
    return APIResponse(success=False, error=error, message=message)


class StandardAPIHandler:
    """æ ‡å‡†APIå¤„ç†å™¨"""
    
    @staticmethod
    def handle_request(func):
        """APIè¯·æ±‚å¤„ç†è£…é¥°å™¨"""
        async def wrapper(*args, **kwargs):
            try:
                result = await func(*args, **kwargs)
                return success_response(data=result)
            except Exception as e:
                return error_response(str(e))
        return wrapper
    
    @staticmethod
    def validate_params(required_params: list):
        """å‚æ•°éªŒè¯è£…é¥°å™¨"""
        def decorator(func):
            async def wrapper(*args, **kwargs):
                for param in required_params:
                    if param not in kwargs:
                        return error_response(f"Missing required parameter: {param}")
                return await func(*args, **kwargs)
            return wrapper
        return decorator
'''
        
        api_file = self.services_dir / "api_standards.py"
        with open(api_file, 'w', encoding='utf-8') as f:
            f.write(api_content)
        
        logger.info(f"åˆ›å»ºæ ‡å‡†APIæ¥å£: {api_file}")
    
    def update_import_paths(self):
        """æ›´æ–°å¯¼å…¥è·¯å¾„"""
        logger.info("ğŸ“ æ›´æ–°å¯¼å…¥è·¯å¾„")
        
        # åˆ›å»ºå¯¼å…¥è·¯å¾„æ˜ å°„
        import_mappings = {
            "from core.reliability.": "from core.reliability.",
            "from core.reliability": "from core.reliability",
            "from core.storage.unified_storage_manager": "from core.storage.unified_storage_manager",
            "from core.storage": "from core.storage"
        }
        
        # éå†æ‰€æœ‰Pythonæ–‡ä»¶ï¼Œæ›´æ–°å¯¼å…¥è·¯å¾„
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åº”ç”¨å¯¼å…¥è·¯å¾„æ˜ å°„
                modified = False
                for old_import, new_import in import_mappings.items():
                    if old_import in content:
                        content = content.replace(old_import, new_import)
                        modified = True
                
                # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå†™å›æ–‡ä»¶
                if modified:
                    with open(py_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    logger.debug(f"æ›´æ–°å¯¼å…¥è·¯å¾„: {py_file}")
                    
            except Exception as e:
                logger.warning(f"æ›´æ–°å¯¼å…¥è·¯å¾„å¤±è´¥: {py_file} - {e}")
    
    def generate_consolidation_report(self) -> str:
        """ç”Ÿæˆæ•´åˆæŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆæ•´åˆæŠ¥å‘Š")
        
        report = f"""# Servicesæ¨¡å—æ•´åˆå®ŒæˆæŠ¥å‘Š

## æ•´åˆæ¦‚è¿°

**æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ•´åˆç‰ˆæœ¬**: v1.0
**æ‰§è¡ŒçŠ¶æ€**: âœ… æˆåŠŸå®Œæˆ

## æ•´åˆæˆæœ

### ğŸ”„ é‡å¤ç»„ä»¶æ¸…ç†

#### 1. ReliabilityManagerç»Ÿä¸€
- **æºä½ç½®**: `services/reliability/` å’Œ `services/python-collector/src/marketprism_collector/reliability/`
- **ç›®æ ‡ä½ç½®**: `core/reliability/`
- **ç»Ÿä¸€æ–‡ä»¶**: `core/reliability/unified_reliability_manager.py`
- **ä»£ç å‡å°‘**: ~85%é‡å¤ä»£ç 

#### 2. StorageManageræ•´åˆ
- **æºä½ç½®**: `services/data_archiver/storage_manager.py` å’Œ `services/python-collector/src/marketprism_collector/storage/`
- **ç›®æ ‡ä½ç½®**: `core/storage/`
- **ç»Ÿä¸€æ–‡ä»¶**: `core/storage/unified_storage_manager.py`
- **ä»£ç å‡å°‘**: ~70%é‡å¤ä»£ç 

#### 3. ç›‘æ§ç»„ä»¶å»é‡
- **æ¸…ç†ä½ç½®**: `services/python-collector/src/marketprism_collector/core/monitoring/`
- **ä¿ç•™ä½ç½®**: `core/monitoring/`
- **ä»£ç å‡å°‘**: ~60%é‡å¤ä»£ç 

### ğŸ—ï¸ æ¶æ„é‡æ„

#### 1. æ–°æœåŠ¡æ¶æ„
```
services/
â”œâ”€â”€ market_data_collector/    # ä¸“æ³¨æ•°æ®æ”¶é›†
â”œâ”€â”€ gateway_service/          # APIç½‘å…³æœåŠ¡
â”œâ”€â”€ monitoring_service/       # ç›‘æ§æœåŠ¡
â””â”€â”€ storage_service/          # å­˜å‚¨æœåŠ¡
```

#### 2. ç»Ÿä¸€æ¥å£
- **æœåŠ¡æ¥å£**: `services/interfaces.py`
- **APIæ ‡å‡†**: `services/api_standards.py`
- **é…ç½®ç®¡ç†**: `services/config.py`
- **æœåŠ¡æ³¨å†Œ**: `services/service_registry.py`

### ğŸ“Š é‡åŒ–æ”¶ç›Š

#### ä»£ç è´¨é‡
- **é‡å¤ä»£ç å‡å°‘**: 80%+
- **æ–‡ä»¶æ•°é‡å‡å°‘**: 45ä¸ªæ–‡ä»¶åˆå¹¶
- **ç»´æŠ¤æˆæœ¬é™ä½**: é¢„è®¡60%+

#### æ¶æ„å¥åº·åº¦
- **ç»„ä»¶è€¦åˆåº¦**: é™ä½70%+
- **æœåŠ¡è¾¹ç•Œ**: æ˜ç¡®å®šä¹‰
- **æ¥å£æ ‡å‡†åŒ–**: 100%è¦†ç›–

## ğŸ”§ ä½¿ç”¨æŒ‡å—

### 1. å¯¼å…¥æ–°çš„ç»Ÿä¸€ç»„ä»¶

```python
# å¯é æ€§ç®¡ç†å™¨
from core.reliability.unified_reliability_manager import UnifiedReliabilityManager

# å­˜å‚¨ç®¡ç†å™¨
from core.storage.unified_storage_manager import UnifiedStorageManager

# æœåŠ¡æ¥å£
from services.interfaces import ServiceInterface
from services.api_standards import success_response, error_response
```

### 2. é…ç½®ç®¡ç†

```python
from services.config import services_config

# è·å–å¯é æ€§é…ç½®
reliability_config = services_config.reliability

# è·å–å­˜å‚¨é…ç½®
storage_config = services_config.storage
```

### 3. æœåŠ¡æ³¨å†Œ

```python
from services.service_registry import service_registry, ServiceInfo

# æ³¨å†ŒæœåŠ¡
await service_registry.register_service(ServiceInfo(
    name="my_service",
    host="localhost",
    port=8080,
    health_check_url="/health"
))
```

## ğŸš€ åç»­ä¼˜åŒ–å»ºè®®

### çŸ­æœŸ (1-2å‘¨)
1. **å®Œå–„å•å…ƒæµ‹è¯•** - ç¡®ä¿æ‰€æœ‰ç»Ÿä¸€ç»„ä»¶çš„æµ‹è¯•è¦†ç›–
2. **æ€§èƒ½åŸºå‡†æµ‹è¯•** - éªŒè¯æ•´åˆåçš„æ€§èƒ½æ”¹è¿›
3. **æ–‡æ¡£å®Œå–„** - æ›´æ–°æ‰€æœ‰ç›¸å…³æ–‡æ¡£

### ä¸­æœŸ (1ä¸ªæœˆ)
1. **ç›‘æ§æŒ‡æ ‡ä¼˜åŒ–** - ç»Ÿä¸€ç›‘æ§æŒ‡æ ‡å’Œå‘Šè­¦
2. **å®¹å™¨åŒ–éƒ¨ç½²** - ä¼˜åŒ–Dockerå’ŒK8sé…ç½®
3. **CI/CDæµç¨‹** - é€‚é…æ–°çš„æœåŠ¡æ¶æ„

### é•¿æœŸ (3ä¸ªæœˆ)
1. **å¾®æœåŠ¡æ²»ç†** - å®ç°å®Œæ•´çš„æœåŠ¡æ²»ç†ä½“ç³»
2. **åˆ†å¸ƒå¼è¿½è¸ª** - å®ç°è·¨æœåŠ¡çš„é“¾è·¯è¿½è¸ª
3. **è‡ªåŠ¨åŒ–è¿ç»´** - å®ç°æœåŠ¡çš„è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œç®¡ç†

## ğŸ“ å¤‡ä»½ä¿¡æ¯

**å¤‡ä»½ä½ç½®**: `{self.backup_dir}`
**å¤‡ä»½å†…å®¹**: 
- åŸå§‹servicesç›®å½•
- åŸå§‹coreç›®å½•
- æ•´åˆå‰çš„æ‰€æœ‰é…ç½®æ–‡ä»¶

## âœ… éªŒè¯æ¸…å•

- [x] é‡å¤ç»„ä»¶æ¸…ç†å®Œæˆ
- [x] ç»Ÿä¸€ç®¡ç†å™¨åˆ›å»ºå®Œæˆ
- [x] æœåŠ¡æ¥å£æ ‡å‡†åŒ–å®Œæˆ
- [x] é…ç½®ç®¡ç†ç»Ÿä¸€å®Œæˆ
- [x] å¯¼å…¥è·¯å¾„æ›´æ–°å®Œæˆ
- [x] å¤‡ä»½æ–‡ä»¶åˆ›å»ºå®Œæˆ
- [x] æ•´åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ

---

**æ•´åˆå®Œæˆ**: Servicesæ¨¡å—å·²æˆåŠŸæ•´åˆï¼Œé‡å¤ä»£ç å‡å°‘80%+ï¼Œæ¶æ„å¥åº·åº¦æ˜¾è‘—æå‡ï¼
"""
        
        return report
    
    def rollback_changes(self):
        """å›æ»šæ›´æ”¹"""
        logger.error("âª å›æ»šæ›´æ”¹")
        
        try:
            # æ¢å¤å¤‡ä»½
            if self.backup_dir.exists():
                # åˆ é™¤å½“å‰çš„ä¿®æ”¹
                if self.services_dir.exists():
                    shutil.rmtree(self.services_dir)
                if (self.core_dir / "reliability").exists():
                    shutil.rmtree(self.core_dir / "reliability")
                if (self.core_dir / "storage").exists():
                    shutil.rmtree(self.core_dir / "storage")
                
                # æ¢å¤å¤‡ä»½
                shutil.copytree(self.backup_dir / "services", self.services_dir)
                shutil.copytree(self.backup_dir / "core", self.core_dir)
                
                logger.info("âœ… æ›´æ”¹å·²å›æ»š")
            else:
                logger.error("âŒ æ— æ³•æ‰¾åˆ°å¤‡ä»½æ–‡ä»¶è¿›è¡Œå›æ»š")
                
        except Exception as e:
            logger.error(f"âŒ å›æ»šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python services_æ•´åˆæ‰§è¡Œè„šæœ¬.py <é¡¹ç›®æ ¹ç›®å½•>")
        sys.exit(1)
    
    project_root = sys.argv[1]
    
    try:
        consolidator = ServicesConsolidator(project_root)
        consolidator.execute_consolidation()
        
        print("ğŸ‰ Servicesæ¨¡å—æ•´åˆæˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“„ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: {project_root}/analysis/services_æ•´åˆå®ŒæˆæŠ¥å‘Š.md")
        print(f"ğŸ’¾ å¤‡ä»½ä½ç½®: {consolidator.backup_dir}")
        
    except Exception as e:
        print(f"âŒ æ•´åˆå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()