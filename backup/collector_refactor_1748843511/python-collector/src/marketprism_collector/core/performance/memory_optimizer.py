"""
ğŸ’¾ MemoryOptimizer - å†…å­˜ä¼˜åŒ–å™¨

å†…å­˜ç›‘æ§å’Œåƒåœ¾å›æ”¶ä¼˜åŒ–
æä¾›å†…å­˜æ³„æ¼æ£€æµ‹ã€GCä¼˜åŒ–ã€å¯¹è±¡æ± ç®¡ç†ã€å†…å­˜åˆ†æç­‰åŠŸèƒ½
"""

import asyncio
import gc
import time
import sys
import weakref
import psutil
import threading
from typing import Dict, Any, Optional, List, Callable, Set, Type, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
from collections import defaultdict, deque
import tracemalloc

logger = logging.getLogger(__name__)


class MemoryStrategy(Enum):
    """å†…å­˜ç­–ç•¥æšä¸¾"""
    AGGRESSIVE = "aggressive"      # æ¿€è¿›å›æ”¶
    BALANCED = "balanced"          # å¹³è¡¡æ¨¡å¼
    CONSERVATIVE = "conservative"  # ä¿å®ˆæ¨¡å¼
    ADAPTIVE = "adaptive"          # è‡ªé€‚åº”


class ObjectPoolType(Enum):
    """å¯¹è±¡æ± ç±»å‹æšä¸¾"""
    FIXED_SIZE = "fixed_size"      # å›ºå®šå¤§å°
    DYNAMIC = "dynamic"            # åŠ¨æ€å¤§å°
    LAZY = "lazy"                  # æ‡’åŠ è½½
    THREAD_LOCAL = "thread_local"  # çº¿ç¨‹æœ¬åœ°


@dataclass
class MemoryConfig:
    """å†…å­˜é…ç½®"""
    strategy: MemoryStrategy = MemoryStrategy.ADAPTIVE
    gc_threshold_0: int = 700      # GCé˜ˆå€¼0
    gc_threshold_1: int = 10       # GCé˜ˆå€¼1
    gc_threshold_2: int = 10       # GCé˜ˆå€¼2
    max_memory_usage: float = 0.8  # æœ€å¤§å†…å­˜ä½¿ç”¨æ¯”ä¾‹
    memory_check_interval: float = 30.0  # å†…å­˜æ£€æŸ¥é—´éš”
    leak_detection_enabled: bool = True
    object_tracking_enabled: bool = True
    enable_tracemalloc: bool = True
    profiling_interval: float = 300.0  # 5åˆ†é’Ÿ


@dataclass
class MemoryStats:
    """å†…å­˜ç»Ÿè®¡"""
    total_memory: int = 0
    available_memory: int = 0
    used_memory: int = 0
    process_memory: int = 0
    gc_collections: Dict[int, int] = field(default_factory=lambda: {0: 0, 1: 0, 2: 0})
    object_counts: Dict[str, int] = field(default_factory=dict)
    memory_usage_history: deque = field(default_factory=lambda: deque(maxlen=100))
    
    @property
    def memory_usage_percent(self) -> float:
        """å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”"""
        if self.total_memory == 0:
            return 0.0
        return (self.used_memory / self.total_memory) * 100
    
    @property
    def process_memory_mb(self) -> float:
        """è¿›ç¨‹å†…å­˜ä½¿ç”¨(MB)"""
        return self.process_memory / (1024 * 1024)


class ObjectPool:
    """å¯¹è±¡æ± """
    
    def __init__(self, factory: Callable, pool_type: ObjectPoolType = ObjectPoolType.DYNAMIC,
                 initial_size: int = 10, max_size: int = 100):
        self.factory = factory
        self.pool_type = pool_type
        self.initial_size = initial_size
        self.max_size = max_size
        self.pool: deque = deque()
        self.created_count = 0
        self.acquired_count = 0
        self.returned_count = 0
        self.lock = threading.RLock()
        
        # é¢„åˆ›å»ºå¯¹è±¡
        if pool_type in [ObjectPoolType.FIXED_SIZE, ObjectPoolType.DYNAMIC]:
            for _ in range(initial_size):
                try:
                    obj = self.factory()
                    self.pool.append(obj)
                    self.created_count += 1
                except Exception as e:
                    logger.error(f"å¯¹è±¡æ± é¢„åˆ›å»ºå¤±è´¥: {e}")
    
    def acquire(self) -> Any:
        """è·å–å¯¹è±¡"""
        with self.lock:
            if self.pool:
                obj = self.pool.popleft()
                self.acquired_count += 1
                return obj
            
            # å¦‚æœæ± ä¸ºç©ºä¸”æœªè¾¾åˆ°æœ€å¤§å¤§å°ï¼Œåˆ›å»ºæ–°å¯¹è±¡
            if self.created_count < self.max_size:
                try:
                    obj = self.factory()
                    self.created_count += 1
                    self.acquired_count += 1
                    return obj
                except Exception as e:
                    logger.error(f"å¯¹è±¡æ± åˆ›å»ºå¯¹è±¡å¤±è´¥: {e}")
                    raise
            
            # å¦‚æœè¾¾åˆ°æœ€å¤§å¤§å°ï¼Œåˆ›å»ºä¸´æ—¶å¯¹è±¡
            return self.factory()
    
    def release(self, obj: Any):
        """é‡Šæ”¾å¯¹è±¡"""
        with self.lock:
            if len(self.pool) < self.max_size:
                # é‡ç½®å¯¹è±¡çŠ¶æ€
                if hasattr(obj, 'reset'):
                    try:
                        obj.reset()
                    except Exception as e:
                        logger.warning(f"å¯¹è±¡é‡ç½®å¤±è´¥: {e}")
                        return
                
                self.pool.append(obj)
                self.returned_count += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return {
                "pool_size": len(self.pool),
                "created_count": self.created_count,
                "acquired_count": self.acquired_count,
                "returned_count": self.returned_count,
                "hit_rate": self.returned_count / max(self.acquired_count, 1)
            }


class MemoryTracker:
    """å†…å­˜è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.tracked_objects: Dict[int, weakref.ref] = {}
        self.object_counts: Dict[str, int] = defaultdict(int)
        self.creation_times: Dict[int, float] = {}
        self.lock = threading.RLock()
    
    def track_object(self, obj: Any):
        """è·Ÿè¸ªå¯¹è±¡"""
        with self.lock:
            obj_id = id(obj)
            obj_type = type(obj).__name__
            
            # åˆ›å»ºå¼±å¼•ç”¨
            def cleanup_callback(ref):
                with self.lock:
                    if obj_id in self.tracked_objects:
                        del self.tracked_objects[obj_id]
                    if obj_id in self.creation_times:
                        del self.creation_times[obj_id]
                    self.object_counts[obj_type] -= 1
            
            weak_ref = weakref.ref(obj, cleanup_callback)
            self.tracked_objects[obj_id] = weak_ref
            self.object_counts[obj_type] += 1
            self.creation_times[obj_id] = time.time()
    
    def get_object_counts(self) -> Dict[str, int]:
        """è·å–å¯¹è±¡è®¡æ•°"""
        with self.lock:
            return dict(self.object_counts)
    
    def get_long_lived_objects(self, min_age: float = 300.0) -> List[Dict[str, Any]]:
        """è·å–é•¿æœŸå­˜æ´»å¯¹è±¡"""
        current_time = time.time()
        long_lived = []
        
        with self.lock:
            for obj_id, creation_time in self.creation_times.items():
                if current_time - creation_time > min_age:
                    if obj_id in self.tracked_objects:
                        weak_ref = self.tracked_objects[obj_id]
                        obj = weak_ref()
                        if obj is not None:
                            long_lived.append({
                                "id": obj_id,
                                "type": type(obj).__name__,
                                "age": current_time - creation_time,
                                "size": sys.getsizeof(obj)
                            })
        
        return sorted(long_lived, key=lambda x: x["age"], reverse=True)


class MemoryOptimizer:
    """
    ğŸ’¾ å†…å­˜ä¼˜åŒ–å™¨
    
    æä¾›å†…å­˜ç›‘æ§ã€åƒåœ¾å›æ”¶ä¼˜åŒ–ã€å¯¹è±¡æ± ç®¡ç†ã€å†…å­˜æ³„æ¼æ£€æµ‹ç­‰åŠŸèƒ½
    """
    
    def __init__(self, config: Optional[MemoryConfig] = None):
        self.config = config or MemoryConfig()
        self.stats = MemoryStats()
        self.object_pools: Dict[str, ObjectPool] = {}
        self.memory_tracker = MemoryTracker()
        self.monitoring_task: Optional[asyncio.Task] = None
        self.profiling_task: Optional[asyncio.Task] = None
        self.is_running = False
        self.process = psutil.Process()
        
        # é…ç½®åƒåœ¾å›æ”¶
        self._configure_gc()
        
        # å¯ç”¨å†…å­˜è·Ÿè¸ª
        if self.config.enable_tracemalloc:
            if not tracemalloc.is_tracing():
                tracemalloc.start()
        
        logger.info(f"MemoryOptimizeråˆå§‹åŒ–: strategy={self.config.strategy.value}")
    
    async def start(self):
        """å¯åŠ¨å†…å­˜ä¼˜åŒ–å™¨"""
        if self.is_running:
            return
        
        self.is_running = True
        
        # å¯åŠ¨ç›‘æ§ä»»åŠ¡
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        
        # å¯åŠ¨æ€§èƒ½åˆ†æ
        self.profiling_task = asyncio.create_task(self._profiling_loop())
        
        logger.info("MemoryOptimizerå·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å†…å­˜ä¼˜åŒ–å™¨"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # å–æ¶ˆä»»åŠ¡
        if self.monitoring_task:
            self.monitoring_task.cancel()
        if self.profiling_task:
            self.profiling_task.cancel()
        
        # åœæ­¢å†…å­˜è·Ÿè¸ª
        if tracemalloc.is_tracing():
            tracemalloc.stop()
        
        logger.info("MemoryOptimizerå·²åœæ­¢")
    
    def create_object_pool(self, name: str, factory: Callable, 
                          pool_type: ObjectPoolType = ObjectPoolType.DYNAMIC,
                          initial_size: int = 10, max_size: int = 100) -> ObjectPool:
        """åˆ›å»ºå¯¹è±¡æ± """
        if name in self.object_pools:
            raise ValueError(f"å¯¹è±¡æ± å·²å­˜åœ¨: {name}")
        
        pool = ObjectPool(factory, pool_type, initial_size, max_size)
        self.object_pools[name] = pool
        
        logger.info(f"åˆ›å»ºå¯¹è±¡æ± : {name}, type={pool_type.value}")
        return pool
    
    def get_object_pool(self, name: str) -> Optional[ObjectPool]:
        """è·å–å¯¹è±¡æ± """
        return self.object_pools.get(name)
    
    def remove_object_pool(self, name: str):
        """ç§»é™¤å¯¹è±¡æ± """
        if name in self.object_pools:
            del self.object_pools[name]
            logger.info(f"ç§»é™¤å¯¹è±¡æ± : {name}")
    
    def track_object(self, obj: Any):
        """è·Ÿè¸ªå¯¹è±¡"""
        if self.config.object_tracking_enabled:
            self.memory_tracker.track_object(obj)
    
    def force_gc(self, generation: Optional[int] = None) -> Dict[str, int]:
        """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        if generation is not None:
            collected = gc.collect(generation)
            self.stats.gc_collections[generation] += 1
            return {f"generation_{generation}": collected}
        else:
            collected = {
                "generation_0": gc.collect(0),
                "generation_1": gc.collect(1),
                "generation_2": gc.collect(2)
            }
            for gen in [0, 1, 2]:
                self.stats.gc_collections[gen] += 1
            return collected
    
    def optimize_memory(self) -> Dict[str, Any]:
        """ä¼˜åŒ–å†…å­˜"""
        optimization_result = {
            "gc_collected": {},
            "memory_before": self._get_memory_usage(),
            "memory_after": 0,
            "optimization_actions": []
        }
        
        # æ ¹æ®ç­–ç•¥æ‰§è¡Œä¼˜åŒ–
        if self.config.strategy == MemoryStrategy.AGGRESSIVE:
            optimization_result["gc_collected"] = self.force_gc()
            optimization_result["optimization_actions"].append("å¼ºåˆ¶åƒåœ¾å›æ”¶")
        
        elif self.config.strategy == MemoryStrategy.BALANCED:
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
            if self.stats.memory_usage_percent > 70:
                optimization_result["gc_collected"] = self.force_gc()
                optimization_result["optimization_actions"].append("æ¡ä»¶åƒåœ¾å›æ”¶")
        
        elif self.config.strategy == MemoryStrategy.ADAPTIVE:
            # è‡ªé€‚åº”ç­–ç•¥
            if self.stats.memory_usage_percent > 80:
                optimization_result["gc_collected"] = self.force_gc()
                optimization_result["optimization_actions"].append("é«˜å†…å­˜ä½¿ç”¨åƒåœ¾å›æ”¶")
            elif len(gc.garbage) > 100:
                optimization_result["gc_collected"] = self.force_gc(2)
                optimization_result["optimization_actions"].append("æ¸…ç†å¾ªç¯å¼•ç”¨")
        
        # æ¸…ç†æ— æ•ˆçš„å¼±å¼•ç”¨
        self._cleanup_weak_references()
        optimization_result["optimization_actions"].append("æ¸…ç†å¼±å¼•ç”¨")
        
        optimization_result["memory_after"] = self._get_memory_usage()
        optimization_result["memory_saved"] = (
            optimization_result["memory_before"] - optimization_result["memory_after"]
        )
        
        return optimization_result
    
    def detect_memory_leaks(self) -> Dict[str, Any]:
        """æ£€æµ‹å†…å­˜æ³„æ¼"""
        if not self.config.leak_detection_enabled:
            return {"enabled": False}
        
        leaks = {
            "long_lived_objects": self.memory_tracker.get_long_lived_objects(),
            "gc_garbage": len(gc.garbage),
            "uncollectable_objects": [],
            "suspicious_growth": []
        }
        
        # æ£€æŸ¥ä¸å¯å›æ”¶å¯¹è±¡
        if gc.garbage:
            for obj in gc.garbage[:10]:  # åªå–å‰10ä¸ªé¿å…è¾“å‡ºè¿‡å¤š
                leaks["uncollectable_objects"].append({
                    "type": type(obj).__name__,
                    "repr": repr(obj)[:100],
                    "referrers_count": len(gc.get_referrers(obj))
                })
        
        # æ£€æŸ¥å¯¹è±¡è®¡æ•°å¼‚å¸¸å¢é•¿
        object_counts = self.memory_tracker.get_object_counts()
        for obj_type, count in object_counts.items():
            if count > 1000:  # é˜ˆå€¼å¯é…ç½®
                leaks["suspicious_growth"].append({
                    "type": obj_type,
                    "count": count
                })
        
        return leaks
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç»Ÿè®¡"""
        self._update_memory_stats()
        
        return {
            "system_memory": {
                "total": self.stats.total_memory,
                "available": self.stats.available_memory,
                "used": self.stats.used_memory,
                "percent": self.stats.memory_usage_percent
            },
            "process_memory": {
                "rss": self.stats.process_memory,
                "rss_mb": self.stats.process_memory_mb
            },
            "gc_stats": {
                "collections": dict(self.stats.gc_collections),
                "garbage_count": len(gc.garbage),
                "thresholds": gc.get_threshold()
            },
            "object_counts": self.memory_tracker.get_object_counts(),
            "pool_stats": {
                name: pool.get_stats() 
                for name, pool in self.object_pools.items()
            }
        }
    
    def get_memory_analysis(self) -> Dict[str, Any]:
        """è·å–å†…å­˜åˆ†æ"""
        stats = self.get_memory_stats()
        leaks = self.detect_memory_leaks()
        
        analysis = {
            "stats": stats,
            "leaks": leaks,
            "recommendations": []
        }
        
        # ç”Ÿæˆå»ºè®®
        if stats["system_memory"]["percent"] > 80:
            analysis["recommendations"].append("ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®é‡Šæ”¾ä¸å¿…è¦çš„å¯¹è±¡")
        
        if stats["gc_stats"]["garbage_count"] > 100:
            analysis["recommendations"].append("å­˜åœ¨è¾ƒå¤šåƒåœ¾å¯¹è±¡ï¼Œå»ºè®®æ£€æŸ¥å¾ªç¯å¼•ç”¨")
        
        if leaks["long_lived_objects"]:
            analysis["recommendations"].append("å­˜åœ¨é•¿æœŸå­˜æ´»å¯¹è±¡ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼")
        
        if any(count > 1000 for count in stats["object_counts"].values()):
            analysis["recommendations"].append("æŸäº›å¯¹è±¡ç±»å‹æ•°é‡è¿‡å¤šï¼Œå»ºè®®ä½¿ç”¨å¯¹è±¡æ± ")
        
        return analysis
    
    def _configure_gc(self):
        """é…ç½®åƒåœ¾å›æ”¶"""
        gc.set_threshold(
            self.config.gc_threshold_0,
            self.config.gc_threshold_1,
            self.config.gc_threshold_2
        )
        
        # å¯ç”¨åƒåœ¾å›æ”¶è°ƒè¯•
        if logger.isEnabledFor(logging.DEBUG):
            gc.set_debug(gc.DEBUG_STATS)
    
    def _get_memory_usage(self) -> int:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨"""
        try:
            return self.process.memory_info().rss
        except:
            return 0
    
    def _update_memory_stats(self):
        """æ›´æ–°å†…å­˜ç»Ÿè®¡"""
        try:
            # ç³»ç»Ÿå†…å­˜
            memory = psutil.virtual_memory()
            self.stats.total_memory = memory.total
            self.stats.available_memory = memory.available
            self.stats.used_memory = memory.used
            
            # è¿›ç¨‹å†…å­˜
            process_memory = self.process.memory_info()
            self.stats.process_memory = process_memory.rss
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.stats.memory_usage_history.append({
                "timestamp": time.time(),
                "system_percent": memory.percent,
                "process_mb": process_memory.rss / (1024 * 1024)
            })
            
            # å¯¹è±¡è®¡æ•°
            self.stats.object_counts = self.memory_tracker.get_object_counts()
            
        except Exception as e:
            logger.error(f"æ›´æ–°å†…å­˜ç»Ÿè®¡å¤±è´¥: {e}")
    
    def _cleanup_weak_references(self):
        """æ¸…ç†æ— æ•ˆçš„å¼±å¼•ç”¨"""
        # è§¦å‘å¼±å¼•ç”¨æ¸…ç†
        gc.collect()
    
    async def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_running:
            try:
                await asyncio.sleep(self.config.memory_check_interval)
                await self._check_memory_usage()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"å†…å­˜ç›‘æ§å¤±è´¥: {e}")
    
    async def _check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨"""
        self._update_memory_stats()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
        if self.stats.memory_usage_percent > self.config.max_memory_usage * 100:
            logger.warning(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {self.stats.memory_usage_percent:.1f}%")
            optimization_result = self.optimize_memory()
            logger.info(f"å†…å­˜ä¼˜åŒ–å®Œæˆ: {optimization_result}")
        
        # æ£€æŸ¥å†…å­˜æ³„æ¼
        if self.config.leak_detection_enabled:
            leaks = self.detect_memory_leaks()
            if leaks.get("long_lived_objects") or leaks.get("gc_garbage", 0) > 100:
                logger.warning(f"æ£€æµ‹åˆ°æ½œåœ¨å†…å­˜æ³„æ¼: {leaks}")
    
    async def _profiling_loop(self):
        """æ€§èƒ½åˆ†æå¾ªç¯"""
        while self.is_running:
            try:
                await asyncio.sleep(self.config.profiling_interval)
                await self._memory_profiling()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"å†…å­˜åˆ†æå¤±è´¥: {e}")
    
    async def _memory_profiling(self):
        """å†…å­˜æ€§èƒ½åˆ†æ"""
        if not tracemalloc.is_tracing():
            return
        
        try:
            # è·å–å†…å­˜å¿«ç…§
            snapshot = tracemalloc.take_snapshot()
            top_stats = snapshot.statistics('lineno')
            
            # è®°å½•å‰10ä¸ªå†…å­˜ä½¿ç”¨æœ€å¤šçš„ä½ç½®
            logger.debug("å†…å­˜ä½¿ç”¨çƒ­ç‚¹:")
            for index, stat in enumerate(top_stats[:10], 1):
                logger.debug(f"{index}. {stat}")
        
        except Exception as e:
            logger.error(f"å†…å­˜åˆ†æå¿«ç…§å¤±è´¥: {e}")


# å·¥å…·å‡½æ•°å’Œè£…é¥°å™¨

def memory_tracked(func):
    """å†…å­˜è·Ÿè¸ªè£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        result = func(*args, **kwargs)
        # è¿™é‡Œéœ€è¦è·å–å…¨å±€çš„MemoryOptimizerå®ä¾‹
        # optimizer.track_object(result)
        return result
    return wrapper


def with_object_pool(pool_name: str):
    """å¯¹è±¡æ± è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(self, *args, **kwargs):
            # è¿™é‡Œéœ€è¦è·å–å¯¹è±¡æ± 
            pool = self.memory_optimizer.get_object_pool(pool_name)
            if pool:
                obj = pool.acquire()
                try:
                    return func(self, obj, *args, **kwargs)
                finally:
                    pool.release(obj)
            else:
                return func(self, *args, **kwargs)
        return wrapper
    return decorator


class MemoryPoolManager:
    """å†…å­˜æ± ç®¡ç†å™¨"""
    
    def __init__(self, optimizer: MemoryOptimizer):
        self.optimizer = optimizer
        self.pools = {}
    
    def get_or_create_pool(self, name: str, factory: Callable, **kwargs) -> ObjectPool:
        """è·å–æˆ–åˆ›å»ºå¯¹è±¡æ± """
        if name not in self.pools:
            pool = self.optimizer.create_object_pool(name, factory, **kwargs)
            self.pools[name] = pool
        return self.pools[name]
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        # æ¸…ç†æ‰€æœ‰æ± 
        for name in list(self.pools.keys()):
            self.optimizer.remove_object_pool(name)
        self.pools.clear()