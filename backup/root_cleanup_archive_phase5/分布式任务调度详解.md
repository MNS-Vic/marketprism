# 分布式任务调度服务 (scheduler-service) 详解

## 🎯 核心功能

分布式任务调度服务是**系统的"时钟大脑"**，负责协调和执行各种定时任务，确保系统按预定计划自动运行各种维护和处理任务。

## 📋 主要职责

### 1. 定时任务管理
```yaml
功能描述: 根据Cron表达式执行定时任务
应用场景:
  - 每日数据归档 (凌晨2:00)
  - 定期数据清理 (每周日3:00)
  - 系统健康检查 (每小时)
  - 性能报告生成 (每日8:00)
  - 数据备份任务 (每12小时)

技术实现:
  - Cron表达式解析
  - 任务队列管理
  - 执行状态跟踪
```

### 2. 分布式协调
```yaml
功能描述: 在多节点环境中协调任务执行，避免重复执行
核心问题:
  - 防止同一任务在多个节点同时执行
  - 节点故障时的任务迁移
  - 负载均衡和任务分发

技术方案:
  - 分布式锁机制
  - 领导者选举算法
  - 任务分片策略
```

### 3. 任务生命周期管理
```yaml
任务状态: 
  - PENDING: 等待执行
  - RUNNING: 正在执行  
  - SUCCESS: 执行成功
  - FAILED: 执行失败
  - RETRY: 重试中
  - CANCELLED: 已取消

生命周期:
  1. 任务注册和调度
  2. 执行前预检查
  3. 任务执行和监控
  4. 结果处理和通知
  5. 下次调度计算
```

## 🏦 在MarketPrism中的具体应用

### 1. 数据生命周期管理任务
```python
# 数据归档任务
@scheduler.cron('0 2 * * *')  # 每天凌晨2点
async def daily_data_archive():
    """将热数据迁移到冷存储"""
    return {
        "task_name": "daily_data_archive",
        "target_service": "data-storage-service",
        "action": "archive_hot_data",
        "parameters": {
            "cutoff_date": "7_days_ago",
            "batch_size": 10000
        }
    }

# 数据清理任务  
@scheduler.cron('0 3 * * 0')  # 每周日凌晨3点
async def weekly_data_cleanup():
    """清理过期的临时数据"""
    return {
        "task_name": "weekly_data_cleanup", 
        "target_service": "data-storage-service",
        "action": "cleanup_expired_data",
        "parameters": {
            "retention_days": 90,
            "data_types": ["temp_calculations", "cache_data"]
        }
    }
```

### 2. 系统维护任务
```python
# 性能监控报告
@scheduler.cron('0 8 * * *')  # 每天早上8点
async def daily_performance_report():
    """生成系统性能报告"""
    return {
        "task_name": "daily_performance_report",
        "target_service": "monitoring-service", 
        "action": "generate_performance_report",
        "parameters": {
            "time_range": "last_24_hours",
            "metrics": ["cpu", "memory", "disk", "network"],
            "recipients": ["admin@company.com"]
        }
    }

# 数据库优化
@scheduler.cron('0 1 * * 1')  # 每周一凌晨1点
async def weekly_database_optimization():
    """数据库表优化和索引重建"""
    return {
        "task_name": "database_optimization",
        "target_service": "data-storage-service",
        "action": "optimize_tables",
        "parameters": {
            "tables": ["market_data", "trade_history"],
            "operations": ["analyze", "optimize", "rebuild_index"]
        }
    }
```

### 3. 数据质量检查任务
```python
# 数据完整性检查
@scheduler.cron('*/30 * * * *')  # 每30分钟
async def data_integrity_check():
    """检查数据收集的完整性"""
    return {
        "task_name": "data_integrity_check",
        "target_service": "market-data-collector",
        "action": "check_data_gaps",
        "parameters": {
            "exchanges": ["binance", "okx", "huobi"],
            "time_window": "last_30_minutes",
            "alert_threshold": 0.95  # 95%完整性阈值
        }
    }

# 异常数据检测
@scheduler.cron('0 */6 * * *')  # 每6小时
async def anomaly_detection():
    """检测市场数据异常"""
    return {
        "task_name": "anomaly_detection",
        "target_service": "data-storage-service", 
        "action": "detect_anomalies",
        "parameters": {
            "detection_models": ["price_spike", "volume_anomaly"],
            "sensitivity": "medium",
            "notification": True
        }
    }
```

### 4. 业务报告生成
```python
# 交易量统计报告
@scheduler.cron('0 0 1 * *')  # 每月1号零点
async def monthly_volume_report():
    """生成月度交易量统计报告"""
    return {
        "task_name": "monthly_volume_report",
        "target_service": "api-gateway-service",
        "action": "generate_volume_stats",
        "parameters": {
            "period": "last_month",
            "breakdown": ["exchange", "symbol", "day"],
            "format": "pdf",
            "delivery": "email"
        }
    }
```

## 🔧 技术架构

### 1. 任务调度引擎
```python
class DistributedScheduler:
    def __init__(self):
        self.task_registry = TaskRegistry()
        self.executor = TaskExecutor()
        self.coordinator = DistributedCoordinator()
        
    async def register_task(self, task_config):
        """注册新的调度任务"""
        task = Task.from_config(task_config)
        await self.task_registry.register(task)
        
    async def schedule_loop(self):
        """主调度循环"""
        while True:
            # 1. 扫描到期任务
            due_tasks = await self.task_registry.get_due_tasks()
            
            # 2. 分布式协调
            for task in due_tasks:
                if await self.coordinator.acquire_lock(task.id):
                    await self.executor.execute(task)
                    await self.coordinator.release_lock(task.id)
            
            await asyncio.sleep(60)  # 每分钟扫描一次
```

### 2. 分布式协调机制
```python
class DistributedCoordinator:
    def __init__(self):
        self.redis_client = redis.Redis()
        self.node_id = generate_node_id()
        
    async def acquire_lock(self, task_id: str, timeout: int = 300):
        """获取任务执行锁"""
        lock_key = f"task_lock:{task_id}"
        lock_value = f"{self.node_id}:{int(time.time())}"
        
        # 使用Redis实现分布式锁
        acquired = await self.redis_client.set(
            lock_key, 
            lock_value, 
            ex=timeout,  # 超时自动释放
            nx=True      # 仅在key不存在时设置
        )
        return acquired
        
    async def release_lock(self, task_id: str):
        """释放任务执行锁"""
        lock_key = f"task_lock:{task_id}"
        await self.redis_client.delete(lock_key)
```

### 3. 任务执行器
```python
class TaskExecutor:
    def __init__(self):
        self.http_client = aiohttp.ClientSession()
        self.message_queue = MessageQueue()
        
    async def execute(self, task: Task):
        """执行任务"""
        try:
            # 1. 任务前置检查
            if not await self._pre_execution_check(task):
                return TaskResult.skip("Pre-check failed")
                
            # 2. 执行任务
            if task.execution_type == "http":
                result = await self._execute_http_task(task)
            elif task.execution_type == "message":
                result = await self._execute_message_task(task)
            else:
                result = await self._execute_local_task(task)
                
            # 3. 处理结果
            await self._post_execution_process(task, result)
            return result
            
        except Exception as e:
            await self._handle_task_failure(task, e)
            return TaskResult.failed(str(e))
```

## 🚀 部署和运维

### 1. 高可用部署
```yaml
# 多节点部署配置
scheduler-cluster:
  nodes: 3                    # 3个节点组成集群
  leader-election: true       # 启用领导者选举
  load-balancing: round-robin # 任务负载均衡
  
  node-1:
    host: scheduler-1.internal
    role: leader              # 主节点
    
  node-2:
    host: scheduler-2.internal  
    role: follower            # 从节点
    
  node-3:
    host: scheduler-3.internal
    role: follower            # 从节点
```

### 2. 监控和告警
```python
# 调度器监控指标
class SchedulerMetrics:
    def collect_metrics(self):
        return {
            "active_tasks": len(self.running_tasks),
            "pending_tasks": len(self.pending_tasks),
            "failed_tasks_last_hour": self.count_recent_failures(),
            "average_task_duration": self.calculate_avg_duration(),
            "cluster_nodes_healthy": self.count_healthy_nodes(),
            "memory_usage": psutil.virtual_memory().percent,
            "cpu_usage": psutil.cpu_percent()
        }
        
    def check_alerts(self):
        """检查告警条件"""
        alerts = []
        
        if self.count_recent_failures() > 5:
            alerts.append("High task failure rate")
            
        if len(self.pending_tasks) > 100:
            alerts.append("Task queue backlog")
            
        return alerts
```

## 💡 为什么需要分布式任务调度？

### 1. 单点故障避免
```
传统方案: 单台服务器上的crontab
问题: 服务器宕机 = 所有定时任务停止

分布式方案: 多节点集群
优势: 任何节点故障，其他节点接管任务
```

### 2. 任务冲突避免
```
场景: 数据归档任务预计30分钟完成
问题: 如果任务超时，下次调度又开始执行
结果: 同一任务重复执行，数据混乱

解决: 分布式锁确保同一时间只有一个实例执行
```

### 3. 负载均衡
```
场景: 100个不同的定时任务
传统: 所有任务在同一台机器执行
问题: 资源争抢，性能瓶颈

分布式: 任务分散到不同节点执行
优势: 充分利用集群资源，提高执行效率
```

### 4. 动态扩展
```
业务增长: 需要更多定时任务
传统方案: 重新配置单机crontab
问题: 配置复杂，容易出错

分布式方案: 通过API动态注册任务
优势: 服务化管理，配置简单，支持热更新
```

## 总结

`scheduler-service` 是MarketPrism的**"自动化大脑"**：

✅ **定时自动化**: 替代手工操作，提高运维效率
✅ **分布式可靠**: 避免单点故障，确保任务可靠执行  
✅ **智能协调**: 防止任务冲突，优化资源利用
✅ **运维友好**: 可视化管理，告警监控，问题追踪
✅ **业务支撑**: 数据归档、清理、监控、报告等核心业务自动化

这个服务让整个MarketPrism系统能够"自动驾驶"，无需人工干预就能按计划执行各种维护和处理任务！