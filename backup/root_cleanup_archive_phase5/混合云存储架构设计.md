# æ··åˆäº‘å­˜å‚¨æ¶æ„è®¾è®¡

## ğŸŒ éƒ¨ç½²éœ€æ±‚åˆ†æ

### ç”¨æˆ·éœ€æ±‚
```yaml
çƒ­æ•°æ®: 
  ä½ç½®: äº‘æœåŠ¡å™¨ (é˜¿é‡Œäº‘/AWS/è…¾è®¯äº‘)
  åŸå› : é«˜æ€§èƒ½ã€é«˜å¯ç”¨ã€ä½å»¶è¿Ÿ
  
å†·æ•°æ®:
  ä½ç½®: æœ¬åœ°NAS
  åŸå› : é™ä½æˆæœ¬ã€å¤§å®¹é‡å­˜å‚¨
```

### æŒ‘æˆ˜åˆ†æ
- **ç½‘ç»œå»¶è¿Ÿ**: äº‘ç«¯åˆ°æœ¬åœ°çš„æ•°æ®ä¼ è¾“å»¶è¿Ÿ
- **å¸¦å®½é™åˆ¶**: å®¶åº­/ä¼ä¸šç½‘ç»œä¸Šè¡Œå¸¦å®½æœ‰é™  
- **å¯é æ€§**: æœ¬åœ°ç½‘ç»œæ•…éšœæ—¶çš„å¤„ç†
- **å®‰å…¨æ€§**: è·¨ç½‘ç»œçš„æ•°æ®ä¼ è¾“å®‰å…¨

## ğŸ—ï¸ æ··åˆäº‘æ¶æ„è®¾è®¡

### 1. æ€»ä½“æ¶æ„
```mermaid
graph TD
    A[ç”¨æˆ·è¯·æ±‚] --> B[api-gateway-service]
    B --> C[data-storage-service äº‘ç«¯]
    
    C --> D[çƒ­å­˜å‚¨ç®¡ç†å™¨ - äº‘ç«¯ClickHouse]
    C --> E[å†·å­˜å‚¨ä»£ç†å™¨]
    E --> F[VPNéš§é“]
    F --> G[æœ¬åœ°NASå­˜å‚¨ç½‘å…³]
    G --> H[å†·å­˜å‚¨ç®¡ç†å™¨ - æœ¬åœ°ClickHouse]
    
    I[scheduler-service] --> C
    C --> J[monitoring-service]
```

### 2. æ ¸å¿ƒç»„ä»¶é‡æ–°è®¾è®¡

#### A. äº‘ç«¯å­˜å‚¨æœåŠ¡ (ä¸»æœåŠ¡)
```python
# éƒ¨ç½²åœ¨äº‘æœåŠ¡å™¨çš„ä¸»å­˜å‚¨æœåŠ¡
class CloudDataStorageService:
    def __init__(self):
        # çƒ­å­˜å‚¨ - äº‘ç«¯ClickHouseé›†ç¾¤
        self.hot_storage = CloudHotStorageManager()
        
        # å†·å­˜å‚¨ä»£ç† - è¿æ¥æœ¬åœ°NAS
        self.cold_storage_proxy = LocalNASProxy()
        
        # æ··åˆæŸ¥è¯¢è·¯ç”±å™¨
        self.hybrid_query_router = HybridQueryRouter()
        
        # ç½‘ç»œæ„ŸçŸ¥çš„è¿ç§»ç®¡ç†å™¨
        self.network_aware_migrator = NetworkAwareMigrator()

    async def query_data(self, query: DataQuery):
        """æ··åˆæŸ¥è¯¢ï¼šäº‘ç«¯çƒ­æ•°æ® + æœ¬åœ°å†·æ•°æ®"""
        if query.is_recent_data():
            # æŸ¥è¯¢äº‘ç«¯çƒ­å­˜å‚¨
            return await self.hot_storage.query(query)
        elif query.is_historical_only():
            # æŸ¥è¯¢æœ¬åœ°å†·å­˜å‚¨
            return await self.cold_storage_proxy.query(query)
        else:
            # æ··åˆæŸ¥è¯¢ï¼šäº‘ç«¯ + æœ¬åœ°
            return await self.hybrid_query_router.query_mixed(query)
```

#### B. æœ¬åœ°NASå­˜å‚¨ç½‘å…³
```python
# éƒ¨ç½²åœ¨æœ¬åœ°NASçš„è½»é‡çº§ç½‘å…³æœåŠ¡
class LocalStorageGateway:
    def __init__(self):
        # æœ¬åœ°ClickHouseå®ä¾‹
        self.local_clickhouse = LocalClickHouseManager()
        
        # äº‘ç«¯è¿æ¥ç®¡ç†å™¨
        self.cloud_connector = CloudConnector()
        
        # æœ¬åœ°å­˜å‚¨ä¼˜åŒ–å™¨
        self.storage_optimizer = LocalStorageOptimizer()

    async def receive_archive_data(self, compressed_data):
        """æ¥æ”¶äº‘ç«¯å‘é€çš„å½’æ¡£æ•°æ®"""
        try:
            # 1. éªŒè¯æ•°æ®å®Œæ•´æ€§
            if not await self._verify_data_integrity(compressed_data):
                raise DataIntegrityError("Data verification failed")
            
            # 2. å†™å…¥æœ¬åœ°å­˜å‚¨
            write_result = await self.local_clickhouse.write_compressed(compressed_data)
            
            # 3. ç¡®è®¤å†™å…¥æˆåŠŸ
            await self.cloud_connector.confirm_archive_success(write_result.batch_id)
            
            return write_result
            
        except Exception as e:
            # é€šçŸ¥äº‘ç«¯å†™å…¥å¤±è´¥
            await self.cloud_connector.report_archive_failure(str(e))
            raise
```

## ğŸ”§ å…³é”®æŠ€æœ¯å®ç°

### 1. ç½‘ç»œè¿æ¥æ–¹æ¡ˆ

#### A. VPNéš§é“ (æ¨è)
```yaml
# äº‘ç«¯é…ç½®
cloud_vpn:
  type: "wireguard"  # æˆ– OpenVPN
  server: "äº‘æœåŠ¡å™¨å…¬ç½‘IP"
  port: 51820
  
# æœ¬åœ°é…ç½®  
local_vpn:
  type: "wireguard"
  client: "æœ¬åœ°NAS"
  connect_to: "äº‘æœåŠ¡å™¨:51820"
  
# å†…ç½‘IPåˆ†é…
vpn_network:
  cloud_internal_ip: "10.0.1.1"
  local_internal_ip: "10.0.1.2"
```

#### B. åå‘ä»£ç†æ–¹æ¡ˆ (å¤‡é€‰)
```yaml
# æœ¬åœ°NASä¸»åŠ¨è¿æ¥äº‘ç«¯
local_nas:
  reverse_proxy: "frp/ngrok"
  connect_to: "äº‘æœåŠ¡å™¨åå‘ä»£ç†æœåŠ¡"
  
# äº‘ç«¯é€šè¿‡åå‘ä»£ç†è®¿é—®æœ¬åœ°
cloud_service:
  proxy_url: "http://localhost:7000"  # åå‘ä»£ç†ç«¯å£
```

### 2. æ•°æ®è¿ç§»ç­–ç•¥

#### A. æ‰¹é‡è¿ç§» (éé«˜å³°æœŸ)
```python
class NetworkAwareMigrator:
    def __init__(self):
        self.bandwidth_monitor = BandwidthMonitor()
        self.compression_engine = UltraCompressionEngine()
        
    async def execute_archive_migration(self, data_batch):
        """ç½‘ç»œæ„ŸçŸ¥çš„æ•°æ®è¿ç§»"""
        # 1. æ£€æŸ¥ç½‘ç»œçŠ¶å†µ
        network_status = await self.bandwidth_monitor.check_connection()
        if not network_status.is_stable:
            # ç½‘ç»œä¸ç¨³å®šï¼Œå»¶è¿Ÿè¿ç§»
            await self._schedule_retry_migration(data_batch)
            return
        
        # 2. è¶…é«˜å‹ç¼© (å‡å°‘ä¼ è¾“é‡)
        compressed_data = await self.compression_engine.ultra_compress(
            data_batch, 
            compression_level='maximum'  # æœ€å¤§å‹ç¼©æ¯”
        )
        
        # 3. åˆ†å—ä¼ è¾“ (æ–­ç‚¹ç»­ä¼ )
        chunk_size = self._calculate_optimal_chunk_size(network_status.bandwidth)
        
        for chunk in self._split_into_chunks(compressed_data, chunk_size):
            success = await self._transfer_chunk_with_retry(chunk)
            if not success:
                await self._handle_transfer_failure(chunk)
                break
        
        # 4. éªŒè¯ä¼ è¾“å®Œæ•´æ€§
        await self._verify_remote_data_integrity(data_batch)

    def _calculate_optimal_chunk_size(self, bandwidth_mbps):
        """æ ¹æ®å¸¦å®½è®¡ç®—æœ€ä¼˜å—å¤§å°"""
        if bandwidth_mbps >= 100:
            return 100 * 1024 * 1024  # 100MB chunks
        elif bandwidth_mbps >= 20:
            return 20 * 1024 * 1024   # 20MB chunks  
        else:
            return 5 * 1024 * 1024    # 5MB chunks
```

#### B. æ¸è¿›å¼è¿ç§» (åˆ†æ•£è´Ÿè½½)
```python
class ProgressiveMigrator:
    async def schedule_migration_windows(self):
        """å®‰æ’è¿ç§»æ—¶é—´çª—å£"""
        migration_schedule = [
            {"time": "02:00-04:00", "priority": "high_volume"},    # å‡Œæ™¨å¤§æ‰¹é‡
            {"time": "14:00-15:00", "priority": "medium_volume"},  # ä¸‹åˆä¸­ç­‰é‡
            {"time": "22:00-23:00", "priority": "low_volume"}     # æ™šä¸Šå°æ‰¹é‡
        ]
        
        for window in migration_schedule:
            await self.scheduler.schedule_migration_task(
                time=window["time"],
                max_data_size=self._get_size_limit(window["priority"])
            )
```

### 3. æ··åˆæŸ¥è¯¢ä¼˜åŒ–

#### A. æ™ºèƒ½ç¼“å­˜ç­–ç•¥
```python
class HybridQueryRouter:
    def __init__(self):
        # æœ¬åœ°ç¼“å­˜çƒ­é—¨å†·æ•°æ®
        self.local_cache = LocalCacheManager()
        
        # æŸ¥è¯¢é¢„æµ‹å™¨
        self.query_predictor = QueryPredictor()
    
    async def query_mixed(self, query: DataQuery):
        """æ··åˆæ•°æ®æºæŸ¥è¯¢"""
        # 1. åˆ†ææŸ¥è¯¢æ¨¡å¼
        hot_part, cold_part = self._split_query_by_time(query)
        
        # 2. å¹¶è¡ŒæŸ¥è¯¢
        tasks = []
        
        # æŸ¥è¯¢äº‘ç«¯çƒ­æ•°æ®
        if hot_part:
            tasks.append(self.hot_storage.query(hot_part))
        
        # æŸ¥è¯¢æœ¬åœ°å†·æ•°æ® (ä¼˜å…ˆæ£€æŸ¥ç¼“å­˜)
        if cold_part:
            cached_result = await self.local_cache.get(cold_part.cache_key)
            if cached_result:
                tasks.append(asyncio.create_task(self._return_cached(cached_result)))
            else:
                tasks.append(self.cold_storage_proxy.query(cold_part))
        
        # 3. ç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 4. åˆå¹¶ç»“æœ
        return self._merge_query_results(results)
```

#### B. é¢„å–ç­–ç•¥
```python
class ColdDataPrefetcher:
    async def predictive_prefetch(self):
        """é¢„æµ‹æ€§é¢„å–å†·æ•°æ®"""
        # åˆ†ææŸ¥è¯¢æ¨¡å¼
        hot_queries = await self.query_analyzer.get_trending_queries()
        
        for query_pattern in hot_queries:
            if self._should_prefetch(query_pattern):
                # é¢„å–åˆ°äº‘ç«¯ç¼“å­˜
                cold_data = await self.nas_proxy.query(query_pattern)
                await self.cloud_cache.store(query_pattern.cache_key, cold_data)
```

## âš™ï¸ é…ç½®å’Œéƒ¨ç½²

### 1. äº‘ç«¯é…ç½®
```yaml
# config/cloud_storage.yaml
service:
  name: "data-storage-service"
  deployment: "cloud"
  
hot_storage:
  type: "clickhouse_cluster"
  nodes:
    - "clickhouse-hot-1.cloud.internal:9000"
    - "clickhouse-hot-2.cloud.internal:9000"
    - "clickhouse-hot-3.cloud.internal:9000"
  retention_days: 7

cold_storage_proxy:
  type: "nas_proxy"
  connection:
    method: "vpn"           # vpn | reverse_proxy
    vpn_endpoint: "10.0.1.2:9000"
    timeout: 30             # æœ¬åœ°ç½‘ç»œè¶…æ—¶æ—¶é—´
    retry_attempts: 3
  
  fallback:
    enabled: true
    cache_duration: "24h"   # æœ¬åœ°æ•…éšœæ—¶ç¼“å­˜æŸ¥è¯¢ç»“æœ
    backup_storage: "cloud_backup_bucket"

migration:
  schedule: "0 2 * * *"
  bandwidth_limit: "10MB/s"  # é™åˆ¶å¸¦å®½é¿å…å½±å“ä¸šåŠ¡
  compression_level: "ultra"
  chunk_size: "50MB"
  verification_enabled: true
```

### 2. æœ¬åœ°NASé…ç½®
```yaml
# config/local_storage.yaml
service:
  name: "local-storage-gateway"
  deployment: "nas"
  
storage:
  type: "clickhouse_single"
  data_path: "/volume1/marketprism/cold_data"
  compression: "zstd_ultra"
  
connection:
  cloud_endpoint: "10.0.1.1:8002"
  heartbeat_interval: 30
  
  # ç½‘ç»œæ•…éšœå¤„ç†
  offline_mode:
    enabled: true
    max_offline_duration: "48h"
    queue_incoming_data: true
```

### 3. Dockeréƒ¨ç½²æ–¹æ¡ˆ

#### A. äº‘ç«¯éƒ¨ç½²
```yaml
# docker-compose.cloud.yml
version: '3.8'
services:
  data-storage-service:
    image: marketprism/storage-cloud:v1.0.0
    ports:
      - "8002:8002"
    environment:
      - DEPLOYMENT_TYPE=cloud
      - CONFIG_PATH=/app/config/cloud_storage.yaml
    volumes:
      - ./config:/app/config
      - /etc/wireguard:/etc/wireguard  # VPNé…ç½®
    
  clickhouse-hot-cluster:
    image: clickhouse/clickhouse-server:latest
    # ... äº‘ç«¯ClickHouseé…ç½®
```

#### B. æœ¬åœ°NASéƒ¨ç½²
```yaml
# docker-compose.nas.yml  
version: '3.8'
services:
  local-storage-gateway:
    image: marketprism/storage-gateway:v1.0.0
    ports:
      - "9000:9000"
    environment:
      - DEPLOYMENT_TYPE=nas
      - CONFIG_PATH=/app/config/local_storage.yaml
    volumes:
      - ./config:/app/config
      - /volume1/marketprism:/app/data  # NASå­˜å‚¨è·¯å¾„
      - /etc/wireguard:/etc/wireguard   # VPNé…ç½®
    
  clickhouse-local:
    image: clickhouse/clickhouse-server:latest
    volumes:
      - /volume1/marketprism/clickhouse:/var/lib/clickhouse
```

## ğŸš¨ æ•…éšœå¤„ç†ç­–ç•¥

### 1. ç½‘ç»œæ•…éšœå¤„ç†
```python
class NetworkFailureHandler:
    async def handle_nas_offline(self):
        """å¤„ç†æœ¬åœ°NASç¦»çº¿"""
        # 1. å¯ç”¨äº‘ç«¯ç¼“å­˜æ¨¡å¼
        await self.enable_cloud_cache_mode()
        
        # 2. æš‚åœæ•°æ®è¿ç§»
        await self.pause_data_migration()
        
        # 3. è®°å½•ç¦»çº¿æœŸé—´çš„æŸ¥è¯¢
        await self.log_offline_queries()
        
        # 4. å‘é€å‘Šè­¦
        await self.send_alert("NAS offline", "Cold data queries degraded")

    async def handle_nas_recovery(self):
        """å¤„ç†æœ¬åœ°NASæ¢å¤"""
        # 1. åŒæ­¥ç¦»çº¿æœŸé—´çš„æ•°æ®
        await self.sync_offline_data()
        
        # 2. æ¢å¤æ­£å¸¸è¿ç§»
        await self.resume_data_migration()
        
        # 3. æ¸…ç†ä¸´æ—¶ç¼“å­˜
        await self.cleanup_temporary_cache()
```

### 2. æ•°æ®ä¸€è‡´æ€§ä¿éšœ
```python
class HybridConsistencyManager:
    async def verify_data_consistency(self):
        """éªŒè¯æ··åˆå­˜å‚¨æ•°æ®ä¸€è‡´æ€§"""
        # 1. æ£€æŸ¥è¿ç§»è®°å½•
        migration_log = await self.get_migration_history()
        
        # 2. éªŒè¯æ•°æ®å®Œæ•´æ€§
        for record in migration_log:
            cloud_hash = await self.cloud_storage.get_data_hash(record.batch_id)
            nas_hash = await self.nas_proxy.get_data_hash(record.batch_id)
            
            if cloud_hash != nas_hash:
                await self._handle_data_inconsistency(record)
```

## ğŸ’° æˆæœ¬æ•ˆç›Šåˆ†æ

### å­˜å‚¨æˆæœ¬å¯¹æ¯”
| æ•°æ®ç±»å‹ | äº‘ç«¯æˆæœ¬/æœˆ | æœ¬åœ°NASæˆæœ¬/æœˆ | èŠ‚çœ |
|----------|-------------|----------------|------|
| çƒ­æ•°æ®(1TB) | Â¥300 | - | - |
| å†·æ•°æ®(10TB) | Â¥3000 | Â¥500 | 83% |
| **æ€»è®¡** | **Â¥3300** | **Â¥800** | **76%** |

### æ€§èƒ½å¯¹æ¯”
| æŒ‡æ ‡ | äº‘ç«¯çƒ­å­˜å‚¨ | æœ¬åœ°å†·å­˜å‚¨ | å½±å“ |
|------|------------|------------|------|
| æŸ¥è¯¢å»¶è¿Ÿ | 10ms | 200ms | å¯æ¥å— |
| å†™å…¥é€Ÿåº¦ | é«˜ | ä¸­ç­‰ | åå°è¿ç§» |
| å¯ç”¨æ€§ | 99.9% | 95% | å†·æ•°æ®å®¹å¿åº¦é«˜ |

## ğŸ¯ æ€»ç»“

### âœ… æ¨èçš„æ··åˆäº‘æ¶æ„

1. **äº‘ç«¯ä¸»æœåŠ¡**: ç»Ÿä¸€çš„data-storage-serviceéƒ¨ç½²åœ¨äº‘ç«¯
2. **æœ¬åœ°å­˜å‚¨ç½‘å…³**: è½»é‡çº§gatewayéƒ¨ç½²åœ¨NAS
3. **VPNéš§é“**: å®‰å…¨çš„äº‘-æœ¬åœ°è¿æ¥
4. **æ™ºèƒ½è·¯ç”±**: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®æº
5. **ç½‘ç»œæ„ŸçŸ¥**: æ ¹æ®ç½‘ç»œçŠ¶å†µè°ƒæ•´ç­–ç•¥

### ğŸ”‘ å…³é”®ä¼˜åŠ¿

- **æˆæœ¬ä¼˜åŒ–**: å†·æ•°æ®æˆæœ¬é™ä½76%
- **æ€§èƒ½ä¿éšœ**: çƒ­æ•°æ®ä¿æŒäº‘ç«¯é«˜æ€§èƒ½  
- **æ¶æ„ç»Ÿä¸€**: å¯¹å¤–ä»ç„¶æ˜¯å•ä¸€æœåŠ¡æ¥å£
- **æ•…éšœå®¹å¿**: ç½‘ç»œæ•…éšœæ—¶æœ‰é™çº§æ–¹æ¡ˆ
- **æ‰©å±•çµæ´»**: å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´çƒ­å†·åˆ†å‰²ç­–ç•¥

è¿™ä¸ªæ¶æ„å®Œç¾è§£å†³äº†ä½ çš„éœ€æ±‚ï¼šäº‘ç«¯æ€§èƒ½ + æœ¬åœ°æˆæœ¬ä¼˜åŒ–ï¼ğŸš€