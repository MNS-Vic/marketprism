"""
ğŸ—„ï¸ CacheOptimizer - ç¼“å­˜ä¼˜åŒ–å™¨

æ™ºèƒ½ç¼“å­˜ç­–ç•¥å’Œå¤šçº§ç¼“å­˜æ¶æ„
æä¾›è‡ªé€‚åº”ç¼“å­˜ã€ç¼“å­˜é¢„çƒ­ã€å¤šçº§ç¼“å­˜ã€ç¼“å­˜åˆ†æç­‰åŠŸèƒ½
"""

import asyncio
import time
import hashlib
import json
from typing import Dict, Any, Optional, List, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum
import weakref
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥æšä¸¾"""
    LRU = "lru"                    # æœ€è¿‘æœ€å°‘ä½¿ç”¨
    LFU = "lfu"                    # æœ€å°‘ä½¿ç”¨é¢‘ç‡
    FIFO = "fifo"                  # å…ˆè¿›å…ˆå‡º
    ADAPTIVE = "adaptive"          # è‡ªé€‚åº”ç­–ç•¥
    TIME_BASED = "time_based"      # åŸºäºæ—¶é—´
    SIZE_BASED = "size_based"      # åŸºäºå¤§å°


class CacheLevel(Enum):
    """ç¼“å­˜çº§åˆ«æšä¸¾"""
    L1_MEMORY = "l1_memory"        # L1å†…å­˜ç¼“å­˜
    L2_REDIS = "l2_redis"          # L2 Redisç¼“å­˜
    L3_DISK = "l3_disk"           # L3ç£ç›˜ç¼“å­˜
    DISTRIBUTED = "distributed"    # åˆ†å¸ƒå¼ç¼“å­˜


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    value: Any
    created_at: float
    accessed_at: float
    access_count: int = 0
    size: int = 0
    ttl: Optional[float] = None
    tags: List[str] = field(default_factory=list)
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if self.ttl is None:
            return False
        return time.time() - self.created_at > self.ttl
    
    def update_access(self):
        """æ›´æ–°è®¿é—®ä¿¡æ¯"""
        self.accessed_at = time.time()
        self.access_count += 1


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡"""
    hits: int = 0
    misses: int = 0
    evictions: int = 0
    total_size: int = 0
    entry_count: int = 0
    
    @property
    def hit_rate(self) -> float:
        """å‘½ä¸­ç‡"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0
    
    @property
    def miss_rate(self) -> float:
        """æœªå‘½ä¸­ç‡"""
        return 1.0 - self.hit_rate


@dataclass
class CacheConfig:
    """ç¼“å­˜é…ç½®"""
    strategy: CacheStrategy = CacheStrategy.ADAPTIVE
    max_size: int = 10000
    max_memory: int = 100 * 1024 * 1024  # 100MB
    default_ttl: Optional[float] = 3600.0  # 1å°æ—¶
    cleanup_interval: float = 300.0  # 5åˆ†é’Ÿ
    preload_enabled: bool = True
    compression_enabled: bool = True
    encryption_enabled: bool = False


class CacheOptimizer:
    """
    ğŸ—„ï¸ ç¼“å­˜ä¼˜åŒ–å™¨
    
    æä¾›æ™ºèƒ½ç¼“å­˜ç­–ç•¥ã€å¤šçº§ç¼“å­˜æ¶æ„ã€ç¼“å­˜é¢„çƒ­ã€æ€§èƒ½åˆ†æç­‰åŠŸèƒ½
    """
    
    def __init__(self, config: Optional[CacheConfig] = None):
        self.config = config or CacheConfig()
        self.caches: Dict[CacheLevel, Dict[str, CacheEntry]] = {
            level: {} for level in CacheLevel
        }
        self.stats: Dict[CacheLevel, CacheStats] = {
            level: CacheStats() for level in CacheLevel
        }
        self.preload_rules: List[Callable] = []
        self.cleanup_tasks: Dict[CacheLevel, Optional[asyncio.Task]] = {
            level: None for level in CacheLevel
        }
        self.access_patterns: Dict[str, List[float]] = defaultdict(list)
        self.is_running = False
        
        logger.info(f"CacheOptimizeråˆå§‹åŒ–å®Œæˆ: strategy={self.config.strategy.value}")
    
    async def start(self):
        """å¯åŠ¨ç¼“å­˜ä¼˜åŒ–å™¨"""
        if self.is_running:
            return
        
        self.is_running = True
        
        # å¯åŠ¨å„çº§ç¼“å­˜çš„æ¸…ç†ä»»åŠ¡
        for level in CacheLevel:
            self.cleanup_tasks[level] = asyncio.create_task(
                self._cleanup_loop(level)
            )
        
        # å¯åŠ¨é¢„çƒ­ä»»åŠ¡
        if self.config.preload_enabled:
            asyncio.create_task(self._preload_cache())
        
        logger.info("CacheOptimizerå·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢ç¼“å­˜ä¼˜åŒ–å™¨"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # å–æ¶ˆæ¸…ç†ä»»åŠ¡
        for task in self.cleanup_tasks.values():
            if task:
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        
        logger.info("CacheOptimizerå·²åœæ­¢")
    
    async def get(self, key: str, level: CacheLevel = CacheLevel.L1_MEMORY) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        cache = self.caches[level]
        stats = self.stats[level]
        
        if key in cache:
            entry = cache[key]
            if not entry.is_expired():
                entry.update_access()
                stats.hits += 1
                self._record_access_pattern(key)
                return entry.value
            else:
                # æ¸…ç†è¿‡æœŸæ¡ç›®
                del cache[key]
                stats.entry_count -= 1
                stats.total_size -= entry.size
        
        stats.misses += 1
        
        # å°è¯•ä»æ›´é«˜çº§åˆ«çš„ç¼“å­˜è·å–
        if level != CacheLevel.L3_DISK:
            next_level = self._get_next_level(level)
            if next_level:
                value = await self.get(key, next_level)
                if value is not None:
                    # å†™å…¥å½“å‰çº§åˆ«ç¼“å­˜
                    await self.set(key, value, level)
                    return value
        
        return None
    
    async def set(self, key: str, value: Any, level: CacheLevel = CacheLevel.L1_MEMORY, 
                  ttl: Optional[float] = None, tags: Optional[List[str]] = None):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        cache = self.caches[level]
        stats = self.stats[level]
        
        # è®¡ç®—æ•°æ®å¤§å°
        size = self._calculate_size(value)
        
        # æ£€æŸ¥å®¹é‡é™åˆ¶
        await self._ensure_capacity(level, size)
        
        # åˆ›å»ºç¼“å­˜æ¡ç›®
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=time.time(),
            accessed_at=time.time(),
            size=size,
            ttl=ttl or self.config.default_ttl,
            tags=tags or []
        )
        
        # ç§»é™¤æ—§æ¡ç›®
        if key in cache:
            old_entry = cache[key]
            stats.total_size -= old_entry.size
        else:
            stats.entry_count += 1
        
        cache[key] = entry
        stats.total_size += size
        
        self._record_access_pattern(key)
        logger.debug(f"ç¼“å­˜è®¾ç½®: key={key}, level={level.value}, size={size}")
    
    async def delete(self, key: str, level: Optional[CacheLevel] = None):
        """åˆ é™¤ç¼“å­˜æ•°æ®"""
        if level:
            levels = [level]
        else:
            levels = list(CacheLevel)
        
        for cache_level in levels:
            cache = self.caches[cache_level]
            stats = self.stats[cache_level]
            
            if key in cache:
                entry = cache[key]
                del cache[key]
                stats.entry_count -= 1
                stats.total_size -= entry.size
                logger.debug(f"ç¼“å­˜åˆ é™¤: key={key}, level={cache_level.value}")
    
    async def invalidate_by_tags(self, tags: List[str]):
        """æ ¹æ®æ ‡ç­¾å¤±æ•ˆç¼“å­˜"""
        for level in CacheLevel:
            cache = self.caches[level]
            keys_to_delete = []
            
            for key, entry in cache.items():
                if any(tag in entry.tags for tag in tags):
                    keys_to_delete.append(key)
            
            for key in keys_to_delete:
                await self.delete(key, level)
        
        logger.info(f"æ ¹æ®æ ‡ç­¾å¤±æ•ˆç¼“å­˜: tags={tags}")
    
    async def clear(self, level: Optional[CacheLevel] = None):
        """æ¸…ç©ºç¼“å­˜"""
        if level:
            levels = [level]
        else:
            levels = list(CacheLevel)
        
        for cache_level in levels:
            self.caches[cache_level].clear()
            self.stats[cache_level] = CacheStats()
        
        logger.info(f"ç¼“å­˜å·²æ¸…ç©º: levels={[l.value for l in levels]}")
    
    def get_stats(self, level: Optional[CacheLevel] = None) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        if level:
            stats = self.stats[level]
            return {
                "level": level.value,
                "hits": stats.hits,
                "misses": stats.misses,
                "hit_rate": stats.hit_rate,
                "miss_rate": stats.miss_rate,
                "evictions": stats.evictions,
                "entry_count": stats.entry_count,
                "total_size": stats.total_size
            }
        else:
            return {
                level.value: {
                    "hits": stats.hits,
                    "misses": stats.misses,
                    "hit_rate": stats.hit_rate,
                    "miss_rate": stats.miss_rate,
                    "evictions": stats.evictions,
                    "entry_count": stats.entry_count,
                    "total_size": stats.total_size
                }
                for level, stats in self.stats.items()
            }
    
    def get_analysis(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜åˆ†æ"""
        analysis = {
            "overall_stats": self.get_stats(),
            "hot_keys": self._get_hot_keys(),
            "optimization_suggestions": self._get_optimization_suggestions(),
            "access_patterns": self._analyze_access_patterns()
        }
        
        return analysis
    
    def add_preload_rule(self, rule: Callable):
        """æ·»åŠ é¢„åŠ è½½è§„åˆ™"""
        self.preload_rules.append(rule)
        logger.info("æ·»åŠ é¢„åŠ è½½è§„åˆ™")
    
    def _get_next_level(self, level: CacheLevel) -> Optional[CacheLevel]:
        """è·å–ä¸‹ä¸€çº§ç¼“å­˜"""
        level_order = [
            CacheLevel.L1_MEMORY,
            CacheLevel.L2_REDIS,
            CacheLevel.L3_DISK,
            CacheLevel.DISTRIBUTED
        ]
        
        try:
            current_index = level_order.index(level)
            if current_index < len(level_order) - 1:
                return level_order[current_index + 1]
        except ValueError:
            pass
        
        return None
    
    def _calculate_size(self, value: Any) -> int:
        """è®¡ç®—æ•°æ®å¤§å°"""
        try:
            if isinstance(value, (str, bytes)):
                return len(value)
            elif isinstance(value, (int, float)):
                return 8
            elif isinstance(value, dict):
                return len(json.dumps(value, default=str))
            else:
                return len(str(value))
        except:
            return 1024  # é»˜è®¤å¤§å°
    
    async def _ensure_capacity(self, level: CacheLevel, new_size: int):
        """ç¡®ä¿ç¼“å­˜å®¹é‡"""
        cache = self.caches[level]
        stats = self.stats[level]
        
        # æ£€æŸ¥æ¡ç›®æ•°é‡é™åˆ¶
        if stats.entry_count >= self.config.max_size:
            await self._evict_entries(level, 1)
        
        # æ£€æŸ¥å†…å­˜å¤§å°é™åˆ¶
        if stats.total_size + new_size > self.config.max_memory:
            needed = stats.total_size + new_size - self.config.max_memory
            await self._evict_by_size(level, needed)
    
    async def _evict_entries(self, level: CacheLevel, count: int):
        """æ·˜æ±°ç¼“å­˜æ¡ç›®"""
        cache = self.caches[level]
        stats = self.stats[level]
        
        if self.config.strategy == CacheStrategy.LRU:
            # æœ€è¿‘æœ€å°‘ä½¿ç”¨
            entries = sorted(cache.items(), key=lambda x: x[1].accessed_at)
        elif self.config.strategy == CacheStrategy.LFU:
            # æœ€å°‘ä½¿ç”¨é¢‘ç‡
            entries = sorted(cache.items(), key=lambda x: x[1].access_count)
        elif self.config.strategy == CacheStrategy.FIFO:
            # å…ˆè¿›å…ˆå‡º
            entries = sorted(cache.items(), key=lambda x: x[1].created_at)
        else:
            # è‡ªé€‚åº”ç­–ç•¥
            entries = sorted(cache.items(), 
                           key=lambda x: x[1].access_count / (time.time() - x[1].created_at + 1))
        
        # æ·˜æ±°æŒ‡å®šæ•°é‡çš„æ¡ç›®
        for i in range(min(count, len(entries))):
            key, entry = entries[i]
            del cache[key]
            stats.entry_count -= 1
            stats.total_size -= entry.size
            stats.evictions += 1
    
    async def _evict_by_size(self, level: CacheLevel, target_size: int):
        """æŒ‰å¤§å°æ·˜æ±°ç¼“å­˜"""
        cache = self.caches[level]
        stats = self.stats[level]
        freed_size = 0
        
        # æŒ‰è®¿é—®é¢‘ç‡æ’åº
        entries = sorted(cache.items(), 
                        key=lambda x: x[1].access_count / (time.time() - x[1].created_at + 1))
        
        for key, entry in entries:
            if freed_size >= target_size:
                break
            
            del cache[key]
            stats.entry_count -= 1
            stats.total_size -= entry.size
            stats.evictions += 1
            freed_size += entry.size
    
    async def _cleanup_loop(self, level: CacheLevel):
        """æ¸…ç†å¾ªç¯"""
        while self.is_running:
            try:
                await asyncio.sleep(self.config.cleanup_interval)
                await self._cleanup_expired(level)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
    
    async def _cleanup_expired(self, level: CacheLevel):
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        cache = self.caches[level]
        stats = self.stats[level]
        expired_keys = []
        
        for key, entry in cache.items():
            if entry.is_expired():
                expired_keys.append(key)
        
        for key in expired_keys:
            entry = cache[key]
            del cache[key]
            stats.entry_count -= 1
            stats.total_size -= entry.size
        
        if expired_keys:
            logger.debug(f"æ¸…ç†è¿‡æœŸç¼“å­˜: level={level.value}, count={len(expired_keys)}")
    
    async def _preload_cache(self):
        """é¢„åŠ è½½ç¼“å­˜"""
        for rule in self.preload_rules:
            try:
                await rule(self)
            except Exception as e:
                logger.error(f"é¢„åŠ è½½è§„åˆ™æ‰§è¡Œå¤±è´¥: {e}")
        
        logger.info("ç¼“å­˜é¢„åŠ è½½å®Œæˆ")
    
    def _record_access_pattern(self, key: str):
        """è®°å½•è®¿é—®æ¨¡å¼"""
        current_time = time.time()
        pattern = self.access_patterns[key]
        pattern.append(current_time)
        
        # åªä¿ç•™æœ€è¿‘1å°æ—¶çš„è®¿é—®è®°å½•
        cutoff = current_time - 3600
        self.access_patterns[key] = [t for t in pattern if t > cutoff]
    
    def _get_hot_keys(self, limit: int = 10) -> List[Tuple[str, int]]:
        """è·å–çƒ­ç‚¹é”®"""
        key_frequencies = {}
        
        for level in CacheLevel:
            cache = self.caches[level]
            for key, entry in cache.items():
                if key not in key_frequencies:
                    key_frequencies[key] = 0
                key_frequencies[key] += entry.access_count
        
        sorted_keys = sorted(key_frequencies.items(), key=lambda x: x[1], reverse=True)
        return sorted_keys[:limit]
    
    def _get_optimization_suggestions(self) -> List[str]:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # åˆ†ææ•´ä½“å‘½ä¸­ç‡
        total_hits = sum(stats.hits for stats in self.stats.values())
        total_requests = sum(stats.hits + stats.misses for stats in self.stats.values())
        overall_hit_rate = total_hits / total_requests if total_requests > 0 else 0
        
        if overall_hit_rate < 0.7:
            suggestions.append("æ•´ä½“ç¼“å­˜å‘½ä¸­ç‡åä½ï¼Œå»ºè®®å¢åŠ ç¼“å­˜å®¹é‡æˆ–è°ƒæ•´TTL")
        
        if overall_hit_rate < 0.5:
            suggestions.append("ç¼“å­˜å‘½ä¸­ç‡ä¸¥é‡åä½ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜ç­–ç•¥å’Œé¢„åŠ è½½è§„åˆ™")
        
        # åˆ†æå†…å­˜ä½¿ç”¨
        l1_stats = self.stats[CacheLevel.L1_MEMORY]
        if l1_stats.total_size > self.config.max_memory * 0.9:
            suggestions.append("L1ç¼“å­˜å†…å­˜ä½¿ç”¨æ¥è¿‘ä¸Šé™ï¼Œå»ºè®®å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–æ·˜æ±°ç­–ç•¥")
        
        # åˆ†ææ·˜æ±°ç‡
        total_evictions = sum(stats.evictions for stats in self.stats.values())
        if total_evictions > total_requests * 0.1:
            suggestions.append("ç¼“å­˜æ·˜æ±°ç‡è¿‡é«˜ï¼Œå»ºè®®å¢åŠ ç¼“å­˜å®¹é‡")
        
        return suggestions
    
    def _analyze_access_patterns(self) -> Dict[str, Any]:
        """åˆ†æè®¿é—®æ¨¡å¼"""
        patterns = {}
        current_time = time.time()
        
        for key, access_times in self.access_patterns.items():
            if len(access_times) < 2:
                continue
            
            # è®¡ç®—è®¿é—®é¢‘ç‡
            frequency = len(access_times) / 3600  # æ¯å°æ—¶è®¿é—®æ¬¡æ•°
            
            # è®¡ç®—è®¿é—®é—´éš”
            intervals = [access_times[i] - access_times[i-1] 
                        for i in range(1, len(access_times))]
            avg_interval = sum(intervals) / len(intervals) if intervals else 0
            
            patterns[key] = {
                "frequency": frequency,
                "avg_interval": avg_interval,
                "last_access": access_times[-1] if access_times else 0,
                "access_count": len(access_times)
            }
        
        return patterns


# è¾…åŠ©å‡½æ•°

def create_cache_key(*args) -> str:
    """åˆ›å»ºç¼“å­˜é”®"""
    key_data = ":".join(str(arg) for arg in args)
    return hashlib.md5(key_data.encode()).hexdigest()


async def cache_decorator(cache_optimizer: CacheOptimizer, 
                         ttl: Optional[float] = None,
                         tags: Optional[List[str]] = None):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = create_cache_key(func.__name__, args, kwargs)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await cache_optimizer.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # æ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            await cache_optimizer.set(cache_key, result, ttl=ttl, tags=tags)
            
            return result
        
        return wrapper
    return decorator