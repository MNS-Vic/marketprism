"""
MarketPrism åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
å®ç°çƒ­ç«¯-å†·ç«¯æ•°æ®å­˜å‚¨æ¶æ„ï¼Œæ”¯æŒæ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
"""

import asyncio
import json
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import structlog

from .unified_clickhouse_writer import UnifiedClickHouseWriter
from .types import (
    NormalizedOrderBook, NormalizedTrade
)


class StorageTier(Enum):
    """å­˜å‚¨å±‚çº§æšä¸¾"""
    HOT = "hot"      # çƒ­ç«¯å­˜å‚¨ï¼šé«˜é¢‘è®¿é—®ï¼ŒçŸ­æœŸä¿ç•™
    COLD = "cold"    # å†·ç«¯å­˜å‚¨ï¼šä½é¢‘è®¿é—®ï¼Œé•¿æœŸä¿ç•™
    ARCHIVE = "archive"  # å½’æ¡£å­˜å‚¨ï¼šæå°‘è®¿é—®ï¼Œæ°¸ä¹…ä¿ç•™


@dataclass
class TierConfig:
    """å­˜å‚¨å±‚çº§é…ç½®"""
    tier: StorageTier
    clickhouse_host: str
    clickhouse_port: int
    clickhouse_user: str
    clickhouse_password: str
    clickhouse_database: str
    retention_days: int
    batch_size: int = 1000
    flush_interval: int = 5
    max_retries: int = 3


@dataclass
class DataTransferTask:
    """æ•°æ®ä¼ è¾“ä»»åŠ¡"""
    task_id: str
    source_tier: StorageTier
    target_tier: StorageTier
    data_type: str
    exchange: str
    symbol: str
    start_time: datetime
    end_time: datetime
    status: str = "pending"  # pending, running, completed, failed
    created_at: datetime = None
    updated_at: datetime = None
    error_message: Optional[str] = None
    records_count: int = 0
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now(timezone.utc)
        if self.updated_at is None:
            self.updated_at = self.created_at


class TieredStorageManager:
    """åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, hot_config: TierConfig, cold_config: TierConfig):
        """
        åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
        
        Args:
            hot_config: çƒ­ç«¯å­˜å‚¨é…ç½®
            cold_config: å†·ç«¯å­˜å‚¨é…ç½®
        """
        self.logger = structlog.get_logger("core.storage.tiered_storage_manager")
        
        # å­˜å‚¨é…ç½®
        self.hot_config = hot_config
        self.cold_config = cold_config
        
        # ClickHouseå†™å…¥å™¨
        self.hot_writer: Optional[UnifiedClickHouseWriter] = None
        self.cold_writer: Optional[UnifiedClickHouseWriter] = None
        
        # æ•°æ®ä¼ è¾“ä»»åŠ¡é˜Ÿåˆ—
        self.transfer_tasks: Dict[str, DataTransferTask] = {}
        self.transfer_queue = asyncio.Queue()
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.transfer_worker_task: Optional[asyncio.Task] = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "hot_storage": {
                "total_writes": 0,
                "failed_writes": 0,
                "last_write_time": None
            },
            "cold_storage": {
                "total_writes": 0,
                "failed_writes": 0,
                "last_write_time": None
            },
            "data_transfers": {
                "total_tasks": 0,
                "completed_tasks": 0,
                "failed_tasks": 0,
                "last_transfer_time": None
            }
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨"""
        try:
            self.logger.info("ğŸš€ åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨")
            
            # åˆå§‹åŒ–çƒ­ç«¯å­˜å‚¨
            self.hot_writer = UnifiedClickHouseWriter(
                host=self.hot_config.clickhouse_host,
                port=self.hot_config.clickhouse_port,
                user=self.hot_config.clickhouse_user,
                password=self.hot_config.clickhouse_password,
                database=self.hot_config.clickhouse_database,
                batch_size=self.hot_config.batch_size,
                flush_interval=self.hot_config.flush_interval
            )
            await self.hot_writer.initialize()
            self.logger.info("âœ… çƒ­ç«¯å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ", 
                           host=self.hot_config.clickhouse_host,
                           database=self.hot_config.clickhouse_database)
            
            # åˆå§‹åŒ–å†·ç«¯å­˜å‚¨
            self.cold_writer = UnifiedClickHouseWriter(
                host=self.cold_config.clickhouse_host,
                port=self.cold_config.clickhouse_port,
                user=self.cold_config.clickhouse_user,
                password=self.cold_config.clickhouse_password,
                database=self.cold_config.clickhouse_database,
                batch_size=self.cold_config.batch_size,
                flush_interval=self.cold_config.flush_interval
            )
            await self.cold_writer.initialize()
            self.logger.info("âœ… å†·ç«¯å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ",
                           host=self.cold_config.clickhouse_host,
                           database=self.cold_config.clickhouse_database)
            
            # å¯åŠ¨æ•°æ®ä¼ è¾“å·¥ä½œå™¨
            self.is_running = True
            self.transfer_worker_task = asyncio.create_task(self._transfer_worker())
            
            self.logger.info("âœ… åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error("âŒ åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥", error=str(e))
            raise
    
    async def close(self):
        """å…³é—­åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨"""
        try:
            self.logger.info("ğŸ›‘ å…³é—­åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨")
            
            # åœæ­¢ä¼ è¾“å·¥ä½œå™¨
            self.is_running = False
            if self.transfer_worker_task:
                self.transfer_worker_task.cancel()
                try:
                    await self.transfer_worker_task
                except asyncio.CancelledError:
                    pass
            
            # å…³é—­å­˜å‚¨å†™å…¥å™¨
            if self.hot_writer:
                await self.hot_writer.close()
                self.logger.info("âœ… çƒ­ç«¯å­˜å‚¨å·²å…³é—­")
            
            if self.cold_writer:
                await self.cold_writer.close()
                self.logger.info("âœ… å†·ç«¯å­˜å‚¨å·²å…³é—­")
            
            self.logger.info("âœ… åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨å·²å…³é—­")
            
        except Exception as e:
            self.logger.error("âŒ å…³é—­åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨å¤±è´¥", error=str(e))
    
    # ==================== æ•°æ®å†™å…¥æ–¹æ³• ====================
    
    async def store_to_hot(self, data_type: str, data: Union[Dict, List[Dict]]) -> bool:
        """å­˜å‚¨æ•°æ®åˆ°çƒ­ç«¯"""
        try:
            if not self.hot_writer:
                self.logger.error("âŒ çƒ­ç«¯å­˜å‚¨æœªåˆå§‹åŒ–")
                return False
            
            # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©å­˜å‚¨æ–¹æ³•
            success = await self._store_by_type(self.hot_writer, data_type, data)
            
            # æ›´æ–°ç»Ÿè®¡
            if success:
                self.stats["hot_storage"]["total_writes"] += 1
                self.stats["hot_storage"]["last_write_time"] = datetime.now(timezone.utc)
            else:
                self.stats["hot_storage"]["failed_writes"] += 1
            
            return success
            
        except Exception as e:
            self.logger.error("âŒ çƒ­ç«¯å­˜å‚¨å¤±è´¥", data_type=data_type, error=str(e))
            self.stats["hot_storage"]["failed_writes"] += 1
            return False
    
    async def store_to_cold(self, data_type: str, data: Union[Dict, List[Dict]]) -> bool:
        """å­˜å‚¨æ•°æ®åˆ°å†·ç«¯"""
        try:
            if not self.cold_writer:
                self.logger.error("âŒ å†·ç«¯å­˜å‚¨æœªåˆå§‹åŒ–")
                return False
            
            # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©å­˜å‚¨æ–¹æ³•
            success = await self._store_by_type(self.cold_writer, data_type, data)
            
            # æ›´æ–°ç»Ÿè®¡
            if success:
                self.stats["cold_storage"]["total_writes"] += 1
                self.stats["cold_storage"]["last_write_time"] = datetime.now(timezone.utc)
            else:
                self.stats["cold_storage"]["failed_writes"] += 1
            
            return success
            
        except Exception as e:
            self.logger.error("âŒ å†·ç«¯å­˜å‚¨å¤±è´¥", data_type=data_type, error=str(e))
            self.stats["cold_storage"]["failed_writes"] += 1
            return False
    
    async def _store_by_type(self, writer: UnifiedClickHouseWriter, data_type: str, data: Union[Dict, List[Dict]]) -> bool:
        """æ ¹æ®æ•°æ®ç±»å‹å­˜å‚¨æ•°æ®"""
        try:
            # ç¡®ä¿æ•°æ®æ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(data, dict):
                data = [data]
            
            # æ ¹æ®æ•°æ®ç±»å‹è°ƒç”¨ç›¸åº”çš„å­˜å‚¨æ–¹æ³•
            if data_type == "orderbook":
                return await writer.store_orderbooks(data)
            elif data_type == "trade":
                return await writer.store_trades(data)
            elif data_type == "funding_rate":
                return await writer.store_funding_rates(data)
            elif data_type == "open_interest":
                return await writer.store_open_interests(data)
            elif data_type == "liquidation":
                return await writer.store_liquidations(data)
            elif data_type == "lsr":
                return await writer.store_lsrs(data)
            elif data_type == "volatility_index":
                return await writer.store_volatility_indices(data)
            else:
                self.logger.error("âŒ ä¸æ”¯æŒçš„æ•°æ®ç±»å‹", data_type=data_type)
                return False
                
        except Exception as e:
            self.logger.error("âŒ æ•°æ®å­˜å‚¨å¤±è´¥", data_type=data_type, error=str(e))
            return False

    # ==================== æ•°æ®ä¼ è¾“æ–¹æ³• ====================

    async def schedule_data_transfer(self, data_type: str, exchange: str, symbol: str,
                                   start_time: datetime, end_time: datetime) -> str:
        """è°ƒåº¦æ•°æ®ä¼ è¾“ä»»åŠ¡"""
        try:
            # ç”Ÿæˆä»»åŠ¡ID
            task_id = f"transfer_{data_type}_{exchange}_{symbol}_{int(time.time())}"

            # åˆ›å»ºä¼ è¾“ä»»åŠ¡
            task = DataTransferTask(
                task_id=task_id,
                source_tier=StorageTier.HOT,
                target_tier=StorageTier.COLD,
                data_type=data_type,
                exchange=exchange,
                symbol=symbol,
                start_time=start_time,
                end_time=end_time
            )

            # æ·»åŠ åˆ°ä»»åŠ¡é˜Ÿåˆ—
            self.transfer_tasks[task_id] = task
            await self.transfer_queue.put(task)

            self.stats["data_transfers"]["total_tasks"] += 1

            self.logger.info("ğŸ“‹ æ•°æ®ä¼ è¾“ä»»åŠ¡å·²è°ƒåº¦",
                           task_id=task_id,
                           data_type=data_type,
                           exchange=exchange,
                           symbol=symbol)

            return task_id

        except Exception as e:
            self.logger.error("âŒ è°ƒåº¦æ•°æ®ä¼ è¾“ä»»åŠ¡å¤±è´¥", error=str(e))
            raise

    async def _transfer_worker(self):
        """æ•°æ®ä¼ è¾“å·¥ä½œå™¨"""
        self.logger.info("ğŸ”„ æ•°æ®ä¼ è¾“å·¥ä½œå™¨å·²å¯åŠ¨")

        while self.is_running:
            try:
                # ç­‰å¾…ä¼ è¾“ä»»åŠ¡
                task = await asyncio.wait_for(self.transfer_queue.get(), timeout=1.0)

                # æ‰§è¡Œæ•°æ®ä¼ è¾“
                await self._execute_transfer_task(task)

            except asyncio.TimeoutError:
                # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­å¾ªç¯
                continue
            except Exception as e:
                self.logger.error("âŒ æ•°æ®ä¼ è¾“å·¥ä½œå™¨å¼‚å¸¸", error=str(e))
                await asyncio.sleep(5)  # é”™è¯¯æ—¶ç­‰å¾…5ç§’

        self.logger.info("ğŸ›‘ æ•°æ®ä¼ è¾“å·¥ä½œå™¨å·²åœæ­¢")

    async def _execute_transfer_task(self, task: DataTransferTask):
        """æ‰§è¡Œæ•°æ®ä¼ è¾“ä»»åŠ¡"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®ä¼ è¾“ä»»åŠ¡", task_id=task.task_id)

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = "running"
            task.updated_at = datetime.now(timezone.utc)

            # ä»çƒ­ç«¯æŸ¥è¯¢æ•°æ®
            hot_data = await self._query_hot_data(
                task.data_type, task.exchange, task.symbol,
                task.start_time, task.end_time
            )

            if not hot_data:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°éœ€è¦ä¼ è¾“çš„æ•°æ®", task_id=task.task_id)
                task.status = "completed"
                task.records_count = 0
                task.updated_at = datetime.now(timezone.utc)
                return

            # å­˜å‚¨åˆ°å†·ç«¯
            success = await self.store_to_cold(task.data_type, hot_data)

            if success:
                task.status = "completed"
                task.records_count = len(hot_data) if isinstance(hot_data, list) else 1
                self.stats["data_transfers"]["completed_tasks"] += 1
                self.stats["data_transfers"]["last_transfer_time"] = datetime.now(timezone.utc)

                self.logger.info("âœ… æ•°æ®ä¼ è¾“ä»»åŠ¡å®Œæˆ",
                               task_id=task.task_id,
                               records_count=task.records_count)

                # å¯é€‰ï¼šåˆ é™¤çƒ­ç«¯æ•°æ®ï¼ˆæ ¹æ®é…ç½®å†³å®šï¼‰
                # await self._cleanup_hot_data(task)

            else:
                task.status = "failed"
                task.error_message = "å†·ç«¯å­˜å‚¨å¤±è´¥"
                self.stats["data_transfers"]["failed_tasks"] += 1

                self.logger.error("âŒ æ•°æ®ä¼ è¾“ä»»åŠ¡å¤±è´¥", task_id=task.task_id)

            task.updated_at = datetime.now(timezone.utc)

        except Exception as e:
            task.status = "failed"
            task.error_message = str(e)
            task.updated_at = datetime.now(timezone.utc)
            self.stats["data_transfers"]["failed_tasks"] += 1

            self.logger.error("âŒ æ‰§è¡Œæ•°æ®ä¼ è¾“ä»»åŠ¡å¼‚å¸¸",
                            task_id=task.task_id, error=str(e))

    async def _query_hot_data(self, data_type: str, exchange: str, symbol: str,
                            start_time: datetime, end_time: datetime) -> List[Dict]:
        """ä»çƒ­ç«¯æŸ¥è¯¢æ•°æ®"""
        try:
            if not self.hot_writer:
                return []

            # æ„å»ºæŸ¥è¯¢SQL
            table_name = self._get_table_name(data_type)
            query = f"""
                SELECT * FROM {table_name}
                WHERE exchange = %(exchange)s
                AND symbol = %(symbol)s
                AND timestamp >= %(start_time)s
                AND timestamp < %(end_time)s
                ORDER BY timestamp
            """

            params = {
                'exchange': exchange,
                'symbol': symbol,
                'start_time': start_time,
                'end_time': end_time
            }

            # æ‰§è¡ŒæŸ¥è¯¢
            result = await self.hot_writer.execute_query(query, params)

            self.logger.debug("ğŸ“Š çƒ­ç«¯æ•°æ®æŸ¥è¯¢å®Œæˆ",
                            data_type=data_type,
                            exchange=exchange,
                            symbol=symbol,
                            records_count=len(result))

            return result

        except Exception as e:
            self.logger.error("âŒ çƒ­ç«¯æ•°æ®æŸ¥è¯¢å¤±è´¥", error=str(e))
            return []

    def _get_table_name(self, data_type: str) -> str:
        """è·å–æ•°æ®ç±»å‹å¯¹åº”çš„è¡¨å"""
        table_mapping = {
            "orderbook": "orderbooks",
            "trade": "trades",
            "funding_rate": "funding_rates",
            "open_interest": "open_interests",
            "liquidation": "liquidations",
            "lsr": "lsrs",
            "volatility_index": "volatility_indices"
        }
        return table_mapping.get(data_type, data_type)

    # ==================== æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç† ====================

    async def cleanup_expired_hot_data(self) -> Dict[str, Any]:
        """æ¸…ç†è¿‡æœŸçš„çƒ­ç«¯æ•°æ®"""
        try:
            self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸçƒ­ç«¯æ•°æ®")

            cutoff_time = datetime.now(timezone.utc) - timedelta(days=self.hot_config.retention_days)

            cleanup_summary = {
                "cutoff_time": cutoff_time.isoformat(),
                "tables_cleaned": {},
                "total_records_deleted": 0
            }

            # æ¸…ç†å„ç§æ•°æ®ç±»å‹çš„è¡¨
            data_types = ["orderbook", "trade", "funding_rate", "open_interest",
                         "liquidation", "lsr", "volatility_index"]

            for data_type in data_types:
                try:
                    table_name = self._get_table_name(data_type)
                    deleted_count = await self._cleanup_table_data(table_name, cutoff_time)

                    cleanup_summary["tables_cleaned"][table_name] = deleted_count
                    cleanup_summary["total_records_deleted"] += deleted_count

                    self.logger.info("âœ… è¡¨æ•°æ®æ¸…ç†å®Œæˆ",
                                   table=table_name,
                                   deleted_count=deleted_count)

                except Exception as e:
                    self.logger.error("âŒ è¡¨æ•°æ®æ¸…ç†å¤±è´¥",
                                    table=table_name, error=str(e))
                    cleanup_summary["tables_cleaned"][table_name] = f"error: {str(e)}"

            self.logger.info("âœ… çƒ­ç«¯æ•°æ®æ¸…ç†å®Œæˆ",
                           total_deleted=cleanup_summary["total_records_deleted"])

            return cleanup_summary

        except Exception as e:
            self.logger.error("âŒ æ¸…ç†è¿‡æœŸçƒ­ç«¯æ•°æ®å¤±è´¥", error=str(e))
            raise

    async def _cleanup_table_data(self, table_name: str, cutoff_time: datetime) -> int:
        """æ¸…ç†æŒ‡å®šè¡¨çš„è¿‡æœŸæ•°æ®"""
        try:
            if not self.hot_writer:
                return 0

            # æ„å»ºåˆ é™¤SQL
            delete_query = f"""
                ALTER TABLE {table_name} DELETE
                WHERE timestamp < %(cutoff_time)s
            """

            params = {'cutoff_time': cutoff_time}

            # æ‰§è¡Œåˆ é™¤
            await self.hot_writer.execute_query(delete_query, params)

            # æŸ¥è¯¢åˆ é™¤çš„è®°å½•æ•°ï¼ˆClickHouseçš„DELETEæ˜¯å¼‚æ­¥çš„ï¼Œè¿™é‡Œè¿”å›ä¼°ç®—å€¼ï¼‰
            count_query = f"""
                SELECT count() FROM {table_name}
                WHERE timestamp < %(cutoff_time)s
            """

            result = await self.hot_writer.execute_query(count_query, params)
            deleted_count = result[0]['count()'] if result else 0

            return deleted_count

        except Exception as e:
            self.logger.error("âŒ æ¸…ç†è¡¨æ•°æ®å¤±è´¥", table=table_name, error=str(e))
            return 0

    # ==================== çŠ¶æ€æŸ¥è¯¢æ–¹æ³• ====================

    def get_transfer_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼ è¾“ä»»åŠ¡çŠ¶æ€"""
        task = self.transfer_tasks.get(task_id)
        if not task:
            return None

        return {
            "task_id": task.task_id,
            "source_tier": task.source_tier.value,
            "target_tier": task.target_tier.value,
            "data_type": task.data_type,
            "exchange": task.exchange,
            "symbol": task.symbol,
            "start_time": task.start_time.isoformat(),
            "end_time": task.end_time.isoformat(),
            "status": task.status,
            "created_at": task.created_at.isoformat(),
            "updated_at": task.updated_at.isoformat(),
            "error_message": task.error_message,
            "records_count": task.records_count
        }

    def get_all_transfer_tasks(self, status_filter: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰ä¼ è¾“ä»»åŠ¡"""
        tasks = []
        for task in self.transfer_tasks.values():
            if status_filter is None or task.status == status_filter:
                tasks.append(self.get_transfer_task_status(task.task_id))

        # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
        tasks.sort(key=lambda x: x["created_at"], reverse=True)
        return tasks

    def get_storage_stats(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "hot_storage": {
                **self.stats["hot_storage"],
                "config": {
                    "host": self.hot_config.clickhouse_host,
                    "database": self.hot_config.clickhouse_database,
                    "retention_days": self.hot_config.retention_days
                },
                "status": "connected" if self.hot_writer else "disconnected"
            },
            "cold_storage": {
                **self.stats["cold_storage"],
                "config": {
                    "host": self.cold_config.clickhouse_host,
                    "database": self.cold_config.clickhouse_database,
                    "retention_days": self.cold_config.retention_days
                },
                "status": "connected" if self.cold_writer else "disconnected"
            },
            "data_transfers": {
                **self.stats["data_transfers"],
                "pending_tasks": len([t for t in self.transfer_tasks.values() if t.status == "pending"]),
                "running_tasks": len([t for t in self.transfer_tasks.values() if t.status == "running"]),
                "queue_size": self.transfer_queue.qsize()
            },
            "system": {
                "is_running": self.is_running,
                "transfer_worker_active": self.transfer_worker_task is not None and not self.transfer_worker_task.done()
            }
        }

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "components": {}
        }

        # æ£€æŸ¥çƒ­ç«¯å­˜å‚¨
        try:
            if self.hot_writer:
                await self.hot_writer.health_check()
                health_status["components"]["hot_storage"] = {"status": "healthy"}
            else:
                health_status["components"]["hot_storage"] = {"status": "not_initialized"}
        except Exception as e:
            health_status["components"]["hot_storage"] = {
                "status": "unhealthy",
                "error": str(e)
            }
            health_status["status"] = "degraded"

        # æ£€æŸ¥å†·ç«¯å­˜å‚¨
        try:
            if self.cold_writer:
                await self.cold_writer.health_check()
                health_status["components"]["cold_storage"] = {"status": "healthy"}
            else:
                health_status["components"]["cold_storage"] = {"status": "not_initialized"}
        except Exception as e:
            health_status["components"]["cold_storage"] = {
                "status": "unhealthy",
                "error": str(e)
            }
            health_status["status"] = "degraded"

        # æ£€æŸ¥ä¼ è¾“å·¥ä½œå™¨
        if self.is_running and self.transfer_worker_task and not self.transfer_worker_task.done():
            health_status["components"]["transfer_worker"] = {"status": "healthy"}
        else:
            health_status["components"]["transfer_worker"] = {"status": "stopped"}
            if health_status["status"] == "healthy":
                health_status["status"] = "degraded"

        return health_status

    # ==================== ä¾¿æ·æ–¹æ³• ====================

    async def auto_schedule_transfers(self, data_types: List[str] = None,
                                    exchanges: List[str] = None,
                                    lookback_hours: int = 24) -> List[str]:
        """è‡ªåŠ¨è°ƒåº¦æ•°æ®ä¼ è¾“ä»»åŠ¡"""
        try:
            if data_types is None:
                data_types = ["orderbook", "trade", "funding_rate", "open_interest",
                             "liquidation", "lsr", "volatility_index"]

            if exchanges is None:
                exchanges = ["binance_spot", "binance_derivatives", "okx_spot",
                           "okx_derivatives", "deribit_derivatives"]

            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now(timezone.utc)
            start_time = end_time - timedelta(hours=lookback_hours)

            task_ids = []

            for data_type in data_types:
                for exchange in exchanges:
                    # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è·å–symbolåˆ—è¡¨
                    # æš‚æ—¶ä½¿ç”¨é€šç”¨symbol
                    symbol = "BTC-USDT"  # å¯ä»¥ä»é…ç½®æˆ–æ•°æ®åº“è·å–

                    try:
                        task_id = await self.schedule_data_transfer(
                            data_type, exchange, symbol, start_time, end_time
                        )
                        task_ids.append(task_id)
                    except Exception as e:
                        self.logger.error("âŒ è‡ªåŠ¨è°ƒåº¦ä¼ è¾“ä»»åŠ¡å¤±è´¥",
                                        data_type=data_type,
                                        exchange=exchange,
                                        error=str(e))

            self.logger.info("âœ… è‡ªåŠ¨è°ƒåº¦ä¼ è¾“ä»»åŠ¡å®Œæˆ",
                           scheduled_tasks=len(task_ids),
                           lookback_hours=lookback_hours)

            return task_ids

        except Exception as e:
            self.logger.error("âŒ è‡ªåŠ¨è°ƒåº¦ä¼ è¾“ä»»åŠ¡å¤±è´¥", error=str(e))
            return []
