services:
  redis:
    image: redis:7-alpine
    container_name: marketprism-redis
    ports:
      - "6379:6379"
    networks:
      - marketprism-network
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3

  postgres:
    image: postgres:15-alpine
    container_name: marketprism-postgres
    ports:
      - "5432:5432"
    networks:
      - marketprism-network
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 3

  nats:
    image: nats:2-alpine
    container_name: marketprism-nats
    ports:
      - "4222:4222"
      - "8222:8222"
    networks:
      - marketprism-network
    restart: unless-stopped
    command: ["-js", "-m", "8222"]
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:8222/healthz || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  prometheus:
    image: prom/prometheus:latest
    container_name: marketprism-prometheus
    ports:
      - "9090:9090"
    networks:
      - marketprism-network
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Grafana仪表板
  grafana:
    image: grafana/grafana:10.1.0
    container_name: marketprism-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    depends_on:
      prometheus:
        condition: service_healthy
    networks:
      - marketprism-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ClickHouse 数据库服务
  clickhouse:
    image: clickhouse/clickhouse-server:24.3-alpine
    container_name: marketprism-clickhouse
    ports:
      - "8123:8123"  # HTTP接口
      - "9000:9000"  # Native接口
    networks:
      - marketprism-network
    restart: unless-stopped
    environment:
      CLICKHOUSE_DB: ${CLICKHOUSE_DB:-marketprism}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-default}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
      - ./scripts/clickhouse:/docker-entrypoint-initdb.d
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # 监控告警服务
  monitoring-alerting:
    build:
      context: .
      dockerfile: services/monitoring-alerting-service/Dockerfile
    container_name: marketprism-monitoring-alerting
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - PROMETHEUS_URL=http://prometheus:9090
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_PORT=${API_PORT:-8082}
    ports:
      - "${API_PORT:-8082}:8082"
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      prometheus:
        condition: service_healthy
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # 统一日志配置
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=monitoring-alerting,environment=${ENVIRONMENT:-staging}"

  # 热数据存储服务
  data-storage-hot:
    build:
      context: .
      dockerfile: services/data-storage-service/Dockerfile
    container_name: marketprism-data-storage-hot
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - STORAGE_MODE=hot
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-default}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-}
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DB:-marketprism}
      - COLD_CLICKHOUSE_HOST=${COLD_CLICKHOUSE_HOST:-nas-clickhouse}
      - COLD_CLICKHOUSE_PORT=${COLD_CLICKHOUSE_PORT:-8123}
      - COLD_CLICKHOUSE_DATABASE=${COLD_CLICKHOUSE_DB:-marketprism_cold}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_PORT=8083
    ports:
      - "8083:8083"
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # 冷数据存储服务（用于测试，生产环境部署在NAS上）
  data-storage-cold:
    build:
      context: .
      dockerfile: services/data-storage-service/Dockerfile
    container_name: marketprism-data-storage-cold
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - STORAGE_MODE=cold
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      # 修复ClickHouse连接配置
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-default}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-}
      - CLICKHOUSE_DATABASE=marketprism_cold
      # 添加环境变量覆盖配置
      - MARKETPRISM_CLICKHOUSE_HOST=clickhouse
      - MARKETPRISM_CLICKHOUSE_PORT=8123
      - MARKETPRISM_CLICKHOUSE_DATABASE=marketprism_cold
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_PORT=8087  # 修复端口冲突：从8083改为8087
    ports:
      - "8087:8087"  # 修复端口冲突：从8083改为8087
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      - clickhouse
      - postgres
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8087/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s



  # API网关服务
  api-gateway:
    build:
      context: .
      dockerfile: services/api-gateway-service/Dockerfile
    container_name: marketprism-api-gateway
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/2
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_PORT=8080
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-marketprism_jwt_secret}
    ports:
      - "8080:8080"
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      - redis
      - monitoring-alerting
      - data-storage-hot
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # 统一日志配置
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=api-gateway,environment=${ENVIRONMENT:-staging}"

  # 数据收集器服务
  data-collector:
    build:
      context: .
      dockerfile: services/data-collector/Dockerfile
    container_name: marketprism-data-collector
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/3
      - NATS_URL=nats://nats:4222
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_PORT=8084
    ports:
      - "8084:8084"
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      - redis
      - postgres
      - data-storage-hot
      - nats
    networks:
      - marketprism-network
    # 统一日志配置
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=data-collector,environment=${ENVIRONMENT:-staging}"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # 订单簿管理系统
  orderbook-manager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: marketprism-orderbook-manager
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - MARKETPRISM_LOG_LEVEL=${MARKETPRISM_LOG_LEVEL:-INFO}
      - NATS_SERVERS=nats://nats:4222
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-default}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-}
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DB:-marketprism}
      - BINANCE_API_KEY=${BINANCE_API_KEY}
      - BINANCE_API_SECRET=${BINANCE_API_SECRET}
      - OKX_API_KEY=${OKX_API_KEY}
      - OKX_API_SECRET=${OKX_API_SECRET}
      - OKX_PASSPHRASE=${OKX_PASSPHRASE}
      - PROMETHEUS_PORT=8081
      - HEALTH_CHECK_PORT=8085  # 修复端口冲突：从8080改为8085
      - HTTP_PROXY=${HTTP_PROXY:-}
      - HTTPS_PROXY=${HTTPS_PROXY:-}
    ports:
      - "8085:8085"  # 修复端口冲突：健康检查端口从8080改为8085
      - "8081:8081"  # Prometheus指标端口
    volumes:
      - ./logs:/var/log/marketprism
      - ./data:/app/data
      - ./config:/app/config:ro
    depends_on:
      nats:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      prometheus:
        condition: service_healthy
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/health"]  # 修复健康检查端口
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=orderbook-manager,environment=${ENVIRONMENT:-staging}"

  # 任务工作者服务
  task-worker:
    build:
      context: .
      dockerfile: services/task-worker-service/Dockerfile
    container_name: marketprism-task-worker
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - NATS_URL=nats://nats:4222
      - WORKER_TYPE=general
      - MAX_CONCURRENT_TASKS=5
    ports:
      - "8090:8090"
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      nats:
        condition: service_started
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # 消息代理服务
  message-broker:
    build:
      context: .
      dockerfile: services/message-broker-service/Dockerfile
    container_name: marketprism-message-broker
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-staging}
      - CONFIG_FACTORY_ENABLED=${CONFIG_FACTORY_ENABLED:-true}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/5
      - NATS_URL=nats://nats:4222
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - API_PORT=8086
    ports:
      - "8086:8086"
    volumes:
      - ./config:/app/config:ro
      - ./core:/app/core:ro
    depends_on:
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    networks:
      - marketprism-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s







volumes:
  redis_data:
    driver: local
  postgres_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  clickhouse_data:
    driver: local
  clickhouse_logs:
    driver: local

networks:
  marketprism-network:
    driver: bridge