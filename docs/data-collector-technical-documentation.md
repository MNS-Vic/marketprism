# MarketPrism Data Collector Service æŠ€æœ¯æ–‡æ¡£

## ç›®å½•

1. [APIæ–‡æ¡£](#1-apiæ–‡æ¡£)
   - [1.1 APIæ¦‚è¿°](#11-apiæ¦‚è¿°)
   - [1.2 ç»Ÿä¸€å“åº”æ ¼å¼](#12-ç»Ÿä¸€å“åº”æ ¼å¼)
   - [1.3 æ ‡å‡†åŒ–é”™è¯¯ä»£ç ](#13-æ ‡å‡†åŒ–é”™è¯¯ä»£ç )
   - [1.4 APIç«¯ç‚¹è¯¦ç»†è¯´æ˜](#14-apiç«¯ç‚¹è¯¦ç»†è¯´æ˜)
   - [1.5 å¥åº·æ£€æŸ¥API](#15-å¥åº·æ£€æŸ¥api)

2. [æ¶æ„æ–‡æ¡£](#2-æ¶æ„æ–‡æ¡£)
   - [2.1 æ•´ä½“æ¶æ„è®¾è®¡](#21-æ•´ä½“æ¶æ„è®¾è®¡)
   - [2.2 æ ¸å¿ƒç»„ä»¶](#22-æ ¸å¿ƒç»„ä»¶)
   - [2.3 BaseServiceæ¡†æ¶é›†æˆ](#23-baseserviceæ¡†æ¶é›†æˆ)
   - [2.4 æ•°æ®æµå¤„ç†](#24-æ•°æ®æµå¤„ç†)
   - [2.5 é…ç½®ç®¡ç†](#25-é…ç½®ç®¡ç†)

3. [éƒ¨ç½²æ–‡æ¡£](#3-éƒ¨ç½²æ–‡æ¡£)
   - [3.1 Dockerå®¹å™¨éƒ¨ç½²](#31-dockerå®¹å™¨éƒ¨ç½²)
   - [3.2 ç¯å¢ƒå˜é‡é…ç½®](#32-ç¯å¢ƒå˜é‡é…ç½®)
   - [3.3 ç½‘ç»œè®¾ç½®](#33-ç½‘ç»œè®¾ç½®)
   - [3.4 å¥åº·æ£€æŸ¥å’Œç›‘æ§](#34-å¥åº·æ£€æŸ¥å’Œç›‘æ§)
   - [3.5 æ•…éšœæ’é™¤](#35-æ•…éšœæ’é™¤)

4. [å¼€å‘æ–‡æ¡£](#4-å¼€å‘æ–‡æ¡£)
   - [4.1 ä»£ç ç»“æ„ä¼˜åŒ–](#41-ä»£ç ç»“æ„ä¼˜åŒ–)
   - [4.2 é”™è¯¯å¤„ç†æœºåˆ¶](#42-é”™è¯¯å¤„ç†æœºåˆ¶)
   - [4.3 æ—¥å¿—è®°å½•æ ‡å‡†](#43-æ—¥å¿—è®°å½•æ ‡å‡†)
   - [4.4 æ€§èƒ½ä¼˜åŒ–æªæ–½](#44-æ€§èƒ½ä¼˜åŒ–æªæ–½)
   - [4.5 ä»£ç ç»´æŠ¤å’Œæ‰©å±•æŒ‡å—](#45-ä»£ç ç»´æŠ¤å’Œæ‰©å±•æŒ‡å—)

---

## 1. APIæ–‡æ¡£

### 1.1 APIæ¦‚è¿°

MarketPrism Data Collector Serviceæä¾›RESTful APIæ¥å£ï¼Œç”¨äºè·å–æ•°æ®æ”¶é›†æœåŠ¡çš„çŠ¶æ€ã€ç»Ÿè®¡ä¿¡æ¯å’Œæ”¶é›†çš„å¸‚åœºæ•°æ®ã€‚æ‰€æœ‰APIç«¯ç‚¹éƒ½éµå¾ªç»Ÿä¸€çš„å“åº”æ ¼å¼æ ‡å‡†ã€‚

**åŸºç¡€URL**: `http://localhost:8084`

**æ”¯æŒçš„HTTPæ–¹æ³•**: GET

**å†…å®¹ç±»å‹**: `application/json`

### 1.2 ç»Ÿä¸€å“åº”æ ¼å¼

#### æˆåŠŸå“åº”æ ¼å¼
```json
{
  "status": "success",
  "message": "æ“ä½œæè¿°ä¿¡æ¯",
  "data": {
    // å…·ä½“æ•°æ®å†…å®¹
  },
  "timestamp": "2025-06-29T04:07:49.066285+00:00"
}
```

#### é”™è¯¯å“åº”æ ¼å¼
```json
{
  "status": "error",
  "error_code": "ERROR_CODE",
  "message": "é”™è¯¯æè¿°ä¿¡æ¯",
  "data": null,
  "timestamp": "2025-06-29T04:07:49.066285+00:00"
}
```

### 1.3 æ ‡å‡†åŒ–é”™è¯¯ä»£ç 

| é”™è¯¯ä»£ç  | HTTPçŠ¶æ€ç  | æè¿° |
|---------|-----------|------|
| `COLLECTOR_NOT_INITIALIZED` | 503 | æ•°æ®æ”¶é›†å™¨æœªåˆå§‹åŒ– |
| `STATS_UNAVAILABLE` | 500 | ç»Ÿè®¡ä¿¡æ¯æš‚æ—¶ä¸å¯ç”¨ |
| `EXCHANGE_STATUS_ERROR` | 500 | äº¤æ˜“æ‰€çŠ¶æ€è·å–å¤±è´¥ |
| `DATA_RETRIEVAL_ERROR` | 500 | æ•°æ®æ£€ç´¢å¤±è´¥ |
| `INVALID_PARAMETERS` | 400 | è¯·æ±‚å‚æ•°æ— æ•ˆ |
| `SERVICE_UNAVAILABLE` | 503 | æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ |
| `INTERNAL_ERROR` | 500 | å†…éƒ¨æœåŠ¡å™¨é”™è¯¯ |

### 1.4 APIç«¯ç‚¹è¯¦ç»†è¯´æ˜

#### 1.4.1 æœåŠ¡çŠ¶æ€API

**ç«¯ç‚¹**: `GET /api/v1/status`

**æè¿°**: è·å–BaseServiceå…¼å®¹çš„æœåŠ¡çŠ¶æ€ä¿¡æ¯

**è¯·æ±‚å‚æ•°**: æ— 

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "success",
  "message": "Service status retrieved successfully",
  "data": {
    "service": "data-collector",
    "status": "running",
    "uptime_seconds": 62.44,
    "version": "1.0.0",
    "environment": "production",
    "features": {
      "collector_initialized": true,
      "orderbook_enabled": true,
      "websocket_enabled": true,
      "normalizer_enabled": true
    },
    "supported_exchanges": ["binance", "okx", "deribit"],
    "collection_stats": {
      "total_collections": 1041,
      "error_count": 0,
      "last_collection_time": "2025-06-29T04:07:46.642797+00:00",
      "data_counts": {
        "tickers": 19,
        "orderbooks": 6,
        "trades": 0
      }
    }
  },
  "timestamp": "2025-06-29T04:07:49.066285+00:00"
}
```

**æ•°æ®å­—æ®µè¯´æ˜**:
- `service`: æœåŠ¡åç§°
- `status`: æœåŠ¡è¿è¡ŒçŠ¶æ€ (running/initializing)
- `uptime_seconds`: æœåŠ¡è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
- `version`: æœåŠ¡ç‰ˆæœ¬å·
- `environment`: è¿è¡Œç¯å¢ƒ
- `features`: åŠŸèƒ½ç‰¹æ€§çŠ¶æ€
- `supported_exchanges`: æ”¯æŒçš„äº¤æ˜“æ‰€åˆ—è¡¨
- `collection_stats`: åŸºç¡€æ”¶é›†ç»Ÿè®¡ä¿¡æ¯

#### 1.4.2 æ”¶é›†å™¨ç»Ÿè®¡API

**ç«¯ç‚¹**: `GET /api/v1/collector/stats`

**æè¿°**: è·å–è¯¦ç»†çš„æ•°æ®æ”¶é›†ç»Ÿè®¡ä¿¡æ¯

**è¯·æ±‚å‚æ•°**: æ— 

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "success",
  "message": "Collection statistics retrieved successfully",
  "data": {
    "collection_stats": {
      "rest_requests": 31,
      "websocket_messages": 1186,
      "errors": 0,
      "last_update": "2025-06-29T03:57:59.372145+00:00",
      "active_sources": 2,
      "websocket_connections": 2
    },
    "service_stats": {
      "uptime_seconds": 52.64,
      "total_collections": 729,
      "error_count": 0,
      "last_collection_time": "2025-06-29T03:57:57.118727+00:00",
      "success_rate": 100.0
    },
    "data_summary": {
      "tickers_count": 19,
      "orderbooks_count": 6,
      "trades_count": 0,
      "total_data_points": 25
    },
    "performance_metrics": {
      "collections_per_minute": 990.14,
      "memory_usage_mb": 0.01
    }
  },
  "timestamp": "2025-06-29T04:07:49.742581+00:00"
}
```

**æ•°æ®å­—æ®µè¯´æ˜**:
- `collection_stats`: æ”¶é›†å™¨åŸå§‹ç»Ÿè®¡ä¿¡æ¯
- `service_stats`: æœåŠ¡çº§åˆ«ç»Ÿè®¡ä¿¡æ¯
- `data_summary`: æ•°æ®æ‘˜è¦ç»Ÿè®¡
- `performance_metrics`: æ€§èƒ½æŒ‡æ ‡

#### 1.4.3 æ”¶é›†å™¨è¯¦ç»†çŠ¶æ€API

**ç«¯ç‚¹**: `GET /api/v1/collector/status`

**æè¿°**: è·å–æ•°æ®æ”¶é›†å™¨çš„è¯¦ç»†çŠ¶æ€ä¿¡æ¯

**è¯·æ±‚å‚æ•°**: æ— 

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "success",
  "message": "Detailed status retrieved successfully",
  "data": {
    "service_info": {
      "name": "data-collector",
      "version": "1.0.0",
      "uptime_seconds": 66.54,
      "initialized": true,
      "start_time": "2025-06-29T04:06:47.095000+00:00",
      "environment": "production",
      "process_id": 1
    },
    "feature_status": {
      "collector_initialized": true,
      "orderbook_enabled": true,
      "websocket_enabled": true,
      "normalizer_enabled": true,
      "orderbook_manager_active": false
    },
    "collector_stats": {
      "rest_requests": 16,
      "websocket_messages": 683,
      "errors": 0,
      "last_update": "2025-06-29T03:57:59.372145+00:00",
      "active_sources": 2,
      "websocket_connections": 2
    },
    "exchanges": {
      "binance": {
        "enabled": true,
        "websocket_connected": true,
        "rest_api_available": true,
        "last_update": "2025-06-29T04:07:53.542387+00:00",
        "status": "active"
      },
      "okx": {
        "enabled": true,
        "websocket_connected": true,
        "rest_api_available": true,
        "last_update": "2025-06-29T04:07:53.542387+00:00",
        "status": "active"
      },
      "deribit": {
        "enabled": true,
        "websocket_connected": true,
        "rest_api_available": true,
        "last_update": "2025-06-29T04:07:53.542387+00:00",
        "status": "active"
      }
    },
    "data_summary": {
      "tickers": 19,
      "orderbooks": 6,
      "trades": 0,
      "total_data_points": 25
    },
    "health_indicators": {
      "overall_health": "healthy",
      "data_flow_active": true,
      "error_rate": 0.0,
      "last_activity": "2025-06-29T04:07:53.120554+00:00"
    }
  },
  "timestamp": "2025-06-29T04:07:53.550272+00:00"
}
```

#### 1.4.4 äº¤æ˜“æ‰€çŠ¶æ€API

**ç«¯ç‚¹**: `GET /api/v1/collector/exchanges`

**æè¿°**: è·å–æ‰€æœ‰æ”¯æŒäº¤æ˜“æ‰€çš„è¿æ¥çŠ¶æ€

**è¯·æ±‚å‚æ•°**: æ— 

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "success",
  "message": "Exchange status retrieved successfully",
  "data": {
    "exchanges": {
      "binance": {
        "enabled": true,
        "websocket_connected": true,
        "rest_api_available": true,
        "last_update": "2025-06-29T04:08:19.358928+00:00",
        "status": "active"
      },
      "okx": {
        "enabled": true,
        "websocket_connected": true,
        "rest_api_available": true,
        "last_update": "2025-06-29T04:08:19.358928+00:00",
        "status": "active"
      },
      "deribit": {
        "enabled": true,
        "websocket_connected": true,
        "rest_api_available": true,
        "last_update": "2025-06-29T04:08:19.358928+00:00",
        "status": "active"
      }
    },
    "summary": {
      "total_exchanges": 3,
      "active_exchanges": 3,
      "websocket_connections": 3,
      "rest_api_available": 3
    },
    "last_updated": "2025-06-29T04:08:19.358928+00:00"
  },
  "timestamp": "2025-06-29T04:08:19.358928+00:00"
}
```

#### 1.4.5 æ”¶é›†æ•°æ®API

**ç«¯ç‚¹**: `GET /api/v1/collector/data`

**æè¿°**: è·å–æ”¶é›†çš„æ•°æ®æ‘˜è¦å’Œæœ€è¿‘æ•°æ®

**è¯·æ±‚å‚æ•°**:
| å‚æ•° | ç±»å‹ | å¿…éœ€ | é»˜è®¤å€¼ | æè¿° |
|------|------|------|--------|------|
| `exchange` | string | å¦ | `all` | äº¤æ˜“æ‰€åç§° (all, binance, okx, deribit) |
| `type` | string | å¦ | `all` | æ•°æ®ç±»å‹ (all, tickers, orderbooks, trades) |
| `limit` | integer | å¦ | `10` | è¿”å›è®°å½•æ•°é™åˆ¶ (1-100) |

**è¯·æ±‚ç¤ºä¾‹**:
```
GET /api/v1/collector/data?exchange=binance&type=tickers&limit=5
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "success",
  "message": "Collected data retrieved successfully",
  "data": {
    "query_parameters": {
      "exchange": "all",
      "type": "all",
      "limit": 10
    },
    "summary": {
      "total_tickers": 19,
      "total_orderbooks": 6,
      "total_trades": 0,
      "total_data_points": 25,
      "last_update": "2025-06-29T04:08:16.643227+00:00",
      "collection_stats": {
        "total_collections": 1722,
        "error_count": 0
      }
    },
    "recent_data": {
      "tickers": {
        "binance:BTCUSDT": {
          "symbol": "BTCUSDT",
          "price": "95234.56",
          "timestamp": "2025-06-29T04:08:16.643227+00:00"
        }
      },
      "orderbooks": {
        "binance:BTCUSDT": {
          "symbol": "BTCUSDT",
          "bids": [["95234.56", "0.123"]],
          "asks": [["95235.67", "0.456"]],
          "timestamp": "2025-06-29T04:08:16.643227+00:00"
        }
      }
    },
    "metadata": {
      "generated_at": "2025-06-29T04:08:19.367315+00:00",
      "data_freshness_seconds": 2.724088
    }
  },
  "timestamp": "2025-06-29T04:08:19.367315+00:00"
}
```

**é”™è¯¯å“åº”ç¤ºä¾‹**:
```json
{
  "status": "error",
  "error_code": "INVALID_PARAMETERS",
  "message": "Limit parameter must be between 1 and 100",
  "data": null,
  "timestamp": "2025-06-29T04:08:04.367315+00:00"
}
```

### 1.5 å¥åº·æ£€æŸ¥API

**ç«¯ç‚¹**: `GET /health`

**æè¿°**: BaseServiceæ¡†æ¶æä¾›çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹

**å“åº”ç¤ºä¾‹**:
```json
{
  "service": "data-collector",
  "status": "healthy",
  "timestamp": "2025-06-29T04:07:49.058462",
  "uptime_seconds": 62.446174,
  "checks": {
    "service_status": {
      "status": "pass",
      "result": "running"
    }
  }
}
```

---

## 2. æ¶æ„æ–‡æ¡£

### 2.1 æ•´ä½“æ¶æ„è®¾è®¡

MarketPrism Data Collector Serviceé‡‡ç”¨å¾®æœåŠ¡æ¶æ„ï¼ŒåŸºäºBaseServiceæ¡†æ¶æ„å»ºï¼Œæä¾›å¤šäº¤æ˜“æ‰€æ•°æ®æ”¶é›†ã€å®æ—¶æ•°æ®å¤„ç†å’ŒAPIæœåŠ¡åŠŸèƒ½ã€‚

```mermaid
graph TB
    subgraph "Data Collector Service"
        API[API Gateway]
        DC[Data Collector]
        DN[Data Normalizer]
        OM[OrderBook Manager]
        SM[Stats Manager]
    end

    subgraph "External Data Sources"
        BE[Binance Exchange]
        OE[OKX Exchange]
        DE[Deribit Exchange]
    end

    subgraph "Internal Services"
        NATS[NATS Message Queue]
        CH[ClickHouse Database]
        PROM[Prometheus Metrics]
    end

    BE --> DC
    OE --> DC
    DE --> DC

    DC --> DN
    DN --> OM
    DC --> SM

    API --> DC
    API --> SM

    DC --> NATS
    OM --> NATS
    SM --> PROM
```

### 2.2 æ ¸å¿ƒç»„ä»¶

#### 2.2.1 DataCollectorService (ä¸»æœåŠ¡ç±»)
- **èŒè´£**: æœåŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€APIè·¯ç”±è®¾ç½®ã€ç»„ä»¶åè°ƒ
- **ç»§æ‰¿**: BaseServiceæ¡†æ¶
- **åŠŸèƒ½**:
  - ç»Ÿä¸€çš„æœåŠ¡å¯åŠ¨å’Œå…³é—­æµç¨‹
  - APIç«¯ç‚¹æ³¨å†Œå’Œç®¡ç†
  - é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
  - å¥åº·æ£€æŸ¥å’Œç›‘æ§æŒ‡æ ‡

#### 2.2.2 PublicDataCollector (æ•°æ®æ”¶é›†å™¨)
- **èŒè´£**: å¤šäº¤æ˜“æ‰€æ•°æ®æ”¶é›†
- **åŠŸèƒ½**:
  - REST APIæ•°æ®è·å–
  - WebSocketå®æ—¶æ•°æ®æµ
  - æ•°æ®å›è°ƒå¤„ç†
  - è¿æ¥çŠ¶æ€ç®¡ç†

#### 2.2.3 DataNormalizer (æ•°æ®æ ‡å‡†åŒ–å™¨)
- **èŒè´£**: æ•°æ®æ ¼å¼æ ‡å‡†åŒ–
- **åŠŸèƒ½**:
  - å¤šäº¤æ˜“æ‰€æ•°æ®æ ¼å¼ç»Ÿä¸€
  - æ•°æ®ç±»å‹è½¬æ¢
  - æ—¶é—´æˆ³æ ‡å‡†åŒ–

#### 2.2.4 OrderBookManager (è®¢å•ç°¿ç®¡ç†å™¨)
- **èŒè´£**: è®¢å•ç°¿å¢é‡ç»´æŠ¤
- **åŠŸèƒ½**:
  - è®¢å•ç°¿å¿«ç…§è·å–
  - å¢é‡æ›´æ–°å¤„ç†
  - æ•°æ®å®Œæ•´æ€§éªŒè¯

### 2.3 BaseServiceæ¡†æ¶é›†æˆ

#### 2.3.1 ç»§æ‰¿å…³ç³»
```python
class DataCollectorService(BaseService):
    def __init__(self, config: Dict[str, Any]):
        super().__init__("data-collector", config)
```

#### 2.3.2 æ¡†æ¶æä¾›çš„åŠŸèƒ½
- **ç”Ÿå‘½å‘¨æœŸç®¡ç†**: `on_startup()`, `on_shutdown()`
- **HTTPæœåŠ¡å™¨**: aiohttpåº”ç”¨å’Œè·¯ç”±ç®¡ç†
- **å¥åº·æ£€æŸ¥**: `/health`ç«¯ç‚¹
- **ç›‘æ§æŒ‡æ ‡**: `/metrics`ç«¯ç‚¹
- **æ—¥å¿—ç³»ç»Ÿ**: ç»“æ„åŒ–æ—¥å¿—è®°å½•

#### 2.3.3 è‡ªå®šä¹‰æ‰©å±•
- **APIè·¯ç”±**: `setup_routes()`æ–¹æ³•ä¸­æ³¨å†Œè‡ªå®šä¹‰ç«¯ç‚¹
- **å“åº”æ ¼å¼**: ç»Ÿä¸€çš„æˆåŠŸå’Œé”™è¯¯å“åº”æ–¹æ³•
- **é”™è¯¯å¤„ç†**: æ ‡å‡†åŒ–é”™è¯¯ä»£ç å’ŒHTTPçŠ¶æ€ç 

### 2.4 æ•°æ®æµå¤„ç†

#### 2.4.1 æ•°æ®æ”¶é›†æµç¨‹
```mermaid
sequenceDiagram
    participant E as Exchange
    participant DC as DataCollector
    participant DN as DataNormalizer
    participant NATS as NATS Queue
    participant API as API Client

    E->>DC: Market Data (REST/WebSocket)
    DC->>DN: Raw Data
    DN->>DC: Normalized Data
    DC->>NATS: Publish Message
    DC->>DC: Store in Memory
    API->>DC: Request Data
    DC->>API: Response with Data
```

#### 2.4.2 æ•°æ®å¤„ç†æ­¥éª¤
1. **æ•°æ®æ¥æ”¶**: ä»äº¤æ˜“æ‰€æ¥æ”¶åŸå§‹å¸‚åœºæ•°æ®
2. **æ•°æ®æ ‡å‡†åŒ–**: ç»Ÿä¸€æ•°æ®æ ¼å¼å’Œç»“æ„
3. **æ•°æ®å­˜å‚¨**: ä¸´æ—¶å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼ˆé™åˆ¶1000æ¡è®°å½•ï¼‰
4. **æ•°æ®å‘å¸ƒ**: æ¨é€åˆ°NATSæ¶ˆæ¯é˜Ÿåˆ—
5. **APIæœåŠ¡**: é€šè¿‡REST APIæä¾›æ•°æ®è®¿é—®

### 2.5 é…ç½®ç®¡ç†

#### 2.5.1 é…ç½®æ–‡ä»¶å±‚æ¬¡
```
config/
â”œâ”€â”€ public_data_sources.yaml    # æ•°æ®æºé…ç½®
â”œâ”€â”€ exchanges.yaml              # äº¤æ˜“æ‰€é…ç½®
â””â”€â”€ service.yaml               # æœåŠ¡é…ç½®
```

#### 2.5.2 ç¯å¢ƒå˜é‡æ”¯æŒ
- `ENVIRONMENT`: è¿è¡Œç¯å¢ƒ (production/staging/development)
- `API_PORT`: APIæœåŠ¡ç«¯å£ (é»˜è®¤8084)
- `LOG_LEVEL`: æ—¥å¿—çº§åˆ« (INFO/DEBUG/WARNING/ERROR)
- `ENABLE_ORDERBOOK`: å¯ç”¨OrderBookåŠŸèƒ½
- `ENABLE_WEBSOCKET`: å¯ç”¨WebSocketè¿æ¥

#### 2.5.3 Dockerå®¹å™¨é€‚é…
- å¤šè·¯å¾„é…ç½®æ–‡ä»¶æŸ¥æ‰¾
- å®¹å™¨ç¯å¢ƒè·¯å¾„è‡ªåŠ¨é€‚é…
- é…ç½®æ–‡ä»¶ç¼ºå¤±æ—¶çš„ä¼˜é›…é™çº§

---

## 3. éƒ¨ç½²æ–‡æ¡£

### 3.1 Dockerå®¹å™¨éƒ¨ç½²

#### 3.1.1 Dockerfileé…ç½®
```dockerfile
FROM python:3.12-slim

LABEL maintainer="MarketPrism Team"
LABEL description="MarketPrism Pythonæ•°æ®æ”¶é›†å™¨"
LABEL version="1.0.0"

ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONPATH=/app
ENV RATE_LIMIT_ENABLED=true
ENV API_TIMEOUT=15
ENV LOG_LEVEL=INFO

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY services/data-collector/ ./services/data-collector/
COPY core/ ./core/
COPY config/ ./config/

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 collector && \
    chown -R collector:collector /app
USER collector

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:8084/health || exit 1

EXPOSE 8084

CMD ["python", "services/data-collector/main.py"]
```

#### 3.1.2 æ„å»ºå’Œè¿è¡Œå‘½ä»¤
```bash
# æ„å»ºé•œåƒ
docker build -t marketprism_data-collector:latest -f services/data-collector/Dockerfile .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name marketprism-data-collector \
  --network marketprism_marketprism-network \
  -p 8084:8084 \
  -e ENVIRONMENT=production \
  -e API_PORT=8084 \
  -e LOG_LEVEL=INFO \
  -e ENABLE_ORDERBOOK=true \
  -e ENABLE_WEBSOCKET=true \
  marketprism_data-collector:latest
```

### 3.2 ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | æè¿° |
|--------|--------|------|
| `ENVIRONMENT` | `production` | è¿è¡Œç¯å¢ƒ |
| `API_PORT` | `8084` | APIæœåŠ¡ç«¯å£ |
| `LOG_LEVEL` | `INFO` | æ—¥å¿—çº§åˆ« |
| `ENABLE_ORDERBOOK` | `true` | å¯ç”¨OrderBookåŠŸèƒ½ |
| `ENABLE_WEBSOCKET` | `true` | å¯ç”¨WebSocketè¿æ¥ |
| `COLLECTION_INTERVAL` | `30` | æ•°æ®æ”¶é›†é—´éš”ï¼ˆç§’ï¼‰ |
| `PYTHONPATH` | `/app` | Pythonè·¯å¾„ |
| `PYTHONUNBUFFERED` | `1` | Pythonè¾“å‡ºç¼“å†² |

### 3.3 ç½‘ç»œè®¾ç½®

#### 3.3.1 Dockerç½‘ç»œé…ç½®
```bash
# åˆ›å»ºä¸“ç”¨ç½‘ç»œ
docker network create marketprism_marketprism-network

# æŸ¥çœ‹ç½‘ç»œä¿¡æ¯
docker network inspect marketprism_marketprism-network
```

#### 3.3.2 ç«¯å£æ˜ å°„
- **8084**: APIæœåŠ¡ç«¯å£
- **å†…éƒ¨é€šä¿¡**: é€šè¿‡Dockerç½‘ç»œè¿›è¡ŒæœåŠ¡é—´é€šä¿¡

#### 3.3.3 æœåŠ¡å‘ç°
- å®¹å™¨åç§°: `marketprism-data-collector`
- ç½‘ç»œåˆ«å: `data-collector`
- å†…éƒ¨è®¿é—®: `http://data-collector:8084`

### 3.4 å¥åº·æ£€æŸ¥å’Œç›‘æ§

#### 3.4.1 Dockerå¥åº·æ£€æŸ¥
```bash
# æ£€æŸ¥å®¹å™¨å¥åº·çŠ¶æ€
docker ps --filter "name=data-collector" --format "table {{.Names}}\t{{.Status}}"

# æŸ¥çœ‹å¥åº·æ£€æŸ¥æ—¥å¿—
docker inspect marketprism-data-collector | jq '.[0].State.Health'
```

#### 3.4.2 APIå¥åº·æ£€æŸ¥
```bash
# åŸºç¡€å¥åº·æ£€æŸ¥
curl -f http://localhost:8084/health

# è¯¦ç»†çŠ¶æ€æ£€æŸ¥
curl -s http://localhost:8084/api/v1/status | jq '.data.status'
```

#### 3.4.3 Prometheusç›‘æ§
```bash
# è·å–ç›‘æ§æŒ‡æ ‡
curl http://localhost:8084/metrics
```

### 3.5 æ•…éšœæ’é™¤

#### 3.5.1 å¸¸è§é—®é¢˜è¯Šæ–­

**1. å®¹å™¨å¯åŠ¨å¤±è´¥**
```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs marketprism-data-collector --tail 50

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker ps -a --filter "name=data-collector"
```

**2. APIæ— å“åº”**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep :8084

# æµ‹è¯•ç½‘ç»œè¿æ¥
curl -v http://localhost:8084/health
```

**3. æ•°æ®æ”¶é›†å¼‚å¸¸**
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker logs -f marketprism-data-collector

# æ£€æŸ¥æ”¶é›†ç»Ÿè®¡
curl -s http://localhost:8084/api/v1/collector/stats | jq '.data.service_stats'
```

#### 3.5.2 æ—¥å¿—åˆ†æ

**æ—¥å¿—çº§åˆ«è¯´æ˜**:
- `DEBUG`: è¯¦ç»†è°ƒè¯•ä¿¡æ¯
- `INFO`: ä¸€èˆ¬ä¿¡æ¯è®°å½•
- `WARNING`: è­¦å‘Šä¿¡æ¯
- `ERROR`: é”™è¯¯ä¿¡æ¯

**å…³é”®æ—¥å¿—æ¨¡å¼**:
```bash
# è¿‡æ»¤é”™è¯¯æ—¥å¿—
docker logs marketprism-data-collector 2>&1 | grep ERROR

# è¿‡æ»¤æ•°æ®æ”¶é›†æ—¥å¿—
docker logs marketprism-data-collector 2>&1 | grep "æ•°æ®æ”¶é›†"

# è¿‡æ»¤APIè®¿é—®æ—¥å¿—
docker logs marketprism-data-collector 2>&1 | grep "aiohttp.access"
```

#### 3.5.3 æ€§èƒ½ç›‘æ§

**å†…å­˜ä½¿ç”¨ç›‘æ§**:
```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats marketprism-data-collector --no-stream

# è·å–å†…å­˜ä½¿ç”¨æŒ‡æ ‡
curl -s http://localhost:8084/api/v1/collector/stats | jq '.data.performance_metrics.memory_usage_mb'
```

**æ•°æ®æ”¶é›†æ€§èƒ½**:
```bash
# è·å–æ”¶é›†é¢‘ç‡
curl -s http://localhost:8084/api/v1/collector/stats | jq '.data.performance_metrics.collections_per_minute'

# è·å–é”™è¯¯ç‡
curl -s http://localhost:8084/api/v1/collector/status | jq '.data.health_indicators.error_rate'
```

---

## 4. å¼€å‘æ–‡æ¡£

### 4.1 ä»£ç ç»“æ„ä¼˜åŒ–

#### 4.1.1 ç›®å½•ç»“æ„
```
services/data-collector/
â”œâ”€â”€ collector/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ service.py              # ä¸»æœåŠ¡ç±»
â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ data_types.py          # æ•°æ®ç±»å‹å®šä¹‰
â”‚   â”œâ”€â”€ normalizer.py          # æ•°æ®æ ‡å‡†åŒ–
â”‚   â””â”€â”€ orderbook_manager.py   # OrderBookç®¡ç†
â”œâ”€â”€ main.py                    # æœåŠ¡å…¥å£ç‚¹
â”œâ”€â”€ Dockerfile                 # Dockeræ„å»ºæ–‡ä»¶
â””â”€â”€ requirements.txt           # Pythonä¾èµ–
```

#### 4.1.2 PEP 8è§„èŒƒéµå¾ª

**å¯¼å…¥è¯­å¥ç»„ç»‡**:
```python
# æ ‡å‡†åº“å¯¼å…¥
import asyncio
import sys
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import structlog
from aiohttp import web

# é¡¹ç›®æ¨¡å—å¯¼å…¥
from core.service_framework import BaseService
from core.data_collection.public_data_collector import PublicDataCollector
```

**å‘½åè§„èŒƒ**:
- ç±»å: `PascalCase` (å¦‚ `DataCollectorService`)
- æ–¹æ³•å: `snake_case` (å¦‚ `_get_service_status`)
- å¸¸é‡: `UPPER_CASE` (å¦‚ `ERROR_CODES`)
- ç§æœ‰æ–¹æ³•: ä»¥`_`å¼€å¤´ (å¦‚ `_create_success_response`)

**ä»£ç æ ¼å¼**:
- è¡Œé•¿åº¦: æœ€å¤§88å­—ç¬¦
- ç¼©è¿›: 4ä¸ªç©ºæ ¼
- æ–‡æ¡£å­—ç¬¦ä¸²: ä½¿ç”¨ä¸‰é‡å¼•å·å’Œè¯¦ç»†æè¿°

#### 4.1.3 ç±»å‹æ³¨è§£
```python
async def _get_service_status(self, request: web.Request) -> web.Response:
    """BaseServiceå…¼å®¹çš„çŠ¶æ€API"""

def _create_success_response(self, data: Any, message: str = "Success") -> web.Response:
    """åˆ›å»ºæˆåŠŸå“åº”"""

def _get_basic_stats(self) -> Dict[str, Any]:
    """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
```

### 4.2 é”™è¯¯å¤„ç†æœºåˆ¶

#### 4.2.1 åˆ†å±‚é”™è¯¯å¤„ç†

**APIå±‚é”™è¯¯å¤„ç†**:
```python
async def _get_collector_stats(self, request: web.Request) -> web.Response:
    try:
        # ä¸šåŠ¡é€»è¾‘
        return self._create_success_response(data, message)
    except Exception as e:
        self.logger.error(f"è·å–æ”¶é›†ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        return self._create_error_response(
            f"Failed to retrieve collection statistics: {str(e)}",
            self.ERROR_CODES['STATS_UNAVAILABLE'],
            500
        )
```

**ä¸šåŠ¡å±‚é”™è¯¯å¤„ç†**:
```python
def _normalize_data(self, data_type: str, exchange: str, data: Dict[str, Any]) -> Dict[str, Any]:
    try:
        if self.data_normalizer:
            return self.data_normalizer.normalize(data)
        else:
            # åŸºç¡€æ ‡å‡†åŒ–
            return self._basic_normalize(data_type, exchange, data)
    except Exception as e:
        self.logger.warning(f"æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
        return self._fallback_normalize(data_type, exchange, data)
```

#### 4.2.2 é”™è¯¯ä»£ç æ ‡å‡†åŒ–
```python
ERROR_CODES = {
    'COLLECTOR_NOT_INITIALIZED': 'COLLECTOR_NOT_INITIALIZED',
    'STATS_UNAVAILABLE': 'STATS_UNAVAILABLE',
    'EXCHANGE_STATUS_ERROR': 'EXCHANGE_STATUS_ERROR',
    'DATA_RETRIEVAL_ERROR': 'DATA_RETRIEVAL_ERROR',
    'INVALID_PARAMETERS': 'INVALID_PARAMETERS',
    'SERVICE_UNAVAILABLE': 'SERVICE_UNAVAILABLE',
    'INTERNAL_ERROR': 'INTERNAL_ERROR'
}
```

#### 4.2.3 å‚æ•°éªŒè¯
```python
# å‚æ•°èŒƒå›´éªŒè¯
try:
    limit = int(request.query.get('limit', '10'))
    if limit < 1 or limit > 100:
        return self._create_error_response(
            "Limit parameter must be between 1 and 100",
            self.ERROR_CODES['INVALID_PARAMETERS'],
            400
        )
except ValueError:
    return self._create_error_response(
        "Limit parameter must be a valid integer",
        self.ERROR_CODES['INVALID_PARAMETERS'],
        400
    )
```

### 4.3 æ—¥å¿—è®°å½•æ ‡å‡†

#### 4.3.1 æ—¥å¿—çº§åˆ«ä½¿ç”¨
```python
# INFO: æ­£å¸¸æ“ä½œä¿¡æ¯
self.logger.info("ğŸ‰ æ•°æ®æ”¶é›†å™¨æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
self.logger.info(f"âœ… æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–æˆåŠŸ")

# WARNING: è­¦å‘Šä¿¡æ¯ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
self.logger.warning(f"è·å–æ”¶é›†å™¨ç»Ÿè®¡å¤±è´¥: {e}")

# ERROR: é”™è¯¯ä¿¡æ¯ï¼Œå½±å“åŠŸèƒ½ä½†ä¸è‡´å‘½
self.logger.error(f"è·å–æ”¶é›†ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
self.logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)

# DEBUG: è¯¦ç»†è°ƒè¯•ä¿¡æ¯
self.logger.debug(f"æ¨¡æ‹Ÿå‘å¸ƒåˆ°NATSä¸»é¢˜: {topic}")
self.logger.debug(f"æ•°æ®æ ‡å‡†åŒ–å®Œæˆ: {normalized_data.get('symbol', 'unknown')}")
```

#### 4.3.2 ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
```python
# ä½¿ç”¨structlogè¿›è¡Œç»“æ„åŒ–æ—¥å¿—è®°å½•
import structlog

# æ—¥å¿—ä¸Šä¸‹æ–‡ä¿¡æ¯
self.logger.info(
    "æ•°æ®æ”¶é›†å®Œæˆ",
    exchange="binance",
    symbol="BTCUSDT",
    data_type="ticker",
    collection_time=datetime.now(timezone.utc).isoformat()
)

# æ€§èƒ½ç›‘æ§æ—¥å¿—
self.logger.info(
    "æ€§èƒ½ç»Ÿè®¡",
    collections_per_minute=990.14,
    memory_usage_mb=0.01,
    error_rate=0.0,
    uptime_seconds=3600
)
```

#### 4.3.3 æ—¥å¿—è½®è½¬å’Œç®¡ç†
```python
# æ—¥å¿—é…ç½®ç¤ºä¾‹
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'detailed': {
            'format': '%(asctime)s [%(levelname)8s] %(name)s: %(message)s'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'detailed'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': '/app/logs/data-collector.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
            'formatter': 'detailed'
        }
    },
    'loggers': {
        'data-collector': {
            'level': 'INFO',
            'handlers': ['console', 'file']
        }
    }
}
```

### 4.4 æ€§èƒ½ä¼˜åŒ–æªæ–½å’Œå†…å­˜ç®¡ç†ç­–ç•¥

#### 4.4.1 å†…å­˜ç®¡ç†ç­–ç•¥

**æ•°æ®å­˜å‚¨é™åˆ¶**:
```python
def _store_data(self, data_type: str, exchange: str, normalized_data: Dict[str, Any]):
    """å­˜å‚¨æ•°æ®åˆ°å†…å­˜"""
    try:
        # æ ¹æ®æ•°æ®ç±»å‹å­˜å‚¨
        if data_type == 'ticker':
            self.collected_data['tickers'][key] = normalized_data
        elif data_type == 'orderbook':
            self.collected_data['orderbooks'][key] = normalized_data
        elif data_type == 'trade':
            self.collected_data['trades'][key] = normalized_data

        # é™åˆ¶å†…å­˜ä½¿ç”¨ï¼Œä¿ç•™æœ€æ–°çš„1000æ¡è®°å½•
        for data_category in ['tickers', 'orderbooks', 'trades']:
            if len(self.collected_data[data_category]) > 1000:
                # åˆ é™¤æœ€æ—§çš„è®°å½•
                oldest_key = next(iter(self.collected_data[data_category]))
                del self.collected_data[data_category][oldest_key]

    except Exception as e:
        self.logger.error(f"æ•°æ®å­˜å‚¨å¤±è´¥: {e}")
```

**å†…å­˜ä½¿ç”¨ç›‘æ§**:
```python
def _estimate_memory_usage(self) -> float:
    """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
    try:
        import sys
        total_size = 0
        for data_category in ['tickers', 'orderbooks', 'trades']:
            total_size += sys.getsizeof(self.collected_data[data_category])
            for item in self.collected_data[data_category].values():
                total_size += sys.getsizeof(item)
        return round(total_size / (1024 * 1024), 2)
    except Exception:
        return 0.0
```

#### 4.4.2 å¼‚æ­¥å¤„ç†ä¼˜åŒ–

**ä»»åŠ¡ç®¡ç†**:
```python
async def _start_collection_tasks(self):
    """å¯åŠ¨æ•°æ®æ”¶é›†ä»»åŠ¡"""
    try:
        if self.public_collector:
            # å¯åŠ¨æ•°æ®æ”¶é›†
            collection_task = asyncio.create_task(self.public_collector.start())
            self.logger.info("âœ… æ•°æ®æ”¶é›†ä»»åŠ¡å¯åŠ¨æˆåŠŸ")

            # å¯åŠ¨ç»Ÿè®¡æ›´æ–°ä»»åŠ¡
            stats_task = asyncio.create_task(self._update_stats_periodically())
            self.logger.info("âœ… ç»Ÿè®¡æ›´æ–°ä»»åŠ¡å¯åŠ¨æˆåŠŸ")

    except Exception as e:
        self.logger.error(f"å¯åŠ¨æ•°æ®æ”¶é›†ä»»åŠ¡å¤±è´¥: {e}")
```

**å¹¶å‘æ§åˆ¶**:
```python
async def _update_stats_periodically(self):
    """å®šæœŸæ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
    while True:
        try:
            await asyncio.sleep(self.collection_interval)

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.collected_data['stats']['total_collections'] += 1
            self.collected_data['stats']['last_collection_time'] = datetime.now(timezone.utc).isoformat()

        except Exception as e:
            self.logger.error(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            self.collected_data['stats']['error_count'] += 1
            await asyncio.sleep(5)  # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…
```

#### 4.4.3 æ€§èƒ½ç›‘æ§æŒ‡æ ‡

**å…³é”®æ€§èƒ½æŒ‡æ ‡**:
```python
def _calculate_collections_per_minute(self, uptime_seconds: float) -> float:
    """è®¡ç®—æ¯åˆ†é’Ÿæ”¶é›†æ¬¡æ•°"""
    if uptime_seconds < 60:
        return 0.0
    minutes = uptime_seconds / 60
    return round(self.collected_data['stats']['total_collections'] / minutes, 2)

def _calculate_success_rate(self) -> float:
    """è®¡ç®—æˆåŠŸç‡"""
    total = self.collected_data['stats']['total_collections']
    errors = self.collected_data['stats']['error_count']
    if total == 0:
        return 100.0
    return round((total - errors) / total * 100, 2)

def _calculate_data_freshness(self) -> float:
    """è®¡ç®—æ•°æ®æ–°é²œåº¦ï¼ˆç§’ï¼‰"""
    last_update = self.collected_data['stats']['last_collection_time']
    if not last_update:
        return float('inf')
    try:
        last_update_dt = datetime.fromisoformat(last_update.replace('Z', '+00:00'))
        return (datetime.now(timezone.utc) - last_update_dt).total_seconds()
    except Exception:
        return float('inf')
```

#### 4.4.4 èµ„æºæ¸…ç†æœºåˆ¶

**ä¼˜é›…å…³é—­**:
```python
async def on_shutdown(self):
    """æœåŠ¡å…³é—­æ¸…ç†"""
    self.logger.info("å¼€å§‹å…³é—­æ•°æ®æ”¶é›†å™¨æœåŠ¡...")

    try:
        # 1. åœæ­¢å…¬å¼€æ•°æ®æ”¶é›†å™¨
        if self.public_collector:
            try:
                await asyncio.wait_for(self.public_collector.stop(), timeout=10.0)
                self.logger.info("âœ… å…¬å¼€æ•°æ®æ”¶é›†å™¨å·²åœæ­¢")
            except asyncio.TimeoutError:
                self.logger.warning("âš ï¸ å…¬å¼€æ•°æ®æ”¶é›†å™¨åœæ­¢è¶…æ—¶")

        # 2. åœæ­¢OrderBook Manager
        if self.orderbook_manager:
            try:
                await asyncio.wait_for(self.orderbook_manager.stop(), timeout=10.0)
                self.logger.info("âœ… OrderBook Managerå·²åœæ­¢")
            except asyncio.TimeoutError:
                self.logger.warning("âš ï¸ OrderBook Manageråœæ­¢è¶…æ—¶")

        # 3. æ¸…ç†æ•°æ®
        self._cleanup_data()

    except Exception as e:
        self.logger.error(f"æœåŠ¡å…³é—­æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
    finally:
        self.logger.info("ğŸ”š æ•°æ®æ”¶é›†å™¨æœåŠ¡å·²å…³é—­")
```

### 4.5 ä»£ç ç»´æŠ¤å’Œæ‰©å±•æŒ‡å—

#### 4.5.1 æ·»åŠ æ–°çš„APIç«¯ç‚¹

**æ­¥éª¤1: å®šä¹‰APIæ–¹æ³•**
```python
async def _get_new_endpoint(self, request: web.Request) -> web.Response:
    """æ–°APIç«¯ç‚¹çš„å®ç°"""
    try:
        # å‚æ•°éªŒè¯
        param = request.query.get('param', 'default')

        # ä¸šåŠ¡é€»è¾‘
        data = self._process_new_feature(param)

        return self._create_success_response(data, "New endpoint data retrieved successfully")

    except Exception as e:
        self.logger.error(f"æ–°ç«¯ç‚¹å¤„ç†å¤±è´¥: {e}", exc_info=True)
        return self._create_error_response(
            f"Failed to process new endpoint: {str(e)}",
            self.ERROR_CODES['INTERNAL_ERROR'],
            500
        )
```

**æ­¥éª¤2: æ³¨å†Œè·¯ç”±**
```python
def setup_routes(self):
    """è®¾ç½®APIè·¯ç”±"""
    # ç°æœ‰è·¯ç”±...

    # æ·»åŠ æ–°è·¯ç”±
    self.app.router.add_get("/api/v1/new-endpoint", self._get_new_endpoint)
```

#### 4.5.2 æ·»åŠ æ–°çš„äº¤æ˜“æ‰€æ”¯æŒ

**æ­¥éª¤1: æ›´æ–°æ”¯æŒåˆ—è¡¨**
```python
def __init__(self, config: Dict[str, Any]):
    # æ·»åŠ æ–°äº¤æ˜“æ‰€åˆ°æ”¯æŒåˆ—è¡¨
    self.supported_exchanges = ['binance', 'okx', 'deribit', 'new_exchange']
```

**æ­¥éª¤2: æ›´æ–°äº¤æ˜“æ‰€çŠ¶æ€æ–¹æ³•**
```python
def _get_exchange_status(self) -> Dict[str, Any]:
    """è·å–äº¤æ˜“æ‰€çŠ¶æ€ä¿¡æ¯"""
    current_time = datetime.now(timezone.utc).isoformat()

    return {
        # ç°æœ‰äº¤æ˜“æ‰€...
        "new_exchange": {
            "enabled": True,
            "websocket_connected": self.enable_websocket,
            "rest_api_available": True,
            "last_update": current_time,
            "status": "active"
        }
    }
```

#### 4.5.3 æ‰©å±•æ•°æ®ç±»å‹æ”¯æŒ

**æ­¥éª¤1: æ›´æ–°æ•°æ®å­˜å‚¨ç»“æ„**
```python
def __init__(self, config: Dict[str, Any]):
    # æ•°æ®å­˜å‚¨
    self.collected_data = {
        'tickers': {},
        'orderbooks': {},
        'trades': {},
        'new_data_type': {},  # æ–°æ•°æ®ç±»å‹
        'stats': {
            'total_collections': 0,
            'last_collection_time': None,
            'error_count': 0
        }
    }
```

**æ­¥éª¤2: æ›´æ–°æ•°æ®å¤„ç†æ–¹æ³•**
```python
def _store_data(self, data_type: str, exchange: str, normalized_data: Dict[str, Any]):
    """å­˜å‚¨æ•°æ®åˆ°å†…å­˜"""
    try:
        # ç°æœ‰æ•°æ®ç±»å‹å¤„ç†...

        elif data_type == 'new_data_type':
            self.collected_data['new_data_type'][key] = normalized_data

        # é™åˆ¶å†…å­˜ä½¿ç”¨
        for data_category in ['tickers', 'orderbooks', 'trades', 'new_data_type']:
            if len(self.collected_data[data_category]) > 1000:
                oldest_key = next(iter(self.collected_data[data_category]))
                del self.collected_data[data_category][oldest_key]

    except Exception as e:
        self.logger.error(f"æ•°æ®å­˜å‚¨å¤±è´¥: {e}")
```

#### 4.5.4 é…ç½®ç®¡ç†æ‰©å±•

**æ·»åŠ æ–°é…ç½®é¡¹**:
```python
def __init__(self, config: Dict[str, Any]):
    # ç°æœ‰é…ç½®...

    # æ–°é…ç½®é¡¹
    self.new_feature_enabled = config.get('new_feature_enabled', False)
    self.new_parameter = config.get('new_parameter', 'default_value')
```

**ç¯å¢ƒå˜é‡æ”¯æŒ**:
```python
# åœ¨Dockeré…ç½®ä¸­æ·»åŠ æ–°ç¯å¢ƒå˜é‡
ENV NEW_FEATURE_ENABLED=true
ENV NEW_PARAMETER=custom_value
```

#### 4.5.5 æµ‹è¯•å’ŒéªŒè¯

**å•å…ƒæµ‹è¯•ç¤ºä¾‹**:
```python
import pytest
from unittest.mock import Mock, AsyncMock

class TestDataCollectorService:
    @pytest.fixture
    def service(self):
        config = {
            'enable_orderbook': True,
            'enable_websocket': True,
            'collection_interval': 30
        }
        return DataCollectorService(config)

    @pytest.mark.asyncio
    async def test_get_service_status(self, service):
        """æµ‹è¯•æœåŠ¡çŠ¶æ€API"""
        request = Mock()
        response = await service._get_service_status(request)

        assert response.status == 200
        # éªŒè¯å“åº”æ ¼å¼å’Œå†…å®¹

    def test_calculate_success_rate(self, service):
        """æµ‹è¯•æˆåŠŸç‡è®¡ç®—"""
        service.collected_data['stats']['total_collections'] = 100
        service.collected_data['stats']['error_count'] = 5

        success_rate = service._calculate_success_rate()
        assert success_rate == 95.0
```

**é›†æˆæµ‹è¯•**:
```bash
# APIç«¯ç‚¹æµ‹è¯•
curl -s http://localhost:8084/api/v1/status | jq '.status'
curl -s http://localhost:8084/api/v1/collector/stats | jq '.data.service_stats'

# é”™è¯¯å¤„ç†æµ‹è¯•
curl -s "http://localhost:8084/api/v1/collector/data?limit=200" | jq '.error_code'
```

#### 4.5.6 ä»£ç è´¨é‡ä¿è¯

**ä»£ç æ£€æŸ¥å·¥å…·**:
```bash
# ä½¿ç”¨flake8è¿›è¡Œä»£ç é£æ ¼æ£€æŸ¥
flake8 services/data-collector/collector/service.py

# ä½¿ç”¨blackè¿›è¡Œä»£ç æ ¼å¼åŒ–
black services/data-collector/collector/service.py

# ä½¿ç”¨mypyè¿›è¡Œç±»å‹æ£€æŸ¥
mypy services/data-collector/collector/service.py
```

**ä»£ç å®¡æŸ¥æ¸…å•**:
- [ ] éµå¾ªPEP 8ä»£ç è§„èŒƒ
- [ ] åŒ…å«å®Œæ•´çš„ç±»å‹æ³¨è§£
- [ ] æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†
- [ ] åŒ…å«å•å…ƒæµ‹è¯•
- [ ] æ›´æ–°APIæ–‡æ¡£
- [ ] éªŒè¯å‘åå…¼å®¹æ€§

---

## æ€»ç»“

MarketPrism Data Collector Serviceæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„æ•°æ®æ”¶é›†å¾®æœåŠ¡ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š

### æ ¸å¿ƒä¼˜åŠ¿
- **ç»Ÿä¸€çš„APIå“åº”æ ¼å¼**: æ‰€æœ‰ç«¯ç‚¹éµå¾ªæ ‡å‡†åŒ–çš„æˆåŠŸå’Œé”™è¯¯å“åº”æ ¼å¼
- **å®Œå–„çš„é”™è¯¯å¤„ç†**: åˆ†å±‚é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œæ ‡å‡†åŒ–é”™è¯¯ä»£ç 
- **é«˜æ€§èƒ½æ•°æ®æ”¶é›†**: æ”¯æŒå¤šäº¤æ˜“æ‰€RESTå’ŒWebSocketæ•°æ®æ”¶é›†
- **å†…å­˜ä¼˜åŒ–ç®¡ç†**: æ™ºèƒ½çš„æ•°æ®å­˜å‚¨é™åˆ¶å’Œæ¸…ç†æœºåˆ¶
- **å®¹å™¨åŒ–éƒ¨ç½²**: å®Œæ•´çš„Dockeræ”¯æŒå’Œå¥åº·æ£€æŸ¥
- **ç›‘æ§å’Œæ—¥å¿—**: è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡å’Œç»“æ„åŒ–æ—¥å¿—è®°å½•

### æŠ€æœ¯ç‰¹æ€§
- **BaseServiceæ¡†æ¶é›†æˆ**: ç»§æ‰¿ç»Ÿä¸€çš„æœåŠ¡ç®¡ç†åŠŸèƒ½
- **å¼‚æ­¥å¤„ç†**: é«˜æ•ˆçš„å¹¶å‘æ•°æ®å¤„ç†èƒ½åŠ›
- **é…ç½®ç®¡ç†**: çµæ´»çš„é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡æ”¯æŒ
- **æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°äº¤æ˜“æ‰€å’Œæ•°æ®ç±»å‹æ”¯æŒ
- **å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„ä»£ç ç»“æ„å’Œå®Œæ•´çš„æ–‡æ¡£

### ç”Ÿäº§å°±ç»ª
- **å¥åº·æ£€æŸ¥**: å®Œæ•´çš„å®¹å™¨å’ŒAPIå¥åº·æ£€æŸ¥æœºåˆ¶
- **æ•…éšœæ’é™¤**: è¯¦ç»†çš„æ•…éšœè¯Šæ–­å’Œæ—¥å¿—åˆ†ææŒ‡å—
- **æ€§èƒ½ç›‘æ§**: å®æ—¶çš„æ€§èƒ½æŒ‡æ ‡å’Œèµ„æºä½¿ç”¨ç›‘æ§
- **ä¼˜é›…å…³é—­**: å®Œå–„çš„èµ„æºæ¸…ç†å’ŒæœåŠ¡å…³é—­æµç¨‹

è¯¥æœåŠ¡ä¸ºMarketPrismç³»ç»Ÿæä¾›äº†ç¨³å®šå¯é çš„æ•°æ®æ”¶é›†åŸºç¡€ï¼Œæ”¯æŒé«˜é¢‘æ•°æ®å¤„ç†å’Œå®æ—¶ç›‘æ§éœ€æ±‚ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2025-06-29
**ç»´æŠ¤å›¢é˜Ÿ**: MarketPrism Development Team