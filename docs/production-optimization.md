# MarketPrism æ™ºèƒ½ç›‘æ§å‘Šè­¦ç³»ç»Ÿç”Ÿäº§ç¯å¢ƒä¼˜åŒ–æŒ‡å—

## ğŸ¯ ç”Ÿäº§ç¯å¢ƒé…ç½®ä¼˜åŒ–

### 1. ç³»ç»Ÿèµ„æºé…ç½®

#### 1.1 æ¨èç¡¬ä»¶é…ç½®
```yaml
# æœ€å°é…ç½®
minimum:
  cpu: 4æ ¸å¿ƒ
  memory: 8GB
  storage: 100GB SSD
  network: 1Gbps

# æ¨èé…ç½®
recommended:
  cpu: 8æ ¸å¿ƒ
  memory: 16GB
  storage: 500GB NVMe SSD
  network: 10Gbps

# é«˜è´Ÿè½½é…ç½®
high_load:
  cpu: 16æ ¸å¿ƒ
  memory: 32GB
  storage: 1TB NVMe SSD
  network: 10Gbps
```

#### 1.2 å®¹å™¨èµ„æºé™åˆ¶
```yaml
# Docker Compose èµ„æºé™åˆ¶
services:
  monitoring-alerting:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  monitoring-dashboard:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
```

### 2. æ•°æ®åº“ä¼˜åŒ–

#### 2.1 Redis ä¼˜åŒ–é…ç½®
```redis
# redis.conf ç”Ÿäº§ç¯å¢ƒé…ç½®
maxmemory 4gb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
tcp-keepalive 300
timeout 0
tcp-backlog 511
databases 16
```

#### 2.2 ClickHouse ä¼˜åŒ–é…ç½®
```xml
<!-- config.xml ç”Ÿäº§ç¯å¢ƒé…ç½® -->
<yandex>
    <max_connections>4096</max_connections>
    <keep_alive_timeout>3</keep_alive_timeout>
    <max_concurrent_queries>100</max_concurrent_queries>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>5368709120</mark_cache_size>
    
    <!-- æ•°æ®å‹ç¼© -->
    <compression>
        <case>
            <method>lz4</method>
        </case>
    </compression>
    
    <!-- æ—¥å¿—é…ç½® -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
    </logger>
</yandex>
```

### 3. åº”ç”¨ç¨‹åºä¼˜åŒ–

#### 3.1 Python åº”ç”¨ä¼˜åŒ–
```python
# ç”Ÿäº§ç¯å¢ƒé…ç½®
PRODUCTION_CONFIG = {
    # å·¥ä½œè¿›ç¨‹é…ç½®
    'MAX_WORKERS': 10,
    'WORKER_TIMEOUT': 30,
    'BATCH_SIZE': 100,
    
    # ç¼“å­˜é…ç½®
    'CACHE_SIZE': 1000,
    'CACHE_TTL': 300,
    
    # æ•°æ®åº“è¿æ¥æ± 
    'DB_POOL_SIZE': 20,
    'DB_POOL_TIMEOUT': 30,
    
    # æ—¥å¿—é…ç½®
    'LOG_LEVEL': 'INFO',
    'LOG_FORMAT': 'json',
    'LOG_ROTATION': '100MB',
    
    # æ€§èƒ½ä¼˜åŒ–
    'ENABLE_PROFILING': False,
    'ENABLE_METRICS': True,
    'METRICS_INTERVAL': 60,
}
```

#### 3.2 Next.js å‰ç«¯ä¼˜åŒ–
```javascript
// next.config.js ç”Ÿäº§ç¯å¢ƒé…ç½®
/** @type {import('next').NextConfig} */
const nextConfig = {
  output: 'standalone',
  compress: true,
  poweredByHeader: false,
  
  // æ€§èƒ½ä¼˜åŒ–
  experimental: {
    optimizeCss: true,
    optimizePackageImports: ['lucide-react', '@radix-ui/react-icons'],
  },
  
  // å›¾ç‰‡ä¼˜åŒ–
  images: {
    formats: ['image/webp', 'image/avif'],
    minimumCacheTTL: 60,
  },
  
  // å®‰å…¨å¤´
  async headers() {
    return [
      {
        source: '/(.*)',
        headers: [
          {
            key: 'X-Frame-Options',
            value: 'DENY',
          },
          {
            key: 'X-Content-Type-Options',
            value: 'nosniff',
          },
          {
            key: 'Referrer-Policy',
            value: 'origin-when-cross-origin',
          },
        ],
      },
    ]
  },
}

module.exports = nextConfig
```

### 4. ç½‘ç»œå’Œå®‰å…¨ä¼˜åŒ–

#### 4.1 Nginx åå‘ä»£ç†é…ç½®
```nginx
# nginx.conf ç”Ÿäº§ç¯å¢ƒé…ç½®
upstream monitoring_backend {
    server monitoring-alerting:8082;
    keepalive 32;
}

upstream dashboard_frontend {
    server monitoring-dashboard:3000;
    keepalive 32;
}

server {
    listen 80;
    listen 443 ssl http2;
    server_name monitoring.yourdomain.com;
    
    # SSL é…ç½®
    ssl_certificate /etc/ssl/certs/monitoring.crt;
    ssl_certificate_key /etc/ssl/private/monitoring.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    
    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";
    
    # å‰ç«¯è·¯ç”±
    location / {
        proxy_pass http://dashboard_frontend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
    
    # API è·¯ç”±
    location /api/ {
        proxy_pass http://monitoring_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }
    
    # é™æ€èµ„æºç¼“å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

#### 4.2 é˜²ç«å¢™é…ç½®
```bash
# UFW é˜²ç«å¢™è§„åˆ™
ufw default deny incoming
ufw default allow outgoing

# å…è®¸SSH
ufw allow 22/tcp

# å…è®¸HTTP/HTTPS
ufw allow 80/tcp
ufw allow 443/tcp

# å…è®¸å†…éƒ¨æœåŠ¡é€šä¿¡
ufw allow from 172.20.0.0/16 to any port 8082
ufw allow from 172.20.0.0/16 to any port 3000
ufw allow from 172.20.0.0/16 to any port 6379
ufw allow from 172.20.0.0/16 to any port 8123

# å¯ç”¨é˜²ç«å¢™
ufw enable
```

### 5. ç›‘æ§å’Œæ—¥å¿—ä¼˜åŒ–

#### 5.1 æ—¥å¿—è½®è½¬é…ç½®
```bash
# /etc/logrotate.d/marketprism
/var/log/marketprism/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 marketprism marketprism
    postrotate
        systemctl reload marketprism-monitoring
    endscript
}
```

#### 5.2 Prometheus ç›‘æ§é…ç½®
```yaml
# prometheus.yml ç”Ÿäº§ç¯å¢ƒé…ç½®
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'marketprism-production'
    environment: 'production'

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'monitoring-alerting'
    static_configs:
      - targets: ['monitoring-alerting:8082']
    scrape_interval: 30s
    metrics_path: '/metrics'
    
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 30s
    
  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']
    scrape_interval: 30s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 6. å¤‡ä»½å’Œæ¢å¤ç­–ç•¥

#### 6.1 è‡ªåŠ¨å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# backup.sh - è‡ªåŠ¨å¤‡ä»½è„šæœ¬

BACKUP_DIR="/backup/marketprism"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR/$DATE"

# å¤‡ä»½Redis
docker exec marketprism-redis redis-cli BGSAVE
docker cp marketprism-redis:/data/dump.rdb "$BACKUP_DIR/$DATE/redis_dump.rdb"

# å¤‡ä»½ClickHouse
docker exec marketprism-clickhouse clickhouse-client --query "BACKUP DATABASE marketprism TO '/backup/clickhouse_$DATE.backup'"

# å¤‡ä»½é…ç½®æ–‡ä»¶
tar -czf "$BACKUP_DIR/$DATE/config.tar.gz" /opt/marketprism/config

# æ¸…ç†æ—§å¤‡ä»½
find "$BACKUP_DIR" -type d -mtime +$RETENTION_DAYS -exec rm -rf {} +

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
# aws s3 sync "$BACKUP_DIR/$DATE" s3://marketprism-backups/
```

#### 6.2 æ¢å¤è„šæœ¬
```bash
#!/bin/bash
# restore.sh - æ•°æ®æ¢å¤è„šæœ¬

BACKUP_DATE="$1"
BACKUP_DIR="/backup/marketprism/$BACKUP_DATE"

if [ ! -d "$BACKUP_DIR" ]; then
    echo "å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: $BACKUP_DIR"
    exit 1
fi

# åœæ­¢æœåŠ¡
docker-compose down

# æ¢å¤Redis
docker cp "$BACKUP_DIR/redis_dump.rdb" marketprism-redis:/data/dump.rdb

# æ¢å¤ClickHouse
docker exec marketprism-clickhouse clickhouse-client --query "RESTORE DATABASE marketprism FROM '/backup/clickhouse_$BACKUP_DATE.backup'"

# æ¢å¤é…ç½®æ–‡ä»¶
tar -xzf "$BACKUP_DIR/config.tar.gz" -C /

# é‡å¯æœåŠ¡
docker-compose up -d

echo "æ•°æ®æ¢å¤å®Œæˆ"
```

### 7. æ€§èƒ½è°ƒä¼˜å»ºè®®

#### 7.1 ç³»ç»Ÿçº§ä¼˜åŒ–
```bash
# /etc/sysctl.conf ç³»ç»Ÿå‚æ•°ä¼˜åŒ–
# ç½‘ç»œä¼˜åŒ–
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_congestion_control = bbr

# æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
fs.file-max = 1000000

# å†…å­˜ç®¡ç†
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
```

#### 7.2 Docker ä¼˜åŒ–
```yaml
# docker-compose.override.yml ç”Ÿäº§ç¯å¢ƒè¦†ç›–
version: '3.8'

services:
  monitoring-alerting:
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    restart: unless-stopped
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    
  redis:
    command: redis-server --appendonly yes --maxmemory 4gb --maxmemory-policy allkeys-lru
    
  clickhouse:
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
```

### 8. å®¹é‡è§„åˆ’

#### 8.1 å­˜å‚¨å®¹é‡è§„åˆ’
```yaml
# å­˜å‚¨éœ€æ±‚ä¼°ç®—
daily_data_volume:
  alerts: 1GB
  metrics: 5GB
  logs: 2GB
  traces: 3GB
  total: 11GB

monthly_storage:
  raw_data: 330GB
  compressed: 100GB  # å‹ç¼©æ¯” 3:1
  backups: 50GB
  total: 480GB

yearly_storage:
  estimated: 6TB
  recommended: 10TB  # åŒ…å«å¢é•¿ç©ºé—´
```

#### 8.2 ç½‘ç»œå¸¦å®½è§„åˆ’
```yaml
# ç½‘ç»œå¸¦å®½éœ€æ±‚
peak_traffic:
  api_requests: 1000 req/s
  data_ingestion: 100 MB/s
  dashboard_users: 50 concurrent
  total_bandwidth: 1 Gbps

average_traffic:
  api_requests: 200 req/s
  data_ingestion: 20 MB/s
  dashboard_users: 10 concurrent
  total_bandwidth: 200 Mbps
```

è¿™äº›ä¼˜åŒ–é…ç½®å°†ç¡®ä¿MarketPrismæ™ºèƒ½ç›‘æ§å‘Šè­¦ç³»ç»Ÿåœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„é«˜æ€§èƒ½ã€é«˜å¯ç”¨æ€§å’Œå®‰å…¨æ€§ã€‚
