# MarketPrism APIä»£ç†é›†æˆåœºæ™¯å®ä¾‹

## ğŸ”„ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

### **åœºæ™¯1: Python Collectoré›†æˆ**
```python
# services/python-collector/src/marketprism_collector/exchanges/binance_collector.py

from core.networking.proxy_adapter import use_api_proxy
import asyncio
import logging

logger = logging.getLogger(__name__)

class BinanceCollector:
    """Binanceæ•°æ®æ”¶é›†å™¨ - é›†æˆAPIä»£ç†"""
    
    def __init__(self, symbols=None):
        self.symbols = symbols or ["BTCUSDT", "ETHUSDT", "BNBUSDT"]
        self.data_buffer = []
    
    @use_api_proxy("binance")
    async def collect_ticker_data(self, session):
        """æ”¶é›†è¡Œæƒ…æ•°æ® - ä½¿ç”¨ä»£ç†ä¿æŠ¤"""
        try:
            # æ‰¹é‡è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„24hè¡Œæƒ…
            if len(self.symbols) == 1:
                # å•ä¸ªäº¤æ˜“å¯¹
                params = {"symbol": self.symbols[0]}
                async with session.get("/api/v3/ticker/24hr", params=params) as response:
                    data = await response.json()
                    return [data] if isinstance(data, dict) else data
            else:
                # å¤šä¸ªäº¤æ˜“å¯¹ - è‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡è¯·æ±‚
                async with session.get("/api/v3/ticker/24hr") as response:
                    all_tickers = await response.json()
                    # è¿‡æ»¤å‡ºæˆ‘ä»¬éœ€è¦çš„äº¤æ˜“å¯¹
                    return [ticker for ticker in all_tickers if ticker['symbol'] in self.symbols]
        
        except Exception as e:
            logger.error(f"æ”¶é›†Binanceè¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
            raise
    
    @use_api_proxy("binance")
    async def collect_depth_data(self, session, symbol, limit=100):
        """æ”¶é›†æ·±åº¦æ•°æ®"""
        params = {"symbol": symbol, "limit": limit}
        async with session.get("/api/v3/depth", params=params) as response:
            return await response.json()
    
    @use_api_proxy("binance")
    async def collect_kline_data(self, session, symbol, interval="1m", limit=500):
        """æ”¶é›†Kçº¿æ•°æ®"""
        params = {
            "symbol": symbol,
            "interval": interval,
            "limit": limit
        }
        async with session.get("/api/v3/klines", params=params) as response:
            return await response.json()
    
    async def run_collection_cycle(self):
        """è¿è¡Œä¸€ä¸ªå®Œæ•´çš„æ•°æ®æ”¶é›†å‘¨æœŸ"""
        try:
            # å¹¶å‘æ”¶é›†å¤šç§æ•°æ®
            tasks = [
                self.collect_ticker_data(),
                *[self.collect_depth_data(symbol, 50) for symbol in self.symbols[:3]],  # é™åˆ¶æ·±åº¦æ•°æ®æ•°é‡
                *[self.collect_kline_data(symbol, "1m", 100) for symbol in self.symbols[:2]]  # é™åˆ¶Kçº¿æ•°æ®æ•°é‡
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            ticker_data = results[0] if not isinstance(results[0], Exception) else []
            depth_data = [r for r in results[1:4] if not isinstance(r, Exception)]
            kline_data = [r for r in results[4:] if not isinstance(r, Exception)]
            
            logger.info(f"æ”¶é›†å®Œæˆ: {len(ticker_data)}ä¸ªè¡Œæƒ…, {len(depth_data)}ä¸ªæ·±åº¦, {len(kline_data)}ä¸ªKçº¿")
            
            return {
                "ticker": ticker_data,
                "depth": depth_data,
                "klines": kline_data
            }
            
        except Exception as e:
            logger.error(f"æ•°æ®æ”¶é›†å‘¨æœŸå¤±è´¥: {e}")
            return {"ticker": [], "depth": [], "klines": []}

# ä½¿ç”¨ç¤ºä¾‹
async def collector_integration_example():
    """æ¼”ç¤ºä¸Python Collectorçš„é›†æˆ"""
    collector = BinanceCollector(["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT"])
    
    # è¿è¡Œ10ä¸ªæ”¶é›†å‘¨æœŸ
    for cycle in range(10):
        print(f"\nğŸ”„ æ‰§è¡Œç¬¬{cycle + 1}ä¸ªæ”¶é›†å‘¨æœŸ...")
        
        start_time = time.time()
        data = await collector.run_collection_cycle()
        elapsed = time.time() - start_time
        
        print(f"âœ… å‘¨æœŸ{cycle + 1}å®Œæˆ: è€—æ—¶{elapsed:.3f}s")
        print(f"   è¡Œæƒ…æ•°æ®: {len(data['ticker'])}æ¡")
        print(f"   æ·±åº¦æ•°æ®: {len(data['depth'])}æ¡")
        print(f"   Kçº¿æ•°æ®: {len(data['klines'])}æ¡")
        
        # ç­‰å¾…ä¸‹ä¸€ä¸ªå‘¨æœŸ
        await asyncio.sleep(30)  # 30ç§’é—´éš”
```

### **åœºæ™¯2: ç›‘æ§æœåŠ¡é›†æˆ**
```python
# core/monitoring/components/exchange_monitor.py

from core.networking.exchange_api_proxy import get_exchange_proxy
from core.storage.unified_clickhouse_writer import UnifiedClickHouseWriter
import asyncio
import json
from datetime import datetime

class ExchangeMonitor:
    """äº¤æ˜“æ‰€ç›‘æ§æœåŠ¡ - é›†æˆAPIä»£ç†"""
    
    def __init__(self):
        self.proxy = get_exchange_proxy()
        self.clickhouse_writer = UnifiedClickHouseWriter()
        self.monitoring_data = []
    
    async def monitor_exchange_health(self):
        """ç›‘æ§äº¤æ˜“æ‰€å¥åº·çŠ¶æ€"""
        exchanges = ["binance", "okx", "deribit"]
        health_endpoints = {
            "binance": "/api/v3/ping",
            "okx": "/api/v5/public/time", 
            "deribit": "/api/v2/public/get_time"
        }
        
        while True:
            try:
                health_data = []
                
                # å¹¶å‘æ£€æŸ¥æ‰€æœ‰äº¤æ˜“æ‰€å¥åº·çŠ¶æ€
                tasks = [
                    self.check_single_exchange_health(exchange, health_endpoints[exchange])
                    for exchange in exchanges
                ]
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for exchange, result in zip(exchanges, results):
                    if isinstance(result, Exception):
                        health_status = {
                            "exchange": exchange,
                            "status": "error",
                            "error": str(result),
                            "response_time": None,
                            "timestamp": datetime.now()
                        }
                    else:
                        health_status = result
                    
                    health_data.append(health_status)
                    print(f"ğŸ¥ {exchange}: {health_status['status']} "
                          f"({health_status.get('response_time', 'N/A')}ms)")
                
                # å­˜å‚¨ç›‘æ§æ•°æ®
                await self.store_monitoring_data(health_data)
                
                # æ£€æŸ¥ä»£ç†è‡ªèº«å¥åº·çŠ¶æ€
                await self.check_proxy_health()
                
                await asyncio.sleep(60)  # 1åˆ†é’Ÿæ£€æŸ¥é—´éš”
                
            except Exception as e:
                print(f"ç›‘æ§æœåŠ¡é”™è¯¯: {e}")
                await asyncio.sleep(300)  # é”™è¯¯æ—¶ç­‰å¾…5åˆ†é’Ÿ
    
    async def check_single_exchange_health(self, exchange, endpoint):
        """æ£€æŸ¥å•ä¸ªäº¤æ˜“æ‰€å¥åº·çŠ¶æ€"""
        start_time = time.time()
        
        try:
            result = await self.proxy.request(exchange, "GET", endpoint)
            response_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            return {
                "exchange": exchange,
                "status": "healthy",
                "response_time": round(response_time, 2),
                "server_time": result.get("serverTime") or result.get("data", {}).get("time"),
                "timestamp": datetime.now()
            }
            
        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            
            return {
                "exchange": exchange,
                "status": "unhealthy",
                "error": str(e),
                "response_time": round(response_time, 2),
                "timestamp": datetime.now()
            }
    
    async def check_proxy_health(self):
        """æ£€æŸ¥ä»£ç†è‡ªèº«å¥åº·çŠ¶æ€"""
        status = self.proxy.get_status()
        health = self.proxy.get_health_report()
        
        print(f"\nğŸ“Š APIä»£ç†çŠ¶æ€:")
        print(f"   æ¨¡å¼: {status['mode']}")
        print(f"   å¯ç”¨IP: {status['available_ips']}/{status['total_ips']}")
        print(f"   æˆåŠŸç‡: {status['recent_success_rate']}")
        print(f"   ç³»ç»Ÿå¥åº·: {health['overall_health']}")
        
        # å¦‚æœæœ‰è­¦å‘Šï¼Œè®°å½•åˆ°ç›‘æ§ç³»ç»Ÿ
        if health['recommendations'] and health['overall_health'] != 'healthy':
            await self.alert_proxy_issues(health)
    
    async def store_monitoring_data(self, health_data):
        """å­˜å‚¨ç›‘æ§æ•°æ®åˆ°ClickHouse"""
        try:
            for data in health_data:
                await self.clickhouse_writer.write_data("exchange_health", {
                    "timestamp": data["timestamp"],
                    "exchange": data["exchange"],
                    "status": data["status"],
                    "response_time": data.get("response_time"),
                    "error": data.get("error", ""),
                    "server_time": data.get("server_time")
                })
        except Exception as e:
            print(f"å­˜å‚¨ç›‘æ§æ•°æ®å¤±è´¥: {e}")
    
    async def alert_proxy_issues(self, health_report):
        """APIä»£ç†é—®é¢˜å‘Šè­¦"""
        print(f"\nğŸš¨ APIä»£ç†å¥åº·è­¦å‘Š:")
        for recommendation in health_report['recommendations']:
            print(f"   â€¢ {recommendation}")

# ä½¿ç”¨ç¤ºä¾‹
async def monitoring_integration_example():
    """æ¼”ç¤ºä¸ç›‘æ§æœåŠ¡çš„é›†æˆ"""
    monitor = ExchangeMonitor()
    await monitor.monitor_exchange_health()
```

### **åœºæ™¯3: æ•°æ®å½’æ¡£æœåŠ¡é›†æˆ**
```python
# services/data_archiver/archive_manager.py

from core.networking.proxy_adapter import get_proxy_session
import asyncio
import json
from datetime import datetime, timedelta

class DataArchiveManager:
    """æ•°æ®å½’æ¡£ç®¡ç†å™¨ - é›†æˆAPIä»£ç†"""
    
    def __init__(self):
        self.archive_tasks = []
    
    async def archive_historical_data(self, exchange, symbol, start_date, end_date):
        """å½’æ¡£å†å²æ•°æ®"""
        proxy_session = get_proxy_session(exchange)
        
        try:
            async with proxy_session as session:
                # æŒ‰å¤©åˆ†æ‰¹å½’æ¡£ï¼Œé¿å…å•æ¬¡è¯·æ±‚é‡è¿‡å¤§
                current_date = start_date
                archived_data = []
                
                while current_date <= end_date:
                    try:
                        # è·å–å½“å¤©çš„Kçº¿æ•°æ®
                        start_timestamp = int(current_date.timestamp() * 1000)
                        end_timestamp = int((current_date + timedelta(days=1)).timestamp() * 1000)
                        
                        if exchange == "binance":
                            params = {
                                "symbol": symbol,
                                "interval": "1h",
                                "startTime": start_timestamp,
                                "endTime": end_timestamp,
                                "limit": 1000
                            }
                            async with session.get("/api/v3/klines", params=params) as response:
                                daily_data = await response.json()
                        
                        elif exchange == "okx":
                            params = {
                                "instId": symbol.replace("USDT", "-USDT"),
                                "bar": "1H",
                                "after": start_timestamp,
                                "before": end_timestamp,
                                "limit": 100
                            }
                            async with session.get("/api/v5/market/history-candles", params=params) as response:
                                result = await response.json()
                                daily_data = result.get("data", [])
                        
                        if daily_data:
                            archived_data.extend(daily_data)
                            print(f"âœ… å½’æ¡£ {exchange} {symbol} {current_date.strftime('%Y-%m-%d')}: {len(daily_data)}æ¡")
                        else:
                            print(f"âš ï¸ æ— æ•°æ® {exchange} {symbol} {current_date.strftime('%Y-%m-%d')}")
                        
                        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                        await asyncio.sleep(1)
                        
                    except Exception as e:
                        print(f"âŒ å½’æ¡£å¤±è´¥ {exchange} {symbol} {current_date.strftime('%Y-%m-%d')}: {e}")
                    
                    current_date += timedelta(days=1)
                
                print(f"ğŸ‰ {exchange} {symbol} å½’æ¡£å®Œæˆ: æ€»è®¡{len(archived_data)}æ¡æ•°æ®")
                return archived_data
                
        except Exception as e:
            print(f"å½’æ¡£ä»»åŠ¡å¤±è´¥: {e}")
            return []
        
        finally:
            await proxy_session.close()
    
    async def batch_archive_multiple_symbols(self, exchange, symbols, days=30):
        """æ‰¹é‡å½’æ¡£å¤šä¸ªäº¤æ˜“å¯¹"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # å¹¶å‘å½’æ¡£ï¼Œä½†é™åˆ¶å¹¶å‘æ•°é¿å…è¿‡è½½
        semaphore = asyncio.Semaphore(3)  # æœ€å¤š3ä¸ªå¹¶å‘ä»»åŠ¡
        
        async def archive_single_symbol(symbol):
            async with semaphore:
                return await self.archive_historical_data(exchange, symbol, start_date, end_date)
        
        # åˆ›å»ºæ‰€æœ‰å½’æ¡£ä»»åŠ¡
        tasks = [archive_single_symbol(symbol) for symbol in symbols]
        
        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å½’æ¡£ {exchange} {len(symbols)}ä¸ªäº¤æ˜“å¯¹ï¼Œæœ€è¿‘{days}å¤©æ•°æ®...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        total_archived = 0
        success_count = 0
        
        for symbol, result in zip(symbols, results):
            if isinstance(result, Exception):
                print(f"âŒ {symbol} å½’æ¡£å¤±è´¥: {result}")
            else:
                total_archived += len(result)
                success_count += 1
        
        print(f"ğŸ“Š æ‰¹é‡å½’æ¡£å®Œæˆ:")
        print(f"   æˆåŠŸ: {success_count}/{len(symbols)} ä¸ªäº¤æ˜“å¯¹")
        print(f"   æ€»æ•°æ®é‡: {total_archived} æ¡è®°å½•")

# ä½¿ç”¨ç¤ºä¾‹
async def archive_integration_example():
    """æ¼”ç¤ºä¸æ•°æ®å½’æ¡£æœåŠ¡çš„é›†æˆ"""
    archive_manager = DataArchiveManager()
    
    # å½’æ¡£ä¸»è¦äº¤æ˜“å¯¹çš„å†å²æ•°æ®
    major_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "DOTUSDT"]
    
    await archive_manager.batch_archive_multiple_symbols("binance", major_symbols, days=7)
```

## ğŸ”§ é…ç½®ç®¡ç†é›†æˆ

### **åœºæ™¯4: ç¯å¢ƒé…ç½®è‡ªåŠ¨é€‚é…**
```python
# config/environments/production.py

import os
from core.networking.exchange_api_proxy import ExchangeAPIProxy, ProxyMode

class ProductionProxyConfig:
    """ç”Ÿäº§ç¯å¢ƒAPIä»£ç†é…ç½®"""
    
    @staticmethod
    def setup_production_proxy():
        """è®¾ç½®ç”Ÿäº§ç¯å¢ƒä»£ç†"""
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        proxy_mode = os.getenv("PROXY_MODE", "auto")
        ip_list = os.getenv("PROXY_IPS", "").split(",") if os.getenv("PROXY_IPS") else []
        
        if proxy_mode == "distributed" and ip_list:
            # åˆ†å¸ƒå¼éƒ¨ç½²
            proxy = ExchangeAPIProxy.distributed_mode([ip.strip() for ip in ip_list if ip.strip()])
            print(f"ğŸŒ ç”Ÿäº§ç¯å¢ƒ: åˆ†å¸ƒå¼ä»£ç†æ¨¡å¼ï¼Œ{len(ip_list)}ä¸ªIP")
            
        elif proxy_mode == "unified":
            # ç»Ÿä¸€ä»£ç†
            main_ip = os.getenv("MAIN_IP")
            proxy = ExchangeAPIProxy.unified_mode(main_ip)
            print(f"ğŸ”— ç”Ÿäº§ç¯å¢ƒ: ç»Ÿä¸€ä»£ç†æ¨¡å¼ï¼ŒIP: {main_ip}")
            
        else:
            # è‡ªåŠ¨æ£€æµ‹
            proxy = ExchangeAPIProxy.auto_configure()
            print(f"ğŸ¤– ç”Ÿäº§ç¯å¢ƒ: è‡ªåŠ¨é…ç½®æ¨¡å¼")
        
        return proxy
    
    @staticmethod
    def setup_monitoring_alerts():
        """è®¾ç½®ç”Ÿäº§ç¯å¢ƒç›‘æ§å‘Šè­¦"""
        return {
            "error_rate_threshold": 0.05,      # 5%é”™è¯¯ç‡å‘Šè­¦
            "response_time_threshold": 3.0,    # 3ç§’å“åº”æ—¶é—´å‘Šè­¦
            "weight_usage_threshold": 0.85,    # 85%æƒé‡ä½¿ç”¨ç‡å‘Šè­¦
            "ip_availability_threshold": 0.7   # 70%IPå¯ç”¨æ€§å‘Šè­¦
        }

# config/environments/development.py

class DevelopmentProxyConfig:
    """å¼€å‘ç¯å¢ƒAPIä»£ç†é…ç½®"""
    
    @staticmethod
    def setup_development_proxy():
        """è®¾ç½®å¼€å‘ç¯å¢ƒä»£ç†"""
        # å¼€å‘ç¯å¢ƒä½¿ç”¨ç®€å•é…ç½®
        proxy = ExchangeAPIProxy.unified_mode()  # å•IPæ¨¡å¼
        print(f"ğŸ”§ å¼€å‘ç¯å¢ƒ: ç»Ÿä¸€ä»£ç†æ¨¡å¼ï¼ˆæœ¬åœ°IPï¼‰")
        return proxy
    
    @staticmethod
    def setup_test_mode():
        """è®¾ç½®æµ‹è¯•æ¨¡å¼"""
        return {
            "enable_mock_responses": True,
            "simulate_rate_limits": False,
            "log_all_requests": True
        }

# ä½¿ç”¨ç¤ºä¾‹
def environment_config_example():
    """ç¯å¢ƒé…ç½®ç¤ºä¾‹"""
    env = os.getenv("ENVIRONMENT", "development")
    
    if env == "production":
        proxy = ProductionProxyConfig.setup_production_proxy()
        alerts = ProductionProxyConfig.setup_monitoring_alerts()
    else:
        proxy = DevelopmentProxyConfig.setup_development_proxy()
        alerts = {"error_rate_threshold": 0.2}  # å¼€å‘ç¯å¢ƒæ›´å®½æ¾
    
    print(f"âœ… {env}ç¯å¢ƒä»£ç†é…ç½®å®Œæˆ")
    return proxy, alerts
```

### **åœºæ™¯5: Dockerå®¹å™¨åŒ–éƒ¨ç½²é›†æˆ**
```python
# docker/proxy_entrypoint.py

#!/usr/bin/env python3
"""
Dockerå®¹å™¨åŒ–éƒ¨ç½²å…¥å£è„šæœ¬
è‡ªåŠ¨é…ç½®APIä»£ç†å¹¶å¯åŠ¨æœåŠ¡
"""

import os
import sys
import asyncio
import signal
from core.networking.exchange_api_proxy import ExchangeAPIProxy

class DockerizedProxyService:
    def __init__(self):
        self.proxy = None
        self.running = True
    
    def setup_proxy_from_env(self):
        """ä»ç¯å¢ƒå˜é‡è®¾ç½®ä»£ç†é…ç½®"""
        # è¯»å–Dockerç¯å¢ƒå˜é‡
        service_name = os.getenv("SERVICE_NAME", "unknown")
        proxy_mode = os.getenv("PROXY_MODE", "auto")
        
        # ä»Docker networkè·å–å…¶ä»–æœåŠ¡IP
        ip_prefix = os.getenv("IP_PREFIX", "172.20.0")
        proxy_ips = []
        
        # è‡ªåŠ¨å‘ç°é›†ç¾¤ä¸­çš„å…¶ä»–ä»£ç†èŠ‚ç‚¹
        for i in range(10, 20):  # æ£€æŸ¥172.20.0.10-19
            ip = f"{ip_prefix}.{i}"
            if ip != os.getenv("MY_IP"):  # æ’é™¤è‡ªå·±
                # è¿™é‡Œå¯ä»¥åŠ å…¥å¥åº·æ£€æŸ¥é€»è¾‘
                proxy_ips.append(ip)
        
        if proxy_mode == "distributed" and proxy_ips:
            self.proxy = ExchangeAPIProxy.distributed_mode(proxy_ips)
            print(f"ğŸ³ Docker: {service_name} åˆ†å¸ƒå¼ä»£ç†å¯åŠ¨ï¼Œ{len(proxy_ips)}ä¸ªèŠ‚ç‚¹")
        else:
            self.proxy = ExchangeAPIProxy.auto_configure()
            print(f"ğŸ³ Docker: {service_name} è‡ªåŠ¨é…ç½®ä»£ç†å¯åŠ¨")
    
    def setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            print(f"\nğŸ›‘ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
            self.running = False
        
        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)
    
    async def health_check_endpoint(self):
        """Dockerå¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        from aiohttp import web
        
        async def health_check(request):
            """å¥åº·æ£€æŸ¥å¤„ç†å™¨"""
            try:
                status = self.proxy.get_status()
                health = self.proxy.get_health_report()
                
                if health['overall_health'] == 'healthy':
                    return web.json_response({
                        "status": "healthy",
                        "proxy_mode": status['mode'],
                        "available_ips": status['available_ips'],
                        "total_ips": status['total_ips']
                    })
                else:
                    return web.json_response({
                        "status": "unhealthy",
                        "issues": health['recommendations']
                    }, status=503)
                    
            except Exception as e:
                return web.json_response({
                    "status": "error",
                    "error": str(e)
                }, status=500)
        
        app = web.Application()
        app.router.add_get('/health', health_check)
        
        runner = web.AppRunner(app)
        await runner.setup()
        
        site = web.TCPSite(runner, '0.0.0.0', 8080)
        await site.start()
        print("ğŸ©º å¥åº·æ£€æŸ¥ç«¯ç‚¹å¯åŠ¨: http://0.0.0.0:8080/health")
    
    async def run_service(self):
        """è¿è¡Œä¸»æœåŠ¡"""
        # å¯åŠ¨å¥åº·æ£€æŸ¥ç«¯ç‚¹
        await self.health_check_endpoint()
        
        # ä¸»æœåŠ¡å¾ªç¯
        while self.running:
            try:
                # å®šæœŸæŠ¥å‘ŠçŠ¶æ€
                status = self.proxy.get_status()
                print(f"ğŸ“Š æœåŠ¡è¿è¡Œä¸­: æˆåŠŸç‡{status['recent_success_rate']}, "
                      f"å¯ç”¨IP{status['available_ips']}/{status['total_ips']}")
                
                await asyncio.sleep(30)  # 30ç§’æŠ¥å‘Šé—´éš”
                
            except Exception as e:
                print(f"æœåŠ¡è¿è¡Œé”™è¯¯: {e}")
                await asyncio.sleep(60)
        
        print("âœ… æœåŠ¡ä¼˜é›…å…³é—­å®Œæˆ")

def main():
    """Dockerå®¹å™¨ä¸»å…¥å£"""
    service = DockerizedProxyService()
    
    # è®¾ç½®ä¿¡å·å¤„ç†
    service.setup_signal_handlers()
    
    # é…ç½®ä»£ç†
    service.setup_proxy_from_env()
    
    # è¿è¡ŒæœåŠ¡
    try:
        asyncio.run(service.run_service())
    except KeyboardInterrupt:
        print("æœåŠ¡è¢«ä¸­æ–­")
    finally:
        print("å®¹å™¨é€€å‡º")

if __name__ == "__main__":
    main()
```

### **å¯¹åº”çš„Dockeré…ç½®æ–‡ä»¶**
```yaml
# docker-compose.yml

version: '3.8'

services:
  marketprism-collector-1:
    build: 
      context: .
      dockerfile: docker/Dockerfile.collector
    environment:
      - SERVICE_NAME=collector-1
      - PROXY_MODE=distributed
      - MY_IP=172.20.0.10
      - IP_PREFIX=172.20.0
    networks:
      marketprism_net:
        ipv4_address: 172.20.0.10
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
  
  marketprism-collector-2:
    build: 
      context: .
      dockerfile: docker/Dockerfile.collector
    environment:
      - SERVICE_NAME=collector-2
      - PROXY_MODE=distributed
      - MY_IP=172.20.0.11
      - IP_PREFIX=172.20.0
    networks:
      marketprism_net:
        ipv4_address: 172.20.0.11
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  marketprism_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

è¿™äº›é›†æˆåœºæ™¯å±•ç¤ºäº†MarketPrismç»Ÿä¸€APIä»£ç†å¦‚ä½•æ— ç¼é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿæ¶æ„ä¸­ï¼Œä»ç®€å•çš„å‡½æ•°è£…é¥°å™¨åˆ°å¤æ‚çš„Dockerå®¹å™¨åŒ–éƒ¨ç½²ï¼Œéƒ½èƒ½æä¾›ä¸€è‡´çš„é€Ÿç‡é™åˆ¶ä¿æŠ¤å’ŒIPç®¡ç†åŠŸèƒ½ï¼