#!/usr/bin/env python3
"""
MarketPrismç»Ÿä¸€ç›‘æ§ç³»ç»ŸåŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€æŒ‡æ ‡ç®¡ç†å™¨è¿›è¡Œç›‘æ§æŒ‡æ ‡çš„æ³¨å†Œã€æ”¶é›†å’Œå¯¼å‡ºã€‚
"""

import time
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "services" / "python-collector" / "src"))

from marketprism_collector.core.monitoring import (
    get_global_manager, 
    MetricType, 
    MetricCategory,
    MetricCollector
)
from marketprism_collector.core.monitoring.exporters import (
    PrometheusExporter,
    JSONExporter,
    create_grafana_dashboard
)


class ExampleMetricCollector(MetricCollector):
    """ç¤ºä¾‹æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def collect_metrics(self):
        """æ”¶é›†ç¤ºä¾‹æŒ‡æ ‡"""
        return {
            "active_connections": 42,
            "queue_size": 128,
            "cpu_usage_percent": 65.5,
            "memory_usage_bytes": 1024 * 1024 * 512  # 512MB
        }
    
    def get_collection_interval(self):
        return 5  # 5ç§’æ”¶é›†ä¸€æ¬¡


def setup_metrics():
    """è®¾ç½®ç›‘æ§æŒ‡æ ‡"""
    print("ğŸ”§ è®¾ç½®ç›‘æ§æŒ‡æ ‡...")
    
    # è·å–å…¨å±€ç®¡ç†å™¨
    manager = get_global_manager()
    
    # æ³¨å†Œä¸šåŠ¡æŒ‡æ ‡
    manager.registry.register_custom_metric(
        "requests_processed",
        MetricType.COUNTER,
        MetricCategory.BUSINESS,
        "å¤„ç†çš„è¯·æ±‚æ€»æ•°",
        labels=["method", "endpoint", "status"]
    )
    
    # æ³¨å†Œæ€§èƒ½æŒ‡æ ‡
    manager.registry.register_custom_metric(
        "request_duration",
        MetricType.HISTOGRAM,
        MetricCategory.PERFORMANCE,
        "è¯·æ±‚å¤„ç†æ—¶é—´åˆ†å¸ƒ",
        labels=["endpoint"],
        unit="seconds"
    )
    
    # æ³¨å†Œç³»ç»ŸæŒ‡æ ‡
    manager.registry.register_custom_metric(
        "active_connections",
        MetricType.GAUGE,
        MetricCategory.NETWORK,
        "å½“å‰æ´»è·ƒè¿æ¥æ•°"
    )
    
    manager.registry.register_custom_metric(
        "queue_size",
        MetricType.GAUGE,
        MetricCategory.SYSTEM,
        "æ¶ˆæ¯é˜Ÿåˆ—å¤§å°"
    )
    
    manager.registry.register_custom_metric(
        "cpu_usage_percent",
        MetricType.GAUGE,
        MetricCategory.RESOURCE,
        "CPUä½¿ç”¨ç‡",
        unit="percent"
    )
    
    manager.registry.register_custom_metric(
        "memory_usage",
        MetricType.GAUGE,
        MetricCategory.RESOURCE,
        "å†…å­˜ä½¿ç”¨é‡",
        unit="bytes"
    )
    
    print("âœ… æŒ‡æ ‡è®¾ç½®å®Œæˆ")
    return manager


def simulate_application_metrics(manager):
    """æ¨¡æ‹Ÿåº”ç”¨ç¨‹åºäº§ç”ŸæŒ‡æ ‡æ•°æ®"""
    print("ğŸ“Š æ¨¡æ‹Ÿåº”ç”¨ç¨‹åºæŒ‡æ ‡...")
    
    # æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†
    endpoints = ["/api/users", "/api/orders", "/api/products"]
    methods = ["GET", "POST", "PUT", "DELETE"]
    statuses = ["200", "201", "400", "404", "500"]
    
    import random
    
    for _ in range(50):
        endpoint = random.choice(endpoints)
        method = random.choice(methods)
        status = random.choice(statuses)
        
        # å¢åŠ è¯·æ±‚è®¡æ•°
        manager.increment(
            "requests_processed", 
            1, 
            {"method": method, "endpoint": endpoint, "status": status}
        )
        
        # è®°å½•è¯·æ±‚æ—¶é—´
        duration = random.uniform(0.01, 2.0)  # 10msåˆ°2s
        manager.observe_histogram(
            "request_duration",
            duration,
            {"endpoint": endpoint}
        )
    
    # è®¾ç½®ç³»ç»ŸæŒ‡æ ‡
    manager.set_gauge("active_connections", random.randint(20, 100))
    manager.set_gauge("queue_size", random.randint(50, 200))
    manager.set_gauge("cpu_usage_percent", random.uniform(30, 90))
    manager.set_gauge("memory_usage", random.randint(300, 800) * 1024 * 1024)
    
    print("âœ… æŒ‡æ ‡æ•°æ®æ¨¡æ‹Ÿå®Œæˆ")


def demonstrate_timer_context(manager):
    """æ¼”ç¤ºè®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    print("â±ï¸  æ¼”ç¤ºè®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨...")
    
    # æ³¨å†Œè®¡æ—¶å™¨æŒ‡æ ‡
    manager.registry.register_custom_metric(
        "operation_duration",
        MetricType.HISTOGRAM,
        MetricCategory.PERFORMANCE,
        "æ“ä½œæ‰§è¡Œæ—¶é—´",
        unit="seconds"
    )
    
    # ä½¿ç”¨è®¡æ—¶å™¨æµ‹é‡æ“ä½œè€—æ—¶
    with manager.timer("operation_duration", {"operation": "data_processing"}):
        print("   æ‰§è¡Œæ•°æ®å¤„ç†æ“ä½œ...")
        time.sleep(0.1)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    
    with manager.timer("operation_duration", {"operation": "api_call"}):
        print("   æ‰§è¡ŒAPIè°ƒç”¨...")
        time.sleep(0.05)  # æ¨¡æ‹ŸAPIè°ƒç”¨
    
    print("âœ… è®¡æ—¶å™¨æ¼”ç¤ºå®Œæˆ")


def export_metrics_examples(manager):
    """æ¼”ç¤ºæŒ‡æ ‡å¯¼å‡º"""
    print("ğŸ“¤ å¯¼å‡ºæŒ‡æ ‡...")
    
    metrics = manager.registry.get_all_metrics()
    
    # Prometheusæ ¼å¼å¯¼å‡º
    print("\n--- Prometheusæ ¼å¼ ---")
    prometheus_exporter = PrometheusExporter(include_help=True, include_timestamp=False)
    prometheus_output = prometheus_exporter.export_metrics(metrics)
    print(prometheus_output[:500] + "..." if len(prometheus_output) > 500 else prometheus_output)
    
    # JSONæ ¼å¼å¯¼å‡º
    print("\n--- JSONæ ¼å¼ ---")
    json_exporter = JSONExporter(pretty_print=True, include_metadata=True)
    json_output = json_exporter.export_metrics(metrics)
    
    # åªæ˜¾ç¤ºéƒ¨åˆ†JSONè¾“å‡º
    import json
    data = json.loads(json_output)
    summary = data.get("summary", {})
    print(f"æŒ‡æ ‡æ€»æ•°: {summary.get('total_metrics', 0)}")
    print(f"å¯¼å‡ºæŒ‡æ ‡æ•°: {summary.get('exported_metrics', 0)}")
    
    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæŒ‡æ ‡çš„è¯¦ç»†ä¿¡æ¯
    if data.get("metrics"):
        first_metric_name = next(iter(data["metrics"]))
        first_metric = data["metrics"][first_metric_name]
        print(f"\nç¤ºä¾‹æŒ‡æ ‡ '{first_metric_name}':")
        print(f"  ç±»å‹: {first_metric['definition']['type']}")
        print(f"  åˆ†ç±»: {first_metric['definition']['category']}")
        print(f"  æè¿°: {first_metric['definition']['description']}")
        print(f"  å€¼æ•°é‡: {len(first_metric['values'])}")


def demonstrate_alert_rules(manager):
    """æ¼”ç¤ºå‘Šè­¦è§„åˆ™"""
    print("ğŸš¨ æ¼”ç¤ºå‘Šè­¦è§„åˆ™...")
    
    from marketprism_collector.core.monitoring import AlertRule, MetricSeverity
    
    # æ·»åŠ CPUä½¿ç”¨ç‡å‘Šè­¦
    cpu_alert = AlertRule(
        metric_name="cpu_usage_percent",
        condition=">",
        threshold=80.0,
        severity=MetricSeverity.HIGH,
        message="CPUä½¿ç”¨ç‡è¿‡é«˜",
        duration=5  # æŒç»­5ç§’
    )
    
    # æ·»åŠ å†…å­˜ä½¿ç”¨å‘Šè­¦
    memory_alert = AlertRule(
        metric_name="memory_usage",
        condition=">",
        threshold=700 * 1024 * 1024,  # 700MB
        severity=MetricSeverity.MEDIUM,
        message="å†…å­˜ä½¿ç”¨é‡è¿‡é«˜"
    )
    
    manager.add_alert_rule(cpu_alert)
    manager.add_alert_rule(memory_alert)
    
    print(f"âœ… æ·»åŠ äº† {len(manager.alert_rules)} ä¸ªå‘Šè­¦è§„åˆ™")
    
    # æ£€æŸ¥å‘Šè­¦
    alerts = manager.check_alerts()
    if alerts:
        print("âš ï¸  æ£€æµ‹åˆ°å‘Šè­¦:")
        for alert in alerts:
            print(f"  - {alert['message']} (å½“å‰å€¼: {alert['value']})")
    else:
        print("âœ… å½“å‰æ— å‘Šè­¦")


def demonstrate_collection_lifecycle(manager):
    """æ¼”ç¤ºæŒ‡æ ‡æ”¶é›†ç”Ÿå‘½å‘¨æœŸ"""
    print("ğŸ”„ æ¼”ç¤ºæŒ‡æ ‡æ”¶é›†ç”Ÿå‘½å‘¨æœŸ...")
    
    # æ³¨å†Œè‡ªå®šä¹‰æ”¶é›†å™¨
    collector = ExampleMetricCollector()
    manager.register_collector("example", collector)
    
    print("å¯åŠ¨æŒ‡æ ‡æ”¶é›†...")
    manager.start_collection(interval=1)  # 1ç§’æ”¶é›†é—´éš”
    
    # è¿è¡Œå‡ ç§’é’Ÿ
    time.sleep(3)
    
    print("åœæ­¢æŒ‡æ ‡æ”¶é›†...")
    manager.stop_collection()
    
    # æ£€æŸ¥æ”¶é›†åˆ°çš„æŒ‡æ ‡
    print("æ”¶é›†åˆ°çš„ç³»ç»ŸæŒ‡æ ‡:")
    for metric_name in ["active_connections", "queue_size", "cpu_usage_percent"]:
        metric = manager.registry.get_metric(metric_name)
        if metric and metric.get_values():
            value = next(iter(metric.get_values().values())).value
            print(f"  {metric_name}: {value}")


def generate_grafana_dashboard(manager):
    """ç”ŸæˆGrafanaä»ªè¡¨æ¿é…ç½®"""
    print("ğŸ“Š ç”ŸæˆGrafanaä»ªè¡¨æ¿...")
    
    metrics = manager.registry.get_all_metrics()
    dashboard = create_grafana_dashboard(
        metrics,
        dashboard_title="MarketPrismç›‘æ§ä»ªè¡¨æ¿",
        refresh_interval="10s"
    )
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    import json
    dashboard_file = project_root / "examples" / "monitoring" / "grafana_dashboard.json"
    with open(dashboard_file, 'w', encoding='utf-8') as f:
        json.dump(dashboard, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Grafanaä»ªè¡¨æ¿é…ç½®å·²ä¿å­˜åˆ°: {dashboard_file}")
    print(f"   é¢æ¿æ•°é‡: {len(dashboard['dashboard']['panels'])}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ MarketPrismç»Ÿä¸€ç›‘æ§ç³»ç»Ÿç¤ºä¾‹")
    print("=" * 50)
    
    # è®¾ç½®æŒ‡æ ‡
    manager = setup_metrics()
    
    # æ¨¡æ‹Ÿåº”ç”¨æŒ‡æ ‡
    simulate_application_metrics(manager)
    
    # æ¼”ç¤ºè®¡æ—¶å™¨
    demonstrate_timer_context(manager)
    
    # å¯¼å‡ºæŒ‡æ ‡
    export_metrics_examples(manager)
    
    # æ¼”ç¤ºå‘Šè­¦è§„åˆ™
    demonstrate_alert_rules(manager)
    
    # æ¼”ç¤ºæ”¶é›†ç”Ÿå‘½å‘¨æœŸ
    demonstrate_collection_lifecycle(manager)
    
    # ç”ŸæˆGrafanaä»ªè¡¨æ¿
    generate_grafana_dashboard(manager)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
    stats = manager.get_stats()
    print(f"  æ€»æŒ‡æ ‡æ•°: {stats['registry_stats']['total_metrics']}")
    print(f"  æ”¶é›†å™¨æ•°: {stats['collectors']}")
    print(f"  å‘Šè­¦è§„åˆ™æ•°: {stats['alert_rules']}")
    print(f"  è¿è¡Œæ—¶é—´: {stats['uptime_seconds']:.2f}ç§’")
    
    # å¥åº·çŠ¶æ€
    health = manager.get_health_status()
    print(f"  ç³»ç»ŸçŠ¶æ€: {health['status']}")
    print(f"  å¥åº·çŠ¶æ€: {'âœ…' if health['healthy'] else 'âš ï¸'}")
    
    print("\nğŸ‰ ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
    print("   ä½ å¯ä»¥æŸ¥çœ‹ç”Ÿæˆçš„Grafanaä»ªè¡¨æ¿é…ç½®æ–‡ä»¶")
    print("   ä¹Ÿå¯ä»¥å°†Prometheusè¾“å‡ºæ¥å…¥ä½ çš„ç›‘æ§ç³»ç»Ÿ")


if __name__ == "__main__":
    main()