# MarketPrism 测试框架设计与规范

## 测试目标

- 保证核心功能的正确性和稳定性
- 支持敏捷开发与持续集成
- 促进代码重构和优化

## 测试目录结构

```
tests/
├── unit/             # 单元测试
│   ├── services/     # 服务模块测试
│   ├── models/       # 数据模型测试
│   └── utils/        # 工具函数测试
├── integration/      # 集成测试
│   ├── api/          # API集成测试
│   └── services/     # 服务间集成测试
├── performance/      # 性能测试
├── functional/       # 功能测试
├── fixtures/         # 测试数据和辅助工具
└── conftest.py       # pytest共享配置和fixture
```

## 测试开发要求

- **TDD原则**：先写测试再写实现，测试与代码优化同步推进。
- **命名规范**：测试文件、类、方法均以 `test_` 开头，类以 `Test` 开头。
- **测试隔离**：单元测试 mock 外部依赖，集成测试用独立环境。
- **覆盖率目标**：核心功能测试覆盖率≥80%。
- **持续集成**：所有提交需通过完整测试。

## TDD开发流程

1. 编写失败的测试（红）
2. 编写最少实现使测试通过（绿）
3. 重构优化，保持测试通过
4. 迭代推进

## 测试执行

```bash
pytest tests/                # 运行全部测试
pytest tests/unit/           # 运行单元测试
pytest --run-integration     # 运行集成测试
pytest --cov=services tests/ # 生成覆盖率报告
```

## 最佳实践

- 测试命名清晰，覆盖边界与异常
- 测试独立、可复用、易维护
- 结构性变更同步更新文档
- 所有测试脚本统一归档于 tests/ 目录下，按功能模块分类

## TDD实践案例：DataNormalizer

### 案例背景

数据标准化模块(DataNormalizer)是市场数据处理流程中的关键环节，负责将不同交易所的异构数据转换为统一格式。我们采用TDD方式开发此模块。

### TDD实践步骤

1. **编写测试（红）**：
   - 设计`test_data_normalizer.py`包含基础验证、交易所特定逻辑测试
   - 测试涵盖：字段验证、类型转换、异常处理和批处理功能

2. **最小实现（绿）**：
   - 创建基础`DataNormalizer`类，实现必要方法
   - 先满足基本测试通过，不追求完美

3. **重构优化**：
   - 添加日志功能
   - 实现交易所特定处理逻辑
   - 改进错误处理和字段映射

4. **扩展测试**：
   - 增加交易所特定字段处理测试
   - 添加边界条件测试
   - 验证错误处理逻辑

5. **重构与扩展实现**：
   - 增加预处理逻辑解决字段映射问题
   - 优化日志输出
   - 完善异常处理机制

### 成果

- 实现了一个健壮的`DataNormalizer`类，能处理不同交易所的数据格式
- 自动化测试覆盖了12个测试用例，包括正常流程和异常处理
- 建立了可维护、可扩展的代码结构
- 代码命名清晰，功能模块化，遵循Python类型提示最佳实践

### 经验教训

- 先设计测试可以帮助明确API接口和功能边界
- 增量实现更易于维护和调试
- 重命名Go风格的`data-normalizer`为Python规范的`data_normalizer`解决了导入问题
- TDD促使我们提前考虑异常情况和边界条件

## 集成测试实践：DataNormalizer系统集成

### 集成测试背景

在完成DataNormalizer的单元测试后，我们开发了集成测试，验证其与NATS消息队列和ClickHouse数据库的交互。这确保了组件不仅在隔离环境中工作正常，也能在实际系统中协同工作。

### 集成测试设计

我们创建了以下集成测试：

1. **NATS到DataNormalizer测试**：
   - 验证从NATS接收消息并通过标准化处理
   - 确保消息反序列化和标准化过程无缝衔接

2. **DataNormalizer到ClickHouse测试**：
   - 验证标准化后的数据可正确写入ClickHouse
   - 确保数据类型转换和字段映射正确

3. **端到端流程测试**：
   - 模拟完整的数据流：NATS → DataNormalizer → ClickHouse
   - 确保数据在整个处理链中保持一致性

### 集成测试环境

为了保证测试的隔离性和可重复性，我们：

1. 创建了专用的Docker Compose配置
2. 使用临时的NATS流和ClickHouse测试表
3. 开发了自动环境设置和清理机制
4. 实现了测试与CI环境兼容的配置管理

### 成果与收获

- 发现并修复了几个仅在集成环境中出现的问题
- 建立了端到端测试的最佳实践模式
- 提高了系统整体的可靠性
- 为开发人员提供了验证组件交互的工具

### 未来发展

集成测试框架为进一步扩展提供了基础：

1. 添加更多组件的集成测试
2. 开发性能测试和负载测试
3. 实现自动化测试报告生成
4. 与CI/CD流程集成

## 整体测试策略与框架

MarketPrism项目采用了全面的测试策略，包括：

1. **单元测试**：测试各个组件的独立功能
   - DataNormalizer标准化服务
   - ClickHouse存储接口
   - 数据采集服务(go-collector)
   - API服务端点

2. **集成测试**：测试组件间的集成和数据流
   - NATS → DataNormalizer → ClickHouse流程
   - 数据采集服务 → NATS
   - 完整端到端(E2E)数据流

3. **模拟测试**：无Docker环境下的集成测试
   - 模拟NATS和ClickHouse服务
   - 验证核心业务逻辑

4. **性能测试**（计划中）：测试系统性能和吞吐量
   - 数据处理性能
   - 存储写入性能
   - 消息传递性能
   - API响应性能

5. **负载测试**（计划中）：测试系统在高负载下的稳定性
   - 高频数据采集
   - 大批量数据处理
   - 多交易所并发数据处理

## 新增测试组件

### ClickHouse存储接口测试

ClickHouse存储接口负责与ClickHouse数据库交互，提供数据存储和查询功能。我们对其进行了全面测试：

1. **核心功能测试**
   - 单条交易数据插入
   - 批量交易数据插入
   - 按时间范围查询交易数据
   - 旧数据清理

2. **边界条件测试**
   - 空批次处理
   - 无结果查询

3. **错误处理测试**
   - 数据库连接错误
   - 查询错误

测试文件：`tests/unit/services/test_clickhouse_storage.py`

### 数据采集服务测试

数据采集服务是系统的数据入口，负责从交易所收集原始数据。我们对其进行了深入测试：

1. **连接管理测试**
   - WebSocket连接建立
   - 连接断开处理
   - 自动重连机制

2. **数据订阅测试**
   - 交易数据订阅
   - 消息格式验证

3. **错误处理测试**
   - 消息处理错误
   - 网络错误处理

测试文件：`services/go-collector/internal/binance/client_test.go`

### API服务端点测试

API服务为外部应用提供数据访问接口。我们测试了所有关键端点：

1. **交易数据API**
   - 基本参数验证
   - 时间范围过滤
   - 默认参数处理

2. **订单簿快照API**
   - 符号和交易所过滤
   - 数据格式验证

3. **市场概况API**
   - 全市场数据获取
   - 特定交易对过滤

测试文件：`tests/unit/services/test_api_endpoints.py`

### 采集服务集成测试

测试数据采集服务与NATS的集成，确保数据能够正确发送至消息系统：

1. **消息格式验证**
   - 验证消息格式符合预期
   - 字段类型和内容测试

2. **数据流测试**
   - 从采集到标准化的流程
   - 消息传递的正确性

3. **多交易所测试**
   - 测试多交易所并发数据采集
   - 验证不同交易所数据的正确处理

测试文件：`tests/integration/services/test_collector_integration.py`

### 端到端(E2E)集成测试

测试从数据采集到存储再到API查询的完整流程：

1. **完整流程测试**
   - 模拟数据采集
   - 数据标准化处理
   - 数据存储和查询

2. **多交易所E2E测试**
   - 测试多交易所数据的完整流程
   - 验证交易所数据的差异性处理

测试文件：`tests/integration/test_e2e_flow.py`

## 测试执行工具

为了方便测试执行，我们创建了自动化测试脚本：

1. **Windows环境**
   - `tests/run_all_tests.bat`：自动执行所有测试
   - 智能检测Docker可用性
   - 按测试类型分组执行

2. **Linux/macOS环境**
   - `tests/run_all_tests.sh`：自动执行所有测试
   - 提供与Windows版本相同的功能
   - 适配Unix环境

## 测试计划与进展

我们创建了详细的测试计划，追踪测试进度和计划：

- 文件：`tests/test_plan.md`
- 内容：测试阶段、优先级、状态、实施步骤
- 进度：前两个阶段（单元测试和集成测试）已完成
- 后续：计划开展性能测试和负载测试

## 测试驱动开发实践经验

在MarketPrism项目中实践TDD方法的主要收获：

1. **设计优先**：先写测试促使我们思考接口设计和功能需求
2. **增量开发**：小步快跑，每个功能都有测试保障
3. **重构信心**：有测试作为保障，可以放心重构代码
4. **文档作用**：测试代码本身就是最好的使用文档
5. **边界覆盖**：TDD帮助我们思考更多边界情况

## 模拟集成测试实践：无Docker环境支持

在实际开发过程中，有时我们可能无法轻松获取Docker环境，特别是在某些限制的CI/CD环境或特定的开发机器上。针对这种情况，我们实现了模拟集成测试方案，确保即使没有实际的NATS和ClickHouse容器，也能验证系统组件的集成功能。

### 模拟服务设计

1. **模拟NATS客户端**：
   - 使用Python的`unittest.mock.AsyncMock`实现了异步NATS客户端
   - 模拟了`subscribe`、`publish`和`close`等关键方法
   - 实现了消息回调机制，允许测试消息流

2. **模拟ClickHouse客户端**：
   - 使用`unittest.mock.MagicMock`模拟数据库客户端
   - 实现了内存存储机制，模拟数据写入和查询
   - 支持SQL语法解析，正确响应不同类型的查询

### 模拟测试场景

我们复制了实际集成测试的两个关键场景：

1. **NATS到标准化器测试**：
   - 验证从模拟NATS接收数据
   - 通过标准化器处理
   - 确认结果正确性

2. **端到端流程测试**：
   - 模拟完整流程：NATS → 标准化器 → ClickHouse
   - 验证数据在整个流程中保持一致性
   - 确认标准化和存储正确执行

### 实现方式

我们创建了两个关键文件：

1. **mock_conftest.py**：
   - 提供测试配置和模拟服务客户端
   - 实现模拟数据存储和检索机制
   - 处理异步通信流程

2. **test_mock_normalizer.py**：
   - 使用模拟服务进行集成测试
   - 实现了与实际集成测试相同的测试用例
   - 不依赖Docker环境运行

### 价值与收获

模拟集成测试为项目带来了以下价值：

1. **开发灵活性**：允许在任何环境下进行测试
2. **CI/CD兼容性**：适用于限制容器使用的CI环境
3. **快速反馈**：测试运行更快，无需等待容器启动
4. **测试覆盖率**：在所有环境中保持高测试覆盖率
5. **代码质量**：确保代码在不同环境中表现一致

# 测试框架

此文档描述 MarketPrism 的测试框架和实现，包括单元测试、集成测试、性能测试和负载测试。

## 1. 测试架构

MarketPrism 采用多层测试架构，确保系统各组件和整体功能的正确性、性能和稳定性。

```
+----------------+    +----------------+    +----------------+    +----------------+
|                |    |                |    |                |    |                |
|   单元测试     |    |   集成测试     |    |   性能测试     |    |   负载测试     |
|                |    |                |    |                |    |                |
+----------------+    +----------------+    +----------------+    +----------------+
      测试各组件           测试组件间            测量性能             测试高负载
      独立功能             交互能力             和响应时间            场景下的稳定性
```

## 2. 单元测试

单元测试确保各组件功能的正确性，覆盖核心服务和功能模块。

### 已实现的单元测试：

1. **数据标准化器测试** (`tests/unit/services/test_data_normalizer.py`)
   - 测试交易数据标准化
   - 测试不同交易所数据格式转换
   - 测试异常处理和边界条件

2. **ClickHouse存储接口测试** (`tests/unit/services/test_clickhouse_storage.py`)
   - 测试数据插入功能
   - 测试查询功能和条件过滤
   - 测试批量操作和事务处理

3. **API端点测试** (`tests/unit/services/test_api_endpoints.py`)
   - 测试各类数据查询API
   - 测试参数验证和错误处理
   - 测试响应格式和内容正确性

## 3. 集成测试

集成测试验证组件间的交互和协作能力，确保不同服务能够正确协同工作。

### 已实现的集成测试：

1. **数据采集器集成测试** (`tests/integration/services/test_collector_integration.py`)
   - 测试数据采集器与NATS的集成
   - 测试WebSocket连接和数据订阅
   - 测试错误处理和恢复机制

2. **数据标准化器集成测试** (`tests/integration/services/test_normalizer_integration.py`)
   - 测试标准化器与NATS的集成
   - 测试标准化器与ClickHouse的集成
   - 测试完整数据流转过程

3. **端到端流程测试** (`tests/integration/test_e2e_flow.py`)
   - 测试从数据采集到API查询的完整流程
   - 测试多交易所数据流
   - 测试系统在各种场景下的稳健性

## 4. 性能测试

性能测试测量系统各组件在不同条件下的性能表现，优化系统响应速度和资源利用。

### 已实现的性能测试：

1. **数据吞吐量测试** (`tests/performance/test_data_throughput.py`)
   - 测试数据标准化组件的吞吐能力
   - 测试ClickHouse写入性能
   - 测试NATS消息传递性能

2. **API响应时间测试** (`tests/performance/test_api_response.py`)
   - 测试各类API端点的响应时间
   - 测试在不同查询条件下的性能表现
   - 测试并发请求处理能力

### 性能指标：

- **数据标准化速度**: 每秒处理消息数 (目标: >1000条/秒)
- **数据存储速度**: 每秒写入ClickHouse记录数 (目标: >5000条/秒)
- **API响应时间**: 95%请求的响应时间 (目标: <500ms)
- **NATS吞吐量**: 消息传递速率 (目标: >5000条/秒)

## 5. 负载测试

负载测试验证系统在高负载条件下的稳定性和性能，模拟极端场景下的系统表现。

### 已实现的负载测试：

1. **高频数据采集测试** (`tests/load_testing/test_high_frequency_collection.py`)
   - 测试高频数据采集场景下的系统表现
   - 测试多交易所并发数据处理能力
   - 验证系统在持续高负载下的稳定性

2. **大批量数据处理测试** (`tests/load_testing/test_large_data_processing.py`)
   - 测试大批量数据标准化性能
   - 测试大批量数据库操作性能
   - 测试历史数据加载场景

### 负载场景：

- **峰值交易数据**: 模拟市场波动时的高频交易数据
- **批量历史数据**: 模拟加载大量历史数据的场景
- **多交易所并发**: 同时处理多个交易所的数据流
- **持续高负载**: 在持续高负载下运行系统

## 6. 测试执行

测试执行可以通过自动化脚本或手动命令进行：

### 自动化执行：

- Windows: `.\tests\run_all_tests.bat`
- Linux/macOS: `bash ./tests/run_all_tests.sh`

### 手动执行：

```bash
# 单元测试
python -m pytest tests/unit/ -v

# 集成测试
python -m pytest tests/integration/ --run-integration -v

# 性能测试
python -m pytest tests/performance/ --run-performance -v

# 负载测试
python -m pytest tests/load_testing/ --run-load-testing -v

# 特定测试文件
python -m pytest tests/path/to/test_file.py -v
```

## 7. 测试环境

测试环境使用Docker容器或模拟对象，根据需要提供不同级别的隔离：

1. **Docker 容器**:
   - `docker-compose.testing.yml` 定义测试所需的服务
   - 包括 NATS、ClickHouse 等依赖服务

2. **模拟对象**:
   - 无 Docker 环境下使用模拟对象替代外部依赖
   - 提供较低隔离度但便于快速测试

## 8. 测试数据

测试数据提供方式：

1. **静态样本数据**: 在 `fixtures/` 目录中定义
2. **动态生成数据**: 使用数据生成工具创建
3. **模拟交易所数据**: 模拟真实交易所数据格式

## 9. 持续集成

测试框架集成到 CI/CD 流程中：

1. GitHub Actions 自动运行单元测试和集成测试
2. 仅在专用环境中运行性能测试和负载测试
3. 测试结果影响部署决策

## 10. 后续计划

1. 增加更多边缘情况测试
2. 改进测试覆盖率报告
3. 扩展负载测试场景
4. 优化测试执行效率
