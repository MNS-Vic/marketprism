#!/usr/bin/env python3
"""
MarketPrism ä¼˜åŒ–åçš„ç«¯åˆ°ç«¯æµ‹è¯•

éªŒè¯ä¼˜åŒ–æ•ˆæœï¼š
1. aiohttpä¼šè¯æ³„æ¼ä¿®å¤
2. äº¤æ˜“æ‰€è¿æ¥ç¨³å®šæ€§æå‡
3. èµ„æºç®¡ç†ä¼˜åŒ–
4. é”™è¯¯å¤„ç†æ”¹è¿›
5. æ€§èƒ½æå‡éªŒè¯
"""

import asyncio
import json
import yaml
import sys
import time
import psutil
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Any
import gc

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.networking.optimized_session_manager import SessionManager, SessionConfig
from core.networking.enhanced_exchange_connector import create_exchange_connector, EXCHANGE_CONFIGS
from core.monitoring.resource_manager import ResourceManager, ResourceConfig
from config.app_config import NetworkConfig


class OptimizedE2ETest:
    """ä¼˜åŒ–åçš„ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = None
        self.session_manager = None
        self.resource_manager = None
        self.connectors = {}
        
        # æ€§èƒ½åŸºå‡†
        self.performance_baseline = {
            'memory_usage_mb': 0,
            'session_leaks': 0,
            'connection_success_rate': 0.0,
            'response_time_ms': 0,
            'gc_collections': 0
        }
    
    async def setup_optimized_components(self):
        """è®¾ç½®ä¼˜åŒ–ç»„ä»¶"""
        print("ğŸ”§ è®¾ç½®ä¼˜åŒ–ç»„ä»¶")
        print("-" * 40)
        
        try:
            # 1. åˆå§‹åŒ–ä¼˜åŒ–çš„ä¼šè¯ç®¡ç†å™¨
            session_config = SessionConfig(
                connection_timeout=15.0,
                read_timeout=30.0,
                total_timeout=60.0,
                connector_limit=50,
                connector_limit_per_host=5,
                max_retries=3,
                proxy_url=NetworkConfig.get_proxy_dict().get('https') if NetworkConfig.get_proxy_dict() else None
            )
            
            self.session_manager = SessionManager(session_config)
            print(f"  âœ… ä¼˜åŒ–ä¼šè¯ç®¡ç†å™¨å·²åˆå§‹åŒ–")
            
            # 2. åˆå§‹åŒ–èµ„æºç®¡ç†å™¨
            resource_config = ResourceConfig(
                max_memory_usage=1024 * 1024 * 1024,  # 1GB
                memory_check_interval=30,
                cleanup_interval=15,
                enable_monitoring=True
            )
            
            self.resource_manager = ResourceManager(resource_config)
            await self.resource_manager.start()
            print(f"  âœ… èµ„æºç®¡ç†å™¨å·²å¯åŠ¨")
            
            # 3. åˆ›å»ºå¢å¼ºçš„äº¤æ˜“æ‰€è¿æ¥å™¨
            exchanges = ['binance', 'okx', 'deribit']
            
            for exchange in exchanges:
                try:
                    config_overrides = {
                        'http_proxy': NetworkConfig.get_proxy_dict().get('https') if NetworkConfig.get_proxy_dict() else None,
                        'request_timeout': 20.0,
                        'max_retries': 3
                    }
                    
                    connector = create_exchange_connector(exchange, config_overrides)
                    await connector.initialize()
                    
                    self.connectors[exchange] = connector
                    print(f"    âœ… {exchange.upper()} è¿æ¥å™¨å·²åˆå§‹åŒ–")
                    
                except Exception as e:
                    print(f"    âš ï¸ {exchange.upper()} è¿æ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                    # ä¸ä¸­æ–­æµ‹è¯•ï¼Œç»§ç»­å…¶ä»–äº¤æ˜“æ‰€
            
            print(f"âœ… ä¼˜åŒ–ç»„ä»¶è®¾ç½®å®Œæˆ: {len(self.connectors)} ä¸ªè¿æ¥å™¨å¯ç”¨")
            return True
            
        except Exception as e:
            print(f"  âŒ ä¼˜åŒ–ç»„ä»¶è®¾ç½®å¤±è´¥: {e}")
            return False
    
    async def test_session_leak_prevention(self):
        """æµ‹è¯•ä¼šè¯æ³„æ¼é¢„é˜²"""
        print("\nğŸ” ä¼šè¯æ³„æ¼é¢„é˜²æµ‹è¯•")
        print("-" * 40)
        
        initial_sessions = len(self.session_manager._sessions)
        initial_refs = len(self.session_manager._session_refs)
        
        print(f"  åˆå§‹ä¼šè¯æ•°: {initial_sessions}")
        print(f"  åˆå§‹å¼•ç”¨æ•°: {initial_refs}")
        
        # åˆ›å»ºå¤šä¸ªä¼šè¯å¹¶æµ‹è¯•æ¸…ç†
        test_sessions = []
        for i in range(20):
            session_key = f"test_session_{i}"
            session = self.session_manager.get_session(session_key)
            test_sessions.append((session_key, session))
        
        current_sessions = len(self.session_manager._sessions)
        print(f"  åˆ›å»ºåä¼šè¯æ•°: {current_sessions}")
        
        # å…³é—­éƒ¨åˆ†ä¼šè¯
        for i in range(0, 10):
            session_key, _ = test_sessions[i]
            await self.session_manager.close_session(session_key)
        
        # ç­‰å¾…æ¸…ç†ä»»åŠ¡è¿è¡Œ
        await asyncio.sleep(5)
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        collected = gc.collect()
        
        final_sessions = len(self.session_manager._sessions)
        final_refs = len(self.session_manager._session_refs)
        
        print(f"  æ¸…ç†åä¼šè¯æ•°: {final_sessions}")
        print(f"  æ¸…ç†åå¼•ç”¨æ•°: {final_refs}")
        print(f"  åƒåœ¾å›æ”¶å¯¹è±¡: {collected}")
        
        # éªŒè¯ç»“æœ
        session_leak_prevented = (current_sessions - final_sessions) >= 10
        reference_cleanup = final_refs <= initial_refs + 10
        
        results = {
            'initial_sessions': initial_sessions,
            'peak_sessions': current_sessions,
            'final_sessions': final_sessions,
            'initial_refs': initial_refs,
            'final_refs': final_refs,
            'gc_collected': collected,
            'leak_prevented': session_leak_prevented,
            'refs_cleaned': reference_cleanup,
            'test_passed': session_leak_prevented and reference_cleanup
        }
        
        status = "âœ… é€šè¿‡" if results['test_passed'] else "âŒ å¤±è´¥"
        print(f"  {status} ä¼šè¯æ³„æ¼é¢„é˜²: {results['leak_prevented']}")
        print(f"  {status} å¼•ç”¨æ¸…ç†: {results['refs_cleaned']}")
        
        return results
    
    async def test_connection_stability(self):
        """æµ‹è¯•è¿æ¥ç¨³å®šæ€§"""
        print("\nğŸŒ è¿æ¥ç¨³å®šæ€§æµ‹è¯•")
        print("-" * 40)
        
        connection_results = {}
        total_attempts = 0
        successful_connections = 0
        
        for exchange, connector in self.connectors.items():
            print(f"  æµ‹è¯• {exchange.upper()} è¿æ¥ç¨³å®šæ€§...")
            
            exchange_attempts = 0
            exchange_successes = 0
            response_times = []
            
            # è¿›è¡Œå¤šæ¬¡è¯·æ±‚æµ‹è¯•
            for attempt in range(5):
                try:
                    start_time = time.time()
                    
                    # æµ‹è¯•è·å–è¡Œæƒ…æ•°æ®
                    if exchange == 'binance':
                        data = await connector.get_ticker('BTCUSDT')
                    elif exchange == 'okx':
                        data = await connector.get_ticker('BTC-USDT')
                    elif exchange == 'deribit':
                        data = await connector.get_ticker('BTC-PERPETUAL')
                    
                    response_time = (time.time() - start_time) * 1000
                    response_times.append(response_time)
                    
                    exchange_attempts += 1
                    exchange_successes += 1
                    
                    print(f"    âœ… å°è¯• {attempt + 1}: {response_time:.1f}ms")
                    
                except Exception as e:
                    exchange_attempts += 1
                    print(f"    âŒ å°è¯• {attempt + 1}: {str(e)[:50]}")
                
                # çŸ­æš‚ç­‰å¾…é¿å…é¢‘ç‡é™åˆ¶
                await asyncio.sleep(0.5)
            
            success_rate = exchange_successes / exchange_attempts if exchange_attempts > 0 else 0
            avg_response_time = sum(response_times) / len(response_times) if response_times else 0
            
            connection_results[exchange] = {
                'attempts': exchange_attempts,
                'successes': exchange_successes,
                'success_rate': success_rate,
                'avg_response_time': avg_response_time,
                'response_times': response_times
            }
            
            total_attempts += exchange_attempts
            successful_connections += exchange_successes
            
            print(f"    ğŸ“Š æˆåŠŸç‡: {success_rate:.1%}, å¹³å‡å“åº”: {avg_response_time:.1f}ms")
        
        overall_success_rate = successful_connections / total_attempts if total_attempts > 0 else 0
        
        results = {
            'total_attempts': total_attempts,
            'successful_connections': successful_connections,
            'overall_success_rate': overall_success_rate,
            'exchange_details': connection_results,
            'test_passed': overall_success_rate >= 0.6  # 60%æˆåŠŸç‡é˜ˆå€¼
        }
        
        status = "âœ… é€šè¿‡" if results['test_passed'] else "âŒ å¤±è´¥"
        print(f"  {status} æ•´ä½“è¿æ¥ç¨³å®šæ€§: {overall_success_rate:.1%}")
        
        return results
    
    async def test_resource_management(self):
        """æµ‹è¯•èµ„æºç®¡ç†"""
        print("\nğŸ’¾ èµ„æºç®¡ç†æµ‹è¯•")
        print("-" * 40)
        
        # è·å–åˆå§‹èµ„æºçŠ¶æ€
        initial_stats = self.resource_manager.get_statistics()
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        print(f"  åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.1f}MB")
        print(f"  åˆå§‹è¿½è¸ªå¯¹è±¡: {initial_stats['tracker_stats']['total_objects']}")
        
        # åˆ›å»ºä¸€äº›å¯¹è±¡è¿›è¡Œèµ„æºç®¡ç†æµ‹è¯•
        managed_objects = []
        for i in range(100):
            obj = {'data': f'test_object_{i}', 'size': 1024 * i}
            self.resource_manager.track_object(obj)
            managed_objects.append(obj)
        
        # æ¨¡æ‹Ÿä¸€äº›ç½‘ç»œè¿æ¥
        connection_keys = []
        for i in range(10):
            key = f"test_connection_{i}"
            connection_keys.append(key)
            
            # ä½¿ç”¨è¿æ¥æ± è·å–æ¨¡æ‹Ÿè¿æ¥
            async def mock_factory():
                return {'mock_connection': True, 'id': key}
            
            await self.resource_manager.get_connection(key, mock_factory)
        
        # ç­‰å¾…ç›‘æ§æ”¶é›†æ•°æ®
        await asyncio.sleep(3)
        
        # è·å–ä¸­é—´çŠ¶æ€
        mid_stats = self.resource_manager.get_statistics()
        mid_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        print(f"  ä¸­é—´å†…å­˜ä½¿ç”¨: {mid_memory:.1f}MB (+{mid_memory - initial_memory:.1f}MB)")
        print(f"  ä¸­é—´è¿½è¸ªå¯¹è±¡: {mid_stats['tracker_stats']['total_objects']}")
        print(f"  è¿æ¥æ± ä½¿ç”¨: {mid_stats['connection_pool_stats']['total_connections']}")
        
        # æ¸…ç†ä¸€åŠå¯¹è±¡
        for i in range(50):
            self.resource_manager.untrack_object(managed_objects[i])
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc_result = self.resource_manager.force_gc()
        
        # ç­‰å¾…æ¸…ç†
        await asyncio.sleep(2)
        
        # è·å–æœ€ç»ˆçŠ¶æ€
        final_stats = self.resource_manager.get_statistics()
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        print(f"  æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_memory:.1f}MB")
        print(f"  æœ€ç»ˆè¿½è¸ªå¯¹è±¡: {final_stats['tracker_stats']['total_objects']}")
        print(f"  GCå›æ”¶å¯¹è±¡: {gc_result['collected_objects']}")
        
        # æ£€æŸ¥èµ„æºç®¡ç†æ•ˆæœ
        memory_growth = final_memory - initial_memory
        object_cleanup = (mid_stats['tracker_stats']['total_objects'] - 
                         final_stats['tracker_stats']['total_objects'])
        
        results = {
            'initial_memory_mb': initial_memory,
            'peak_memory_mb': mid_memory,
            'final_memory_mb': final_memory,
            'memory_growth_mb': memory_growth,
            'initial_objects': initial_stats['tracker_stats']['total_objects'],
            'peak_objects': mid_stats['tracker_stats']['total_objects'],
            'final_objects': final_stats['tracker_stats']['total_objects'],
            'objects_cleaned': object_cleanup,
            'gc_collected': gc_result['collected_objects'],
            'connections_managed': mid_stats['connection_pool_stats']['total_connections'],
            'memory_stable': memory_growth < 50,  # å†…å­˜å¢é•¿ä¸è¶…è¿‡50MB
            'objects_managed': object_cleanup >= 40,  # è‡³å°‘æ¸…ç†40ä¸ªå¯¹è±¡
            'test_passed': memory_growth < 50 and object_cleanup >= 40
        }
        
        status = "âœ… é€šè¿‡" if results['test_passed'] else "âŒ å¤±è´¥"
        print(f"  {status} å†…å­˜ç®¡ç†: å¢é•¿ {memory_growth:.1f}MB")
        print(f"  {status} å¯¹è±¡ç®¡ç†: æ¸…ç† {object_cleanup} ä¸ªå¯¹è±¡")
        
        return results
    
    async def test_error_handling_improvements(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†æ”¹è¿›"""
        print("\nğŸ› ï¸ é”™è¯¯å¤„ç†æ”¹è¿›æµ‹è¯•")
        print("-" * 40)
        
        error_scenarios = []
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„é”™è¯¯å¤„ç†
        for exchange, connector in self.connectors.items():
            print(f"  æµ‹è¯• {exchange.upper()} é”™è¯¯å¤„ç†...")
            
            # 1. æµ‹è¯•æ— æ•ˆç¬¦å·é”™è¯¯å¤„ç†
            try:
                await connector.get_ticker('INVALID_SYMBOL_12345')
                error_scenarios.append({
                    'exchange': exchange,
                    'scenario': 'invalid_symbol',
                    'handled': False,
                    'error': 'No error raised'
                })
            except Exception as e:
                error_scenarios.append({
                    'exchange': exchange,
                    'scenario': 'invalid_symbol',
                    'handled': True,
                    'error': str(e)[:100]
                })
                print(f"    âœ… æ— æ•ˆç¬¦å·é”™è¯¯æ­£ç¡®å¤„ç†: {str(e)[:50]}")
            
            # 2. æµ‹è¯•è¶…æ—¶å¤„ç†ï¼ˆå¿«é€Ÿå¤±è´¥ï¼‰
            try:
                # æ¨¡æ‹Ÿè¶…æ—¶åœºæ™¯
                original_timeout = connector.config.request_timeout
                connector.config.request_timeout = 0.1  # æçŸ­è¶…æ—¶
                
                await connector.get_ticker('BTCUSDT')
                
                connector.config.request_timeout = original_timeout
                error_scenarios.append({
                    'exchange': exchange,
                    'scenario': 'timeout',
                    'handled': False,
                    'error': 'No timeout occurred'
                })
            except Exception as e:
                connector.config.request_timeout = original_timeout
                error_scenarios.append({
                    'exchange': exchange,
                    'scenario': 'timeout',
                    'handled': True,
                    'error': str(e)[:100]
                })
                print(f"    âœ… è¶…æ—¶é”™è¯¯æ­£ç¡®å¤„ç†: {str(e)[:50]}")
        
        # ç»Ÿè®¡é”™è¯¯å¤„ç†æ•ˆæœ
        total_scenarios = len(error_scenarios)
        handled_scenarios = sum(1 for s in error_scenarios if s['handled'])
        error_handling_rate = handled_scenarios / total_scenarios if total_scenarios > 0 else 0
        
        results = {
            'total_scenarios': total_scenarios,
            'handled_scenarios': handled_scenarios,
            'error_handling_rate': error_handling_rate,
            'error_details': error_scenarios,
            'test_passed': error_handling_rate >= 0.8  # 80%é”™è¯¯å¤„ç†ç‡
        }
        
        status = "âœ… é€šè¿‡" if results['test_passed'] else "âŒ å¤±è´¥"
        print(f"  {status} é”™è¯¯å¤„ç†ç‡: {error_handling_rate:.1%}")
        
        return results
    
    async def run_performance_benchmark(self):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\nâš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("-" * 40)
        
        # å¹¶å‘è¯·æ±‚æµ‹è¯•
        concurrent_requests = 50
        start_time = time.time()
        
        async def make_concurrent_request(session_key: str):
            """å¹¶å‘è¯·æ±‚å‡½æ•°"""
            try:
                async with self.session_manager.request(
                    'GET', 
                    'https://httpbin.org/delay/1',
                    session_key=session_key
                ) as response:
                    return await response.json()
            except Exception as e:
                return {'error': str(e)}
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        tasks = [
            make_concurrent_request(f"perf_test_{i}")
            for i in range(concurrent_requests)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # ç»Ÿè®¡ç»“æœ
        successful_requests = sum(1 for r in results if isinstance(r, dict) and 'error' not in r)
        failed_requests = concurrent_requests - successful_requests
        requests_per_second = concurrent_requests / duration
        
        # å†…å­˜æ€§èƒ½æµ‹è¯•
        memory_before = psutil.Process().memory_info().rss / 1024 / 1024
        
        # åˆ›å»ºå¤§é‡ä¸´æ—¶å¯¹è±¡
        temp_objects = []
        for i in range(1000):
            temp_objects.append({'id': i, 'data': 'x' * 1000})
        
        memory_after = psutil.Process().memory_info().rss / 1024 / 1024
        memory_usage = memory_after - memory_before
        
        # æ¸…ç†å¹¶æ£€æŸ¥å†…å­˜å›æ”¶
        del temp_objects
        gc.collect()
        await asyncio.sleep(1)
        
        memory_final = psutil.Process().memory_info().rss / 1024 / 1024
        memory_recovered = memory_after - memory_final
        
        performance_results = {
            'concurrent_requests': concurrent_requests,
            'successful_requests': successful_requests,
            'failed_requests': failed_requests,
            'success_rate': successful_requests / concurrent_requests,
            'duration_seconds': duration,
            'requests_per_second': requests_per_second,
            'memory_usage_mb': memory_usage,
            'memory_recovered_mb': memory_recovered,
            'memory_recovery_rate': memory_recovered / memory_usage if memory_usage > 0 else 0,
            'test_passed': (
                successful_requests / concurrent_requests >= 0.8 and
                requests_per_second >= 10 and
                memory_recovery_rate >= 0.5
            )
        }
        
        status = "âœ… é€šè¿‡" if performance_results['test_passed'] else "âŒ å¤±è´¥"
        print(f"  {status} å¹¶å‘æ€§èƒ½: {requests_per_second:.1f} req/s")
        print(f"  {status} æˆåŠŸç‡: {performance_results['success_rate']:.1%}")
        print(f"  {status} å†…å­˜å›æ”¶: {performance_results['memory_recovery_rate']:.1%}")
        
        return performance_results
    
    async def generate_optimization_report(self, test_results: Dict[str, Any]):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        end_time = datetime.now(timezone.utc)
        duration = (end_time - self.start_time).total_seconds()
        
        # æ±‡æ€»æµ‹è¯•ç»“æœ
        all_tests_passed = all(
            result.get('test_passed', False) 
            for result in test_results.values()
        )
        
        # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
        improvements = {
            'session_leak_prevention': test_results['session_leak']['leak_prevented'],
            'connection_stability': test_results['connection']['overall_success_rate'] >= 0.6,
            'resource_management': test_results['resource']['test_passed'],
            'error_handling': test_results['error_handling']['error_handling_rate'] >= 0.8,
            'performance': test_results['performance']['test_passed']
        }
        
        improvement_score = sum(improvements.values()) / len(improvements)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        optimization_report = {
            'test_metadata': {
                'test_type': 'OPTIMIZED_E2E_COMPREHENSIVE',
                'version': '1.0',
                'start_time': self.start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'duration_seconds': duration,
                'test_environment': 'optimization_validation'
            },
            'optimization_summary': {
                'all_tests_passed': all_tests_passed,
                'improvement_score': improvement_score,
                'improvements': improvements,
                'optimized_components': [
                    'session_manager',
                    'exchange_connectors',
                    'resource_manager',
                    'error_handling',
                    'performance_tuning'
                ]
            },
            'detailed_results': test_results,
            'component_statistics': {
                'session_manager': self.session_manager.get_statistics() if self.session_manager else {},
                'resource_manager': self.resource_manager.get_statistics() if self.resource_manager else {},
                'connectors': {
                    exchange: connector.get_statistics()
                    for exchange, connector in self.connectors.items()
                }
            },
            'recommendations': self._generate_recommendations(test_results)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"optimization_report_{int(self.start_time.timestamp())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(optimization_report, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°æ€»ç»“
        print("=" * 80)
        print("ğŸ“Š MarketPrism ç³»ç»Ÿä¼˜åŒ–æŠ¥å‘Š")
        print("=" * 80)
        print(f"ğŸ• æµ‹è¯•æ—¶é•¿: {duration:.2f}ç§’")
        print(f"ğŸ¯ ä¼˜åŒ–è¯„åˆ†: {improvement_score:.1%}")
        print(f"ğŸ“ˆ æ€»ä½“çŠ¶æ€: {'âœ… ä¼˜åŒ–æˆåŠŸ' if all_tests_passed else 'âš ï¸ éƒ¨åˆ†é—®é¢˜'}")
        
        print(f"\nğŸ”§ ä¼˜åŒ–ç»„ä»¶çŠ¶æ€:")
        for component, improved in improvements.items():
            status = "âœ…" if improved else "âŒ"
            print(f"  {status} {component.replace('_', ' ').title()}")
        
        print(f"\nğŸ“Š è¯¦ç»†æŒ‡æ ‡:")
        session_leak = test_results['session_leak']
        print(f"  ä¼šè¯ç®¡ç†: æ³„æ¼é¢„é˜² {session_leak['leak_prevented']}, å¼•ç”¨æ¸…ç† {session_leak['refs_cleaned']}")
        
        connection = test_results['connection']
        print(f"  è¿æ¥ç¨³å®šæ€§: {connection['overall_success_rate']:.1%} æˆåŠŸç‡")
        
        resource = test_results['resource']
        print(f"  èµ„æºç®¡ç†: å†…å­˜å¢é•¿ {resource['memory_growth_mb']:.1f}MB, å¯¹è±¡æ¸…ç† {resource['objects_cleaned']}")
        
        error_handling = test_results['error_handling']
        print(f"  é”™è¯¯å¤„ç†: {error_handling['error_handling_rate']:.1%} å¤„ç†ç‡")
        
        performance = test_results['performance']
        print(f"  æ€§èƒ½æŒ‡æ ‡: {performance['requests_per_second']:.1f} req/s, {performance['memory_recovery_rate']:.1%} å†…å­˜å›æ”¶")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print("=" * 80)
        
        return optimization_report
    
    def _generate_recommendations(self, test_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # ä¼šè¯ç®¡ç†å»ºè®®
        session_leak = test_results['session_leak']
        if not session_leak['leak_prevented']:
            recommendations.append("æ”¹è¿›ä¼šè¯æ¸…ç†æœºåˆ¶ï¼Œå®šæœŸæ£€æŸ¥å¹¶å…³é—­æœªä½¿ç”¨çš„ä¼šè¯")
        
        # è¿æ¥ç¨³å®šæ€§å»ºè®®
        connection = test_results['connection']
        if connection['overall_success_rate'] < 0.8:
            recommendations.append("ä¼˜åŒ–ç½‘ç»œè¿æ¥é…ç½®ï¼Œå¢åŠ é‡è¯•æœºåˆ¶å’Œä»£ç†åˆ‡æ¢")
        
        # èµ„æºç®¡ç†å»ºè®®
        resource = test_results['resource']
        if resource['memory_growth_mb'] > 30:
            recommendations.append("ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå¢åŠ å®šæœŸåƒåœ¾å›æ”¶å’Œå¯¹è±¡æ± æœºåˆ¶")
        
        # é”™è¯¯å¤„ç†å»ºè®®
        error_handling = test_results['error_handling']
        if error_handling['error_handling_rate'] < 0.9:
            recommendations.append("å®Œå–„é”™è¯¯åˆ†ç±»å’Œå¤„ç†ç­–ç•¥ï¼Œå¢åŠ è‡ªåŠ¨æ¢å¤æœºåˆ¶")
        
        # æ€§èƒ½å»ºè®®
        performance = test_results['performance']
        if performance['requests_per_second'] < 20:
            recommendations.append("ä¼˜åŒ–å¹¶å‘å¤„ç†æ€§èƒ½ï¼Œè€ƒè™‘è¿æ¥æ± å¤ç”¨å’Œå¼‚æ­¥ä¼˜åŒ–")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿä¼˜åŒ–çŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ç›‘æ§å’Œå®šæœŸç»´æŠ¤")
        
        return recommendations
    
    async def cleanup(self):
        """æ¸…ç†æµ‹è¯•èµ„æº"""
        try:
            # å…³é—­è¿æ¥å™¨
            for connector in self.connectors.values():
                await connector.close()
            
            # å…³é—­ä¼šè¯ç®¡ç†å™¨
            if self.session_manager:
                await self.session_manager.close()
            
            # åœæ­¢èµ„æºç®¡ç†å™¨
            if self.resource_manager:
                await self.resource_manager.stop()
            
            print("ğŸ§¹ æµ‹è¯•èµ„æºå·²æ¸…ç†")
            
        except Exception as e:
            print(f"âš ï¸ èµ„æºæ¸…ç†å¼‚å¸¸: {e}")
    
    async def run_optimization_test(self):
        """è¿è¡Œä¼˜åŒ–æµ‹è¯•"""
        self.start_time = datetime.now(timezone.utc)
        
        print("ğŸš€ MarketPrism ç³»ç»Ÿä¼˜åŒ–éªŒè¯æµ‹è¯•")
        print("=" * 80)
        print("ğŸ¯ ç›®æ ‡: éªŒè¯ä¼šè¯ç®¡ç†ã€è¿æ¥ç¨³å®šæ€§ã€èµ„æºç®¡ç†ã€é”™è¯¯å¤„ç†ç­‰ä¼˜åŒ–æ•ˆæœ")
        print("=" * 80)
        
        try:
            # 1. è®¾ç½®ä¼˜åŒ–ç»„ä»¶
            if not await self.setup_optimized_components():
                raise Exception("ä¼˜åŒ–ç»„ä»¶è®¾ç½®å¤±è´¥")
            
            # 2. è¿è¡Œå„é¡¹æµ‹è¯•
            test_results = {}
            
            # ä¼šè¯æ³„æ¼é¢„é˜²æµ‹è¯•
            test_results['session_leak'] = await self.test_session_leak_prevention()
            
            # è¿æ¥ç¨³å®šæ€§æµ‹è¯•
            test_results['connection'] = await self.test_connection_stability()
            
            # èµ„æºç®¡ç†æµ‹è¯•
            test_results['resource'] = await self.test_resource_management()
            
            # é”™è¯¯å¤„ç†æ”¹è¿›æµ‹è¯•
            test_results['error_handling'] = await self.test_error_handling_improvements()
            
            # æ€§èƒ½åŸºå‡†æµ‹è¯•
            test_results['performance'] = await self.run_performance_benchmark()
            
            # 3. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
            optimization_report = await self.generate_optimization_report(test_results)
            
            return 0
            
        except Exception as e:
            print(f"\nâŒ ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 1
        
        finally:
            await self.cleanup()


async def main():
    """ä¸»å‡½æ•°"""
    tester = OptimizedE2ETest()
    
    try:
        return await tester.run_optimization_test()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        return 1
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return 1
    finally:
        await tester.cleanup()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    print(f"\nğŸ¯ ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼Œé€€å‡ºä»£ç : {exit_code}")
    sys.exit(exit_code)