#!/usr/bin/env python3
"""
MarketPrism å®Œæ•´æ•°æ®é“¾è·¯å‹åŠ›æµ‹è¯•å’Œè´¨é‡éªŒè¯è„šæœ¬
- è¿è¡Œ 15-20 åˆ†é’Ÿå®Œæ•´å‹åŠ›æµ‹è¯•
- éªŒè¯æ‰€æœ‰ 8 ç§æ•°æ®ç±»å‹çš„å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€å»é‡æ€§ã€å®æ—¶æ€§ã€è¿ç»­æ€§
- ç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼šååé‡ â‰¥125.5 msg/sï¼ŒæˆåŠŸç‡ â‰¥99.6%ï¼Œé”™è¯¯ç‡ â‰ˆ0%
- ç”Ÿæˆè¯¦ç»†çš„æ•°æ®è´¨é‡æŠ¥å‘Š
"""

import asyncio
import aiohttp
import json
import time
import statistics
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import sys

# é…ç½®
TEST_DURATION_MINUTES = 18  # æµ‹è¯•æŒç»­æ—¶é—´
SAMPLE_INTERVAL_SECONDS = 30  # é‡‡æ ·é—´éš”
TARGET_THROUGHPUT = 125.5  # ç›®æ ‡ååé‡ msg/s
TARGET_SUCCESS_RATE = 99.6  # ç›®æ ‡æˆåŠŸç‡ %
MAX_ERROR_RATE = 0.4  # æœ€å¤§é”™è¯¯ç‡ %

# æœåŠ¡ç«¯ç‚¹
COLLECTOR_HEALTH = "http://127.0.0.1:8087/health"
COLLECTOR_METRICS = "http://127.0.0.1:9093/metrics"
HOT_STORAGE_HEALTH = "http://127.0.0.1:8085/health"
COLD_STORAGE_HEALTH = "http://127.0.0.1:8086/health"
NATS_MONITORING = "http://127.0.0.1:8222"
CLICKHOUSE_HTTP = "http://127.0.0.1:8123"

# æ•°æ®ç±»å‹å’Œè¡¨æ˜ å°„
DATA_TYPES = {
    "orderbook": "orderbooks",
    "trade": "trades", 
    "funding_rate": "funding_rates",
    "open_interest": "open_interests",
    "liquidation": "liquidations",
    "lsr_top_position": "lsr_top_positions",
    "lsr_all_account": "lsr_all_accounts",
    "volatility_index": "volatility_indices"
}

# äº¤æ˜“æ‰€å’Œäº¤æ˜“å¯¹
EXCHANGES = {
    "binance_spot": ["BTCUSDT", "ETHUSDT"],
    "binance_derivatives": ["BTCUSDT", "ETHUSDT"],
    "okx_spot": ["BTC-USDT", "ETH-USDT"],
    "okx_derivatives": ["BTC-USDT-SWAP", "ETH-USDT-SWAP"],
    "deribit_derivatives": ["BTC", "ETH"]
}

class StressTestMonitor:
    def __init__(self):
        self.start_time = None
        self.samples = []
        self.initial_counts = {}
        self.session = None
        self.report_data = {
            "test_config": {
                "duration_minutes": TEST_DURATION_MINUTES,
                "target_throughput": TARGET_THROUGHPUT,
                "target_success_rate": TARGET_SUCCESS_RATE,
                "max_error_rate": MAX_ERROR_RATE
            },
            "performance_samples": [],
            "data_quality": {},
            "final_statistics": {}
        }

    async def initialize(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10))
        self.start_time = datetime.now(timezone.utc)
        
        print(f"ğŸš€ MarketPrism å®Œæ•´æ•°æ®é“¾è·¯å‹åŠ›æµ‹è¯•")
        print(f"{'='*50}")
        print(f"æµ‹è¯•æ—¶é•¿: {TEST_DURATION_MINUTES} åˆ†é’Ÿ")
        print(f"ç›®æ ‡ååé‡: â‰¥{TARGET_THROUGHPUT} msg/s")
        print(f"ç›®æ ‡æˆåŠŸç‡: â‰¥{TARGET_SUCCESS_RATE}%")
        print(f"æœ€å¤§é”™è¯¯ç‡: â‰¤{MAX_ERROR_RATE}%")
        print(f"å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        print()

        # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        await self._check_services_health()
        
        # è®°å½•åˆå§‹æ•°æ®è®¡æ•°
        await self._record_initial_counts()

    async def _check_services_health(self):
        """æ£€æŸ¥æ‰€æœ‰æœåŠ¡å¥åº·çŠ¶æ€"""
        print("ğŸ” æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€...")
        
        services = [
            ("Collector", COLLECTOR_HEALTH),
            ("Hot Storage", HOT_STORAGE_HEALTH), 
            ("Cold Storage", COLD_STORAGE_HEALTH)
        ]
        
        all_healthy = True
        for name, url in services:
            try:
                async with self.session.get(url) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        status = data.get("status", "unknown")
                        print(f"  âœ… {name}: {status}")
                        if status != "healthy":
                            all_healthy = False
                    else:
                        print(f"  âŒ {name}: HTTP {resp.status}")
                        all_healthy = False
            except Exception as e:
                print(f"  âŒ {name}: {e}")
                all_healthy = False
        
        if not all_healthy:
            raise RuntimeError("éƒ¨åˆ†æœåŠ¡ä¸å¥åº·ï¼Œæ— æ³•å¼€å§‹å‹åŠ›æµ‹è¯•")

    async def _record_initial_counts(self):
        """è®°å½•åˆå§‹æ•°æ®è®¡æ•°"""
        print("ğŸ“Š è®°å½•åˆå§‹æ•°æ®è®¡æ•°...")
        
        for data_type, table_name in DATA_TYPES.items():
            try:
                # çƒ­ç«¯è®¡æ•°
                hot_count = await self._query_clickhouse(
                    f"SELECT count() FROM marketprism_hot.{table_name}"
                )
                # å†·ç«¯è®¡æ•°
                cold_count = await self._query_clickhouse(
                    f"SELECT count() FROM marketprism_cold.{table_name}"
                )
                
                self.initial_counts[data_type] = {
                    "hot": int(hot_count.strip() or 0),
                    "cold": int(cold_count.strip() or 0)
                }
                print(f"  {data_type}: çƒ­ç«¯={self.initial_counts[data_type]['hot']}, "
                      f"å†·ç«¯={self.initial_counts[data_type]['cold']}")
                
            except Exception as e:
                print(f"  âŒ è·å– {data_type} è®¡æ•°å¤±è´¥: {e}")
                self.initial_counts[data_type] = {"hot": 0, "cold": 0}

    async def run_stress_test(self):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"\nğŸ”¥ å¼€å§‹ {TEST_DURATION_MINUTES} åˆ†é’Ÿå‹åŠ›æµ‹è¯•...")
        print(f"é‡‡æ ·é—´éš”: {SAMPLE_INTERVAL_SECONDS} ç§’")
        print()

        test_end_time = self.start_time + timedelta(minutes=TEST_DURATION_MINUTES)
        sample_count = 0
        
        while datetime.now(timezone.utc) < test_end_time:
            sample_count += 1
            elapsed_minutes = (datetime.now(timezone.utc) - self.start_time).total_seconds() / 60
            
            print(f"ğŸ“ˆ é‡‡æ · #{sample_count} (å·²è¿è¡Œ {elapsed_minutes:.1f} åˆ†é’Ÿ)")
            
            # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
            sample_data = await self._collect_performance_sample()
            sample_data["sample_number"] = sample_count
            sample_data["elapsed_minutes"] = elapsed_minutes
            
            self.samples.append(sample_data)
            self.report_data["performance_samples"].append(sample_data)
            
            # æ˜¾ç¤ºå®æ—¶æŒ‡æ ‡
            self._display_sample_metrics(sample_data)
            
            # ç­‰å¾…ä¸‹æ¬¡é‡‡æ ·
            await asyncio.sleep(SAMPLE_INTERVAL_SECONDS)
        
        print(f"\nâœ… å‹åŠ›æµ‹è¯•å®Œæˆï¼æ€»é‡‡æ ·æ¬¡æ•°: {sample_count}")

    async def _collect_performance_sample(self) -> Dict[str, Any]:
        """æ”¶é›†å•æ¬¡æ€§èƒ½é‡‡æ ·æ•°æ®"""
        sample = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "services": {},
            "nats": {},
            "data_counts": {},
            "throughput": 0,
            "error_rate": 0
        }

        # æ”¶é›†æœåŠ¡å¥åº·çŠ¶æ€
        for service_name, url in [("collector", COLLECTOR_HEALTH), 
                                  ("hot_storage", HOT_STORAGE_HEALTH),
                                  ("cold_storage", COLD_STORAGE_HEALTH)]:
            try:
                async with self.session.get(url) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        sample["services"][service_name] = {
                            "status": data.get("status", "unknown"),
                            "healthy": data.get("status") == "healthy"
                        }
                    else:
                        sample["services"][service_name] = {"status": "error", "healthy": False}
            except:
                sample["services"][service_name] = {"status": "unreachable", "healthy": False}

        # æ”¶é›† NATS æŒ‡æ ‡
        try:
            async with self.session.get(f"{NATS_MONITORING}/jsz") as resp:
                if resp.status == 200:
                    nats_data = await resp.json()
                    sample["nats"] = {
                        "total_messages": nats_data.get("messages", 0),
                        "total_bytes": nats_data.get("bytes", 0),
                        "streams": nats_data.get("streams", 0),
                        "consumers": nats_data.get("consumers", 0)
                    }
        except:
            sample["nats"] = {"error": "unreachable"}

        # æ”¶é›†æ•°æ®è®¡æ•°
        for data_type, table_name in DATA_TYPES.items():
            try:
                hot_count = await self._query_clickhouse(
                    f"SELECT count() FROM marketprism_hot.{table_name}"
                )
                cold_count = await self._query_clickhouse(
                    f"SELECT count() FROM marketprism_cold.{table_name}"
                )
                
                sample["data_counts"][data_type] = {
                    "hot": int(hot_count.strip() or 0),
                    "cold": int(cold_count.strip() or 0)
                }
            except:
                sample["data_counts"][data_type] = {"hot": 0, "cold": 0}

        # è®¡ç®—ååé‡ï¼ˆåŸºäºæ€»æ¶ˆæ¯æ•°å˜åŒ–ï¼‰
        if len(self.samples) > 0:
            prev_sample = self.samples[-1]
            if "nats" in prev_sample and "total_messages" in prev_sample["nats"]:
                msg_diff = sample["nats"].get("total_messages", 0) - prev_sample["nats"].get("total_messages", 0)
                time_diff = SAMPLE_INTERVAL_SECONDS
                sample["throughput"] = msg_diff / time_diff if time_diff > 0 else 0

        return sample

    def _display_sample_metrics(self, sample: Dict[str, Any]):
        """æ˜¾ç¤ºé‡‡æ ·æŒ‡æ ‡"""
        # æœåŠ¡çŠ¶æ€
        services_status = []
        for name, info in sample["services"].items():
            status = "âœ…" if info.get("healthy") else "âŒ"
            services_status.append(f"{name}:{status}")
        
        print(f"  æœåŠ¡çŠ¶æ€: {' '.join(services_status)}")
        
        # NATS æŒ‡æ ‡
        if "total_messages" in sample["nats"]:
            print(f"  NATS: {sample['nats']['total_messages']:,} æ¶ˆæ¯, "
                  f"{sample['nats']['streams']} æµ, {sample['nats']['consumers']} æ¶ˆè´¹è€…")
        
        # ååé‡
        if sample["throughput"] > 0:
            throughput_status = "âœ…" if sample["throughput"] >= TARGET_THROUGHPUT else "âš ï¸"
            print(f"  ååé‡: {sample['throughput']:.1f} msg/s {throughput_status}")
        
        # æ•°æ®å¢é•¿
        growth_summary = []
        for data_type, counts in sample["data_counts"].items():
            if data_type in self.initial_counts:
                hot_growth = counts["hot"] - self.initial_counts[data_type]["hot"]
                if hot_growth > 0:
                    growth_summary.append(f"{data_type}:+{hot_growth}")
        
        if growth_summary:
            print(f"  æ•°æ®å¢é•¿: {', '.join(growth_summary[:4])}")  # åªæ˜¾ç¤ºå‰4ä¸ª
        
        print()

    async def _query_clickhouse(self, query: str) -> str:
        """æŸ¥è¯¢ ClickHouse"""
        url = f"{CLICKHOUSE_HTTP}/?query={query.replace(' ', '%20')}"
        async with self.session.get(url) as resp:
            if resp.status == 200:
                return await resp.text()
            else:
                raise Exception(f"ClickHouse query failed: {resp.status}")

    async def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š...")
        
        # è®¡ç®—æœ€ç»ˆæ•°æ®è®¡æ•°
        final_counts = {}
        for data_type, table_name in DATA_TYPES.items():
            try:
                hot_count = await self._query_clickhouse(
                    f"SELECT count() FROM marketprism_hot.{table_name}"
                )
                cold_count = await self._query_clickhouse(
                    f"SELECT count() FROM marketprism_cold.{table_name}"
                )
                
                final_counts[data_type] = {
                    "hot": int(hot_count.strip() or 0),
                    "cold": int(cold_count.strip() or 0),
                    "hot_growth": int(hot_count.strip() or 0) - self.initial_counts[data_type]["hot"],
                    "cold_growth": int(cold_count.strip() or 0) - self.initial_counts[data_type]["cold"]
                }
            except Exception as e:
                print(f"  âŒ è·å–æœ€ç»ˆ {data_type} è®¡æ•°å¤±è´¥: {e}")
                final_counts[data_type] = {"hot": 0, "cold": 0, "hot_growth": 0, "cold_growth": 0}

        # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
        throughputs = [s["throughput"] for s in self.samples if s["throughput"] > 0]
        avg_throughput = statistics.mean(throughputs) if throughputs else 0
        max_throughput = max(throughputs) if throughputs else 0
        min_throughput = min(throughputs) if throughputs else 0

        # è®¡ç®—æœåŠ¡å¯ç”¨æ€§
        service_availability = {}
        for service_name in ["collector", "hot_storage", "cold_storage"]:
            healthy_samples = sum(1 for s in self.samples 
                                if s["services"].get(service_name, {}).get("healthy", False))
            availability = (healthy_samples / len(self.samples)) * 100 if self.samples else 0
            service_availability[service_name] = availability

        # ä¿å­˜æŠ¥å‘Šæ•°æ®
        self.report_data["final_statistics"] = {
            "test_duration_minutes": TEST_DURATION_MINUTES,
            "total_samples": len(self.samples),
            "data_counts": final_counts,
            "performance": {
                "avg_throughput": avg_throughput,
                "max_throughput": max_throughput,
                "min_throughput": min_throughput,
                "throughput_target_met": avg_throughput >= TARGET_THROUGHPUT
            },
            "service_availability": service_availability,
            "overall_success": all(avail >= TARGET_SUCCESS_RATE for avail in service_availability.values())
        }

        # æ˜¾ç¤ºæŠ¥å‘Š
        await self._display_final_report()
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        await self._save_report_to_file()

    async def _display_final_report(self):
        """æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š"""
        stats = self.report_data["final_statistics"]
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š MarketPrism å‹åŠ›æµ‹è¯•æœ€ç»ˆæŠ¥å‘Š")
        print(f"{'='*60}")
        
        print(f"\nğŸ•’ æµ‹è¯•æ¦‚å†µ:")
        print(f"  æµ‹è¯•æ—¶é•¿: {stats['test_duration_minutes']} åˆ†é’Ÿ")
        print(f"  é‡‡æ ·æ¬¡æ•°: {stats['total_samples']}")
        print(f"  å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        print(f"  ç»“æŸæ—¶é—´: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}")

        print(f"\nğŸš€ æ€§èƒ½æŒ‡æ ‡:")
        perf = stats["performance"]
        throughput_status = "âœ… è¾¾æ ‡" if perf["throughput_target_met"] else "âŒ æœªè¾¾æ ‡"
        print(f"  å¹³å‡ååé‡: {perf['avg_throughput']:.1f} msg/s (ç›®æ ‡: â‰¥{TARGET_THROUGHPUT}) {throughput_status}")
        print(f"  æœ€å¤§ååé‡: {perf['max_throughput']:.1f} msg/s")
        print(f"  æœ€å°ååé‡: {perf['min_throughput']:.1f} msg/s")

        print(f"\nğŸ¥ æœåŠ¡å¯ç”¨æ€§:")
        for service, availability in stats["service_availability"].items():
            status = "âœ… è¾¾æ ‡" if availability >= TARGET_SUCCESS_RATE else "âŒ æœªè¾¾æ ‡"
            print(f"  {service}: {availability:.1f}% (ç›®æ ‡: â‰¥{TARGET_SUCCESS_RATE}%) {status}")

        print(f"\nğŸ“ˆ æ•°æ®å¢é•¿ç»Ÿè®¡:")
        total_hot_growth = 0
        total_cold_growth = 0
        
        for data_type, counts in stats["data_counts"].items():
            hot_growth = counts["hot_growth"]
            cold_growth = counts["cold_growth"]
            total_hot_growth += hot_growth
            total_cold_growth += cold_growth
            
            if hot_growth > 0 or cold_growth > 0:
                print(f"  {data_type}:")
                print(f"    çƒ­ç«¯å¢é•¿: +{hot_growth:,} (æ€»è®¡: {counts['hot']:,})")
                print(f"    å†·ç«¯å¢é•¿: +{cold_growth:,} (æ€»è®¡: {counts['cold']:,})")

        print(f"\nğŸ“Š æ€»ä½“æ•°æ®å¢é•¿:")
        print(f"  çƒ­ç«¯æ€»å¢é•¿: +{total_hot_growth:,}")
        print(f"  å†·ç«¯æ€»å¢é•¿: +{total_cold_growth:,}")

        # æœ€ç»ˆè¯„ä¼°
        overall_success = stats["overall_success"] and perf["throughput_target_met"]
        print(f"\nğŸ¯ æœ€ç»ˆè¯„ä¼°:")
        if overall_success:
            print("  âœ… å‹åŠ›æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿæ»¡è¶³ç”Ÿäº§ç¯å¢ƒè¦æ±‚")
        else:
            print("  âŒ å‹åŠ›æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œå­˜åœ¨æ€§èƒ½æˆ–å¯ç”¨æ€§é—®é¢˜")

    async def _save_report_to_file(self):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_file = Path("logs") / f"stress_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_file.parent.mkdir(exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.session:
            await self.session.close()

async def main():
    """ä¸»å‡½æ•°"""
    monitor = StressTestMonitor()
    
    try:
        await monitor.initialize()
        await monitor.run_stress_test()
        await monitor.generate_final_report()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await monitor.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
