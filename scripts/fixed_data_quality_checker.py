#!/usr/bin/env python3
"""
ä¿®å¤åçš„æ•°æ®è´¨é‡æ£€æµ‹å™¨
æ£€æµ‹æ—¶é—´æˆ³å’Œæ•°æ®ç±»å‹å­—æ®µçš„ä¿®å¤æ•ˆæœ
"""

import asyncio
import json
import time
from collections import defaultdict, deque
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import nats
from nats.js.api import StreamInfo


class FixedDataQualityChecker:
    def __init__(self):
        self.nc = None
        self.js = None
        self.stats = defaultdict(lambda: {
            'count': 0,
            'last_timestamp': None,
            'gaps': [],
            'duplicates': 0,
            'invalid_data': 0,
            'latency_samples': deque(maxlen=100),
            'size_samples': deque(maxlen=100),
            'timestamp_formats': set(),
            'data_type_values': set()
        })
        self.subjects = [
            "orderbook.>",
            "trade.>", 
            "funding_rate.>",
            "open_interest.>",
            "liquidation.>",
            "lsr_top_position.>",
            "lsr_all_account.>",
            "volatility_index.>"
        ]
        
    async def connect(self):
        """è¿æ¥åˆ° NATS"""
        self.nc = await nats.connect("nats://localhost:4222")
        self.js = self.nc.jetstream()
        print("âœ… å·²è¿æ¥åˆ° NATS JetStream")
        
    async def check_data_quality(self, duration_seconds: int = 30):
        """æ£€æŸ¥æ•°æ®è´¨é‡"""
        print(f"ğŸ” å¼€å§‹ä¿®å¤åæ•°æ®è´¨é‡æ£€æµ‹ ({duration_seconds}ç§’)...")
        
        # è®¢é˜…æ‰€æœ‰ä¸»é¢˜
        subscribers = []
        for subject in self.subjects:
            durable = f"fixed_quality_check_{subject.replace('.>', '').replace('_', '')}"
            sub = await self.js.subscribe(
                subject, 
                cb=self._message_callback,
                durable=durable,
                stream="MARKET_DATA"
            )
            subscribers.append(sub)
            
        print(f"ğŸ“¡ å·²è®¢é˜… {len(subscribers)} ä¸ªä¸»é¢˜")
        
        # è¿è¡Œæ£€æµ‹
        start_time = time.time()
        await asyncio.sleep(duration_seconds)
        
        # åœæ­¢è®¢é˜…
        for sub in subscribers:
            await sub.drain()
            
        # åˆ†æç»“æœ
        await self._analyze_results(duration_seconds)
        
    async def _message_callback(self, msg):
        """æ¶ˆæ¯å›è°ƒå¤„ç†"""
        try:
            subject = msg.subject
            data = json.loads(msg.data.decode())
            current_time = time.time()
            
            # æ›´æ–°ç»Ÿè®¡
            stats = self.stats[subject]
            stats['count'] += 1
            
            # è®°å½•æ—¶é—´æˆ³æ ¼å¼
            if 'timestamp' in data:
                timestamp_str = str(data['timestamp'])
                stats['timestamp_formats'].add(timestamp_str[:20] + "..." if len(timestamp_str) > 20 else timestamp_str)
                
                # è§£ææ—¶é—´æˆ³å¹¶è®¡ç®—å»¶è¿Ÿ
                msg_timestamp = self._parse_timestamp(data['timestamp'])
                if msg_timestamp:
                    latency = current_time - msg_timestamp
                    stats['latency_samples'].append(latency)
                    
                    # æ£€æŸ¥æ—¶é—´é—´éš”
                    if stats['last_timestamp']:
                        gap = msg_timestamp - stats['last_timestamp']
                        if gap > 10:  # è¶…è¿‡10ç§’çš„é—´éš”è®¤ä¸ºæ˜¯å¼‚å¸¸
                            stats['gaps'].append(gap)
                    
                    stats['last_timestamp'] = msg_timestamp
            
            # è®°å½• data_type å€¼
            if 'data_type' in data:
                stats['data_type_values'].add(data['data_type'])
            
            # æ£€æŸ¥æ•°æ®å¤§å°
            data_size = len(msg.data)
            stats['size_samples'].append(data_size)
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            if not self._validate_data_structure(subject, data):
                stats['invalid_data'] += 1
                
        except json.JSONDecodeError:
            self.stats[msg.subject]['invalid_data'] += 1
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ¶ˆæ¯å¼‚å¸¸: {e}")
            
    def _parse_timestamp(self, timestamp_str: str) -> Optional[float]:
        """è§£ææ—¶é—´æˆ³ - æ”¯æŒISOæ ¼å¼"""
        try:
            if isinstance(timestamp_str, (int, float)):
                return float(timestamp_str)
            
            # å°è¯•è§£æ ISO æ ¼å¼
            if isinstance(timestamp_str, str):
                if 'T' in timestamp_str:
                    # ISO 8601æ ¼å¼: 2024-12-07T10:30:45.123Z
                    dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                    return dt.timestamp()
                elif ' ' in timestamp_str and ':' in timestamp_str:
                    # è‡ªå®šä¹‰æ ¼å¼: 2024-12-07 10:30:45.123
                    try:
                        dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S.%f')
                        return dt.timestamp()
                    except:
                        dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                        return dt.timestamp()
            
            return None
        except Exception as e:
            print(f"æ—¶é—´æˆ³è§£æå¤±è´¥: {timestamp_str}, é”™è¯¯: {e}")
            return None
            
    def _validate_data_structure(self, subject: str, data: dict) -> bool:
        """éªŒè¯æ•°æ®ç»“æ„"""
        try:
            # åŸºæœ¬å­—æ®µæ£€æŸ¥
            required_fields = ['timestamp', 'exchange', 'symbol']
            for field in required_fields:
                if field not in data:
                    return False
                    
            # æ ¹æ®æ•°æ®ç±»å‹æ£€æŸ¥ç‰¹å®šå­—æ®µ
            if 'orderbook' in subject:
                return 'bids' in data and 'asks' in data
            elif 'trade' in subject:
                return 'price' in data and 'quantity' in data
            elif 'funding_rate' in subject:
                return 'current_funding_rate' in data or 'funding_rate' in data
            elif 'open_interest' in subject:
                return 'open_interest_value' in data or 'open_interest' in data
            elif 'liquidation' in subject:
                return 'price' in data and 'quantity' in data
            elif 'lsr_' in subject:
                return 'long_short_ratio' in data
            elif 'volatility_index' in subject:
                return 'volatility_index' in data
                
            return True
        except:
            return False
            
    async def _analyze_results(self, duration: int):
        """åˆ†ææ£€æµ‹ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ“Š ä¿®å¤åæ•°æ®è´¨é‡æ£€æµ‹æŠ¥å‘Š")
        print("="*80)
        
        total_messages = sum(stats['count'] for stats in self.stats.values())
        print(f"ğŸ“ˆ æ€»æ¶ˆæ¯æ•°: {total_messages:,}")
        print(f"â±ï¸  æ£€æµ‹æ—¶é•¿: {duration}ç§’")
        print(f"ğŸ“Š å¹³å‡é€Ÿç‡: {total_messages/duration:.1f} æ¶ˆæ¯/ç§’")
        
        print("\nğŸ” å„ä¸»é¢˜è¯¦ç»†ç»Ÿè®¡:")
        print("-" * 80)
        
        issues_found = []
        improvements = []
        
        for subject, stats in sorted(self.stats.items()):
            if stats['count'] == 0:
                continue
                
            print(f"\nğŸ“¡ {subject}")
            print(f"   æ¶ˆæ¯æ•°é‡: {stats['count']:,}")
            print(f"   æ¶ˆæ¯é€Ÿç‡: {stats['count']/duration:.1f}/ç§’")
            
            # æ—¶é—´æˆ³æ ¼å¼åˆ†æ
            if stats['timestamp_formats']:
                print(f"   æ—¶é—´æˆ³æ ¼å¼: {list(stats['timestamp_formats'])}")
                
            # data_type å€¼åˆ†æ
            if stats['data_type_values']:
                print(f"   data_typeå€¼: {list(stats['data_type_values'])}")
                
            # å»¶è¿Ÿåˆ†æ
            if stats['latency_samples']:
                latencies = list(stats['latency_samples'])
                avg_latency = sum(latencies) / len(latencies)
                max_latency = max(latencies)
                print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.3f}ç§’")
                print(f"   æœ€å¤§å»¶è¿Ÿ: {max_latency:.3f}ç§’")
                
                if avg_latency < 1.0:
                    improvements.append(f"{subject}: å»¶è¿Ÿå·²ä¼˜åŒ– ({avg_latency:.3f}ç§’)")
                elif avg_latency > 5.0:
                    issues_found.append(f"{subject}: ä»æœ‰é«˜å»¶è¿Ÿ ({avg_latency:.3f}ç§’)")
                    
            # æ•°æ®é—´éš”åˆ†æ
            if stats['gaps']:
                print(f"   âš ï¸  å‘ç° {len(stats['gaps'])} ä¸ªæ•°æ®é—´éš”å¼‚å¸¸")
                issues_found.append(f"{subject}: {len(stats['gaps'])} ä¸ªæ•°æ®é—´éš”å¼‚å¸¸")
                
            # æ— æ•ˆæ•°æ®
            if stats['invalid_data'] > 0:
                invalid_rate = stats['invalid_data'] / stats['count'] * 100
                print(f"   âŒ æ— æ•ˆæ•°æ®: {stats['invalid_data']} ({invalid_rate:.1f}%)")
                if invalid_rate > 0:
                    issues_found.append(f"{subject}: {invalid_rate:.1f}% æ— æ•ˆæ•°æ®")
            else:
                improvements.append(f"{subject}: æ•°æ®éªŒè¯100%é€šè¿‡")
                
        # æ€»ç»“
        print("\n" + "="*80)
        if improvements:
            print("âœ… ä¿®å¤æˆåŠŸçš„æ”¹è¿›:")
            for i, improvement in enumerate(improvements, 1):
                print(f"   {i}. {improvement}")
                
        if issues_found:
            print("\nâš ï¸  ä»éœ€è§£å†³çš„é—®é¢˜:")
            for i, issue in enumerate(issues_found, 1):
                print(f"   {i}. {issue}")
        else:
            print("\nğŸ‰ æ‰€æœ‰æ•°æ®è´¨é‡é—®é¢˜å·²ä¿®å¤ï¼")
            
        print("="*80)
        
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.nc:
            await self.nc.close()
            print("ğŸ”Œ å·²æ–­å¼€ NATS è¿æ¥")


async def main():
    checker = FixedDataQualityChecker()
    
    try:
        await checker.connect()
        await checker.check_data_quality(duration_seconds=30)
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ£€æµ‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    finally:
        await checker.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
