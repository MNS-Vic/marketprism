#!/usr/bin/env python3
"""
ç”Ÿäº§çº§åˆ«WebSocketæ•°æ®æµæµ‹è¯•
ç›´æ¥è¿æ¥çœŸå®äº¤æ˜“æ‰€WebSocketï¼Œæµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†é“¾è·¯

è¿™æ˜¯ä¸€ä¸ªçœŸæ­£æ¥è¿‘å®ç›˜çš„æµ‹è¯•ï¼š
- çœŸå®çš„é«˜é¢‘äº¤æ˜“æ‰€WebSocketè¿æ¥
- çœŸå®çš„å¸‚åœºæ•°æ®å¤„ç†
- å®Œæ•´çš„æ•°æ®åˆ†æå’Œç»Ÿè®¡
- ç”Ÿäº§çº§åˆ«çš„é”™è¯¯å¤„ç†å’Œç›‘æ§

ä½¿ç”¨æ–¹æ³•:
    source scripts/proxy_config.sh
    python scripts/production_websocket_test.py --duration 180 --symbols BTC/USDT,ETH/USDT,BNB/USDT
"""

import asyncio
import json
import time
import logging
import os
import sys
import argparse
import signal
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Set
import websockets
from collections import defaultdict, deque
import threading
import statistics
import csv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from config.app_config import AppConfig, NetworkConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f'production_websocket_test_{int(time.time())}.log')
    ]
)
logger = logging.getLogger(__name__)

class ProductionWebSocketTester:
    """ç”Ÿäº§çº§åˆ«WebSocketæ•°æ®æµæµ‹è¯•å™¨"""
    
    def __init__(self, test_duration: int = 180, symbols: List[str] = None):
        self.test_duration = test_duration
        self.symbols = symbols or ['BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'SOL/USDT', 'ADA/USDT']
        self.running = False
        self.start_time = None
        
        # WebSocketè¿æ¥æ± 
        self.websocket_connections = {}
        self.connection_status = {}
        
        # ç”Ÿäº§çº§åˆ«ç»Ÿè®¡æ•°æ®
        self.production_metrics = {
            'test_config': {
                'start_time': None,
                'end_time': None,
                'duration_seconds': test_duration,
                'symbols': self.symbols,
                'proxy_used': bool(os.getenv('HTTP_PROXY'))
            },
            
            # è¿æ¥ç»Ÿè®¡
            'connection_stats': {
                'total_connections': 0,
                'successful_connections': 0,
                'failed_connections': 0,
                'reconnection_attempts': 0,
                'connection_uptime_seconds': defaultdict(float),
                'connection_errors': defaultdict(int)
            },
            
            # æ•°æ®æµç»Ÿè®¡
            'data_flow_stats': {
                'total_messages': 0,
                'messages_per_second_history': deque(maxlen=1000),
                'max_messages_per_second': 0,
                'avg_messages_per_second': 0,
                'total_bytes_received': 0,
                'message_size_history': deque(maxlen=1000)
            },
            
            # æŒ‰æ¶ˆæ¯ç±»å‹ç»Ÿè®¡
            'message_type_stats': {
                'trade_messages': 0,
                'orderbook_messages': 0,
                'ticker_messages': 0,
                'other_messages': 0,
                'invalid_messages': 0
            },
            
            # æŒ‰äº¤æ˜“å¯¹ç»Ÿè®¡
            'symbol_stats': defaultdict(lambda: {
                'trades': 0,
                'orderbooks': 0,
                'tickers': 0,
                'last_price': 0,
                'price_changes': deque(maxlen=100),
                'volume_24h': 0,
                'data_gaps': 0,
                'last_update': None
            }),
            
            # å¸‚åœºæ•°æ®è´¨é‡ç»Ÿè®¡
            'data_quality_stats': {
                'duplicate_messages': 0,
                'out_of_sequence_messages': 0,
                'data_gaps_detected': 0,
                'price_anomalies': 0,
                'latency_samples': deque(maxlen=1000),
                'avg_latency_ms': 0,
                'max_latency_ms': 0
            },
            
            # é”™è¯¯ç»Ÿè®¡
            'error_stats': {
                'websocket_errors': 0,
                'json_parse_errors': 0,
                'network_timeouts': 0,
                'connection_drops': 0,
                'unknown_errors': 0,
                'error_details': []
            },
            
            # æ€§èƒ½ç»Ÿè®¡
            'performance_stats': {
                'cpu_usage_samples': deque(maxlen=100),
                'memory_usage_samples': deque(maxlen=100),
                'network_latency_samples': deque(maxlen=100),
                'processing_time_samples': deque(maxlen=100)
            }
        }
        
        # æ•°æ®å¤„ç†é˜Ÿåˆ—å’Œç¼“å­˜
        self.message_sequences = defaultdict(int)
        self.last_message_times = defaultdict(float)
        self.price_history = defaultdict(lambda: deque(maxlen=50))
        
        # å®æ—¶ç»Ÿè®¡æ›´æ–°
        self.stats_update_interval = 10  # 10ç§’æ›´æ–°ä¸€æ¬¡ç»Ÿè®¡
        self.last_stats_update = time.time()
        
        # ä¼˜é›…é€€å‡º
        self.shutdown_event = threading.Event()
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡ä¼˜é›…é€€å‡º...")
        self.shutdown_event.set()
        self.running = False
    
    async def start_production_test(self):
        """å¯åŠ¨ç”Ÿäº§çº§åˆ«æµ‹è¯•"""
        logger.info(f"ğŸš€ å¯åŠ¨ç”Ÿäº§çº§åˆ«WebSocketæ•°æ®æµæµ‹è¯•")
        logger.info(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {self.test_duration} ç§’")
        logger.info(f"ğŸ“Š ç›‘æ§äº¤æ˜“å¯¹: {', '.join(self.symbols)}")
        logger.info(f"ğŸŒ ä»£ç†é…ç½®: {'æ˜¯' if self.production_metrics['test_config']['proxy_used'] else 'å¦'}")
        
        self.running = True
        self.start_time = time.time()
        self.production_metrics['test_config']['start_time'] = datetime.now()
        
        try:
            # å¯åŠ¨æ‰€æœ‰WebSocketè¿æ¥
            await self._start_all_websocket_connections()
            
            # å¯åŠ¨ç»Ÿè®¡ç›‘æ§ä»»åŠ¡
            asyncio.create_task(self._stats_monitor())
            
            # ä¸»æµ‹è¯•å¾ªç¯
            await self._run_test_loop()
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿäº§æµ‹è¯•å¼‚å¸¸: {e}")
            self.production_metrics['error_stats']['unknown_errors'] += 1
            self.production_metrics['error_stats']['error_details'].append(str(e))
        
        finally:
            self.running = False
            self.production_metrics['test_config']['end_time'] = datetime.now()
            
            # ç­‰å¾…è¿æ¥æ¸…ç†
            await self._cleanup_connections()
            
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            await self._generate_production_report()
    
    async def _start_all_websocket_connections(self):
        """å¯åŠ¨æ‰€æœ‰WebSocketè¿æ¥"""
        logger.info("ğŸ”Œ å¯åŠ¨WebSocketè¿æ¥æ± ...")
        
        connection_tasks = []
        for symbol in self.symbols:
            task = asyncio.create_task(self._manage_websocket_connection(symbol))
            connection_tasks.append(task)
            
            # é¿å…åŒæ—¶å¯åŠ¨è¿‡å¤šè¿æ¥
            await asyncio.sleep(0.5)
        
        logger.info(f"âœ… å·²å¯åŠ¨ {len(connection_tasks)} ä¸ªWebSocketè¿æ¥ä»»åŠ¡")
    
    async def _manage_websocket_connection(self, symbol: str):
        """ç®¡ç†å•ä¸ªWebSocketè¿æ¥ (åŒ…å«é‡è¿é€»è¾‘)"""
        retry_count = 0
        max_retries = 10
        
        while self.running and retry_count < max_retries:
            try:
                await self._connect_binance_websocket(symbol)
                retry_count = 0  # æˆåŠŸè¿æ¥åé‡ç½®é‡è¯•è®¡æ•°
                
            except Exception as e:
                retry_count += 1
                self.production_metrics['connection_stats']['failed_connections'] += 1
                self.production_metrics['connection_stats']['reconnection_attempts'] += 1
                
                logger.warning(f"âš ï¸ {symbol} è¿æ¥å¤±è´¥ (å°è¯• {retry_count}/{max_retries}): {e}")
                
                if retry_count < max_retries:
                    wait_time = min(retry_count * 2, 30)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š30ç§’
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ {symbol} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢è¿æ¥")
                    break
    
    async def _connect_binance_websocket(self, symbol: str):
        """è¿æ¥Binance WebSocket"""
        binance_symbol = symbol.replace('/', '').lower()
        
        # ç”Ÿäº§çº§åˆ«çš„æµè®¢é˜…
        streams = [
            f"{binance_symbol}@trade",           # äº¤æ˜“æ•°æ®
            f"{binance_symbol}@depth@100ms",     # æ·±åº¦æ•°æ®
            f"{binance_symbol}@ticker",          # 24hç»Ÿè®¡
            f"{binance_symbol}@miniTicker"       # ç®€åŒ–Ticker
        ]
        
        ws_url = f"wss://stream.binance.com:9443/stream?streams={'/'.join(streams)}"
        
        logger.info(f"ğŸ“¡ è¿æ¥ {symbol} WebSocket...")
        
        connection_start = time.time()
        
        # ç”Ÿäº§çº§åˆ«çš„WebSocketè¿æ¥å‚æ•°
        async with websockets.connect(
            ws_url,
            ping_interval=20,
            ping_timeout=10,
            close_timeout=10,
            max_size=10**7,  # 10MB æ¶ˆæ¯é™åˆ¶
            max_queue=1000,  # æ¶ˆæ¯é˜Ÿåˆ—é™åˆ¶
            compression=None  # ç¦ç”¨å‹ç¼©æé«˜æ€§èƒ½
        ) as websocket:
            
            connection_uptime_start = time.time()
            self.websocket_connections[symbol] = websocket
            self.connection_status[symbol] = 'connected'
            self.production_metrics['connection_stats']['successful_connections'] += 1
            
            logger.info(f"âœ… {symbol} WebSocketè¿æ¥æˆåŠŸ")
            
            try:
                # æ¶ˆæ¯æ¥æ”¶å¾ªç¯
                async for message in websocket:
                    if not self.running:
                        break
                    
                    # è®°å½•è¿æ¥æ—¶é•¿
                    current_time = time.time()
                    uptime = current_time - connection_uptime_start
                    self.production_metrics['connection_stats']['connection_uptime_seconds'][symbol] = uptime
                    
                    # å¤„ç†æ¶ˆæ¯
                    await self._process_production_message(symbol, message, current_time)
                    
            except websockets.exceptions.ConnectionClosed:
                logger.warning(f"âš ï¸ {symbol} WebSocketè¿æ¥å…³é—­")
                self.production_metrics['error_stats']['connection_drops'] += 1
                raise
            
            except asyncio.TimeoutError:
                logger.warning(f"â° {symbol} WebSocketè¶…æ—¶")
                self.production_metrics['error_stats']['network_timeouts'] += 1
                raise
            
            finally:
                # æ¸…ç†è¿æ¥çŠ¶æ€
                if symbol in self.websocket_connections:
                    del self.websocket_connections[symbol]
                self.connection_status[symbol] = 'disconnected'
    
    async def _process_production_message(self, symbol: str, message: str, recv_time: float):
        """å¤„ç†ç”Ÿäº§çº§åˆ«æ¶ˆæ¯"""
        try:
            # åŸºç¡€ç»Ÿè®¡
            self.production_metrics['data_flow_stats']['total_messages'] += 1
            self.production_metrics['data_flow_stats']['total_bytes_received'] += len(message)
            self.production_metrics['data_flow_stats']['message_size_history'].append(len(message))
            
            # è§£æJSON
            try:
                data = json.loads(message)
            except json.JSONDecodeError:
                self.production_metrics['message_type_stats']['invalid_messages'] += 1
                self.production_metrics['error_stats']['json_parse_errors'] += 1
                return
            
            # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
            if 'stream' in data and 'data' in data:
                stream = data['stream']
                message_data = data['data']
                
                # è®¡ç®—æ¶ˆæ¯å»¶è¿Ÿ
                if 'E' in message_data:  # Binanceäº‹ä»¶æ—¶é—´
                    event_time = message_data['E'] / 1000
                    latency = (recv_time - event_time) * 1000  # æ¯«ç§’
                    if latency > 0 and latency < 10000:  # åˆç†çš„å»¶è¿ŸèŒƒå›´
                        self.production_metrics['data_quality_stats']['latency_samples'].append(latency)
                
                # å¤„ç†ä¸åŒç±»å‹çš„æµ
                if '@trade' in stream:
                    await self._process_trade_data(symbol, message_data, recv_time)
                elif '@depth' in stream:
                    await self._process_orderbook_data(symbol, message_data, recv_time)
                elif '@ticker' in stream or '@miniTicker' in stream:
                    await self._process_ticker_data(symbol, message_data, recv_time)
                else:
                    self.production_metrics['message_type_stats']['other_messages'] += 1
            
            # æ›´æ–°ç¬¦å·ç»Ÿè®¡
            self.production_metrics['symbol_stats'][symbol]['last_update'] = recv_time
            
            # æ£€æµ‹æ•°æ®ä¸­æ–­
            if symbol in self.last_message_times:
                gap = recv_time - self.last_message_times[symbol]
                if gap > 5.0:  # 5ç§’ä»¥ä¸Šçš„é—´éš”
                    self.production_metrics['data_quality_stats']['data_gaps_detected'] += 1
                    self.production_metrics['symbol_stats'][symbol]['data_gaps'] += 1
            
            self.last_message_times[symbol] = recv_time
            
        except Exception as e:
            self.production_metrics['error_stats']['websocket_errors'] += 1
            logger.error(f"âŒ å¤„ç†{symbol}æ¶ˆæ¯å¤±è´¥: {e}")
    
    async def _process_trade_data(self, symbol: str, data: Dict[str, Any], recv_time: float):
        """å¤„ç†äº¤æ˜“æ•°æ®"""
        try:
            price = float(data['p'])
            quantity = float(data['q'])
            
            # æ›´æ–°ç»Ÿè®¡
            self.production_metrics['message_type_stats']['trade_messages'] += 1
            self.production_metrics['symbol_stats'][symbol]['trades'] += 1
            self.production_metrics['symbol_stats'][symbol]['last_price'] = price
            
            # ä»·æ ¼å˜åŒ–åˆ†æ
            self.price_history[symbol].append(price)
            if len(self.price_history[symbol]) >= 2:
                price_change = price - self.price_history[symbol][-2]
                self.production_metrics['symbol_stats'][symbol]['price_changes'].append(price_change)
                
                # æ£€æµ‹ä»·æ ¼å¼‚å¸¸ (è¶…è¿‡2%çš„å•æ¬¡å˜åŒ–)
                if abs(price_change / price) > 0.02:
                    self.production_metrics['data_quality_stats']['price_anomalies'] += 1
                    logger.warning(f"âš ï¸ {symbol} ä»·æ ¼å¼‚å¸¸å˜åŒ–: {price_change:.2f} ({price_change/price*100:.1f}%)")
            
        except (KeyError, ValueError) as e:
            self.production_metrics['message_type_stats']['invalid_messages'] += 1
    
    async def _process_orderbook_data(self, symbol: str, data: Dict[str, Any], recv_time: float):
        """å¤„ç†è®¢å•ç°¿æ•°æ®"""
        try:
            # æ›´æ–°ç»Ÿè®¡
            self.production_metrics['message_type_stats']['orderbook_messages'] += 1
            self.production_metrics['symbol_stats'][symbol]['orderbooks'] += 1
            
            # åºåˆ—å·æ£€æŸ¥ (æ£€æµ‹æ¶ˆæ¯ä¹±åº)
            if 'u' in data:  # æ›´æ–°ID
                update_id = data['u']
                if symbol in self.message_sequences:
                    if update_id <= self.message_sequences[symbol]:
                        self.production_metrics['data_quality_stats']['out_of_sequence_messages'] += 1
                self.message_sequences[symbol] = update_id
            
        except (KeyError, ValueError) as e:
            self.production_metrics['message_type_stats']['invalid_messages'] += 1
    
    async def _process_ticker_data(self, symbol: str, data: Dict[str, Any], recv_time: float):
        """å¤„ç†Tickeræ•°æ®"""
        try:
            # æ›´æ–°ç»Ÿè®¡
            self.production_metrics['message_type_stats']['ticker_messages'] += 1
            self.production_metrics['symbol_stats'][symbol]['tickers'] += 1
            
            # æ›´æ–°24häº¤æ˜“é‡
            if 'v' in data:
                self.production_metrics['symbol_stats'][symbol]['volume_24h'] = float(data['v'])
            
        except (KeyError, ValueError) as e:
            self.production_metrics['message_type_stats']['invalid_messages'] += 1
    
    async def _stats_monitor(self):
        """ç»Ÿè®¡ç›‘æ§ä»»åŠ¡"""
        while self.running:
            await asyncio.sleep(self.stats_update_interval)
            
            try:
                await self._update_realtime_stats()
                await self._print_realtime_stats()
            except Exception as e:
                logger.error(f"âŒ ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")
    
    async def _update_realtime_stats(self):
        """æ›´æ–°å®æ—¶ç»Ÿè®¡"""
        current_time = time.time()
        elapsed = current_time - self.start_time
        
        if elapsed > 0:
            # æ›´æ–°æ¶ˆæ¯é¢‘ç‡
            total_messages = self.production_metrics['data_flow_stats']['total_messages']
            current_rate = total_messages / elapsed
            self.production_metrics['data_flow_stats']['avg_messages_per_second'] = current_rate
            self.production_metrics['data_flow_stats']['messages_per_second_history'].append(current_rate)
            
            # æ›´æ–°æœ€å¤§é¢‘ç‡
            if current_rate > self.production_metrics['data_flow_stats']['max_messages_per_second']:
                self.production_metrics['data_flow_stats']['max_messages_per_second'] = current_rate
        
        # æ›´æ–°å»¶è¿Ÿç»Ÿè®¡
        latency_samples = self.production_metrics['data_quality_stats']['latency_samples']
        if latency_samples:
            self.production_metrics['data_quality_stats']['avg_latency_ms'] = statistics.mean(latency_samples)
            self.production_metrics['data_quality_stats']['max_latency_ms'] = max(latency_samples)
    
    async def _print_realtime_stats(self):
        """æ‰“å°å®æ—¶ç»Ÿè®¡"""
        elapsed = time.time() - self.start_time
        remaining = max(0, self.test_duration - elapsed)
        
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ“Š ç”Ÿäº§çº§åˆ«å®æ—¶ç»Ÿè®¡ (å·²è¿è¡Œ {elapsed:.0f}ç§’, å‰©ä½™ {remaining:.0f}ç§’)")
        logger.info(f"{'='*80}")
        
        # è¿æ¥ç»Ÿè®¡
        active_connections = len([s for s, status in self.connection_status.items() if status == 'connected'])
        logger.info(f"ğŸ”Œ è¿æ¥çŠ¶æ€: {active_connections}/{len(self.symbols)} æ´»è·ƒ")
        
        # æ•°æ®æµç»Ÿè®¡
        total_msg = self.production_metrics['data_flow_stats']['total_messages']
        avg_rate = self.production_metrics['data_flow_stats']['avg_messages_per_second']
        max_rate = self.production_metrics['data_flow_stats']['max_messages_per_second']
        total_mb = self.production_metrics['data_flow_stats']['total_bytes_received'] / 1024 / 1024
        
        logger.info(f"ğŸ“ˆ æ•°æ®æµ: {total_msg:,} æ¡æ¶ˆæ¯ ({avg_rate:.1f} msg/s å¹³å‡, {max_rate:.1f} msg/s å³°å€¼)")
        logger.info(f"ğŸ’¾ æ•°æ®é‡: {total_mb:.2f} MB")
        
        # æ¶ˆæ¯ç±»å‹åˆ†å¸ƒ
        trades = self.production_metrics['message_type_stats']['trade_messages']
        orderbooks = self.production_metrics['message_type_stats']['orderbook_messages']
        tickers = self.production_metrics['message_type_stats']['ticker_messages']
        
        logger.info(f"ğŸ“‹ æ¶ˆæ¯ç±»å‹: äº¤æ˜“={trades:,}, è®¢å•ç°¿={orderbooks:,}, Ticker={tickers:,}")
        
        # æ•°æ®è´¨é‡
        gaps = self.production_metrics['data_quality_stats']['data_gaps_detected']
        anomalies = self.production_metrics['data_quality_stats']['price_anomalies']
        avg_latency = self.production_metrics['data_quality_stats']['avg_latency_ms']
        
        logger.info(f"ğŸ¯ æ•°æ®è´¨é‡: ä¸­æ–­={gaps}, ä»·æ ¼å¼‚å¸¸={anomalies}, å¹³å‡å»¶è¿Ÿ={avg_latency:.1f}ms")
        
        # é”™è¯¯ç»Ÿè®¡
        total_errors = sum(self.production_metrics['error_stats'].values()) - len(self.production_metrics['error_stats']['error_details'])
        logger.info(f"âŒ é”™è¯¯: {total_errors} ä¸ª")
        
        # å„äº¤æ˜“å¯¹è¡¨ç°
        logger.info("ğŸ’¹ äº¤æ˜“å¯¹è¡¨ç°:")
        for symbol, stats in self.production_metrics['symbol_stats'].items():
            if stats['last_update']:
                last_update_ago = time.time() - stats['last_update']
                status = "ğŸŸ¢" if last_update_ago < 10 else "ğŸŸ¡" if last_update_ago < 30 else "ğŸ”´"
                logger.info(f"  {status} {symbol}: ä»·æ ¼={stats['last_price']:.2f}, äº¤æ˜“={stats['trades']}, è®¢å•ç°¿={stats['orderbooks']}")
    
    async def _run_test_loop(self):
        """ä¸»æµ‹è¯•å¾ªç¯"""
        while self.running and (time.time() - self.start_time) < self.test_duration:
            if not self.shutdown_event.is_set():
                await asyncio.sleep(1)
            else:
                logger.info("æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æµ‹è¯•...")
                break
        
        logger.info("â° æµ‹è¯•æ—¶é—´ç»“æŸï¼Œæ­£åœ¨æ”¶é›†æœ€ç»ˆæ•°æ®...")
    
    async def _cleanup_connections(self):
        """æ¸…ç†è¿æ¥"""
        logger.info("ğŸ§¹ æ¸…ç†WebSocketè¿æ¥...")
        
        for symbol, ws in self.websocket_connections.items():
            try:
                await ws.close()
            except:
                pass
        
        self.websocket_connections.clear()
        logger.info("âœ… è¿æ¥æ¸…ç†å®Œæˆ")
    
    async def _generate_production_report(self):
        """ç”Ÿæˆç”Ÿäº§çº§åˆ«æŠ¥å‘Š"""
        logger.info(f"\n{'='*100}")
        logger.info(f"ğŸ“ˆ MarketPrism ç”Ÿäº§çº§åˆ«WebSocketæ•°æ®æµæµ‹è¯•æœ€ç»ˆæŠ¥å‘Š")
        logger.info(f"{'='*100}")
        
        # è®¡ç®—æµ‹è¯•æ—¶é•¿
        start_time = self.production_metrics['test_config']['start_time']
        end_time = self.production_metrics['test_config']['end_time']
        actual_duration = (end_time - start_time).total_seconds()
        
        logger.info(f"ğŸ• æµ‹è¯•æ—¶é—´: {start_time} åˆ° {end_time}")
        logger.info(f"â±ï¸  è®¡åˆ’æ—¶é•¿: {self.test_duration} ç§’")
        logger.info(f"â±ï¸  å®é™…æ—¶é•¿: {actual_duration:.1f} ç§’")
        logger.info(f"ğŸ¯ ç›‘æ§äº¤æ˜“å¯¹: {', '.join(self.symbols)}")
        logger.info(f"ğŸŒ ä»£ç†ä½¿ç”¨: {'æ˜¯' if self.production_metrics['test_config']['proxy_used'] else 'å¦'}")
        logger.info("")
        
        # è¿æ¥æ€§èƒ½
        conn_stats = self.production_metrics['connection_stats']
        success_rate = (conn_stats['successful_connections'] / max(conn_stats['total_connections'] or len(self.symbols), 1)) * 100
        
        logger.info("ğŸ”Œ è¿æ¥æ€§èƒ½:")
        logger.info(f"  æˆåŠŸè¿æ¥: {conn_stats['successful_connections']}")
        logger.info(f"  å¤±è´¥è¿æ¥: {conn_stats['failed_connections']}")
        logger.info(f"  é‡è¿å°è¯•: {conn_stats['reconnection_attempts']}")
        logger.info(f"  è¿æ¥æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info("")
        
        # æ•°æ®æµæ€§èƒ½
        data_stats = self.production_metrics['data_flow_stats']
        logger.info("ğŸ“Š æ•°æ®æµæ€§èƒ½:")
        logger.info(f"  æ€»æ¶ˆæ¯æ•°: {data_stats['total_messages']:,}")
        logger.info(f"  å¹³å‡é¢‘ç‡: {data_stats['avg_messages_per_second']:.1f} æ¶ˆæ¯/ç§’")
        logger.info(f"  å³°å€¼é¢‘ç‡: {data_stats['max_messages_per_second']:.1f} æ¶ˆæ¯/ç§’")
        logger.info(f"  æ•°æ®æ€»é‡: {data_stats['total_bytes_received']/1024/1024:.2f} MB")
        if data_stats['message_size_history']:
            avg_size = statistics.mean(data_stats['message_size_history'])
            logger.info(f"  å¹³å‡æ¶ˆæ¯å¤§å°: {avg_size:.0f} å­—èŠ‚")
        logger.info("")
        
        # æ¶ˆæ¯ç±»å‹åˆ†æ
        msg_stats = self.production_metrics['message_type_stats']
        total_valid = msg_stats['trade_messages'] + msg_stats['orderbook_messages'] + msg_stats['ticker_messages']
        
        logger.info("ğŸ“‹ æ¶ˆæ¯ç±»å‹åˆ†æ:")
        logger.info(f"  äº¤æ˜“æ¶ˆæ¯: {msg_stats['trade_messages']:,} ({msg_stats['trade_messages']/max(total_valid,1)*100:.1f}%)")
        logger.info(f"  è®¢å•ç°¿æ¶ˆæ¯: {msg_stats['orderbook_messages']:,} ({msg_stats['orderbook_messages']/max(total_valid,1)*100:.1f}%)")
        logger.info(f"  Tickeræ¶ˆæ¯: {msg_stats['ticker_messages']:,} ({msg_stats['ticker_messages']/max(total_valid,1)*100:.1f}%)")
        logger.info(f"  å…¶ä»–æ¶ˆæ¯: {msg_stats['other_messages']:,}")
        logger.info(f"  æ— æ•ˆæ¶ˆæ¯: {msg_stats['invalid_messages']:,}")
        logger.info("")
        
        # æ•°æ®è´¨é‡åˆ†æ
        quality_stats = self.production_metrics['data_quality_stats']
        logger.info("ğŸ¯ æ•°æ®è´¨é‡åˆ†æ:")
        logger.info(f"  é‡å¤æ¶ˆæ¯: {quality_stats['duplicate_messages']}")
        logger.info(f"  ä¹±åºæ¶ˆæ¯: {quality_stats['out_of_sequence_messages']}")
        logger.info(f"  æ•°æ®ä¸­æ–­: {quality_stats['data_gaps_detected']}")
        logger.info(f"  ä»·æ ¼å¼‚å¸¸: {quality_stats['price_anomalies']}")
        logger.info(f"  å¹³å‡å»¶è¿Ÿ: {quality_stats['avg_latency_ms']:.1f} ms")
        logger.info(f"  æœ€å¤§å»¶è¿Ÿ: {quality_stats['max_latency_ms']:.1f} ms")
        logger.info("")
        
        # å„äº¤æ˜“å¯¹è¯¦ç»†åˆ†æ
        logger.info("ğŸ’¹ å„äº¤æ˜“å¯¹è¯¦ç»†åˆ†æ:")
        for symbol, stats in self.production_metrics['symbol_stats'].items():
            total_msg = stats['trades'] + stats['orderbooks'] + stats['tickers']
            msg_rate = total_msg / actual_duration if actual_duration > 0 else 0
            
            logger.info(f"  {symbol}:")
            logger.info(f"    æ€»æ¶ˆæ¯: {total_msg:,} ({msg_rate:.1f} msg/s)")
            logger.info(f"    äº¤æ˜“: {stats['trades']:,}")
            logger.info(f"    è®¢å•ç°¿: {stats['orderbooks']:,}")
            logger.info(f"    Ticker: {stats['tickers']:,}")
            logger.info(f"    æœ€æ–°ä»·æ ¼: {stats['last_price']:.2f}")
            logger.info(f"    24häº¤æ˜“é‡: {stats['volume_24h']:.2f}")
            logger.info(f"    æ•°æ®ä¸­æ–­: {stats['data_gaps']}")
            
            if stats['price_changes']:
                avg_change = statistics.mean([abs(x) for x in stats['price_changes']])
                logger.info(f"    å¹³å‡ä»·æ ¼å˜åŒ–: {avg_change:.4f}")
        logger.info("")
        
        # é”™è¯¯åˆ†æ
        error_stats = self.production_metrics['error_stats']
        total_errors = (error_stats['websocket_errors'] + error_stats['json_parse_errors'] + 
                       error_stats['network_timeouts'] + error_stats['connection_drops'])
        
        logger.info("âŒ é”™è¯¯åˆ†æ:")
        logger.info(f"  WebSocketé”™è¯¯: {error_stats['websocket_errors']}")
        logger.info(f"  JSONè§£æé”™è¯¯: {error_stats['json_parse_errors']}")
        logger.info(f"  ç½‘ç»œè¶…æ—¶: {error_stats['network_timeouts']}")
        logger.info(f"  è¿æ¥ä¸­æ–­: {error_stats['connection_drops']}")
        logger.info(f"  æ€»é”™è¯¯æ•°: {total_errors}")
        error_rate = (total_errors / max(data_stats['total_messages'], 1)) * 100
        logger.info(f"  é”™è¯¯ç‡: {error_rate:.3f}%")
        logger.info("")
        
        # æ•´ä½“è¯„ä¼°
        logger.info("ğŸ† æ•´ä½“è¯„ä¼°:")
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        connection_score = min(success_rate, 100)
        data_quality_score = max(0, 100 - (quality_stats['data_gaps_detected'] * 2) - (quality_stats['price_anomalies'] * 1))
        error_score = max(0, 100 - (error_rate * 10))
        performance_score = min(data_stats['avg_messages_per_second'] / 10 * 100, 100)  # å‡è®¾10 msg/sä¸ºæ»¡åˆ†
        
        overall_score = (connection_score + data_quality_score + error_score + performance_score) / 4
        
        logger.info(f"  è¿æ¥ç¨³å®šæ€§: {connection_score:.1f}/100")
        logger.info(f"  æ•°æ®è´¨é‡: {data_quality_score:.1f}/100")
        logger.info(f"  é”™è¯¯æ§åˆ¶: {error_score:.1f}/100")
        logger.info(f"  æ€§èƒ½è¡¨ç°: {performance_score:.1f}/100")
        logger.info(f"  ç»¼åˆè¯„åˆ†: {overall_score:.1f}/100")
        
        if overall_score >= 90:
            logger.info("ğŸ‰ ä¼˜ç§€ï¼ç³»ç»Ÿè¾¾åˆ°ç”Ÿäº§çº§åˆ«æ ‡å‡†ï¼Œå¯ä»¥å¤„ç†çœŸå®é«˜é¢‘äº¤æ˜“æ•°æ®ï¼")
        elif overall_score >= 80:
            logger.info("âœ… è‰¯å¥½ï¼ç³»ç»ŸåŸºæœ¬æ»¡è¶³ç”Ÿäº§è¦æ±‚ï¼Œå»ºè®®ä¼˜åŒ–éƒ¨åˆ†æ€§èƒ½æŒ‡æ ‡")
        elif overall_score >= 70:
            logger.info("âš ï¸ åˆæ ¼ï¼ç³»ç»Ÿå¯ç”¨ä½†éœ€è¦æ”¹è¿›ï¼Œç‰¹åˆ«å…³æ³¨é”™è¯¯å¤„ç†å’Œç¨³å®šæ€§")
        else:
            logger.info("âŒ éœ€è¦æ”¹è¿›ï¼ç³»ç»Ÿè·ç¦»ç”Ÿäº§çº§åˆ«è¿˜æœ‰å·®è·ï¼Œè¯·é‡ç‚¹ä¼˜åŒ–")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        await self._save_detailed_report()
    
    async def _save_detailed_report(self):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            timestamp = int(time.time())
            report_file = f"production_websocket_test_report_{timestamp}.json"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                # è½¬æ¢dequeä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
                report_data = {}
                for key, value in self.production_metrics.items():
                    if isinstance(value, dict):
                        report_data[key] = {}
                        for k, v in value.items():
                            if isinstance(v, deque):
                                report_data[key][k] = list(v)
                            elif isinstance(v, defaultdict):
                                report_data[key][k] = dict(v)
                            else:
                                report_data[key][k] = v
                    else:
                        report_data[key] = value
                
                json.dump(report_data, f, indent=2, default=str)
            
            logger.info(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MarketPrism ç”Ÿäº§çº§åˆ«WebSocketæ•°æ®æµæµ‹è¯•')
    parser.add_argument('--duration', type=int, default=180, help='æµ‹è¯•æŒç»­æ—¶é—´(ç§’)')
    parser.add_argument('--symbols', default='BTC/USDT,ETH/USDT,BNB/USDT', help='äº¤æ˜“å¯¹åˆ—è¡¨(é€—å·åˆ†éš”)')
    
    args = parser.parse_args()
    symbols = [s.strip() for s in args.symbols.split(',')]
    
    # åº”ç”¨ä»£ç†é…ç½®
    AppConfig.detect_system_proxy()
    
    logger.info(f"ğŸš€ å¯åŠ¨ç”Ÿäº§çº§åˆ«WebSocketæµ‹è¯•")
    logger.info(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {args.duration} ç§’")
    logger.info(f"ğŸ“Š ç›‘æ§äº¤æ˜“å¯¹: {symbols}")
    
    tester = ProductionWebSocketTester(args.duration, symbols)
    
    try:
        await tester.start_production_test()
        return 0
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        return 1
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
        return 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except Exception as e:
        logger.error(f"å¯åŠ¨å¼‚å¸¸: {e}")
        sys.exit(1)