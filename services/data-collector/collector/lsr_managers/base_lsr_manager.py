"""
å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨åŸºç±»

æä¾›ç»Ÿä¸€çš„æ¶æ„æ¨¡å¼å’Œæ¥å£å®šä¹‰ï¼Œæ”¯æŒæŒ‰æŒä»“é‡å’ŒæŒ‰è´¦æˆ·æ•°ä¸¤ç§è®¡ç®—æ–¹å¼
"""

import asyncio
from abc import ABC, abstractmethod
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Union
import aiohttp

import structlog
from collector.data_types import Exchange, MarketType, NormalizedLSRTopPosition, NormalizedLSRAllAccount
from collector.normalizer import DataNormalizer


class BaseLSRManager(ABC):
    """
    å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨åŸºç±»

    æ¶æ„ç‰¹ç‚¹ï¼š
    1. å®šæœŸREST APIè°ƒç”¨è·å–æ•°æ®
    2. æ•°æ®æ ‡å‡†åŒ–å’ŒNATSå‘å¸ƒ
    3. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
    4. ç»Ÿä¸€çš„æ—¥å¿—ç®¡ç†
    5. æ”¯æŒæŒ‰æŒä»“é‡å’ŒæŒ‰è´¦æˆ·æ•°ä¸¤ç§è®¡ç®—æ–¹å¼
    """
    
    def __init__(self,
                 exchange: Exchange,
                 market_type: MarketType,
                 data_type: str,  # 'lsr_position' æˆ– 'lsr_account'
                 symbols: List[str],
                 normalizer: DataNormalizer,
                 nats_publisher: Any,  # ä½¿ç”¨Anyç±»å‹é¿å…å¯¼å…¥é—®é¢˜
                 config: dict):
        """
        åˆå§‹åŒ–å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨

        Args:
            exchange: äº¤æ˜“æ‰€æšä¸¾
            market_type: å¸‚åœºç±»å‹æšä¸¾
            data_type: æ•°æ®ç±»å‹ ('lsr_position' æˆ– 'lsr_account')
            symbols: äº¤æ˜“å¯¹åˆ—è¡¨
            normalizer: æ•°æ®æ ‡å‡†åŒ–å™¨
            nats_publisher: NATSå‘å¸ƒå™¨
            config: é…ç½®ä¿¡æ¯
        """
        self.exchange = exchange
        self.market_type = market_type
        self.data_type = data_type  # 'lsr_position' æˆ– 'lsr_account'
        self.symbols = symbols
        self.normalizer = normalizer
        self.nats_publisher = nats_publisher
        self.config = config

        # æ—¥å¿—ç³»ç»Ÿ
        self.logger = structlog.get_logger(
            f"lsr_{data_type}_{exchange.value.lower()}_{market_type.value.lower()}"
        )

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'requests_sent': 0,
            'requests_successful': 0,
            'requests_failed': 0,
            'data_points_received': 0,
            'data_points_processed': 0,
            'data_points_published': 0,
            'last_request_time': None,
            'last_data_time': None,
            'errors': 0
        }

        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.fetch_task: Optional[asyncio.Task] = None

        # é…ç½®å‚æ•°
        self.fetch_interval = config.get('fetch_interval', 10)  # é»˜è®¤10ç§’
        self.period = config.get('period', '1h')  # é»˜è®¤1å°æ—¶å‘¨æœŸ
        self.limit = config.get('limit', 30)  # é»˜è®¤è·å–30ä¸ªæ•°æ®ç‚¹
        self.max_retries = config.get('max_retries', 3)
        self.retry_delay = config.get('retry_delay', 5)

        # HTTPä¼šè¯
        self.session: Optional[aiohttp.ClientSession] = None

        self.logger.info(f"ğŸ­ {self.__class__.__name__}åˆå§‹åŒ–å®Œæˆ",
                        exchange=exchange.value,
                        market_type=market_type.value,
                        data_type=data_type,
                        symbols=symbols,
                        fetch_interval=self.fetch_interval,
                        period=self.period)

    async def start(self) -> bool:
        """
        å¯åŠ¨é¡¶çº§äº¤æ˜“è€…å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨
        
        Returns:
            bool: å¯åŠ¨æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info(
                f"å¯åŠ¨{self.data_type}æ•°æ®ç®¡ç†å™¨",
                exchange=self.exchange.value,
                market_type=self.market_type.value,
                data_type=self.data_type
            )
            
            if self.is_running:
                self.logger.warning("é¡¶çº§äº¤æ˜“è€…å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨å·²åœ¨è¿è¡Œä¸­")
                return True
            
            # åˆ›å»ºHTTPä¼šè¯ï¼ˆå¢åŠ æ›´çŸ­çš„è¶…æ—¶æ—¶é—´ï¼‰
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=10, connect=5),
                headers={'User-Agent': 'MarketPrism/1.0'}
            )
            
            self.is_running = True

            # å¯åŠ¨å®šæœŸè·å–ä»»åŠ¡ï¼ˆå»¶è¿Ÿå¯åŠ¨ï¼Œé¿å…å¯åŠ¨æ—¶é˜»å¡ï¼‰
            # ä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿï¼Œç¡®ä¿ç³»ç»Ÿå®Œå…¨å¯åŠ¨åå†å¼€å§‹æ•°æ®è·å–
            self.fetch_task = asyncio.create_task(self._delayed_fetch_start())
            
            self.logger.info(
                f"{self.data_type}æ•°æ®ç®¡ç†å™¨å¯åŠ¨æˆåŠŸ",
                exchange=self.exchange.value,
                market_type=self.market_type.value,
                data_type=self.data_type
            )
            return True
            
        except Exception as e:
            self.logger.error(
                "é¡¶çº§äº¤æ˜“è€…å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨å¯åŠ¨å¤±è´¥",
                error=e,
                exchange=self.exchange.value,
                market_type=self.market_type.value
            )
            self.stats['errors'] += 1
            return False

    async def stop(self):
        """åœæ­¢é¡¶çº§äº¤æ˜“è€…å¤šç©ºæŒä»“æ¯”ä¾‹æ•°æ®ç®¡ç†å™¨"""
        try:
            self.logger.info(f"åœæ­¢{self.data_type}æ•°æ®ç®¡ç†å™¨")
            
            self.is_running = False
            
            # å–æ¶ˆè·å–ä»»åŠ¡
            if self.fetch_task and not self.fetch_task.done():
                self.fetch_task.cancel()
                try:
                    await self.fetch_task
                except asyncio.CancelledError:
                    pass
            
            # å…³é—­HTTPä¼šè¯
            await self._close_http_session()
            
            self.logger.info(f"{self.data_type}æ•°æ®ç®¡ç†å™¨å·²åœæ­¢")
            
        except Exception as e:
            self.logger.error(f"åœæ­¢{self.data_type}æ•°æ®ç®¡ç†å™¨å¤±è´¥", error=e)

    async def _close_http_session(self):
        """å®‰å…¨å…³é—­HTTPä¼šè¯"""
        if self.session and not self.session.closed:
            try:
                await self.session.close()
                self.logger.debug("HTTPä¼šè¯å·²å…³é—­")
            except Exception as e:
                self.logger.warning("å…³é—­HTTPä¼šè¯æ—¶å‡ºé”™", error=str(e))
            finally:
                self.session = None

    async def _delayed_fetch_start(self):
        """å»¶è¿Ÿå¯åŠ¨æ•°æ®è·å–ï¼Œé¿å…å¯åŠ¨æ—¶é˜»å¡"""
        try:
            # ç­‰å¾…10ç§’åå¼€å§‹æ•°æ®è·å–ï¼Œè®©ç³»ç»Ÿå®Œå…¨å¯åŠ¨å¹¶ç¨³å®šè¿è¡Œ
            self.logger.info(f"{self.data_type}æ•°æ®ç®¡ç†å™¨å°†åœ¨10ç§’åå¼€å§‹æ•°æ®è·å–")
            await asyncio.sleep(10)

            if self.is_running:
                self.logger.info(f"å¼€å§‹{self.data_type}æ•°æ®è·å–å¾ªç¯")
                await self._fetch_data_loop()
            else:
                self.logger.info(f"{self.data_type}æ•°æ®ç®¡ç†å™¨å·²åœæ­¢ï¼Œå–æ¶ˆæ•°æ®è·å–")
        except Exception as e:
            self.logger.error(f"å»¶è¿Ÿå¯åŠ¨{self.data_type}æ•°æ®è·å–å¤±è´¥", error=e)

    async def _fetch_data_loop(self):
        """å®šæœŸè·å–æ•°æ®çš„ä¸»å¾ªç¯"""
        while self.is_running:
            try:
                # ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹è·å–æ•°æ®
                for symbol in self.symbols:
                    if not self.is_running:
                        break
                    
                    await self._fetch_symbol_data(symbol)
                    
                    # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    await asyncio.sleep(1)
                
                # ç­‰å¾…ä¸‹æ¬¡è·å–
                await asyncio.sleep(self.fetch_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error("æ•°æ®è·å–å¾ªç¯å¼‚å¸¸", error=e)
                self.stats['errors'] += 1
                await asyncio.sleep(self.retry_delay)

    async def _fetch_symbol_data(self, symbol: str):
        """è·å–å•ä¸ªäº¤æ˜“å¯¹çš„æ•°æ®"""
        for attempt in range(self.max_retries):
            try:
                self.stats['requests_sent'] += 1
                self.stats['last_request_time'] = datetime.now(timezone.utc)
                
                # è°ƒç”¨å…·ä½“äº¤æ˜“æ‰€çš„å®ç°
                raw_data = await self._fetch_data_from_api(symbol)
                
                if raw_data:
                    self.stats['requests_successful'] += 1
                    await self._process_raw_data(symbol, raw_data)
                    return
                else:
                    self.stats['requests_failed'] += 1
                    
            except Exception as e:
                self.logger.error(
                    f"è·å–{symbol}æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries})",
                    error=e,
                    symbol=symbol
                )
                self.stats['requests_failed'] += 1
                
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)

    async def _process_raw_data(self, symbol: str, raw_data: Dict[str, Any]):
        """å¤„ç†åŸå§‹æ•°æ®"""
        try:
            # æ·»åŠ è¯·æ±‚å‚æ•°åˆ°åŸå§‹æ•°æ®ä¸­ï¼Œä¾›æ ‡å‡†åŒ–ä½¿ç”¨
            raw_data['instId'] = symbol
            raw_data['period'] = self.period
            
            # æ ‡å‡†åŒ–æ•°æ®
            normalized_data = await self._normalize_data(raw_data)
            
            if normalized_data:
                self.stats['data_points_processed'] += 1
                self.stats['last_data_time'] = normalized_data.timestamp
                
                # å‘å¸ƒåˆ°NATS
                await self._publish_to_nats(normalized_data)
                self.stats['data_points_published'] += 1
                
                # æ„å»ºæ—¥å¿—ä¿¡æ¯
                log_data = {
                    'exchange': normalized_data.exchange_name,
                    'symbol': normalized_data.symbol_name,
                    'long_short_ratio': str(normalized_data.long_short_ratio),
                    'data_type': self.data_type
                }

                # æ ¹æ®æ•°æ®ç±»å‹æ·»åŠ ç‰¹å®šå­—æ®µåˆ°æ—¥å¿—
                if self.data_type == 'lsr_top_position':
                    log_data.update({
                        'long_position_ratio': str(normalized_data.long_position_ratio),
                        'short_position_ratio': str(normalized_data.short_position_ratio)
                    })
                elif self.data_type == 'lsr_all_account':
                    log_data.update({
                        'long_account_ratio': str(normalized_data.long_account_ratio),
                        'short_account_ratio': str(normalized_data.short_account_ratio)
                    })

                self.logger.info(f"{self.data_type}æ•°æ®å¤„ç†å®Œæˆ", **log_data)
            
        except Exception as e:
            self.logger.error("å¤„ç†åŸå§‹æ•°æ®å¤±è´¥", error=e, symbol=symbol)
            self.stats['errors'] += 1

    async def _publish_to_nats(self, normalized_data):
        """å‘å¸ƒæ•°æ®åˆ°NATS - ä¿®å¤ç‰ˆï¼šä½¿ç”¨ç»Ÿä¸€çš„ä¸»é¢˜æ ¼å¼"""
        try:
            # ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„LSRä¸»é¢˜æ ¼å¼ä»¥åŒ¹é…å­˜å‚¨æœåŠ¡è®¢é˜…
            # å°† lsr_top_position -> top-position, lsr_all_account -> all-account
            lsr_subtype = self.data_type.replace('lsr_', '').replace('_', '-')
            topic = f"lsr-data.{normalized_data.exchange_name}.{normalized_data.product_type.value}.{lsr_subtype}.{normalized_data.symbol_name}"

            # ğŸ” è°ƒè¯•ï¼šLSRæ•°æ®å‘å¸ƒå¼€å§‹
            self.logger.debug("ğŸ” LSRæ•°æ®å¼€å§‹å‘å¸ƒåˆ°NATS",
                            data_type=self.data_type,
                            exchange=normalized_data.exchange_name,
                            symbol=normalized_data.symbol_name,
                            topic=topic)

            # æ„å»ºå‘å¸ƒæ•°æ®
            data_dict = {
                'exchange': normalized_data.exchange_name,
                'symbol': normalized_data.symbol_name,
                'product_type': normalized_data.product_type.value,
                'instrument_id': normalized_data.instrument_id,
                'timestamp': normalized_data.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                'long_short_ratio': str(normalized_data.long_short_ratio),
                'period': normalized_data.period,
                'data_source': 'marketprism'
            }

            # æ ¹æ®æ•°æ®ç±»å‹æ·»åŠ ç‰¹å®šå­—æ®µ
            if self.data_type == 'lsr_top_position':
                data_dict.update({
                    'long_position_ratio': str(normalized_data.long_position_ratio),
                    'short_position_ratio': str(normalized_data.short_position_ratio)
                })
            elif self.data_type == 'lsr_all_account':
                data_dict.update({
                    'long_account_ratio': str(normalized_data.long_account_ratio),
                    'short_account_ratio': str(normalized_data.short_account_ratio)
                })
            
            # ğŸ” è°ƒè¯•ï¼šå‡†å¤‡è°ƒç”¨NATSå‘å¸ƒå™¨
            self.logger.debug("ğŸ” å‡†å¤‡è°ƒç”¨NATSå‘å¸ƒå™¨",
                            data_type=self.data_type,
                            data_dict_keys=list(data_dict.keys()))

            # å‘å¸ƒåˆ°NATS
            success = await self.nats_publisher.publish_data(
                data_type=self.data_type,
                exchange=normalized_data.exchange_name,
                market_type=normalized_data.product_type.value,
                symbol=normalized_data.symbol_name,
                data=data_dict
            )

            # ğŸ” è°ƒè¯•ï¼šNATSå‘å¸ƒç»“æœ
            if success:
                self.logger.debug("ğŸ” LSRæ•°æ®NATSå‘å¸ƒæˆåŠŸ",
                                symbol=normalized_data.symbol_name,
                                topic=topic,
                                data_type=self.data_type)
            else:
                self.logger.warning("ğŸ” LSRæ•°æ®NATSå‘å¸ƒå¤±è´¥",
                                  symbol=normalized_data.symbol_name,
                                  topic=topic,
                                  data_type=self.data_type)
                
        except Exception as e:
            self.logger.error("å‘å¸ƒåˆ°NATSå¤±è´¥", error=e, symbol=normalized_data.symbol_name)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()

    @abstractmethod
    async def _fetch_data_from_api(self, symbol: str) -> Optional[Dict[str, Any]]:
        """ä»APIè·å–æ•°æ® - å­ç±»å®ç°"""
        pass

    @abstractmethod
    async def _normalize_data(self, raw_data: Dict[str, Any]) -> Optional[Union[NormalizedLSRTopPosition, NormalizedLSRAllAccount]]:
        """æ ‡å‡†åŒ–æ•°æ® - å­ç±»å®ç°"""
        pass
