"""
é€šç”¨NATSæ¶ˆæ¯å‘å¸ƒå™¨

æ”¯æŒMarketPrismæ•°æ®æ”¶é›†å™¨çš„æ‰€æœ‰æ•°æ®ç±»å‹å‘å¸ƒéœ€æ±‚
"""

import asyncio
import json
import os
import time
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, field
import structlog

try:
    import nats
    from nats.aio.client import Client as NATSClient
    from nats.js.api import StreamConfig, RetentionPolicy, StorageType, DiscardPolicy
    NATS_AVAILABLE = True
except ImportError:
    NATS_AVAILABLE = False
    NATSClient = None

from .data_types import Exchange, MarketType, DataType
from .normalizer import DataNormalizer
from .log_sampler import should_log_data_processing



@dataclass
class NATSConfig:
    """NATSé…ç½®"""
    # ğŸ”§ æ”¯æŒç¯å¢ƒå˜é‡é…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨ MARKETPRISM_NATS_URLï¼Œå…¶æ¬¡ NATS_URL
    servers: List[str] = field(default_factory=lambda: [os.getenv('MARKETPRISM_NATS_URL', os.getenv('NATS_URL', 'nats://localhost:4222'))])
    client_name: str = "unified-collector"
    max_reconnect_attempts: int = 10
    reconnect_time_wait: int = 2
    timeout: int = 5
    max_retries: int = 3
    batch_size: int = 100

    # ä¸»é¢˜æ¨¡æ¿ï¼ˆå•ä¸€çœŸæºï¼šæ¥è‡ª YAML çš„ nats.streams æ˜ å°„ï¼‰
    subject_templates: Dict[str, str] = field(default_factory=dict)



    # JetStreamæµé…ç½® - ğŸ”§ ä¿®å¤ï¼šå¯ç”¨JetStreamç¡®ä¿é‡‘èæ•°æ®ä¸ä¸¢å¤±
    enable_jetstream: bool = True
    streams: Dict[str, Dict[str, Any]] = field(default_factory=lambda: {
        "MARKET_DATA": {
            "name": "MARKET_DATA",
            # ä¸ç»Ÿä¸€é…ç½®ä¸€è‡´ï¼šç»Ÿä¸€ä¸ºä¸‹åˆ’çº¿å‘½åï¼›ä¸ä½¿ç”¨ -data åç¼€
            "subjects": [
                "orderbook.>",
                "trade.>",
                "funding_rate.>",
                "open_interest.>",
                "liquidation.>",
                "volatility_index.>",
                "lsr_top_position.>",
                "lsr_all_account.>"
            ],
            "retention": "limits",
            # ğŸ”§ ä¼˜åŒ–ï¼šé‡‘èæ•°æ®é…ç½® - ç¡®ä¿æ•°æ®ä¸ä¸¢å¤±
            "max_msgs": 5000000,      # å¢åŠ åˆ°500ä¸‡æ¡æ¶ˆæ¯
            "max_bytes": 2147483648,  # å¢åŠ åˆ°2GB
            "max_age": 172800,        # å¢åŠ åˆ°48å°æ—¶
            "max_consumers": 50,      # æ”¯æŒæ›´å¤šæ¶ˆè´¹è€…
            "replicas": 1,
            # ğŸ”§ æ–°å¢ï¼šé‡‘èæ•°æ®ç‰¹å®šé…ç½®
            "storage": "file",        # ä½¿ç”¨æ–‡ä»¶å­˜å‚¨ç¡®ä¿æŒä¹…åŒ–
            "discard": "old",         # è¾¾åˆ°é™åˆ¶æ—¶ä¸¢å¼ƒæ—§æ¶ˆæ¯
            "duplicate_window": 120   # 2åˆ†é’Ÿé‡å¤æ¶ˆæ¯æ£€æµ‹çª—å£
        }
    })


def create_nats_config_from_yaml(config_dict: Dict[str, Any]) -> NATSConfig:
    """
    ä»YAMLé…ç½®åˆ›å»ºNATSé…ç½®ï¼ˆå•ä¸€çœŸæºï¼‰

    ä¼˜å…ˆä» YAML nats.streams æ˜ å°„æ„å»ºä¸»é¢˜æ¨¡æ¿ï¼›ä»£ç ä¸å†å†…ç½®ä¸»é¢˜å­—ç¬¦ä¸²ï¼Œé¿å…é…ç½®æ¼‚ç§»ã€‚
    """
    nats_cfg = config_dict.get('nats', {})
    publish_cfg = nats_cfg.get('publish', {})
    jetstream_cfg = nats_cfg.get('jetstream', {})

    # ä» YAML çš„ nats.streams æ„å»º subject_templates
    streams_map = nats_cfg.get('streams', {})
    subject_templates = {}
    # å°† YAML é”®æ˜ å°„åˆ° DataType
    from .data_types import DataType
    mapping = {
        'orderbook': DataType.ORDERBOOK,
        'trade': DataType.TRADE,
        'funding_rate': DataType.FUNDING_RATE,
        'open_interest': DataType.OPEN_INTEREST,
        'liquidation': DataType.LIQUIDATION,
        'volatility_index': DataType.VOLATILITY_INDEX,
        'lsr_top_position': DataType.LSR_TOP_POSITION,
        'lsr_all_account': DataType.LSR_ALL_ACCOUNT,
    }
    for key, template in streams_map.items():
        dt = mapping.get(key)
        if dt:
            subject_templates[dt] = template

    # ç¯å¢ƒå˜é‡è¦†ç›–ä¼˜å…ˆï¼šMARKETPRISM_NATS_URL > NATS_URL > YAML
    env_url = os.getenv('MARKETPRISM_NATS_URL') or os.getenv('NATS_URL')
    servers = [env_url] if env_url else nats_cfg.get('servers', ['nats://localhost:4222'])

    return NATSConfig(
        servers=servers,
        client_name=nats_cfg.get('client_name', 'unified-collector'),
        max_reconnect_attempts=nats_cfg.get('max_reconnect_attempts', 10),
        reconnect_time_wait=nats_cfg.get('reconnect_time_wait', 2),
        timeout=publish_cfg.get('timeout', 5),
        max_retries=publish_cfg.get('max_retries', 3),
        batch_size=publish_cfg.get('batch_size', 100),
        enable_jetstream=jetstream_cfg.get('enabled', True),
        streams=jetstream_cfg.get('streams', {}),
        subject_templates=subject_templates
    )


@dataclass
class PublishStats:
    """å‘å¸ƒç»Ÿè®¡"""
    total_published: int = 0
    successful_published: int = 0
    failed_published: int = 0
    last_publish_time: Optional[float] = None
    connection_errors: int = 0
    publish_errors: int = 0
    data_quality_issues: int = 0


class NATSPublisher:
    """
    é€šç”¨NATSæ¶ˆæ¯å‘å¸ƒå™¨

    æ”¯æŒæ‰€æœ‰æ•°æ®ç±»å‹çš„ç»Ÿä¸€å‘å¸ƒæ¥å£
    """

    def __init__(self, config: Optional[NATSConfig] = None, normalizer: Optional[DataNormalizer] = None):
        self.config = config or NATSConfig()
        self.normalizer = normalizer or DataNormalizer()  # ğŸ”§ æ·»åŠ Normalizerç”¨äºSymbolæ ‡å‡†åŒ–
        self.logger = structlog.get_logger(__name__)

        # è¿æ¥ç®¡ç†
        self.client: Optional[NATSClient] = None
        self.js = None  # JetStream context
        self._is_connected = False
        self.connection_lock = asyncio.Lock()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = PublishStats()

        # å•ä¸€çœŸæºï¼šå¦‚ YAML æä¾› subject_templatesï¼Œåˆ™è¦†ç›–å†…ç½®é»˜è®¤ï¼›å¦åˆ™é€€å›é»˜è®¤
        default_templates = {
            DataType.ORDERBOOK: "orderbook.{exchange}.{market_type}.{symbol}",
            DataType.TRADE: "trade.{exchange}.{market_type}.{symbol}",
            DataType.FUNDING_RATE: "funding_rate.{exchange}.{market_type}.{symbol}",
            DataType.OPEN_INTEREST: "open_interest.{exchange}.{market_type}.{symbol}",
            DataType.LIQUIDATION: "liquidation.{exchange}.{market_type}.{symbol}",
            DataType.LSR_TOP_POSITION: "lsr_top_position.{exchange}.{market_type}.{symbol}",
            DataType.LSR_ALL_ACCOUNT: "lsr_all_account.{exchange}.{market_type}.{symbol}",
            DataType.VOLATILITY_INDEX: "volatility_index.{exchange}.{market_type}.{symbol}",
        }
        # è‹¥é…ç½®ä¸­æä¾›äº†æ¨¡æ¿ï¼Œåˆ™ä»¥é…ç½®ä¸ºå‡†
        if getattr(self.config, 'subject_templates', None):
            default_templates.update(self.config.subject_templates)
        self.subject_templates = default_templates

        # æ‰¹é‡å‘å¸ƒç¼“å†²åŒº
        self.publish_buffer: List[Dict[str, Any]] = []
        self.buffer_lock = asyncio.Lock()
        self.last_flush_time = time.time()

        # æ£€æŸ¥NATSå¯ç”¨æ€§
        if not NATS_AVAILABLE:
            self.logger.warning("NATSå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install nats-py")

    async def connect(self) -> bool:
        """è¿æ¥åˆ°NATSæœåŠ¡å™¨"""
        if not NATS_AVAILABLE:
            self.logger.error("NATSå®¢æˆ·ç«¯ä¸å¯ç”¨")
            return False

        async with self.connection_lock:
            if self.is_connected:
                return True

            try:
                self.logger.info("è¿æ¥åˆ°NATSæœåŠ¡å™¨", servers=self.config.servers)

                # åˆ›å»ºNATSå®¢æˆ·ç«¯
                self.client = await nats.connect(
                    servers=self.config.servers,
                    name=self.config.client_name,
                    error_cb=self._error_handler,
                    closed_cb=self._closed_handler,
                    reconnected_cb=self._reconnected_handler,
                    max_reconnect_attempts=self.config.max_reconnect_attempts,
                    reconnect_time_wait=self.config.reconnect_time_wait,
                )

                # è·å–JetStreamä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
                if self.config.enable_jetstream:
                    try:
                        self.js = self.client.jetstream()
                        self.logger.info("âœ… JetStreamä¸Šä¸‹æ–‡å·²åˆ›å»º")

                        # ç¡®ä¿æµå­˜åœ¨
                        jetstream_available = await self._ensure_streams()
                        if jetstream_available:
                            self.logger.info("âœ… JetStreamæµé…ç½®å®Œæˆ - é‡‘èæ•°æ®å°†æŒä¹…åŒ–å­˜å‚¨")
                        else:
                            self.js = None
                            self.logger.warning("âš ï¸ JetStreamæœåŠ¡ä¸å¯ç”¨ï¼Œé™çº§åˆ°æ ¸å¿ƒNATS",
                                              fallback="æ•°æ®ä»ä¼šå‘å¸ƒä½†ä¸ä¼šæŒä¹…åŒ–")

                    except Exception as e:
                        self.logger.warning("âš ï¸ JetStreamä¸å¯ç”¨ï¼Œé™çº§åˆ°æ ¸å¿ƒNATS",
                                          error=str(e),
                                          fallback="æ•°æ®ä»ä¼šå‘å¸ƒä½†ä¸ä¼šæŒä¹…åŒ–")
                        self.js = None
                        # ğŸ”§ é‡è¦ï¼šå³ä½¿JetStreamå¤±è´¥ï¼Œä¹Ÿè¦ç»§ç»­ä½¿ç”¨æ ¸å¿ƒNATS
                        # è¿™ç¡®ä¿äº†æ•°æ®æµçš„è¿ç»­æ€§
                else:
                    self.js = None
                    self.logger.info("ğŸ“¡ ä½¿ç”¨æ ¸å¿ƒNATSæ¨¡å¼ - å®æ—¶ä¼ è¾“ä¼˜å…ˆ")

                self._is_connected = True
                self.logger.info("NATSè¿æ¥æˆåŠŸ")
                return True

            except Exception as e:
                self.logger.error("NATSè¿æ¥å¤±è´¥", error=str(e))
                self.stats.connection_errors += 1
                self._is_connected = False
                return False

    async def disconnect(self):
        """æ–­å¼€NATSè¿æ¥"""
        async with self.connection_lock:
            try:
                # åˆ·æ–°ç¼“å†²åŒº
                await self._flush_buffer()

                self._is_connected = False

                if self.client and not self.client.is_closed:
                    await asyncio.wait_for(self.client.close(), timeout=5.0)
                    self.logger.info("NATSè¿æ¥å·²æ–­å¼€")

            except asyncio.TimeoutError:
                self.logger.warning("NATSæ–­å¼€è¿æ¥è¶…æ—¶")
            except Exception as e:
                self.logger.error("æ–­å¼€NATSè¿æ¥æ—¶å‡ºé”™", error=str(e))
            finally:
                self.client = None
                self.js = None
                self._is_connected = False

    @property
    def is_connected(self) -> bool:
        """
        æ£€æŸ¥NATSè¿æ¥çŠ¶æ€ - ğŸ”§ ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„æ–¹æ³•

        Returns:
            bool: è¿æ¥çŠ¶æ€
        """
        return hasattr(self, '_is_connected') and self._is_connected and self.client is not None and not self.client.is_closed

    async def _ensure_streams(self):
        """
        ç¡®ä¿æ‰€éœ€çš„JetStreamæµå­˜åœ¨

        Returns:
            bool: JetStreamæ˜¯å¦å¯ç”¨
        """
        if not self.js:
            return False

        jetstream_available = True
        for stream_name, stream_config in self.config.streams.items():
            try:
                # å°è¯•è·å–æµä¿¡æ¯
                try:
                    existing = await self.js.stream_info(stream_name)
                    self.logger.debug("JetStreamæµå·²å­˜åœ¨", stream=stream_name)
                    # è‹¥å·²æœ‰æµç¼ºå°‘éœ€è¦çš„subjectsï¼Œåˆ™æ‰§è¡Œæ›´æ–°ä»¥è¿½åŠ 
                    try:
                        existing_subjects = set(getattr(existing.config, 'subjects', []) or [])
                        target_subjects = set(stream_config.get("subjects", []) or [])
                        # ç²¾å‡†æ›´æ–°ï¼šä»¥é…ç½®ä¸ºå‡†ï¼Œç§»é™¤ä¸åœ¨ç›®æ ‡é›†åˆä¸­çš„æ—§subjectsï¼Œé¿å…æ··æ·†
                        if existing_subjects != target_subjects:
                            update_cfg = StreamConfig(
                                name=stream_config["name"],
                                subjects=sorted(list(target_subjects)),
                                retention=RetentionPolicy.LIMITS,
                                max_msgs=stream_config["max_msgs"],
                                max_bytes=stream_config["max_bytes"],
                                max_age=stream_config["max_age"],
                                max_consumers=stream_config["max_consumers"],
                                num_replicas=stream_config["replicas"],
                                storage=StorageType.FILE if stream_config.get("storage") == "file" else StorageType.MEMORY,
                                discard=DiscardPolicy.OLD if stream_config.get("discard") == "old" else DiscardPolicy.NEW,
                                duplicate_window=stream_config.get("duplicate_window", 120),
                                max_msgs_per_subject=stream_config.get("max_msgs_per_subject", 0)
                            )
                            await self.js.update_stream(update_cfg)
                            self.logger.info(
                                "JetStreamæµsubjectså·²æ›¿æ¢æ›´æ–°",
                                stream=stream_name,
                                removed=list(existing_subjects - target_subjects),
                                added=list(target_subjects - existing_subjects)
                            )
                    except Exception as e:
                        self.logger.warning("æ›´æ–°JetStreamæµsubjectså¤±è´¥ï¼ˆå°†ç»§ç»­ä½¿ç”¨ç°æœ‰é…ç½®ï¼‰", stream=stream_name, error=str(e))
                except:
                    # æµä¸å­˜åœ¨ï¼Œåˆ›å»ºæµ
                    # ğŸ”§ ä¿®å¤ï¼šæ”¯æŒæ–°çš„é‡‘èæ•°æ®é…ç½®å‚æ•°
                    config = StreamConfig(
                        name=stream_config["name"],
                        subjects=stream_config["subjects"],
                        retention=RetentionPolicy.LIMITS,
                        max_msgs=stream_config["max_msgs"],
                        max_bytes=stream_config["max_bytes"],
                        max_age=stream_config["max_age"],
                        max_consumers=stream_config["max_consumers"],
                        num_replicas=stream_config["replicas"],
                        # ğŸ”§ æ–°å¢ï¼šé‡‘èæ•°æ®ç‰¹å®šé…ç½®
                        storage=StorageType.FILE if stream_config.get("storage") == "file" else StorageType.MEMORY,
                        discard=DiscardPolicy.OLD if stream_config.get("discard") == "old" else DiscardPolicy.NEW,
                        duplicate_window=stream_config.get("duplicate_window", 120),
                        max_msgs_per_subject=stream_config.get("max_msgs_per_subject", 0)
                    )

                    await self.js.add_stream(config)
                    self.logger.info("åˆ›å»ºJetStreamæµ", stream=stream_name)

            except Exception as e:
                error_str = str(e)
                # æ£€æŸ¥æ˜¯å¦æ˜¯æµå·²å­˜åœ¨çš„é”™è¯¯
                if "stream name already in use" in error_str.lower() or "stream already exists" in error_str.lower():
                    self.logger.info("JetStreamæµå·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º", stream=stream_name)
                elif ("service unavailable" in error_str.lower() or
                      "serviceunavailableerror" in error_str.lower() or
                      "jetstream not enabled" in error_str.lower()):
                    self.logger.warning("JetStreamæœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ ¸å¿ƒNATS", stream=stream_name, error=error_str)
                    jetstream_available = False  # æ ‡è®°JetStreamä¸å¯ç”¨
                else:
                    self.logger.error("åˆ›å»ºJetStreamæµå¤±è´¥", stream=stream_name, error=error_str)
                    jetstream_available = False  # å…¶ä»–é”™è¯¯ä¹Ÿæ ‡è®°ä¸ºä¸å¯ç”¨
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ä½¿ç”¨æ ¸å¿ƒNATS

        return jetstream_available

    # ğŸ”§ ç§»é™¤é‡å¤çš„Symbolæ ‡å‡†åŒ–é€»è¾‘ - ç°åœ¨ä½¿ç”¨Normalizerçš„æ ‡å‡†åŒ–ç»“æœ
    # NATS Publisherä¸å†è¿›è¡ŒSymbolæ ¼å¼è½¬æ¢ï¼Œç›´æ¥ä½¿ç”¨å·²æ ‡å‡†åŒ–çš„æ•°æ®

    def _generate_subject(self, data_type: str, exchange: str, market_type: str, symbol: str) -> str:
        """
        ç”ŸæˆNATSä¸»é¢˜

        Args:
            data_type: æ•°æ®ç±»å‹ (orderbook, trade, funding_rate, open_interest)
            exchange: äº¤æ˜“æ‰€åç§°
            market_type: å¸‚åœºç±»å‹ (spot, perpetual)
            symbol: äº¤æ˜“å¯¹ç¬¦å·

        Returns:
            NATSä¸»é¢˜å­—ç¬¦ä¸²
        """
        # è½¬æ¢æ•°æ®ç±»å‹
        if isinstance(data_type, DataType):
            data_type_str = data_type.value
        else:
            data_type_str = str(data_type).lower()

        # ğŸ”§ ç›´æ¥ä½¿ç”¨å·²æ ‡å‡†åŒ–çš„symbolï¼ˆä»Normalizerè·å¾—ï¼‰
        normalized_symbol = symbol

        # è·å–ä¸»é¢˜æ¨¡æ¿
        template = self.subject_templates.get(
            DataType(data_type_str) if data_type_str in [dt.value for dt in DataType] else None,
            f"{data_type_str}.{{exchange}}.{{market_type}}.{{symbol}}"
        )

        # ğŸ¯ æ ¼å¼åŒ–ä¸»é¢˜ - æ–°çš„å¸‚åœºåˆ†ç±»æ¶æ„
        # exchangeåç§°ä¿æŒåŸæ ·ï¼ˆå¦‚binance_spot, binance_derivativesï¼‰
        # market_typeè½¬ä¸ºå°å†™ï¼ˆå¦‚spot, perpetualï¼‰
        subject = template.format(
            exchange=exchange,  # ğŸ”§ ä¿æŒåŸæ ·ï¼Œä¸è½¬æ¢ä¸ºå°å†™
            market_type=market_type.lower(),
            symbol=normalized_symbol
        )

        return subject


    def _build_msg_id(self, data_type: str, exchange: str, symbol: str, data: Dict[str, Any]) -> Optional[str]:
        """ç»Ÿä¸€æ„å»ºNATS Msg-Idç”¨äºJetStreamå¹‚ç­‰ï¼Œä¼˜å…ˆä½¿ç”¨æ¯«ç§’æ•´å‹ ts_msã€‚"""
        try:
            dt = data_type if isinstance(data_type, str) else str(data_type)
            dt = dt.lower()
            ex = str(exchange)
            sym = str(symbol)

            # ç»Ÿä¸€è·å–äº‹ä»¶æ¯«ç§’æ—¶é—´
            ts = data.get('ts_ms') or data.get('timestamp') or data.get('trade_time') or data.get('ts')

            if dt == 'trade':
                tid = data.get('trade_id') or data.get('id')
                if tid:
                    return f"trade:{ex}:{sym}:{tid}"
                px = data.get('price'); qty = data.get('quantity') or data.get('qty'); side = data.get('side')
                if ts and px and qty and side:
                    return f"trade:{ex}:{sym}:{ts}:{px}:{qty}:{side}"
                return None

            if dt == 'orderbook':
                lid = data.get('last_update_id') or data.get('lastUpdateId') or data.get('u')
                if lid:
                    return f"orderbook:{ex}:{sym}:{lid}"
                bids = data.get('bids') or []; asks = data.get('asks') or []
                best_bid = bids[0][0] if bids and isinstance(bids[0], list) and bids[0] else None
                best_ask = asks[0][0] if asks and isinstance(asks[0], list) and asks[0] else None
                if ts:
                    return f"orderbook:{ex}:{sym}:{ts}:{best_bid}:{best_ask}"
                return None

            if dt == 'funding_rate':
                ts2 = data.get('ts_ms') or data.get('funding_ts_ms') or data.get('funding_time')
                if ts2:
                    return f"funding_rate:{ex}:{sym}:{ts2}"
                return None

            if dt == 'open_interest':
                ts2 = data.get('ts_ms') or data.get('ts')
                if ts2:
                    return f"open_interest:{ex}:{sym}:{ts2}"
                return None

            if dt == 'liquidation':
                oid = data.get('order_id') or data.get('liquidation_id') or data.get('trade_id')
                if oid:
                    return f"liquidation:{ex}:{sym}:{oid}"
                px = data.get('price'); qty = data.get('quantity') or data.get('qty'); side = data.get('side')
                if ts and px and qty and side:
                    return f"liquidation:{ex}:{sym}:{ts}:{px}:{qty}:{side}"
                return None

            if dt == 'volatility_index':
                if ts:
                    return f"volatility_index:{ex}:{sym}:{ts}"
                return None

            if dt in ('lsr_top_position', 'lsr_all_account', 'top_trader_long_short_ratio', 'market_long_short_ratio'):
                period = data.get('period')
                if ts and period:
                    return f"{dt}:{ex}:{sym}:{ts}:{period}"
                if ts:
                    return f"{dt}:{ex}:{sym}:{ts}"
                return None

            if ts:
                return f"{dt}:{ex}:{sym}:{ts}"
            return None
        except Exception:
            return None

    # ğŸ”§ ç§»é™¤å¸‚åœºç±»å‹æ¨æ–­é€»è¾‘ - ç°åœ¨ä»é…ç½®è·å–market_typeï¼Œä¸è¿›è¡Œæ¨æ–­
    # å¸‚åœºç±»å‹åº”è¯¥ä»OrderBook Managerä¼ å…¥ï¼Œè€Œä¸æ˜¯æ ¹æ®Symbolæ¨æ–­

    async def publish_data(self, data_type: Union[str, DataType], exchange: str,
                          market_type: str, symbol: str, data: Dict[str, Any],
                          use_jetstream: Optional[bool] = None) -> bool:
        """
        å‘å¸ƒæ•°æ®åˆ°NATSï¼ˆJetStreamä¼˜å…ˆï¼‰

        Args:
            data_type: æ•°æ®ç±»å‹
            exchange: äº¤æ˜“æ‰€åç§°
            market_type: å¸‚åœºç±»å‹
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            data: è¦å‘å¸ƒçš„æ•°æ®
            use_jetstream: æ˜¯å¦ä½¿ç”¨JetStreamï¼›None è¡¨ç¤ºâ€œè‹¥å¯ç”¨åˆ™è‡ªåŠ¨ä½¿ç”¨â€

        Returns:
            å‘å¸ƒæ˜¯å¦æˆåŠŸ
        """
        if not self.is_connected:
            # å°è¯•é‡è¿
            self.logger.warning("NATSæœªè¿æ¥ï¼Œå°è¯•é‡æ–°è¿æ¥",
                              exchange=exchange,
                              market_type=market_type,
                              symbol=symbol)
            if not await self.connect():
                self.logger.error("NATSé‡è¿å¤±è´¥ï¼Œæ— æ³•å‘å¸ƒæ•°æ®",
                                exchange=exchange,
                                market_type=market_type,
                                symbol=symbol)
                return False

        try:
            # ğŸ”§ ç›´æ¥ä½¿ç”¨å·²æ ‡å‡†åŒ–çš„symbolï¼ˆä»Normalizerè·å¾—ï¼‰
            normalized_symbol = symbol

            # ç”Ÿæˆä¸»é¢˜
            subject = self._generate_subject(data_type, exchange, market_type, normalized_symbol)

            # ğŸ” è°ƒè¯•ï¼šè¾“å‡ºæœ€ç»ˆNATSä¸»é¢˜ç”Ÿæˆ
            self.logger.debug("ğŸ” æœ€ç»ˆNATSä¸»é¢˜ç”Ÿæˆè°ƒè¯•",
                           data_type=str(data_type),
                           exchange=exchange,
                           market_type=market_type,
                           normalized_symbol=normalized_symbol,
                           final_subject=subject)

            # å‡†å¤‡æ¶ˆæ¯æ•°æ® - ç»Ÿä¸€æ¯«ç§’æ—¶é—´ï¼šä»…ä½¿ç”¨ ts_msï¼ˆUTC æ¯«ç§’ï¼‰
            # ğŸ”§ ä¿®å¤ï¼šæ— è®ºæ•°æ®æ ¼å¼å¦‚ä½•ï¼Œéƒ½è¦ç¡®ä¿åŒ…å« data_type ä¸ ts_ms å­—æ®µ
            if isinstance(data, dict) and 'exchange' in data and 'symbol' in data:
                # æ•°æ®å·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼Œä½†éœ€è¦ç¡®ä¿åŒ…å«å¿…è¦å­—æ®µ
                message_data = data.copy()  # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                dt_val = data_type.value if hasattr(data_type, 'value') else str(data_type)
                message_data['data_type'] = dt_val
                message_data['market_type'] = message_data.get('market_type', market_type)
                message_data['symbol'] = normalized_symbol
                # ç»Ÿä¸€ ts_ms
                if 'ts_ms' not in message_data:
                    message_data['ts_ms'] = int(datetime.now(timezone.utc).timestamp() * 1000)
                # trade: trade_ts_ms å…œåº•
                if message_data['data_type'] == 'trade' and 'trade_ts_ms' not in message_data:
                    message_data['trade_ts_ms'] = message_data.get('ts_ms')
                if 'publisher' not in message_data:
                    message_data['publisher'] = 'unified-collector'
            else:
                # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯æ ¼å¼ï¼ˆæ— å­—ç¬¦ä¸²æ—¶é—´ï¼‰
                message_data = {
                    'exchange': exchange,
                    'market_type': market_type,
                    'symbol': normalized_symbol,
                    'data_type': {
                        'funding-rate': 'funding_rate',
                        'open-interest': 'open_interest',
                        'lsr-top-position': 'lsr_top_position',
                        'lsr-all-account': 'lsr_all_account',
                        'volatility-index': 'volatility_index'
                    }.get(data_type.value if hasattr(data_type, 'value') else str(data_type), data_type.value if hasattr(data_type, 'value') else str(data_type)),
                    'ts_ms': int(datetime.now(timezone.utc).timestamp() * 1000),
                    'publisher': 'unified-collector'
                }

                # å®‰å…¨åœ°æ·»åŠ æ•°æ®å†…å®¹
                if isinstance(data, dict):
                    message_data.update(data)
                    if message_data.get('data_type') == 'trade' and 'trade_ts_ms' not in message_data:
                        message_data['trade_ts_ms'] = message_data.get('ts_ms')
                        self.logger.debug(
                            "Trade data missing trade_ts_ms, using ts_ms fallback",
                            exchange=exchange, symbol=symbol
                        )
                else:
                    message_data['data'] = data

            # æœ€ç»ˆå…œåº•ï¼štrade_ts_ms
            if message_data.get('data_type') == 'trade' and (
                'trade_ts_ms' not in message_data or not message_data.get('trade_ts_ms')
            ):
                message_data['trade_ts_ms'] = message_data.get('ts_ms', int(datetime.now(timezone.utc).timestamp() * 1000))
                self.logger.warning(
                    "Trade data missing valid trade_ts_ms, using system ts_ms fallback",
                    exchange=exchange, symbol=symbol,
                    original_keys=list(message_data.keys())
                )
                self.stats.data_quality_issues += 1

            # æ•°æ®è´¨é‡éªŒè¯ï¼ˆä»…å¯¹äº¤æ˜“æ•°æ®ï¼‰
            if message_data.get('data_type') == 'trade':
                validation_issues = []

                # éªŒè¯å…³é”®æ•°å€¼å­—æ®µ
                price = message_data.get('price')
                if price is None or (isinstance(price, (int, float, str)) and (not price or float(price) <= 0)):
                    validation_issues.append('invalid_price')

                quantity = message_data.get('quantity')
                if quantity is None or (isinstance(quantity, (int, float, str)) and (not quantity or float(quantity) <= 0)):
                    validation_issues.append('invalid_quantity')

                # éªŒè¯äº¤æ˜“æ–¹å‘
                side = message_data.get('side')
                if side not in ['buy', 'sell', 'BUY', 'SELL']:
                    validation_issues.append('invalid_side')

                # å¦‚æœæœ‰éªŒè¯é—®é¢˜ï¼Œè®°å½•ä½†ä¸é˜»æ­¢å‘å¸ƒï¼ˆä¿è¯æ•°æ®æµè¿ç»­æ€§ï¼‰
                if validation_issues:
                    self.logger.warning(f"Trade data validation issues detected",
                                      exchange=exchange, symbol=symbol,
                                      issues=validation_issues,
                                      price=price, quantity=quantity, side=side)
                    self.stats.data_quality_issues += 1

            # å§”æ‰˜ Normalizer ç»Ÿä¸€è§„èŒƒæ—¶é—´å­—æ®µï¼ˆClickHouseå‹å¥½: YYYY-MM-DD HH:MM:SS.mmm, UTCï¼‰
            message_data = self.normalizer.normalize_time_fields(message_data)

            # åºåˆ—åŒ–æ¶ˆæ¯
            message_bytes = json.dumps(message_data, ensure_ascii=False, default=str).encode('utf-8')

            # JetStream ä½¿ç”¨ç­–ç•¥ï¼šé»˜è®¤åœ¨å¯ç”¨æ—¶ä½¿ç”¨
            use_js = (self.js is not None) if use_jetstream is None else (use_jetstream and self.js is not None)

            # å‘å¸ƒæ¶ˆæ¯
            if use_js:
                # ä½¿ç”¨JetStreamå‘å¸ƒï¼Œæ”¯æŒå¹‚ç­‰å»é‡ï¼ˆMsg-Idï¼‰
                headers = None
                try:
                    dt_val = message_data.get('data_type')
                    msg_id = self._build_msg_id(dt_val, exchange, normalized_symbol, message_data)
                    if msg_id:
                        headers = {'Nats-Msg-Id': msg_id}
                except Exception:
                    headers = None

                ack = await self.js.publish(subject, message_bytes, headers=headers)
                self.logger.debug("JetStreamæ¶ˆæ¯å‘å¸ƒæˆåŠŸ",
                                subject=subject, sequence=ack.seq)

            else:
                # ä½¿ç”¨æ ¸å¿ƒNATSå‘å¸ƒ
                await self.client.publish(subject, message_bytes)
                self.logger.debug("NATSæ¶ˆæ¯å‘å¸ƒæˆåŠŸ", subject=subject)

            # ä½é¢‘æ•°æ®ï¼šç›´æ¥Infoæ—¥å¿—æå‡å¯è§‚æµ‹æ€§
            low_freq_types = {DataType.VOLATILITY_INDEX, DataType.FUNDING_RATE, DataType.OPEN_INTEREST, DataType.LIQUIDATION}
            if data_type in low_freq_types:
                try:
                    key = None
                    if isinstance(data, dict):
                        key = data.get('vol_index') or data.get('volatility_index') or data.get('funding_rate') or data.get('open_interest')
                    self.logger.info("âœ… ä½é¢‘æ•°æ®å‘å¸ƒæˆåŠŸ", subject=subject, key=str(key) if key is not None else None)
                except Exception:
                    # é˜²å¾¡æ€§
                    self.logger.info("âœ… ä½é¢‘æ•°æ®å‘å¸ƒæˆåŠŸ", subject=subject)

            # ğŸ”§ å¯¹tradeæ•°æ®æ·»åŠ æŠ½æ ·çš„INFOçº§åˆ«æ—¥å¿—ï¼Œä¾¿äºç«¯åˆ°ç«¯è§‚æµ‹
            if data_type == DataType.TRADE:
                should_log = should_log_data_processing(
                    data_type="trade",
                    exchange=exchange,
                    market_type=market_type,
                    symbol=symbol,
                    is_error=False
                )
                if should_log:
                    self.logger.info("âœ… Trade NATSå‘å¸ƒæˆåŠŸ",
                                   subject=subject,
                                   symbol=symbol,
                                   exchange=exchange,
                                   total_published=self.stats.total_published + 1)

            # æ›´æ–°ç»Ÿè®¡
            self.stats.total_published += 1
            self.stats.successful_published += 1
            self.stats.last_publish_time = time.time()

            return True

        except Exception as e:
            # æ”¹è¿›çš„é”™è¯¯å¤„ç†
            from collector.exceptions import handle_error

            wrapped_error = handle_error(
                e, "nats_publisher", "publish",
                additional_data={"subject": subject if 'subject' in locals() else 'unknown'}
            )

            self.logger.error("å‘å¸ƒæ¶ˆæ¯å¤±è´¥",
                            subject=subject if 'subject' in locals() else 'unknown',
                            error=str(wrapped_error))
            self.stats.total_published += 1
            self.stats.failed_published += 1
            self.stats.publish_errors += 1
            return False

    async def _publish_with_retry(self, subject: str, message_data: str):
        """å¸¦é‡è¯•æœºåˆ¶çš„å‘å¸ƒæ–¹æ³•"""
        from collector.retry_mechanism import nats_retry

        @nats_retry("nats_publish")
        async def _do_publish():
            message_bytes = message_data.encode('utf-8')

            if self.config.enable_jetstream and self.js:
                # ä½¿ç”¨JetStreamå‘å¸ƒï¼ˆé™„å¸¦Msg-Idä»¥å¹‚ç­‰å»é‡ï¼‰
                headers = None
                try:
                    try:
                        payload = json.loads(message_data)
                    except Exception:
                        payload = {}
                    parts = subject.split('.')
                    dt = parts[0] if parts else payload.get('data_type')
                    # å…¼å®¹å¯èƒ½çš„ "orderbook-data" ä¸»é¢˜å‰ç¼€
                    dt = (dt.split('-')[0] if isinstance(dt, str) else dt) or ''
                    ex = parts[1] if len(parts) > 1 else payload.get('exchange')
                    sym = parts[3] if len(parts) > 3 else payload.get('symbol')
                    msg_id = self._build_msg_id(dt, ex or '', sym or '', payload)
                    if msg_id:
                        headers = {'Nats-Msg-Id': msg_id}
                except Exception:
                    headers = None
                ack = await self.js.publish(subject, message_bytes, headers=headers)
                self.logger.debug("JetStreamæ¶ˆæ¯å‘å¸ƒæˆåŠŸ",
                                subject=subject, sequence=ack.seq)
            else:
                # ä½¿ç”¨æ ¸å¿ƒNATSå‘å¸ƒ
                await self.client.publish(subject, message_bytes)
                self.logger.debug("NATSæ¶ˆæ¯å‘å¸ƒæˆåŠŸ", subject=subject)

        await _do_publish()

    async def publish_orderbook(self, exchange: str, market_type: str, symbol: str,
                               orderbook_data: Dict[str, Any]) -> bool:
        """
        å‘å¸ƒè®¢å•ç°¿æ•°æ® - ä¼˜åŒ–ï¼šé›†ä¸­åŒ–æ•°æ®æ ‡å‡†åŒ–

        ğŸ”§ æ¶æ„ä¼˜åŒ–ï¼šç»Ÿä¸€æ ‡å‡†åŒ–å…¥å£ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®æ ¼å¼ä¸€è‡´
        """
        try:
            # ğŸ”§ é›†ä¸­åŒ–æ ‡å‡†åŒ–ï¼šåœ¨æ­¤å¤„ç»Ÿä¸€è¿›è¡Œæ‰€æœ‰æ•°æ®æ ‡å‡†åŒ–
            if orderbook_data.get('raw_data', False):
                # å¤„ç†åŸå§‹æ•°æ®ï¼Œè¿›è¡Œå®Œæ•´æ ‡å‡†åŒ–
                standardized_data = await self._standardize_orderbook_data(
                    orderbook_data, exchange, market_type, symbol
                )
            else:
                # å¤„ç†å·²éƒ¨åˆ†æ ‡å‡†åŒ–çš„æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
                standardized_data = orderbook_data

            # ï¿½ é˜²å¾¡ï¼šbids/asksä¸ºç©ºæ—¶è·³è¿‡å‘å¸ƒï¼Œé¿å…ç©ºæ•°ç»„è¯¯å‘
            bids = standardized_data.get('bids') or []
            asks = standardized_data.get('asks') or []
            if not bids or not asks:
                self.logger.warning("âš ï¸ è·³è¿‡å‘å¸ƒç©ºè®¢å•ç°¿", exchange=exchange, market_type=market_type, symbol=symbol,
                                   bids_len=len(bids), asks_len=len(asks))
                return False

            # ï¿½ğŸ”§ Symbolæ ‡å‡†åŒ–ï¼šç»Ÿä¸€æ ¼å¼ BTCUSDT -> BTC-USDT, BTC-USDT-SWAP -> BTC-USDT
            normalized_symbol = self.normalizer.normalize_symbol_format(symbol, exchange)

            # ç¡®ä¿æ ‡å‡†åŒ–æ•°æ®åŒ…å«ç»Ÿä¸€å­—æ®µ
            standardized_data.update({
                'normalized_symbol': normalized_symbol,
                'standardized_at': datetime.now(timezone.utc).isoformat(),
                'standardization_version': '2.0'
            })

            return await self.publish_data(
                DataType.ORDERBOOK, exchange, market_type, normalized_symbol, standardized_data
            )

        except Exception as e:
            self.logger.error(f"âŒ è®¢å•ç°¿æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return False

    async def publish_trade(self, exchange: str, market_type: str, symbol: str,
                           trade_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒäº¤æ˜“æ•°æ®"""
        return await self.publish_data(
            DataType.TRADE, exchange, market_type, symbol, trade_data
        )

    # åˆ«åæ–¹æ³•ï¼Œç”¨äºå…¼å®¹æ¼”ç¤ºè„šæœ¬
    async def publish_orderbook_data(self, exchange: str, market_type: str, symbol: str,
                                   data: Dict[str, Any]) -> bool:
        """å‘å¸ƒè®¢å•ç°¿æ•°æ®ï¼ˆåˆ«åæ–¹æ³•ï¼‰"""
        return await self.publish_orderbook(exchange, market_type, symbol, data)

    async def publish_trade_data(self, trade_data: Dict[str, Any],
                               exchange: Exchange, market_type, symbol: str) -> bool:
        """
        ğŸ”§ ä¼˜åŒ–ï¼šç»Ÿä¸€æˆäº¤æ•°æ®å‘å¸ƒæ–¹æ³•
        æ”¯æŒåŸå§‹æ•°æ®å’Œæ ‡å‡†åŒ–æ•°æ®çš„å¤„ç†
        """
        try:
            # ğŸ”§ é›†ä¸­åŒ–æ ‡å‡†åŒ–ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºåŸå§‹æ•°æ®
            if trade_data.get('raw_data', False):
                # å¤„ç†åŸå§‹æ•°æ®ï¼Œè¿›è¡Œå®Œæ•´æ ‡å‡†åŒ–
                standardized_data = await self._standardize_trade_data(
                    trade_data, exchange, market_type, symbol
                )
            else:
                # å¤„ç†å·²æ ‡å‡†åŒ–çš„æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
                standardized_data = trade_data

            # Symbolæ ‡å‡†åŒ–
            normalized_symbol = self.normalizer.normalize_symbol_format(symbol, exchange.value)

            # ç¡®ä¿æ ‡å‡†åŒ–æ•°æ®åŒ…å«ç»Ÿä¸€å­—æ®µ
            standardized_data.update({
                'normalized_symbol': normalized_symbol,
                'standardized_at': datetime.now(timezone.utc).isoformat(),
                'standardization_version': '2.0'
            })

            # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€ä½¿ç”¨æ ‡å‡†ä¸»é¢˜æ¨¡æ¿ï¼Œé¿å…å‘½åä¸ä¸€è‡´
            # ç›´æ¥ä½¿ç”¨ publish_dataï¼Œå®ƒä¼šé€šè¿‡ _generate_subject ç”Ÿæˆæ­£ç¡®çš„ "trade.{...}" ä¸»é¢˜ï¼ˆæ—  -data åç¼€ï¼‰
            return await self.publish_data(
                DataType.TRADE, exchange.value, market_type.value, normalized_symbol, standardized_data
            )

        except Exception as e:
            self.logger.error(f"âŒ æˆäº¤æ•°æ®å‘å¸ƒå¤±è´¥: {e}")
            return False

    async def publish_trade_data_raw(self, raw_trade_data: Dict[str, Any],
                                   exchange: Exchange, market_type, symbol: str) -> bool:
        """
        ğŸ”§ æ–°å¢ï¼šå¤„ç†åŸå§‹æˆäº¤æ•°æ®çš„å‘å¸ƒæ–¹æ³•
        é›†ä¸­åŒ–æ ‡å‡†åŒ–é€»è¾‘ï¼Œç¡®ä¿è¾“å‡ºæ ¼å¼ç»Ÿä¸€
        """
        try:
            # ğŸ”§ é›†ä¸­åŒ–æ ‡å‡†åŒ–ï¼šç»Ÿä¸€æˆäº¤æ•°æ®æ ¼å¼
            standardized_data = await self._standardize_trade_data(
                raw_trade_data, exchange, market_type, symbol
            )

            # Symbolæ ‡å‡†åŒ–
            normalized_symbol = self.normalizer.normalize_symbol_format(symbol, exchange.value)

            # ç¡®ä¿æ ‡å‡†åŒ–æ•°æ®åŒ…å«ç»Ÿä¸€å­—æ®µ
            standardized_data.update({
                'normalized_symbol': normalized_symbol,
                'standardized_at': datetime.now(timezone.utc).isoformat(),
                'standardization_version': '2.0'
            })

            return await self.publish_data(
                DataType.TRADE, exchange.value, market_type.value, normalized_symbol, standardized_data
            )

        except Exception as e:
            self.logger.error(f"âŒ åŸå§‹æˆäº¤æ•°æ®å‘å¸ƒå¤±è´¥: {e}")
            return False

    async def publish_trade_data_legacy(self, exchange: str, market_type: str, symbol: str,
                               data: Dict[str, Any]) -> bool:
        """å‘å¸ƒäº¤æ˜“æ•°æ®ï¼ˆæ—§ç‰ˆåˆ«åæ–¹æ³•ï¼‰"""
        return await self.publish_trade(exchange, market_type, symbol, data)

    async def publish_ticker_data(self, exchange: str, market_type: str, symbol: str,
                                data: Dict[str, Any]) -> bool:
        """å‘å¸ƒä»·æ ¼æ•°æ®ï¼ˆåˆ«åæ–¹æ³•ï¼‰"""
        return await self.publish_data(DataType.TICKER, exchange, market_type, symbol, data)

    async def publish_funding_rate(self, exchange: str, market_type: str, symbol: str,
                                  funding_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒèµ„é‡‘è´¹ç‡æ•°æ®"""
        return await self.publish_data(
            DataType.FUNDING_RATE, exchange, market_type, symbol, funding_data
        )

    async def publish_open_interest(self, exchange: str, market_type: str, symbol: str,
                                   oi_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒæŒä»“é‡æ•°æ®"""
        return await self.publish_data(
            DataType.OPEN_INTEREST, exchange, market_type, symbol, oi_data
        )


    async def publish_liquidation(self, exchange: str, market_type: str, symbol: str,
                                 liquidation_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒå¼ºå¹³æ•°æ®"""
        return await self.publish_data(
            DataType.LIQUIDATION, exchange, market_type, symbol, liquidation_data
        )

    async def publish_top_trader_ratio(self, exchange: str, market_type: str, symbol: str,
                                      ratio_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒå¤§æˆ·æŒä»“æ¯”æ•°æ®"""
        return await self.publish_data(
            DataType.TOP_TRADER_LONG_SHORT_RATIO, exchange, market_type, symbol, ratio_data
        )

    async def publish_market_ratio(self, exchange: str, market_type: str, symbol: str,
                                  ratio_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒå¸‚åœºå¤šç©ºæ¯”æ•°æ®"""
        return await self.publish_data(
            DataType.MARKET_LONG_SHORT_RATIO, exchange, market_type, symbol, ratio_data
        )

    async def publish_volatility_index(self, exchange: str, market_type: str, symbol: str,
                                      volatility_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒæ³¢åŠ¨ç‡æŒ‡æ•°æ•°æ®"""
        return await self.publish_data(
            DataType.VOLATILITY_INDEX, exchange, market_type, symbol, volatility_data
        )

    # ğŸ”§ é‡æ„ä¼˜åŒ–ï¼šç»Ÿä¸€çš„å¢å¼ºè®¢å•ç°¿å‘å¸ƒæ–¹æ³•
    async def publish_enhanced_orderbook(self, orderbook) -> bool:
        """
        ç»Ÿä¸€çš„å¢å¼ºè®¢å•ç°¿å‘å¸ƒæ–¹æ³•

        ğŸ”§ æ¶æ„åˆ†ç¦»ï¼šåœ¨æ­¤å¤„è¿›è¡ŒSymbolæ ‡å‡†åŒ–ï¼Œä¿æŒä¸šåŠ¡é€»è¾‘ä½¿ç”¨åŸå§‹æ ¼å¼
        ğŸ”§ é‡æ„ä¼˜åŒ–ï¼šæ¶ˆé™¤é‡å¤é€»è¾‘ï¼Œæä¾›ç»Ÿä¸€çš„å‘å¸ƒæ¥å£
        """
        if not (hasattr(orderbook, 'exchange_name') and hasattr(orderbook, 'symbol_name')):
            self.logger.error("è®¢å•ç°¿å¯¹è±¡ç¼ºå°‘å¿…è¦å±æ€§",
                            has_exchange=hasattr(orderbook, 'exchange_name'),
                            has_symbol=hasattr(orderbook, 'symbol_name'))
            return False

        # ğŸ”§ åœ¨å‘å¸ƒæ—¶è¿›è¡ŒSymbolæ ‡å‡†åŒ–ï¼šBTCUSDT -> BTC-USDT, BTC-USDT-SWAP -> BTC-USDT
        normalized_symbol = self.normalizer.normalize_symbol_format(
            orderbook.symbol_name, orderbook.exchange_name
        )

        # ğŸ” è°ƒè¯•ï¼šè¾“å‡ºSymbolæ ‡å‡†åŒ–è¿‡ç¨‹
        self.logger.debug("ğŸ” Symbolæ ‡å‡†åŒ–è°ƒè¯•",
                       original_symbol=orderbook.symbol_name,
                       exchange_name=orderbook.exchange_name,
                       normalized_symbol=normalized_symbol)

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        # ç”ŸæˆISOæ ¼å¼æ—¶é—´æˆ³ï¼ˆUTCï¼‰
        iso_timestamp = (
            orderbook.timestamp.isoformat() + 'Z'
            if hasattr(orderbook, 'timestamp') and orderbook.timestamp else
            datetime.now(timezone.utc).isoformat() + 'Z'
        )
        collected_timestamp = datetime.now(timezone.utc).isoformat() + 'Z'

        orderbook_data = {
            'exchange': orderbook.exchange_name,
            'symbol': normalized_symbol,  # ä½¿ç”¨æ ‡å‡†åŒ–åçš„symbol
            'bids': [[str(bid.price), str(bid.quantity)] for bid in orderbook.bids] if hasattr(orderbook, 'bids') else [],
            'asks': [[str(ask.price), str(ask.quantity)] for ask in orderbook.asks] if hasattr(orderbook, 'asks') else [],
            'timestamp': iso_timestamp,  # ä½¿ç”¨ISOæ ¼å¼ï¼ˆäº‹ä»¶æ—¶é—´ï¼‰
            'collected_at': collected_timestamp,  # é‡‡é›†æ—¶é—´ï¼ˆISOæ ¼å¼UTCï¼‰
            'last_update_id': getattr(orderbook, 'last_update_id', None),
            'data_source': 'marketprism'
        }

        # ğŸ”§ ä»è®¢å•ç°¿å¯¹è±¡è·å–å¸‚åœºç±»å‹ï¼Œä¸è¿›è¡Œæ¨æ–­
        # ğŸš¨ ä¿®å¤ï¼šorderbookå¯¹è±¡å¯èƒ½æ²¡æœ‰market_typeå±æ€§ï¼Œéœ€è¦ä»exchange_nameæ¨æ–­
        if hasattr(orderbook, 'market_type') and orderbook.market_type:
            market_type = orderbook.market_type
        else:
            # ä»exchange_nameæ¨æ–­å¸‚åœºç±»å‹
            exchange_name = orderbook.exchange_name.lower()
            if 'derivatives' in exchange_name or 'perpetual' in exchange_name or 'swap' in exchange_name:
                market_type = 'perpetual'
            else:
                market_type = 'spot'

        # ç¡®ä¿market_typeæ˜¯å­—ç¬¦ä¸²
        if hasattr(market_type, 'value'):
            market_type = market_type.value
        market_type = str(market_type).lower()

        # ğŸ” è°ƒè¯•ï¼šè¾“å‡ºmarket_typeè·å–è¿‡ç¨‹
        self.logger.debug("ğŸ” NATSPublisher market_typeè·å–è°ƒè¯•",
                       exchange_name=orderbook.exchange_name,
                       has_market_type_attr=hasattr(orderbook, 'market_type'),
                       original_market_type=getattr(orderbook, 'market_type', 'none'),
                       inferred_market_type=market_type)

        return await self.publish_orderbook(
            orderbook.exchange_name, market_type, normalized_symbol, orderbook_data
        )

    async def _standardize_orderbook_data(self, raw_data: Dict[str, Any],
                                         exchange: str, market_type: str, symbol: str) -> Dict[str, Any]:
        """
        ğŸ”§ é›†ä¸­åŒ–è®¢å•ç°¿æ•°æ®æ ‡å‡†åŒ– + é˜²å¾¡æ€§æ·±åº¦è£å‰ª
        ç»Ÿä¸€æ‰€æœ‰äº¤æ˜“æ‰€çš„è®¢å•ç°¿æ•°æ®æ ¼å¼ï¼Œç¡®ä¿æ·±åº¦ä¸è¶…è¿‡400æ¡£
        """
        try:
            # ğŸ”§ ä¿®å¤ï¼šé˜²å¾¡æ€§æ·±åº¦è£å‰ª - è·å–åŸå§‹bids/asks
            raw_bids = raw_data.get('bids', [])
            raw_asks = raw_data.get('asks', [])

            # ğŸ”§ ä¿®å¤ï¼šå¼ºåˆ¶é™åˆ¶åˆ°400æ¡£ï¼Œé˜²æ­¢ä¸Šæ¸¸å¼‚å¸¸
            MAX_DEPTH = 400
            trimmed_bids = raw_bids[:MAX_DEPTH] if len(raw_bids) > MAX_DEPTH else raw_bids
            trimmed_asks = raw_asks[:MAX_DEPTH] if len(raw_asks) > MAX_DEPTH else raw_asks

            # è®°å½•è£å‰ªç»Ÿè®¡
            bids_trimmed = len(raw_bids) - len(trimmed_bids)
            asks_trimmed = len(raw_asks) - len(trimmed_asks)

            if bids_trimmed > 0 or asks_trimmed > 0:
                self.logger.warning("ğŸ”§ é˜²å¾¡æ€§æ·±åº¦è£å‰ªè§¦å‘",
                                  exchange=exchange,
                                  symbol=symbol,
                                  original_bids=len(raw_bids),
                                  original_asks=len(raw_asks),
                                  trimmed_bids=bids_trimmed,
                                  trimmed_asks=asks_trimmed,
                                  max_depth=MAX_DEPTH)

            # åŸºç¡€æ ‡å‡†åŒ–å­—æ®µ
            standardized = {
                'exchange': exchange,
                'market_type': market_type,
                'symbol': symbol,
                'data_type': 'orderbook',
                'timestamp': raw_data.get('timestamp', datetime.now(timezone.utc).isoformat() + 'Z'),
                'last_update_id': raw_data.get('last_update_id') or raw_data.get('lastUpdateId'),
                'bids': trimmed_bids,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨è£å‰ªåçš„æ•°æ®
                'asks': trimmed_asks,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨è£å‰ªåçš„æ•°æ®
                'depth_levels': len(trimmed_bids) + len(trimmed_asks),  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨è£å‰ªåçš„è®¡æ•°
                'update_type': raw_data.get('update_type', 'update'),
                # é‡‡é›†æ—¶é—´ï¼šISOæ ¼å¼UTC
                'collected_at': datetime.now(timezone.utc).isoformat() + 'Z',
                # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ è£å‰ªå…ƒæ•°æ®
                'depth_metadata': {
                    'max_allowed_depth': MAX_DEPTH,
                    'original_bids_count': len(raw_bids),
                    'original_asks_count': len(raw_asks),
                    'bids_trimmed': bids_trimmed,
                    'asks_trimmed': asks_trimmed,
                    'was_trimmed': bids_trimmed > 0 or asks_trimmed > 0
                }
            }

            # ä¿ç•™äº¤æ˜“æ‰€ç‰¹å®šä¿¡æ¯
            if 'exchange_specific' in raw_data:
                standardized['exchange_specific'] = raw_data['exchange_specific']

            return standardized

        except Exception as e:
            self.logger.error(f"âŒ è®¢å•ç°¿æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return raw_data

    async def _standardize_trade_data(self, raw_data: Dict[str, Any],
                                    exchange: Exchange, market_type, symbol: str) -> Dict[str, Any]:
        """
        ğŸ”§ é›†ä¸­åŒ–æˆäº¤æ•°æ®æ ‡å‡†åŒ–
        ç»Ÿä¸€æ‰€æœ‰äº¤æ˜“æ‰€çš„æˆäº¤æ•°æ®æ ¼å¼
        """
        try:
            # åŸºç¡€æ ‡å‡†åŒ–å­—æ®µ
            ts = raw_data.get('timestamp')
            standardized = {
                'exchange': exchange.value,
                'market_type': market_type.value,
                'symbol': symbol,
                'data_type': 'trade',
                'price': raw_data.get('price'),
                'quantity': raw_data.get('quantity'),
                'timestamp': ts,
                'trade_time': ts,  # è¡¥é½trade_time
                'side': raw_data.get('side'),
                'trade_id': raw_data.get('trade_id')
            }

            # ä¿ç•™äº¤æ˜“æ‰€ç‰¹å®šä¿¡æ¯
            if 'exchange_specific' in raw_data:
                standardized['exchange_specific'] = raw_data['exchange_specific']

            return standardized

        except Exception as e:
            self.logger.error(f"âŒ æˆäº¤æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return raw_data

    # ğŸ”§ é‡æ„å®Œæˆï¼šåˆ é™¤é‡å¤çš„legacyæ–¹æ³•ï¼Œç»Ÿä¸€ä½¿ç”¨publish_enhanced_orderbook

    async def publish_trade_legacy(self, trade) -> bool:
        """å…¼å®¹æ—§ç‰ˆäº¤æ˜“å‘å¸ƒæ–¹æ³•"""
        if hasattr(trade, 'exchange_name') and hasattr(trade, 'symbol_name'):
            timestamp_iso = trade.timestamp.isoformat() if hasattr(trade, 'timestamp') and trade.timestamp else None
            trade_data = {
                'exchange': trade.exchange_name,
                'symbol': trade.symbol_name,
                'price': str(getattr(trade, 'price', 0)),
                'quantity': str(getattr(trade, 'quantity', 0)),
                'side': getattr(trade, 'side', 'unknown'),
                'timestamp': timestamp_iso,
                'trade_time': timestamp_iso,  # è¡¥é½ trade_time å­—æ®µ
                'trade_id': getattr(trade, 'trade_id', None),
                'collected_at': datetime.now(timezone.utc).isoformat()
            }

            market_type = 'spot'  # é»˜è®¤ç°è´§

            return await self.publish_trade(
                trade.exchange_name, market_type, trade.symbol_name, trade_data
            )
        return False

    def _serialize_orderbook(self, orderbook) -> str:
        """
        åºåˆ—åŒ–è®¢å•ç°¿æ•°æ® - ğŸ”§ ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„åºåˆ—åŒ–æ–¹æ³•

        Args:
            orderbook: EnhancedOrderBookå¯¹è±¡

        Returns:
            JSONå­—ç¬¦ä¸²
        """
        try:
            orderbook_data = {
                'exchange_name': orderbook.exchange_name,
                'symbol_name': orderbook.symbol_name,
                'last_update_id': orderbook.last_update_id,
                'bids': [[str(bid.price), str(bid.quantity)] for bid in orderbook.bids] if hasattr(orderbook, 'bids') else [],
                'asks': [[str(ask.price), str(ask.quantity)] for ask in orderbook.asks] if hasattr(orderbook, 'asks') else [],
                'timestamp': orderbook.timestamp.isoformat() if hasattr(orderbook, 'timestamp') and orderbook.timestamp else None,
                'update_type': orderbook.update_type.value if hasattr(orderbook, 'update_type') else 'UPDATE',
                'depth_levels': getattr(orderbook, 'depth_levels', len(orderbook.bids) + len(orderbook.asks)),
                'collected_at': orderbook.collected_at.isoformat() if hasattr(orderbook, 'collected_at') and orderbook.collected_at else datetime.now(timezone.utc).isoformat()
            }

            # æ·»åŠ å¯é€‰å­—æ®µ
            if hasattr(orderbook, 'checksum') and orderbook.checksum is not None:
                orderbook_data['checksum'] = orderbook.checksum

            return json.dumps(orderbook_data, ensure_ascii=False)

        except Exception as e:
            self.logger.error(f"è®¢å•ç°¿åºåˆ—åŒ–å¤±è´¥: {e}", exc_info=True)
            return ""

    async def batch_publish(self, messages: List[Dict[str, Any]]) -> int:
        """
        æ‰¹é‡å‘å¸ƒæ¶ˆæ¯

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯åŒ…å«data_type, exchange, market_type, symbol, data

        Returns:
            æˆåŠŸå‘å¸ƒçš„æ¶ˆæ¯æ•°é‡
        """
        if not messages:
            return 0

        success_count = 0

        for message in messages:
            try:
                success = await self.publish_data(
                    message['data_type'],
                    message['exchange'],
                    message['market_type'],
                    message['symbol'],
                    message['data']
                )
                if success:
                    success_count += 1
            except Exception as e:
                self.logger.error("æ‰¹é‡å‘å¸ƒæ¶ˆæ¯å¤±è´¥", error=str(e))

        return success_count

    async def _flush_buffer(self):
        """åˆ·æ–°å‘å¸ƒç¼“å†²åŒº"""
        async with self.buffer_lock:
            if not self.publish_buffer:
                return

            messages_to_publish = self.publish_buffer.copy()
            self.publish_buffer.clear()

            success_count = await self.batch_publish(messages_to_publish)
            self.logger.debug("ç¼“å†²åŒºåˆ·æ–°å®Œæˆ",
                            total=len(messages_to_publish),
                            success=success_count)

    async def _error_handler(self, error):
        """NATSé”™è¯¯å¤„ç†å™¨"""
        self.logger.error("NATSé”™è¯¯", error=str(error))
        self.stats.connection_errors += 1

    async def _closed_handler(self):
        """NATSè¿æ¥å…³é—­å¤„ç†å™¨"""
        self._is_connected = False
        self.logger.info("NATSè¿æ¥å·²å…³é—­")

    async def _reconnected_handler(self):
        """NATSé‡è¿å¤„ç†å™¨"""
        self._is_connected = True
        self.logger.info("NATSé‡è¿æˆåŠŸ")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–å‘å¸ƒç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_published': self.stats.total_published,
            'successful_published': self.stats.successful_published,
            'failed_published': self.stats.failed_published,
            'success_rate': (
                self.stats.successful_published / max(self.stats.total_published, 1) * 100
            ),
            'last_publish_time': self.stats.last_publish_time,
            'connection_errors': self.stats.connection_errors,
            'publish_errors': self.stats.publish_errors,
            'is_connected': self.is_connected,
            'buffer_size': len(self.publish_buffer)
        }

    def get_health_status(self) -> Dict[str, Any]:
        """è·å–å¥åº·çŠ¶æ€"""
        return {
            'connected': self.is_connected,
            'servers': self.config.servers,
            'client_name': self.config.client_name,
            'jetstream_available': self.js is not None,
            'stats': self.get_stats(),
            'last_check': datetime.now(timezone.utc).isoformat()
        }
