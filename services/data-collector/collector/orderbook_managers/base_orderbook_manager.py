"""
è®¢å•ç°¿ç®¡ç†å™¨åŸºç¡€æŠ½è±¡ç±»

å®šä¹‰æ‰€æœ‰äº¤æ˜“æ‰€è®¢å•ç°¿ç®¡ç†å™¨çš„é€šç”¨æ¥å£å’ŒåŸºç¡€åŠŸèƒ½
ä¿æŒä¸åŸæœ‰æ¶æ„çš„å®Œå…¨å…¼å®¹æ€§
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
import asyncio
import time
from datetime import datetime, timezone, timedelta
from structlog import get_logger

from ..data_types import EnhancedOrderBook, OrderBookState


class BaseOrderBookManager(ABC):
    """è®¢å•ç°¿ç®¡ç†å™¨åŸºç¡€æŠ½è±¡ç±»"""

    def __init__(self, exchange: str, market_type: str, symbols: List[str],
                 normalizer, nats_publisher, config: dict):
        """
        åˆå§‹åŒ–è®¢å•ç°¿ç®¡ç†å™¨

        Args:
            exchange: äº¤æ˜“æ‰€åç§° (å¦‚ 'binance_spot', 'okx_derivatives')
            market_type: å¸‚åœºç±»å‹ ('spot'/'perpetual')
            symbols: äº¤æ˜“å¯¹åˆ—è¡¨
            normalizer: æ•°æ®æ ‡å‡†åŒ–å™¨
            nats_publisher: NATSå‘å¸ƒå™¨
            config: é…ç½®ä¿¡æ¯
        """
        self.exchange = exchange
        self.market_type = market_type
        self.symbols = symbols
        self.normalizer = normalizer
        self.nats_publisher = nats_publisher
        self.config = config
        self.logger = get_logger(f"{exchange}_{market_type}_orderbook")

        # è®¢å•ç°¿çŠ¶æ€å­˜å‚¨ - ä¿æŒä¸åŸæœ‰æ¶æ„ä¸€è‡´
        self.orderbook_states: Dict[str, OrderBookState] = {}

        # æ¶ˆæ¯å¤„ç†é˜Ÿåˆ— - ä¿æŒä¸²è¡Œå¤„ç†æœºåˆ¶
        self.message_queues: Dict[str, asyncio.Queue] = {}
        self.processing_locks: Dict[str, asyncio.Lock] = {}
        self.processing_tasks: Dict[str, asyncio.Task] = {}

        # è¿è¡ŒçŠ¶æ€
        self._is_running = False
        self.message_processors_running = False
        self.memory_management_task = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'messages_processed': 0,
            'snapshots_applied': 0,
            'updates_applied': 0,
            'errors': 0,
            'last_update_time': None,
            'resync_count': 0,
            'reconnection_count': 0,
            'reconnection_failures': 0,
            'last_reconnection_time': None,
            'connection_health_checks': 0
        }

        # ç»Ÿä¸€çš„é‡è¿é…ç½® - åŸºäºå®˜æ–¹æ–‡æ¡£æœ€ä½³å®è·µ
        self.reconnect_config = {
            'enabled': True,
            'max_attempts': -1,  # -1è¡¨ç¤ºæ— é™é‡è¿
            'initial_delay': 1.0,  # åˆå§‹å»¶è¿Ÿ1ç§’
            'max_delay': 30.0,  # æœ€å¤§å»¶è¿Ÿ30ç§’
            'backoff_multiplier': 2.0,  # æŒ‡æ•°é€€é¿å€æ•°
            'connection_timeout': 10.0,  # è¿æ¥è¶…æ—¶10ç§’
            'health_check_interval': 30.0,  # å¥åº·æ£€æŸ¥é—´éš”30ç§’
            'heartbeat_timeout': 60.0  # å¿ƒè·³è¶…æ—¶60ç§’
        }

        # é‡è¿çŠ¶æ€ç®¡ç†
        self.reconnect_attempts = 0
        self.is_reconnecting = False
        self.last_successful_connection = None
        self.connection_start_time = datetime.now(timezone.utc)

        # å†…å­˜ç®¡ç†é…ç½®
        self.memory_config = {
            'enabled': True,
            'max_orderbook_states': 1000,  # æœ€å¤§è®¢å•ç°¿çŠ¶æ€æ•°é‡
            'cleanup_interval': 300.0,  # æ¸…ç†é—´éš”5åˆ†é’Ÿ
            'inactive_threshold': 3600.0,  # éæ´»è·ƒé˜ˆå€¼1å°æ—¶
            'memory_check_interval': 60.0,  # å†…å­˜æ£€æŸ¥é—´éš”1åˆ†é’Ÿ
            'max_memory_mb': 512,  # æœ€å¤§å†…å­˜ä½¿ç”¨512MB
            'memory_warning_threshold': 0.8  # å†…å­˜è­¦å‘Šé˜ˆå€¼80%
        }

        # å†…å­˜ç®¡ç†çŠ¶æ€
        self.last_memory_cleanup = datetime.now(timezone.utc)
        self.last_memory_check = datetime.now(timezone.utc)
        self.memory_cleanup_count = 0
        self.memory_warnings = 0

        # é”™è¯¯æ¢å¤é…ç½®
        self.error_recovery_config = {
            'enabled': True,
            'max_consecutive_errors': 5,  # æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°
            'error_reset_interval': 300.0,  # é”™è¯¯é‡ç½®é—´éš”5åˆ†é’Ÿ
            'checksum_failure_threshold': 3,  # checksumå¤±è´¥é˜ˆå€¼
            'sequence_error_threshold': 3,  # åºåˆ—é”™è¯¯é˜ˆå€¼
            'auto_resync_enabled': True,  # è‡ªåŠ¨é‡æ–°åŒæ­¥
            'resync_delay': 5.0,  # é‡æ–°åŒæ­¥å»¶è¿Ÿ5ç§’
            'max_resync_attempts': 3  # æœ€å¤§é‡æ–°åŒæ­¥å°è¯•æ¬¡æ•°
        }

        # é”™è¯¯æ¢å¤çŠ¶æ€
        self.consecutive_errors = 0
        self.last_error_time = None
        self.checksum_failures = 0
        self.sequence_errors = 0
        self.resync_attempts = 0
        self.last_resync_time = None

        # æ€§èƒ½ç›‘æ§é…ç½®ï¼ˆåŸºäºAPIæµ‹è¯•ä¼˜åŒ–ï¼‰
        self.performance_config = {
            'enabled': True,
            'monitoring_interval': 60.0,  # ç›‘æ§é—´éš”1åˆ†é’Ÿ
            'latency_warning_threshold': 200.0,  # å»¶è¿Ÿè­¦å‘Šé˜ˆå€¼200msï¼ˆåŸºäºAPIæµ‹è¯•ä¼˜åŒ–ï¼‰
            'throughput_warning_threshold': 10.0,  # ååé‡è­¦å‘Šé˜ˆå€¼10msg/s
            'cpu_warning_threshold': 80.0,  # CPUè­¦å‘Šé˜ˆå€¼80%
            'detailed_stats_interval': 300.0,  # è¯¦ç»†ç»Ÿè®¡é—´éš”5åˆ†é’Ÿ
            'performance_history_size': 100  # æ€§èƒ½å†å²è®°å½•å¤§å°
        }

        # æ€§èƒ½ç›‘æ§çŠ¶æ€
        self.last_performance_check = datetime.now(timezone.utc)
        self.last_detailed_stats = datetime.now(timezone.utc)
        self.performance_warnings = 0
        self.message_timestamps = []  # æ¶ˆæ¯æ—¶é—´æˆ³é˜Ÿåˆ—
        self.processing_times = []  # å¤„ç†æ—¶é—´é˜Ÿåˆ—
        self.performance_history = []  # æ€§èƒ½å†å²è®°å½•

        # æ—¥å¿—è®°å½•é…ç½®
        self.logging_config = {
            'enabled': True,
            'log_level': 'INFO',  # DEBUG, INFO, WARNING, ERROR
            'structured_logging': True,  # ç»“æ„åŒ–æ—¥å¿—
            'log_performance': True,  # è®°å½•æ€§èƒ½æ—¥å¿—
            'log_errors': True,  # è®°å½•é”™è¯¯æ—¥å¿—
            'log_connections': True,  # è®°å½•è¿æ¥æ—¥å¿—
            'log_data_flow': False,  # è®°å½•æ•°æ®æµæ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
            'context_fields': ['exchange', 'market_type', 'symbol'],  # ä¸Šä¸‹æ–‡å­—æ®µ
            'sensitive_fields': ['api_key', 'api_secret', 'passphrase']  # æ•æ„Ÿå­—æ®µ
        }

        # æ—¥å¿—è®°å½•çŠ¶æ€
        self.log_context = {
            'exchange': self.exchange,
            'market_type': self.market_type,
            'manager_id': f"{self.exchange}_{self.market_type}_{id(self)}"
        }

        # æ·±åº¦é…ç½®
        self.snapshot_depth = self._get_snapshot_depth()
        self.websocket_depth = self._get_websocket_depth()
        self.nats_publish_depth = 400  # ç»Ÿä¸€å‘å¸ƒ400æ¡£

        self.logger.info(f"ğŸ—ï¸ {self.__class__.__name__}åˆå§‹åŒ–å®Œæˆ",
                        exchange=exchange, market_type=market_type, symbols=symbols,
                        snapshot_depth=self.snapshot_depth, websocket_depth=self.websocket_depth)

    @abstractmethod
    def _get_snapshot_depth(self) -> int:
        """è·å–å¿«ç…§æ·±åº¦é…ç½®"""
        pass

    @abstractmethod
    def _get_websocket_depth(self) -> int:
        """è·å–WebSocketæ·±åº¦é…ç½®"""
        pass

    @abstractmethod
    async def initialize_orderbook_states(self):
        """åˆå§‹åŒ–è®¢å•ç°¿çŠ¶æ€"""
        pass

    @abstractmethod
    async def process_websocket_message(self, symbol: str, message: dict):
        """å¤„ç†WebSocketæ¶ˆæ¯ - äº¤æ˜“æ‰€ç‰¹å®šå®ç°"""
        pass

    @abstractmethod
    async def _apply_snapshot(self, symbol: str, snapshot_data: dict, state: OrderBookState):
        """åº”ç”¨å¿«ç…§æ•°æ® - äº¤æ˜“æ‰€ç‰¹å®šå®ç°"""
        pass

    @abstractmethod
    async def _apply_update(self, symbol: str, update_data: dict, state: OrderBookState):
        """åº”ç”¨å¢é‡æ›´æ–° - äº¤æ˜“æ‰€ç‰¹å®šå®ç°"""
        pass

    @abstractmethod
    def _validate_message_sequence(self, symbol: str, message: dict, state: OrderBookState) -> tuple[bool, str]:
        """éªŒè¯æ¶ˆæ¯åºåˆ— - äº¤æ˜“æ‰€ç‰¹å®šå®ç°"""
        pass

    @abstractmethod
    async def _fetch_initial_snapshot(self, symbol: str) -> Optional[EnhancedOrderBook]:
        """è·å–åˆå§‹å¿«ç…§ - äº¤æ˜“æ‰€ç‰¹å®šå®ç°"""
        pass

    def _get_unique_key(self, symbol: str) -> str:
        """ç”Ÿæˆå”¯ä¸€é”® - ä¿æŒä¸åŸæœ‰æ¶æ„ä¸€è‡´"""
        return f"{self.exchange}_{self.market_type}_{symbol}"

    async def start(self):
        """å¯åŠ¨è®¢å•ç°¿ç®¡ç†å™¨"""
        self.logger.info(f"ğŸ” DEBUG: start()æ–¹æ³•è¢«è°ƒç”¨ - {self.__class__.__name__}")

        if self._is_running:
            self.logger.warning("ç®¡ç†å™¨å·²åœ¨è¿è¡Œä¸­")
            return

        self.log_info(f"ğŸš€ å¯åŠ¨{self.__class__.__name__}",
                     symbols=self.symbols,
                     snapshot_depth=self.snapshot_depth,
                     websocket_depth=self.websocket_depth)

        try:
            # 1. åˆå§‹åŒ–è®¢å•ç°¿çŠ¶æ€
            self.logger.info("ğŸ“‹ æ­¥éª¤1ï¼šåˆå§‹åŒ–è®¢å•ç°¿çŠ¶æ€")
            await self.initialize_orderbook_states()
            self.logger.info("âœ… è®¢å•ç°¿çŠ¶æ€åˆå§‹åŒ–å®Œæˆ")

            # 2. å¯åŠ¨ä¸²è¡Œæ¶ˆæ¯å¤„ç†å™¨
            self.logger.info("ğŸ“‹ æ­¥éª¤2ï¼šå¯åŠ¨ä¸²è¡Œæ¶ˆæ¯å¤„ç†å™¨")
            await self._start_message_processors(self.symbols)
            self.logger.info("âœ… ä¸²è¡Œæ¶ˆæ¯å¤„ç†å™¨å¯åŠ¨å®Œæˆ")

            # 3. å¯åŠ¨å†…å­˜ç®¡ç†ä»»åŠ¡
            self.logger.info("ğŸ“‹ æ­¥éª¤3ï¼šå¯åŠ¨å†…å­˜ç®¡ç†ä»»åŠ¡")
            if self.memory_config['enabled']:
                self.memory_management_task = asyncio.create_task(self._memory_management_loop())
                self.logger.info("ğŸ§¹ å†…å­˜ç®¡ç†ä»»åŠ¡å·²å¯åŠ¨")
            else:
                self.logger.info("â­ï¸ å†…å­˜ç®¡ç†ä»»åŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡")

            # 4. äº¤æ˜“æ‰€ç‰¹å®šçš„åˆå§‹åŒ–
            self.logger.info("ğŸ“‹ æ­¥éª¤4ï¼šå¼€å§‹äº¤æ˜“æ‰€ç‰¹å®šåˆå§‹åŒ–")
            await self._exchange_specific_initialization()
            self.logger.info("âœ… äº¤æ˜“æ‰€ç‰¹å®šåˆå§‹åŒ–å®Œæˆ")

            self._is_running = True
            self.log_info(f"âœ… {self.__class__.__name__}å¯åŠ¨å®Œæˆ",
                         startup_time=f"{(datetime.now(timezone.utc) - self.connection_start_time).total_seconds():.2f}s")

        except Exception as e:
            self.log_error(f"âŒ å¯åŠ¨å¤±è´¥", exception=e)
            await self.stop()
            raise

    async def stop(self):
        """åœæ­¢è®¢å•ç°¿ç®¡ç†å™¨"""
        if not self._is_running:
            return

        self.logger.info(f"ğŸ›‘ åœæ­¢{self.__class__.__name__}")

        # åœæ­¢æ¶ˆæ¯å¤„ç†å™¨
        await self._stop_message_processors()

        # åœæ­¢å†…å­˜ç®¡ç†ä»»åŠ¡
        if hasattr(self, 'memory_management_task') and self.memory_management_task:
            self.memory_management_task.cancel()
            try:
                await self.memory_management_task
            except asyncio.CancelledError:
                pass
            self.logger.info("ğŸ§¹ å†…å­˜ç®¡ç†ä»»åŠ¡å·²åœæ­¢")

        # äº¤æ˜“æ‰€ç‰¹å®šçš„æ¸…ç†
        await self._exchange_specific_cleanup()

        self._is_running = False
        self.log_info(f"âœ… {self.__class__.__name__}å·²åœæ­¢",
                     uptime_seconds=int((datetime.now(timezone.utc) - self.connection_start_time).total_seconds()),
                     total_messages=self.stats.get('messages_processed', 0),
                     total_errors=self.stats.get('errors', 0))

    async def _start_message_processors(self, symbols: List[str] = None):
        """å¯åŠ¨ä¸²è¡Œæ¶ˆæ¯å¤„ç†å™¨ - ä¿æŒåŸæœ‰æœºåˆ¶"""
        if self.message_processors_running:
            return

        self.message_processors_running = True

        # ä½¿ç”¨ä¼ å…¥çš„symbolsæˆ–é»˜è®¤ä½¿ç”¨self.symbols
        symbols_to_use = symbols if symbols is not None else self.symbols

        for symbol in symbols_to_use:
            # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—å’Œé”
            self.message_queues[symbol] = asyncio.Queue()
            self.processing_locks[symbol] = asyncio.Lock()

            # å¯åŠ¨ä¸²è¡Œå¤„ç†ä»»åŠ¡
            task = asyncio.create_task(self._process_messages_serially(symbol))
            self.processing_tasks[symbol] = task

        self.logger.info(f"ğŸ”§ å·²å¯åŠ¨{len(self.symbols)}ä¸ªä¸²è¡Œæ¶ˆæ¯å¤„ç†å™¨")

    async def _stop_message_processors(self):
        """åœæ­¢æ¶ˆæ¯å¤„ç†å™¨"""
        self.message_processors_running = False

        # å‘é€åœæ­¢ä¿¡å·
        for symbol in self.symbols:
            if symbol in self.message_queues:
                await self.message_queues[symbol].put(None)

        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        for symbol, task in self.processing_tasks.items():
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass

        self.processing_tasks.clear()
        self.message_queues.clear()
        self.processing_locks.clear()

    async def _process_messages_serially(self, symbol: str):
        """ä¸²è¡Œå¤„ç†å•ä¸ªäº¤æ˜“å¯¹çš„æ¶ˆæ¯ - ä¿æŒåŸæœ‰æœºåˆ¶"""
        queue = self.message_queues[symbol]
        lock = self.processing_locks[symbol]

        self.logger.debug(f"ğŸ”§ å¯åŠ¨{symbol}çš„ä¸²è¡Œæ¶ˆæ¯å¤„ç†å™¨")

        try:
            while True:
                # ä»é˜Ÿåˆ—ä¸­è·å–æ¶ˆæ¯
                message_data = await queue.get()

                # æ£€æŸ¥åœæ­¢ä¿¡å·
                if message_data is None:
                    break

                # ä¸²è¡Œå¤„ç†æ¶ˆæ¯ï¼ˆä½¿ç”¨é”ç¡®ä¿åŸå­æ€§ï¼‰
                async with lock:
                    start_time = time.time()
                    try:
                        await self._process_single_message(symbol, message_data)

                        # è®°å½•å¤„ç†æ€§èƒ½
                        if self.performance_config['enabled']:
                            processing_time = time.time() - start_time
                            message_size = len(str(message_data)) if message_data else 0
                            await self._record_message_processing(symbol, processing_time, message_size)

                    except Exception as e:
                        self.logger.error(f"âŒ å¤„ç†{symbol}æ¶ˆæ¯å¤±è´¥: {e}")
                        self.stats['errors'] += 1
                    finally:
                        queue.task_done()

        except asyncio.CancelledError:
            self.logger.info(f"ğŸ”§ {symbol}ä¸²è¡Œå¤„ç†å™¨å·²å–æ¶ˆ")
        except Exception as e:
            self.logger.error(f"âŒ {symbol}ä¸²è¡Œå¤„ç†å™¨å¼‚å¸¸: {e}")

    async def _process_single_message(self, symbol: str, message_data: dict):
        """å¤„ç†å•æ¡æ¶ˆæ¯ - è°ƒç”¨äº¤æ˜“æ‰€ç‰¹å®šå®ç°"""
        update = message_data['update']
        await self.process_websocket_message(symbol, update)

        # æ›´æ–°ç»Ÿè®¡
        self.stats['messages_processed'] += 1
        self.stats['last_update_time'] = time.time()

    async def handle_websocket_message(self, symbol: str, message: dict):
        """å¤„ç†WebSocketæ¶ˆæ¯çš„å…¥å£ç‚¹ - ä¿æŒåŸæœ‰æ¥å£"""
        try:
            # å°†æ¶ˆæ¯æ”¾å…¥å¯¹åº”çš„å¤„ç†é˜Ÿåˆ—
            if symbol in self.message_queues:
                await self.message_queues[symbol].put({
                    'timestamp': time.time(),
                    'symbol': symbol,
                    'update': message
                })
            else:
                self.logger.warning(f"âš ï¸ æœªçŸ¥äº¤æ˜“å¯¹: {symbol}")
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†WebSocketæ¶ˆæ¯å¤±è´¥: {symbol}, error={e}")
            self.stats['errors'] += 1

    async def publish_orderbook(self, symbol: str, orderbook: EnhancedOrderBook):
        """
        å‘å¸ƒè®¢å•ç°¿æ•°æ®åˆ°NATS - ä¼˜åŒ–ï¼šå»¶è¿Ÿæ ‡å‡†åŒ–åˆ°NATSå±‚

        ğŸ”§ æ¶æ„ä¼˜åŒ–ï¼šç§»é™¤ä¸­é—´æ ‡å‡†åŒ–ï¼Œä¿æŒåŸå§‹æ•°æ®åˆ°æœ€åå‘å¸ƒæ—¶åˆ»
        è¿™æ ·ç¡®ä¿æ‰€æœ‰éªŒè¯å’Œè®¡ç®—éƒ½ä½¿ç”¨åŸå§‹äº¤æ˜“æ‰€æ ¼å¼
        """
        try:
            # ğŸ”§ ä¼˜åŒ–ï¼šç›´æ¥æ„å»ºåŸå§‹æ ¼å¼æ•°æ®ï¼Œä¸è¿›è¡Œæ ‡å‡†åŒ–
            # æ ‡å‡†åŒ–å°†åœ¨NATS Publisherå±‚ç»Ÿä¸€è¿›è¡Œ
            raw_orderbook_data = {
                'exchange': self.exchange,
                'market_type': self.market_type,
                'symbol': symbol,  # ä¿æŒåŸå§‹symbolæ ¼å¼
                'last_update_id': orderbook.last_update_id,
                'bids': [[str(level.price), str(level.quantity)] for level in orderbook.bids[:400]],
                'asks': [[str(level.price), str(level.quantity)] for level in orderbook.asks[:400]],
                'timestamp': orderbook.timestamp.isoformat(),
                'update_type': orderbook.update_type.value if hasattr(orderbook.update_type, 'value') else str(orderbook.update_type),
                'depth_levels': min(len(orderbook.bids) + len(orderbook.asks), 800),
                'raw_data': True  # æ ‡è®°ä¸ºåŸå§‹æ•°æ®
            }

            # ğŸ”§ ä¼˜åŒ–ï¼šå‘å¸ƒåŸå§‹æ•°æ®ï¼Œæ ‡å‡†åŒ–åœ¨NATS Publisherä¸­è¿›è¡Œ
            await self.nats_publisher.publish_orderbook(
                self.exchange,
                self.market_type,
                symbol,  # ä½¿ç”¨åŸå§‹symbol
                raw_orderbook_data
            )

        except Exception as e:
            self.logger.error(f"âŒ å‘å¸ƒè®¢å•ç°¿å¤±è´¥: {symbol}, error={e}")

    @abstractmethod
    async def _exchange_specific_initialization(self):
        """äº¤æ˜“æ‰€ç‰¹å®šçš„åˆå§‹åŒ–é€»è¾‘"""
        pass

    @abstractmethod
    async def _exchange_specific_cleanup(self):
        """äº¤æ˜“æ‰€ç‰¹å®šçš„æ¸…ç†é€»è¾‘"""
        pass

    def _calculate_okx_checksum(self, orderbook: dict) -> str:
        """
        ç»Ÿä¸€çš„OKX checksumè®¡ç®—æ–¹æ³•

        æ ¹æ®OKXå®˜æ–¹æ–‡æ¡£è§„èŒƒï¼š
        1. å–å‰25æ¡£ä¹°å–å•
        2. æŒ‰bid:askäº¤æ›¿æ’åˆ—ï¼šbid[ä»·æ ¼:æ•°é‡]:ask[ä»·æ ¼:æ•°é‡]:bid[ä»·æ ¼:æ•°é‡]:ask[ä»·æ ¼:æ•°é‡]...
        3. bidæˆ–askä¸è¶³25æ¡£æ—¶ï¼Œç›´æ¥å¿½ç•¥ç¼ºå¤±çš„æ·±åº¦
        4. ä½¿ç”¨CRC32è®¡ç®—æ ¡éªŒå’Œï¼ˆ32ä½æœ‰ç¬¦å·æ•´å‹ï¼‰

        Args:
            orderbook: è®¢å•ç°¿æ•°æ® {'bids': {price: quantity}, 'asks': {price: quantity}}

        Returns:
            str: CRC32æ ¡éªŒå’Œå­—ç¬¦ä¸²
        """
        try:
            # è·å–å‰25æ¡£ä¹°å–å•å¹¶æ’åº
            bids = sorted(orderbook.get('bids', {}).items(), key=lambda x: x[0], reverse=True)[:25]
            asks = sorted(orderbook.get('asks', {}).items(), key=lambda x: x[0])[:25]

            # æ„å»ºæ ¡éªŒå­—ç¬¦ä¸² - ä¸¥æ ¼æŒ‰ç…§OKXå®˜æ–¹æ–‡æ¡£çš„äº¤æ›¿æ’åˆ—
            checksum_parts = []
            min_len = min(len(bids), len(asks))

            # å…ˆå¤„ç†ç›¸åŒé•¿åº¦çš„éƒ¨åˆ†ï¼ˆäº¤æ›¿æ’åˆ—ï¼‰
            for i in range(min_len):
                bid_price, bid_quantity = bids[i]
                ask_price, ask_quantity = asks[i]

                # ğŸ¯ å…³é”®ï¼šä½¿ç”¨æ­£ç¡®çš„æ•°æ®æ ¼å¼åŒ–ï¼ˆç§»é™¤å°¾éšé›¶ï¼‰
                bid_price_str = self._format_price_for_checksum(bid_price)
                bid_quantity_str = self._format_quantity_for_checksum(bid_quantity)
                ask_price_str = self._format_price_for_checksum(ask_price)
                ask_quantity_str = self._format_quantity_for_checksum(ask_quantity)

                checksum_parts.extend([bid_price_str, bid_quantity_str, ask_price_str, ask_quantity_str])

            # å¤„ç†å‰©ä½™çš„éƒ¨åˆ†ï¼ˆå¦‚æœbidæˆ–askæœ‰å‰©ä½™ï¼‰
            if len(bids) > min_len:
                # å‰©ä½™çš„bids
                for i in range(min_len, len(bids)):
                    bid_price, bid_quantity = bids[i]
                    bid_price_str = self._format_price_for_checksum(bid_price)
                    bid_quantity_str = self._format_quantity_for_checksum(bid_quantity)
                    checksum_parts.extend([bid_price_str, bid_quantity_str])
            elif len(asks) > min_len:
                # å‰©ä½™çš„asks
                for i in range(min_len, len(asks)):
                    ask_price, ask_quantity = asks[i]
                    ask_price_str = self._format_price_for_checksum(ask_price)
                    ask_quantity_str = self._format_quantity_for_checksum(ask_quantity)
                    checksum_parts.extend([ask_price_str, ask_quantity_str])

            # æ‹¼æ¥ä¸ºå®Œæ•´å­—ç¬¦ä¸²
            checksum_str = ':'.join(checksum_parts)

            # è®¡ç®—CRC32æ ¡éªŒå’Œï¼ˆ32ä½æœ‰ç¬¦å·æ•´å‹ï¼‰
            import zlib
            crc32_value = zlib.crc32(checksum_str.encode('utf-8'))
            # è½¬æ¢ä¸º32ä½æœ‰ç¬¦å·æ•´å‹
            if crc32_value >= 2**31:
                crc32_value -= 2**32

            return str(crc32_value)

        except Exception as e:
            self.logger.error(f"âŒ è®¡ç®—OKX checksumå¤±è´¥: {e}")
            return ""

    def _format_price_for_checksum(self, price) -> str:
        """
        æ ¼å¼åŒ–ä»·æ ¼ç”¨äºchecksumè®¡ç®—
        ğŸ”§ ä¿®å¤ï¼šä¿æŒåŸå§‹å­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…ç§‘å­¦è®¡æ•°æ³•
        """
        try:
            # ç›´æ¥ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²ï¼Œé¿å…Decimalçš„normalize()å¯¼è‡´ç§‘å­¦è®¡æ•°æ³•
            if isinstance(price, str):
                return price
            else:
                return str(price)

        except Exception:
            return str(price)

    def _format_quantity_for_checksum(self, quantity) -> str:
        """
        æ ¼å¼åŒ–æ•°é‡ç”¨äºchecksumè®¡ç®—
        ğŸ”§ ä¿®å¤ï¼šä¿æŒåŸå§‹å­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…ç§‘å­¦è®¡æ•°æ³•
        """
        try:
            # ç›´æ¥ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²ï¼Œé¿å…Decimalçš„normalize()å¯¼è‡´ç§‘å­¦è®¡æ•°æ³•
            if isinstance(quantity, str):
                return quantity
            else:
                return str(quantity)

        except Exception:
            return str(quantity)

    async def _calculate_reconnect_delay(self) -> float:
        """
        è®¡ç®—é‡è¿å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ç®—æ³•ï¼‰

        Returns:
            float: å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        """
        if not self.reconnect_config['enabled']:
            return 0

        delay = min(
            self.reconnect_config['initial_delay'] * (
                self.reconnect_config['backoff_multiplier'] ** self.reconnect_attempts
            ),
            self.reconnect_config['max_delay']
        )

        return delay

    async def _should_attempt_reconnect(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å°è¯•é‡è¿

        Returns:
            bool: æ˜¯å¦åº”è¯¥é‡è¿
        """
        if not self.reconnect_config['enabled']:
            return False

        max_attempts = self.reconnect_config['max_attempts']
        if max_attempts > 0 and self.reconnect_attempts >= max_attempts:
            self.logger.error(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•°é™åˆ¶: {max_attempts}")
            return False

        return True

    async def _on_connection_lost(self, reason: str = "Unknown"):
        """
        è¿æ¥ä¸¢å¤±å¤„ç†

        Args:
            reason: è¿æ¥ä¸¢å¤±åŸå› 
        """
        self.log_connection(f"ğŸ”— è¿æ¥ä¸¢å¤±: {reason}",
                           reconnection_failures=self.stats['reconnection_failures'] + 1)
        self.stats['reconnection_failures'] += 1

        if await self._should_attempt_reconnect():
            await self._attempt_reconnection(reason)

    async def _attempt_reconnection(self, reason: str):
        """
        å°è¯•é‡è¿

        Args:
            reason: é‡è¿åŸå› 
        """
        if self.is_reconnecting:
            self.logger.debug("ğŸ”„ é‡è¿å·²åœ¨è¿›è¡Œä¸­ï¼Œè·³è¿‡")
            return

        self.is_reconnecting = True
        self.reconnect_attempts += 1

        try:
            delay = await self._calculate_reconnect_delay()

            self.logger.info(f"ğŸ”„ å‡†å¤‡é‡è¿ (ç¬¬{self.reconnect_attempts}æ¬¡)",
                           reason=reason, delay=f"{delay:.1f}s")

            if delay > 0:
                await asyncio.sleep(delay)

            # è°ƒç”¨å­ç±»å®ç°çš„é‡è¿é€»è¾‘
            success = await self._perform_reconnection()

            if success:
                self.log_connection(f"âœ… é‡è¿æˆåŠŸ (ç¬¬{self.reconnect_attempts}æ¬¡)",
                                  reconnection_count=self.stats['reconnection_count'] + 1,
                                  total_attempts=self.reconnect_attempts)
                self.stats['reconnection_count'] += 1
                self.stats['last_reconnection_time'] = datetime.now(timezone.utc)
                self.reconnect_attempts = 0  # é‡ç½®é‡è¿è®¡æ•°
                self.last_successful_connection = datetime.now(timezone.utc)

                # é‡è¿æˆåŠŸåæ¢å¤è®¢å•ç°¿çŠ¶æ€
                await self._restore_orderbook_states()
            else:
                self.log_error(f"âŒ é‡è¿å¤±è´¥ (ç¬¬{self.reconnect_attempts}æ¬¡)",
                             attempt=self.reconnect_attempts)

        except Exception as e:
            self.logger.error(f"âŒ é‡è¿è¿‡ç¨‹å¼‚å¸¸: {e}")
        finally:
            self.is_reconnecting = False

    @abstractmethod
    async def _perform_reconnection(self) -> bool:
        """
        æ‰§è¡Œé‡è¿æ“ä½œ - å­ç±»å®ç°

        Returns:
            bool: é‡è¿æ˜¯å¦æˆåŠŸ
        """
        pass

    async def _restore_orderbook_states(self):
        """
        é‡è¿åæ¢å¤è®¢å•ç°¿çŠ¶æ€
        """
        try:
            self.logger.info("ğŸ”„ é‡è¿åæ¢å¤è®¢å•ç°¿çŠ¶æ€")

            # æ¸…ç†æ‰€æœ‰è®¢å•ç°¿çŠ¶æ€ï¼Œå¼ºåˆ¶é‡æ–°åŒæ­¥
            for symbol, state in self.orderbook_states.items():
                state.is_synced = False
                state.local_orderbook = None
                self.logger.debug(f"ğŸ”„ é‡ç½®{symbol}è®¢å•ç°¿çŠ¶æ€")

            # é‡æ–°åˆå§‹åŒ–è®¢å•ç°¿çŠ¶æ€
            await self.initialize_orderbook_states()

            self.logger.info("âœ… è®¢å•ç°¿çŠ¶æ€æ¢å¤å®Œæˆ")

        except Exception as e:
            self.logger.error(f"âŒ æ¢å¤è®¢å•ç°¿çŠ¶æ€å¤±è´¥: {e}")

    async def _check_connection_health(self) -> bool:
        """
        æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€ - å­ç±»å¯é‡å†™

        Returns:
            bool: è¿æ¥æ˜¯å¦å¥åº·
        """
        self.stats['connection_health_checks'] += 1

        # åŸºç¡€å¥åº·æ£€æŸ¥ï¼šæ£€æŸ¥æœ€åæ›´æ–°æ—¶é—´
        if self.stats['last_update_time']:
            time_since_last_update = datetime.now(timezone.utc) - self.stats['last_update_time']
            if time_since_last_update.total_seconds() > self.reconnect_config['heartbeat_timeout']:
                self.logger.warning(f"âš ï¸ è¿æ¥å¯èƒ½ä¸å¥åº·: {time_since_last_update.total_seconds():.1f}sæ— æ•°æ®æ›´æ–°")
                return False

        return True

    async def _get_memory_usage(self) -> dict:
        """
        è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ

        Returns:
            dict: å†…å­˜ä½¿ç”¨ç»Ÿè®¡
        """
        try:
            import psutil
            import sys

            # è·å–è¿›ç¨‹å†…å­˜ä¿¡æ¯
            process = psutil.Process()
            memory_info = process.memory_info()

            # è®¡ç®—å†…å­˜ä½¿ç”¨
            memory_mb = memory_info.rss / 1024 / 1024
            memory_percent = process.memory_percent()

            # ç»Ÿè®¡è®¢å•ç°¿çŠ¶æ€æ•°é‡
            orderbook_count = len(self.orderbook_states)

            # ä¼°ç®—è®¢å•ç°¿å†…å­˜ä½¿ç”¨
            orderbook_memory_estimate = 0
            for state in self.orderbook_states.values():
                if state.local_orderbook:
                    # ç²—ç•¥ä¼°ç®—ï¼šæ¯ä¸ªä»·ä½çº¦100å­—èŠ‚
                    if hasattr(state.local_orderbook, 'bids') and hasattr(state.local_orderbook, 'asks'):
                        orderbook_memory_estimate += (len(state.local_orderbook.bids) + len(state.local_orderbook.asks)) * 100

            orderbook_memory_mb = orderbook_memory_estimate / 1024 / 1024

            return {
                'total_memory_mb': memory_mb,
                'memory_percent': memory_percent,
                'orderbook_count': orderbook_count,
                'orderbook_memory_mb': orderbook_memory_mb,
                'max_memory_mb': self.memory_config['max_memory_mb'],
                'memory_usage_ratio': memory_mb / self.memory_config['max_memory_mb']
            }

        except ImportError:
            self.logger.warning("âš ï¸ psutilæœªå®‰è£…ï¼Œæ— æ³•è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ")
            return {
                'total_memory_mb': 0,
                'memory_percent': 0,
                'orderbook_count': len(self.orderbook_states),
                'orderbook_memory_mb': 0,
                'max_memory_mb': self.memory_config['max_memory_mb'],
                'memory_usage_ratio': 0
            }
        except Exception as e:
            self.logger.error(f"âŒ è·å–å†…å­˜ä½¿ç”¨æƒ…å†µå¤±è´¥: {e}")
            return {}

    async def _check_memory_usage(self):
        """
        æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µå¹¶å‘å‡ºè­¦å‘Š
        """
        try:
            current_time = datetime.now(timezone.utc)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œå†…å­˜æ£€æŸ¥
            if (current_time - self.last_memory_check).total_seconds() < self.memory_config['memory_check_interval']:
                return

            self.last_memory_check = current_time

            # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory_stats = await self._get_memory_usage()
            if not memory_stats:
                return

            # æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦è¶…è¿‡è­¦å‘Šé˜ˆå€¼
            usage_ratio = memory_stats.get('memory_usage_ratio', 0)
            warning_threshold = self.memory_config['memory_warning_threshold']

            if usage_ratio > warning_threshold:
                self.memory_warnings += 1
                self.logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜",
                                  memory_mb=f"{memory_stats['total_memory_mb']:.1f}MB",
                                  usage_ratio=f"{usage_ratio:.1%}",
                                  orderbook_count=memory_stats['orderbook_count'],
                                  warning_count=self.memory_warnings)

                # å¦‚æœå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œè§¦å‘æ¸…ç†
                if usage_ratio > 0.9:  # 90%ä»¥ä¸Šå¼ºåˆ¶æ¸…ç†
                    self.logger.warning("ğŸ§¹ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå¼ºåˆ¶æ‰§è¡Œæ¸…ç†")
                    await self._cleanup_memory()

            # å®šæœŸè®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ
            if self.memory_warnings == 0 and memory_stats['orderbook_count'] > 0:
                self.logger.debug(f"ğŸ“Š å†…å­˜ä½¿ç”¨æƒ…å†µ",
                                memory_mb=f"{memory_stats['total_memory_mb']:.1f}MB",
                                orderbook_count=memory_stats['orderbook_count'],
                                orderbook_memory_mb=f"{memory_stats['orderbook_memory_mb']:.1f}MB")

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥å†…å­˜ä½¿ç”¨å¤±è´¥: {e}")

    async def _cleanup_memory(self):
        """
        æ‰§è¡Œå†…å­˜æ¸…ç†
        """
        try:
            if not self.memory_config['enabled']:
                return

            current_time = datetime.now(timezone.utc)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
            if (current_time - self.last_memory_cleanup).total_seconds() < self.memory_config['cleanup_interval']:
                return

            self.logger.info("ğŸ§¹ å¼€å§‹å†…å­˜æ¸…ç†")

            # æ¸…ç†éæ´»è·ƒçš„è®¢å•ç°¿çŠ¶æ€
            inactive_threshold = self.memory_config['inactive_threshold']
            max_states = self.memory_config['max_orderbook_states']

            # æ‰¾å‡ºéæ´»è·ƒçš„çŠ¶æ€
            inactive_keys = []
            for key, state in self.orderbook_states.items():
                if state.last_update_time:
                    time_since_update = (current_time - state.last_update_time).total_seconds()
                    if time_since_update > inactive_threshold:
                        inactive_keys.append(key)

            # æ¸…ç†éæ´»è·ƒçŠ¶æ€
            cleaned_count = 0
            for key in inactive_keys:
                if len(self.orderbook_states) <= max_states // 2:  # ä¿ç•™è‡³å°‘ä¸€åŠçš„çŠ¶æ€
                    break
                del self.orderbook_states[key]
                cleaned_count += 1

            # å¦‚æœçŠ¶æ€æ•°é‡ä»ç„¶è¿‡å¤šï¼Œæ¸…ç†æœ€æ—§çš„çŠ¶æ€
            if len(self.orderbook_states) > max_states:
                # æŒ‰æœ€åæ›´æ–°æ—¶é—´æ’åºï¼Œæ¸…ç†æœ€æ—§çš„
                sorted_states = sorted(
                    self.orderbook_states.items(),
                    key=lambda x: x[1].last_update_time or datetime.min.replace(tzinfo=timezone.utc)
                )

                excess_count = len(self.orderbook_states) - max_states
                for i in range(excess_count):
                    key = sorted_states[i][0]
                    del self.orderbook_states[key]
                    cleaned_count += 1

            self.last_memory_cleanup = current_time
            self.memory_cleanup_count += 1

            if cleaned_count > 0:
                self.logger.info(f"ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ",
                               cleaned_states=cleaned_count,
                               remaining_states=len(self.orderbook_states),
                               cleanup_count=self.memory_cleanup_count)
            else:
                self.logger.debug("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆï¼Œæ— éœ€æ¸…ç†çŠ¶æ€")

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()

        except Exception as e:
            self.logger.error(f"âŒ å†…å­˜æ¸…ç†å¤±è´¥: {e}")

    async def _periodic_memory_management(self):
        """
        å®šæœŸå†…å­˜ç®¡ç†ä»»åŠ¡
        """
        try:
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            await self._check_memory_usage()

            # æ‰§è¡Œæ¸…ç†
            await self._cleanup_memory()

            # æ‰§è¡Œé”™è¯¯æ¢å¤æ£€æŸ¥
            await self._periodic_error_recovery_check()

            # æ‰§è¡Œæ€§èƒ½ç›‘æ§
            if self.performance_config['enabled']:
                await self._periodic_performance_monitoring()

        except Exception as e:
            self.logger.error(f"âŒ å®šæœŸå†…å­˜ç®¡ç†å¤±è´¥: {e}")

    async def _memory_management_loop(self):
        """
        å†…å­˜ç®¡ç†å¾ªç¯ä»»åŠ¡
        """
        self.logger.info("ğŸ§¹ å†…å­˜ç®¡ç†å¾ªç¯å·²å¯åŠ¨")

        try:
            while self._is_running:
                try:
                    # æ‰§è¡Œå®šæœŸå†…å­˜ç®¡ç†
                    await self._periodic_memory_management()

                    # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                    await asyncio.sleep(self.memory_config['memory_check_interval'])

                except asyncio.CancelledError:
                    break
                except Exception as e:
                    self.logger.error(f"âŒ å†…å­˜ç®¡ç†å¾ªç¯å¼‚å¸¸: {e}")
                    await asyncio.sleep(30)  # å‡ºé”™æ—¶ç­‰å¾…30ç§’å†é‡è¯•

        except asyncio.CancelledError:
            self.logger.info("ğŸ§¹ å†…å­˜ç®¡ç†å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            self.logger.error(f"âŒ å†…å­˜ç®¡ç†å¾ªç¯å¤±è´¥: {e}")
        finally:
            self.logger.info("ğŸ§¹ å†…å­˜ç®¡ç†å¾ªç¯å·²åœæ­¢")

    async def _handle_error(self, symbol: str, error_type: str, error_msg: str, exception: Exception = None):
        """
        ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æœºåˆ¶

        Args:
            symbol: äº¤æ˜“å¯¹
            error_type: é”™è¯¯ç±»å‹ ('checksum', 'sequence', 'processing', 'connection')
            error_msg: é”™è¯¯æ¶ˆæ¯
            exception: å¼‚å¸¸å¯¹è±¡
        """
        try:
            current_time = datetime.now(timezone.utc)

            # è®°å½•é”™è¯¯
            self.consecutive_errors += 1
            self.last_error_time = current_time
            self.stats['errors'] += 1

            # æ ¹æ®é”™è¯¯ç±»å‹æ›´æ–°è®¡æ•°
            if error_type == 'checksum':
                self.checksum_failures += 1
            elif error_type == 'sequence':
                self.sequence_errors += 1

            self.logger.error(f"âŒ {error_type}é”™è¯¯: {symbol}",
                            error_msg=error_msg,
                            consecutive_errors=self.consecutive_errors,
                            checksum_failures=self.checksum_failures,
                            sequence_errors=self.sequence_errors,
                            exception=str(exception) if exception else None)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é”™è¯¯æ¢å¤
            await self._check_error_recovery(symbol, error_type)

        except Exception as e:
            self.logger.error(f"âŒ é”™è¯¯å¤„ç†å¤±è´¥: {e}")

    async def _check_error_recovery(self, symbol: str, error_type: str):
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œé”™è¯¯æ¢å¤

        Args:
            symbol: äº¤æ˜“å¯¹
            error_type: é”™è¯¯ç±»å‹
        """
        try:
            if not self.error_recovery_config['enabled']:
                return

            # æ£€æŸ¥è¿ç»­é”™è¯¯æ¬¡æ•°
            if self.consecutive_errors >= self.error_recovery_config['max_consecutive_errors']:
                self.logger.warning(f"âš ï¸ è¿ç»­é”™è¯¯æ¬¡æ•°è¿‡å¤š({self.consecutive_errors})ï¼Œè§¦å‘é”™è¯¯æ¢å¤")
                await self._trigger_error_recovery(symbol, f"è¿ç»­{self.consecutive_errors}æ¬¡é”™è¯¯")
                return

            # æ£€æŸ¥ç‰¹å®šé”™è¯¯ç±»å‹çš„é˜ˆå€¼
            if error_type == 'checksum' and self.checksum_failures >= self.error_recovery_config['checksum_failure_threshold']:
                self.logger.warning(f"âš ï¸ checksumå¤±è´¥æ¬¡æ•°è¿‡å¤š({self.checksum_failures})ï¼Œè§¦å‘é‡æ–°åŒæ­¥")
                await self._trigger_resync(symbol, f"checksumå¤±è´¥{self.checksum_failures}æ¬¡")

            elif error_type == 'sequence' and self.sequence_errors >= self.error_recovery_config['sequence_error_threshold']:
                self.logger.warning(f"âš ï¸ åºåˆ—é”™è¯¯æ¬¡æ•°è¿‡å¤š({self.sequence_errors})ï¼Œè§¦å‘é‡æ–°åŒæ­¥")
                await self._trigger_resync(symbol, f"åºåˆ—é”™è¯¯{self.sequence_errors}æ¬¡")

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥é”™è¯¯æ¢å¤å¤±è´¥: {e}")

    async def _trigger_error_recovery(self, symbol: str, reason: str):
        """
        è§¦å‘é”™è¯¯æ¢å¤

        Args:
            symbol: äº¤æ˜“å¯¹
            reason: æ¢å¤åŸå› 
        """
        try:
            self.logger.info(f"ğŸ”„ å¼€å§‹é”™è¯¯æ¢å¤: {symbol}, åŸå› : {reason}")

            # é‡ç½®é”™è¯¯è®¡æ•°
            self._reset_error_counters()

            # è§¦å‘é‡æ–°åŒæ­¥
            await self._trigger_resync(symbol, reason)

            # å¦‚æœé‡æ–°åŒæ­¥å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œè§¦å‘é‡è¿
            if self.resync_attempts >= self.error_recovery_config['max_resync_attempts']:
                self.logger.warning(f"âš ï¸ é‡æ–°åŒæ­¥å¤±è´¥æ¬¡æ•°è¿‡å¤š({self.resync_attempts})ï¼Œè§¦å‘é‡è¿")
                await self._on_connection_lost(f"é‡æ–°åŒæ­¥å¤±è´¥{self.resync_attempts}æ¬¡")

        except Exception as e:
            self.logger.error(f"âŒ é”™è¯¯æ¢å¤å¤±è´¥: {e}")

    async def _trigger_resync(self, symbol: str, reason: str):
        """
        è§¦å‘é‡æ–°åŒæ­¥

        Args:
            symbol: äº¤æ˜“å¯¹
            reason: é‡æ–°åŒæ­¥åŸå› 
        """
        try:
            if not self.error_recovery_config['auto_resync_enabled']:
                self.logger.info(f"âš ï¸ è‡ªåŠ¨é‡æ–°åŒæ­¥å·²ç¦ç”¨: {symbol}")
                return

            current_time = datetime.now(timezone.utc)

            # æ£€æŸ¥é‡æ–°åŒæ­¥é—´éš”
            if (self.last_resync_time and
                (current_time - self.last_resync_time).total_seconds() < self.error_recovery_config['resync_delay']):
                self.logger.debug(f"â° é‡æ–°åŒæ­¥é—´éš”æœªåˆ°ï¼Œè·³è¿‡: {symbol}")
                return

            self.resync_attempts += 1
            self.last_resync_time = current_time
            self.stats['resync_count'] += 1

            self.logger.info(f"ğŸ”„ è§¦å‘é‡æ–°åŒæ­¥: {symbol}",
                           reason=reason,
                           attempt=self.resync_attempts,
                           total_resyncs=self.stats['resync_count'])

            # é‡ç½®è®¢å•ç°¿çŠ¶æ€
            unique_key = self._get_unique_key(symbol)
            state = self.orderbook_states.get(unique_key)
            if state:
                state.is_synced = False
                state.local_orderbook = None

                # é‡ç½®ç‰¹å®šäºäº¤æ˜“æ‰€çš„çŠ¶æ€
                if hasattr(state, 'last_update_id'):
                    state.last_update_id = 0
                if hasattr(state, 'last_seq_id'):
                    state.last_seq_id = None

                self.logger.debug(f"ğŸ”„ é‡ç½®è®¢å•ç°¿çŠ¶æ€: {symbol}")

            # ç­‰å¾…é‡æ–°åŒæ­¥å»¶è¿Ÿ
            if self.error_recovery_config['resync_delay'] > 0:
                await asyncio.sleep(self.error_recovery_config['resync_delay'])

            # è°ƒç”¨äº¤æ˜“æ‰€ç‰¹å®šçš„é‡æ–°åŒæ­¥é€»è¾‘
            await self._exchange_specific_resync(symbol, reason)

        except Exception as e:
            self.logger.error(f"âŒ è§¦å‘é‡æ–°åŒæ­¥å¤±è´¥: {symbol}, error={e}")

    async def _exchange_specific_resync(self, symbol: str, reason: str):
        """
        äº¤æ˜“æ‰€ç‰¹å®šçš„é‡æ–°åŒæ­¥é€»è¾‘ - å­ç±»å¯é‡å†™

        Args:
            symbol: äº¤æ˜“å¯¹
            reason: é‡æ–°åŒæ­¥åŸå› 
        """
        # é»˜è®¤å®ç°ï¼šç­‰å¾…WebSocketé‡æ–°æ¨é€æ•°æ®
        self.logger.info(f"ğŸ“¡ ç­‰å¾…WebSocketé‡æ–°æ¨é€æ•°æ®: {symbol}")

    def _reset_error_counters(self):
        """é‡ç½®é”™è¯¯è®¡æ•°å™¨"""
        self.consecutive_errors = 0
        self.checksum_failures = 0
        self.sequence_errors = 0
        self.resync_attempts = 0
        self.logger.debug("ğŸ”„ é”™è¯¯è®¡æ•°å™¨å·²é‡ç½®")

    async def _periodic_error_recovery_check(self):
        """
        å®šæœŸé”™è¯¯æ¢å¤æ£€æŸ¥
        """
        try:
            current_time = datetime.now(timezone.utc)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®é”™è¯¯è®¡æ•°å™¨
            if (self.last_error_time and
                (current_time - self.last_error_time).total_seconds() > self.error_recovery_config['error_reset_interval']):

                if self.consecutive_errors > 0 or self.checksum_failures > 0 or self.sequence_errors > 0:
                    self.logger.info(f"ğŸ”„ é”™è¯¯é‡ç½®é—´éš”å·²åˆ°ï¼Œé‡ç½®é”™è¯¯è®¡æ•°å™¨")
                    self._reset_error_counters()

        except Exception as e:
            self.logger.error(f"âŒ å®šæœŸé”™è¯¯æ¢å¤æ£€æŸ¥å¤±è´¥: {e}")

    async def _on_successful_operation(self, symbol: str, operation_type: str):
        """
        æˆåŠŸæ“ä½œå›è°ƒ - ç”¨äºé‡ç½®é”™è¯¯çŠ¶æ€

        Args:
            symbol: äº¤æ˜“å¯¹
            operation_type: æ“ä½œç±»å‹ ('snapshot', 'update', 'checksum', 'sequence')
        """
        try:
            # æˆåŠŸæ“ä½œæ—¶ï¼Œå¯ä»¥è€ƒè™‘éƒ¨åˆ†é‡ç½®é”™è¯¯è®¡æ•°
            if operation_type in ['snapshot', 'update']:
                # æˆåŠŸå¤„ç†æ•°æ®ï¼Œé‡ç½®è¿ç»­é”™è¯¯è®¡æ•°
                if self.consecutive_errors > 0:
                    self.consecutive_errors = max(0, self.consecutive_errors - 1)

            elif operation_type == 'checksum':
                # checksuméªŒè¯æˆåŠŸï¼Œé‡ç½®checksumå¤±è´¥è®¡æ•°
                if self.checksum_failures > 0:
                    self.checksum_failures = max(0, self.checksum_failures - 1)

            elif operation_type == 'sequence':
                # åºåˆ—éªŒè¯æˆåŠŸï¼Œé‡ç½®åºåˆ—é”™è¯¯è®¡æ•°
                if self.sequence_errors > 0:
                    self.sequence_errors = max(0, self.sequence_errors - 1)

        except Exception as e:
            self.logger.error(f"âŒ æˆåŠŸæ“ä½œå›è°ƒå¤±è´¥: {e}")

    async def _record_message_processing(self, symbol: str, processing_time: float, message_size: int = 0):
        """
        è®°å½•æ¶ˆæ¯å¤„ç†æ€§èƒ½

        Args:
            symbol: äº¤æ˜“å¯¹
            processing_time: å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
            message_size: æ¶ˆæ¯å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        try:
            current_time = datetime.now(timezone.utc)

            # è®°å½•å¤„ç†æ—¶é—´
            self.processing_times.append({
                'timestamp': current_time,
                'symbol': symbol,
                'processing_time': processing_time,
                'message_size': message_size
            })

            # ä¿æŒé˜Ÿåˆ—å¤§å°
            max_size = self.performance_config['performance_history_size']
            if len(self.processing_times) > max_size:
                self.processing_times = self.processing_times[-max_size:]

            # è®°å½•æ¶ˆæ¯æ—¶é—´æˆ³ï¼ˆç”¨äºè®¡ç®—ååé‡ï¼‰
            self.message_timestamps.append(current_time)
            if len(self.message_timestamps) > max_size:
                self.message_timestamps = self.message_timestamps[-max_size:]

            # æ£€æŸ¥å»¶è¿Ÿè­¦å‘Š
            latency_ms = processing_time * 1000
            if latency_ms > self.performance_config['latency_warning_threshold']:
                self.performance_warnings += 1
                self.logger.warning(f"âš ï¸ æ¶ˆæ¯å¤„ç†å»¶è¿Ÿè¿‡é«˜: {symbol}",
                                  latency_ms=f"{latency_ms:.1f}ms",
                                  threshold=f"{self.performance_config['latency_warning_threshold']:.1f}ms",
                                  warning_count=self.performance_warnings)

        except Exception as e:
            self.logger.error(f"âŒ è®°å½•æ¶ˆæ¯å¤„ç†æ€§èƒ½å¤±è´¥: {e}")

    async def _get_performance_stats(self) -> dict:
        """
        è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

        Returns:
            dict: æ€§èƒ½ç»Ÿè®¡æ•°æ®
        """
        try:
            current_time = datetime.now(timezone.utc)

            # è®¡ç®—ååé‡ï¼ˆæœ€è¿‘1åˆ†é’Ÿï¼‰
            one_minute_ago = current_time - timedelta(minutes=1)
            recent_messages = [ts for ts in self.message_timestamps if ts > one_minute_ago]
            throughput = len(recent_messages) / 60.0  # æ¶ˆæ¯/ç§’

            # è®¡ç®—å¹³å‡å»¶è¿Ÿï¼ˆæœ€è¿‘1åˆ†é’Ÿï¼‰
            recent_processing_times = [
                pt['processing_time'] for pt in self.processing_times
                if pt['timestamp'] > one_minute_ago
            ]

            avg_latency_ms = 0
            max_latency_ms = 0
            min_latency_ms = 0

            if recent_processing_times:
                avg_latency_ms = sum(recent_processing_times) / len(recent_processing_times) * 1000
                max_latency_ms = max(recent_processing_times) * 1000
                min_latency_ms = min(recent_processing_times) * 1000

            # è·å–CPUä½¿ç”¨ç‡
            cpu_percent = 0
            try:
                import psutil
                cpu_percent = psutil.cpu_percent(interval=0.1)
            except ImportError:
                pass

            # è®¡ç®—è®¢å•ç°¿æ›´æ–°é¢‘ç‡
            update_frequency = self.stats.get('updates_applied', 0) / max(
                (current_time - self.connection_start_time).total_seconds(), 1
            )

            return {
                'throughput_msg_per_sec': throughput,
                'avg_latency_ms': avg_latency_ms,
                'max_latency_ms': max_latency_ms,
                'min_latency_ms': min_latency_ms,
                'cpu_percent': cpu_percent,
                'update_frequency': update_frequency,
                'total_messages': len(self.message_timestamps),
                'performance_warnings': self.performance_warnings,
                'orderbook_count': len(self.orderbook_states),
                'synced_orderbooks': sum(1 for state in self.orderbook_states.values() if state.is_synced)
            }

        except Exception as e:
            self.logger.error(f"âŒ è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {e}")
            return {}

    async def _check_performance_metrics(self):
        """
        æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡å¹¶å‘å‡ºè­¦å‘Š
        """
        try:
            current_time = datetime.now(timezone.utc)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œæ€§èƒ½æ£€æŸ¥
            if (current_time - self.last_performance_check).total_seconds() < self.performance_config['monitoring_interval']:
                return

            self.last_performance_check = current_time

            # è·å–æ€§èƒ½ç»Ÿè®¡
            stats = await self._get_performance_stats()
            if not stats:
                return

            # æ£€æŸ¥ååé‡è­¦å‘Š
            throughput = stats.get('throughput_msg_per_sec', 0)
            if throughput < self.performance_config['throughput_warning_threshold']:
                self.performance_warnings += 1
                self.logger.warning(f"âš ï¸ æ¶ˆæ¯ååé‡è¿‡ä½",
                                  throughput=f"{throughput:.1f}msg/s",
                                  threshold=f"{self.performance_config['throughput_warning_threshold']:.1f}msg/s",
                                  warning_count=self.performance_warnings)

            # æ£€æŸ¥CPUä½¿ç”¨ç‡è­¦å‘Š
            cpu_percent = stats.get('cpu_percent', 0)
            if cpu_percent > self.performance_config['cpu_warning_threshold']:
                self.performance_warnings += 1
                self.logger.warning(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜",
                                  cpu_percent=f"{cpu_percent:.1f}%",
                                  threshold=f"{self.performance_config['cpu_warning_threshold']:.1f}%",
                                  warning_count=self.performance_warnings)

            # è®°å½•æ€§èƒ½å†å²
            self.performance_history.append({
                'timestamp': current_time,
                'stats': stats
            })

            # ä¿æŒå†å²è®°å½•å¤§å°
            max_size = self.performance_config['performance_history_size']
            if len(self.performance_history) > max_size:
                self.performance_history = self.performance_history[-max_size:]

            # å®šæœŸè¾“å‡ºè¯¦ç»†ç»Ÿè®¡
            if (current_time - self.last_detailed_stats).total_seconds() >= self.performance_config['detailed_stats_interval']:
                self.last_detailed_stats = current_time
                await self._log_detailed_performance_stats(stats)
                await self._log_system_status()

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")

    async def _log_detailed_performance_stats(self, stats: dict):
        """
        è®°å½•è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

        Args:
            stats: æ€§èƒ½ç»Ÿè®¡æ•°æ®
        """
        try:
            self.logger.info("ğŸ“Š è¯¦ç»†æ€§èƒ½ç»Ÿè®¡",
                           throughput=f"{stats.get('throughput_msg_per_sec', 0):.1f}msg/s",
                           avg_latency=f"{stats.get('avg_latency_ms', 0):.1f}ms",
                           max_latency=f"{stats.get('max_latency_ms', 0):.1f}ms",
                           cpu_usage=f"{stats.get('cpu_percent', 0):.1f}%",
                           update_frequency=f"{stats.get('update_frequency', 0):.2f}updates/s",
                           orderbook_count=stats.get('orderbook_count', 0),
                           synced_count=stats.get('synced_orderbooks', 0),
                           total_messages=stats.get('total_messages', 0),
                           performance_warnings=stats.get('performance_warnings', 0),
                           memory_warnings=self.memory_warnings,
                           reconnection_count=self.stats.get('reconnection_count', 0),
                           resync_count=self.stats.get('resync_count', 0))

        except Exception as e:
            self.logger.error(f"âŒ è®°å½•è¯¦ç»†æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {e}")

    async def _periodic_performance_monitoring(self):
        """
        å®šæœŸæ€§èƒ½ç›‘æ§ä»»åŠ¡
        """
        try:
            # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
            await self._check_performance_metrics()

        except Exception as e:
            self.logger.error(f"âŒ å®šæœŸæ€§èƒ½ç›‘æ§å¤±è´¥: {e}")

    def _create_log_context(self, symbol: str = None, **kwargs) -> dict:
        """
        åˆ›å»ºæ—¥å¿—ä¸Šä¸‹æ–‡

        Args:
            symbol: äº¤æ˜“å¯¹
            **kwargs: é¢å¤–çš„ä¸Šä¸‹æ–‡å­—æ®µ

        Returns:
            dict: æ—¥å¿—ä¸Šä¸‹æ–‡
        """
        context = self.log_context.copy()

        if symbol:
            context['symbol'] = symbol
            context['unique_key'] = self._get_unique_key(symbol)

        # æ·»åŠ é¢å¤–å­—æ®µ
        for key, value in kwargs.items():
            if key not in self.logging_config['sensitive_fields']:
                context[key] = value

        return context

    def _sanitize_log_data(self, data: Any) -> Any:
        """
        æ¸…ç†æ—¥å¿—æ•°æ®ï¼Œç§»é™¤æ•æ„Ÿä¿¡æ¯

        Args:
            data: åŸå§‹æ•°æ®

        Returns:
            Any: æ¸…ç†åçš„æ•°æ®
        """
        if isinstance(data, dict):
            sanitized = {}
            for key, value in data.items():
                if key.lower() in self.logging_config['sensitive_fields']:
                    sanitized[key] = "***REDACTED***"
                elif isinstance(value, (dict, list)):
                    sanitized[key] = self._sanitize_log_data(value)
                else:
                    sanitized[key] = value
            return sanitized
        elif isinstance(data, list):
            return [self._sanitize_log_data(item) for item in data]
        else:
            return data

    def log_info(self, message: str, symbol: str = None, **kwargs):
        """
        è®°å½•ä¿¡æ¯æ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            symbol: äº¤æ˜“å¯¹
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if not self.logging_config['enabled']:
            return

        try:
            context = self._create_log_context(symbol, **kwargs)
            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                self.logger.info(message, **sanitized_context)
            else:
                self.logger.info(f"{message} | {sanitized_context}")

        except Exception as e:
            # é¿å…æ—¥å¿—è®°å½•æœ¬èº«å‡ºé”™å½±å“ä¸»æµç¨‹
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def log_warning(self, message: str, symbol: str = None, **kwargs):
        """
        è®°å½•è­¦å‘Šæ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            symbol: äº¤æ˜“å¯¹
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if not self.logging_config['enabled']:
            return

        try:
            context = self._create_log_context(symbol, **kwargs)
            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                self.logger.warning(message, **sanitized_context)
            else:
                self.logger.warning(f"{message} | {sanitized_context}")

        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def log_error(self, message: str, symbol: str = None, exception: Exception = None, **kwargs):
        """
        è®°å½•é”™è¯¯æ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            symbol: äº¤æ˜“å¯¹
            exception: å¼‚å¸¸å¯¹è±¡
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if not self.logging_config['enabled'] or not self.logging_config['log_errors']:
            return

        try:
            context = self._create_log_context(symbol, **kwargs)

            if exception:
                context['exception_type'] = type(exception).__name__
                context['exception_message'] = str(exception)
                context['traceback'] = True

            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                if exception:
                    self.logger.error(message, exc_info=True, **sanitized_context)
                else:
                    self.logger.error(message, **sanitized_context)
            else:
                self.logger.error(f"{message} | {sanitized_context}")

        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def log_debug(self, message: str, symbol: str = None, **kwargs):
        """
        è®°å½•è°ƒè¯•æ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            symbol: äº¤æ˜“å¯¹
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if (not self.logging_config['enabled'] or
            self.logging_config['log_level'] not in ['DEBUG']):
            return

        try:
            context = self._create_log_context(symbol, **kwargs)
            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                self.logger.debug(message, **sanitized_context)
            else:
                self.logger.debug(f"{message} | {sanitized_context}")

        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def log_performance(self, message: str, symbol: str = None, **kwargs):
        """
        è®°å½•æ€§èƒ½æ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            symbol: äº¤æ˜“å¯¹
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if (not self.logging_config['enabled'] or
            not self.logging_config['log_performance']):
            return

        try:
            context = self._create_log_context(symbol, **kwargs)
            context['log_type'] = 'performance'
            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                self.logger.info(message, **sanitized_context)
            else:
                self.logger.info(f"[PERF] {message} | {sanitized_context}")

        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def log_connection(self, message: str, **kwargs):
        """
        è®°å½•è¿æ¥æ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if (not self.logging_config['enabled'] or
            not self.logging_config['log_connections']):
            return

        try:
            context = self._create_log_context(**kwargs)
            context['log_type'] = 'connection'
            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                self.logger.info(message, **sanitized_context)
            else:
                self.logger.info(f"[CONN] {message} | {sanitized_context}")

        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def log_data_flow(self, message: str, symbol: str = None, data_size: int = 0, **kwargs):
        """
        è®°å½•æ•°æ®æµæ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            symbol: äº¤æ˜“å¯¹
            data_size: æ•°æ®å¤§å°
            **kwargs: é¢å¤–çš„æ—¥å¿—å­—æ®µ
        """
        if (not self.logging_config['enabled'] or
            not self.logging_config['log_data_flow']):
            return

        try:
            context = self._create_log_context(symbol, **kwargs)
            context['log_type'] = 'data_flow'
            context['data_size'] = data_size
            sanitized_context = self._sanitize_log_data(context)

            if self.logging_config['structured_logging']:
                self.logger.debug(message, **sanitized_context)
            else:
                self.logger.debug(f"[DATA] {message} | {sanitized_context}")

        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    async def _log_system_status(self):
        """
        è®°å½•ç³»ç»ŸçŠ¶æ€æ—¥å¿—
        """
        try:
            if not self.logging_config['enabled']:
                return

            # è·å–ç³»ç»ŸçŠ¶æ€
            memory_stats = await self._get_memory_usage()
            performance_stats = await self._get_performance_stats()

            # ç»Ÿè®¡è®¢å•ç°¿çŠ¶æ€
            total_orderbooks = len(self.orderbook_states)
            synced_orderbooks = sum(1 for state in self.orderbook_states.values() if state.is_synced)

            # è®°å½•ç³»ç»ŸçŠ¶æ€
            self.log_info("ğŸ“Š ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š",
                        total_orderbooks=total_orderbooks,
                        synced_orderbooks=synced_orderbooks,
                        sync_ratio=f"{synced_orderbooks/max(total_orderbooks,1)*100:.1f}%",
                        memory_mb=f"{memory_stats.get('total_memory_mb', 0):.1f}MB",
                        cpu_percent=f"{performance_stats.get('cpu_percent', 0):.1f}%",
                        throughput=f"{performance_stats.get('throughput_msg_per_sec', 0):.1f}msg/s",
                        avg_latency=f"{performance_stats.get('avg_latency_ms', 0):.1f}ms",
                        total_messages=self.stats.get('messages_processed', 0),
                        total_errors=self.stats.get('errors', 0),
                        reconnection_count=self.stats.get('reconnection_count', 0),
                        resync_count=self.stats.get('resync_count', 0),
                        uptime_seconds=int((datetime.now(timezone.utc) - self.connection_start_time).total_seconds()))

        except Exception as e:
            self.log_error("âŒ è®°å½•ç³»ç»ŸçŠ¶æ€å¤±è´¥", exception=e)

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()

    def get_orderbook_state(self, symbol: str) -> Optional[OrderBookState]:
        """è·å–è®¢å•ç°¿çŠ¶æ€"""
        unique_key = self._get_unique_key(symbol)
        return self.orderbook_states.get(unique_key)

    @property
    def is_running(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return self._is_running