"""
MarketPrism Data Collector Service - é›†æˆå¾®æœåŠ¡
é›†æˆäº†æ•°æ®æ”¶é›†ã€OrderBookç®¡ç†å’Œæ•°æ®èšåˆåŠŸèƒ½çš„ç»Ÿä¸€å¾®æœåŠ¡

åŠŸèƒ½ç‰¹æ€§:
- å¤šäº¤æ˜“æ‰€æ•°æ®æ”¶é›† (Binance, OKX, Deribit)
- å®æ—¶WebSocketæ•°æ®æµ
- OrderBookå¢é‡ç»´æŠ¤
- æ•°æ®æ ‡å‡†åŒ–å’Œèšåˆ
- NATSæ¶ˆæ¯é˜Ÿåˆ—é›†æˆ
- BaseServiceæ¡†æ¶é›†æˆ
"""

# æ ‡å‡†åº“å¯¼å…¥
import asyncio
import sys
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import structlog
from aiohttp import web
import nats
import json

# é¡¹ç›®è·¯å¾„é…ç½® - é€‚é…Dockerå®¹å™¨ç¯å¢ƒ
try:
    project_root = Path(__file__).parent.parent.parent.parent
    sys.path.insert(0, str(project_root))
    sys.path.insert(0, '/app')
except Exception as e:
    print(f"è·¯å¾„é…ç½®è­¦å‘Š: {e}")
    project_root = Path('/app')
    sys.path.insert(0, '/app')

# æ ¸å¿ƒæ¡†æ¶å¯¼å…¥
from core.service_framework import BaseService

# æ•°æ®æ”¶é›†æ¨¡å—å¯¼å…¥
try:
    from core.data_collection.public_data_collector import PublicDataCollector
except ImportError as e:
    print(f"æ•°æ®æ”¶é›†æ¨¡å—å¯¼å…¥è­¦å‘Š: {e}")
    PublicDataCollector = None

# æœ¬åœ°æ¨¡å—å¯¼å…¥
try:
    from .config import ConfigPathManager
    from .data_types import Exchange, ExchangeConfig
    from .normalizer import DataNormalizer
except ImportError as e:
    print(f"æœ¬åœ°æ¨¡å—å¯¼å…¥è­¦å‘Š: {e}")
    ConfigPathManager = None
    Exchange = None
    ExchangeConfig = None
    DataNormalizer = None


class DataCollectorService(BaseService):
    """
    MarketPrismæ•°æ®æ”¶é›†å™¨å¾®æœåŠ¡

    åŠŸèƒ½:
    - å¤šäº¤æ˜“æ‰€æ•°æ®æ”¶é›† (Binance, OKX, Deribit)
    - å®æ—¶WebSocketæ•°æ®æµå¤„ç†
    - OrderBookå¢é‡ç»´æŠ¤
    - æ•°æ®æ ‡å‡†åŒ–å’Œèšåˆ
    - NATSæ¶ˆæ¯é˜Ÿåˆ—é›†æˆ

    æ¶æ„:
    - ç»§æ‰¿BaseServiceæ¡†æ¶ï¼Œæä¾›ç»Ÿä¸€çš„æœåŠ¡ç®¡ç†
    - æ”¯æŒDockerå®¹å™¨åŒ–éƒ¨ç½²
    - æä¾›RESTful APIæ¥å£
    - é›†æˆPrometheusç›‘æ§æŒ‡æ ‡
    """

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨æœåŠ¡

        Args:
            config: æœåŠ¡é…ç½®å­—å…¸
        """
        super().__init__("data-collector", config)

        # æ ¸å¿ƒç»„ä»¶
        self.public_collector: Optional[PublicDataCollector] = None
        self.orderbook_manager: Optional[Any] = None
        self.data_normalizer: Optional[DataNormalizer] = None

        # NATSå®¢æˆ·ç«¯
        self.nats_client = None
        # ä»æ­£ç¡®çš„é…ç½®è·¯å¾„è·å–NATSé…ç½®
        data_collection_config = config.get('data_collection', {})
        self.nats_config = data_collection_config.get('nats_streaming', {
            'servers': ['nats://localhost:4222'],
            'enabled': True
        })

        # æœåŠ¡çŠ¶æ€
        self.start_time = datetime.now(timezone.utc)
        self.is_initialized = False

        # åŠŸèƒ½é…ç½®
        self.enable_orderbook = config.get('enable_orderbook', True)
        self.enable_websocket = config.get('enable_websocket', True)
        self.collection_interval = config.get('collection_interval', 30)

        # å…¨å±€Rate Limitingä¿æŠ¤ - æœåŠ¡çº§åˆ«åŸºç¡€ä¿æŠ¤
        # TODO: å®ç°å…¨å±€é™æµå™¨ï¼ˆæš‚æ—¶è·³è¿‡ï¼‰
        self.global_rate_limiter = None

        # é€‚é…å™¨ç®¡ç†
        self.exchange_adapters = {}
        self.adapter_stats = {}

        # æ•°æ®å­˜å‚¨
        self.collected_data = {
            'orderbooks': {},
            'trades': {},
            'klines': {},
            'funding_rates': {},
            'open_interest': {},
            'volatility_index': {},
            'top_trader_ratio': {},
            'global_long_short_ratio': {},
            'liquidations': {},
            'stats': {
                'total_collections': 0,
                'last_collection_time': None,
                'error_count': 0,
                'nats_published': 0,
                'nats_errors': 0
            }
        }

        # æ”¯æŒçš„äº¤æ˜“æ‰€åˆ—è¡¨
        self.supported_exchanges = ['binance', 'okx', 'deribit']

        self.logger.info(f"æ•°æ®æ”¶é›†å™¨æœåŠ¡åˆå§‹åŒ–å®Œæˆ: orderbook={self.enable_orderbook}, websocket={self.enable_websocket}")

    def setup_routes(self):
        """è®¾ç½®APIè·¯ç”±"""
        # åŸºç¡€è·¯ç”±å·²åœ¨BaseServiceä¸­è®¾ç½®ï¼Œè¿™é‡Œæ·»åŠ data-collectorç‰¹å®šçš„APIç«¯ç‚¹

        # æ³¨å†ŒAPIè·¯ç”±
        self.app.router.add_get("/api/v1/status", self._get_service_status)
        self.app.router.add_get("/api/v1/collector/stats", self._get_collector_stats)
        self.app.router.add_get("/api/v1/collector/status", self._get_collector_status)
        self.app.router.add_get("/api/v1/collector/exchanges", self._get_exchanges_status)
        self.app.router.add_get("/api/v1/collector/data", self._get_collected_data)

    def _create_success_response(self, data: Any, message: str = "Success") -> web.Response:
        """åˆ›å»ºæˆåŠŸå“åº”"""
        return web.json_response({
            "status": "success",
            "message": message,
            "data": data,
            "timestamp": datetime.now(timezone.utc).isoformat()
        })

    def _create_error_response(self, message: str, error_code: str = "INTERNAL_ERROR",
                              status_code: int = 500) -> web.Response:
        """
        åˆ›å»ºæ ‡å‡†åŒ–é”™è¯¯å“åº”

        Args:
            message: é”™è¯¯æè¿°ä¿¡æ¯
            error_code: æ ‡å‡†åŒ–é”™è¯¯ä»£ç 
            status_code: HTTPçŠ¶æ€ç 

        Returns:
            æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”
        """
        return web.json_response({
            "status": "error",
            "error_code": error_code,
            "message": message,
            "data": None,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }, status=status_code)

    # æ ‡å‡†åŒ–é”™è¯¯ä»£ç å¸¸é‡
    ERROR_CODES = {
        'COLLECTOR_NOT_INITIALIZED': 'COLLECTOR_NOT_INITIALIZED',
        'STATS_UNAVAILABLE': 'STATS_UNAVAILABLE',
        'EXCHANGE_STATUS_ERROR': 'EXCHANGE_STATUS_ERROR',
        'DATA_RETRIEVAL_ERROR': 'DATA_RETRIEVAL_ERROR',
        'INVALID_PARAMETERS': 'INVALID_PARAMETERS',
        'SERVICE_UNAVAILABLE': 'SERVICE_UNAVAILABLE',
        'INTERNAL_ERROR': 'INTERNAL_ERROR'
    }

    async def _get_service_status(self, request: web.Request) -> web.Response:
        """
        BaseServiceå…¼å®¹çš„çŠ¶æ€API

        Returns:
            æ ‡å‡†åŒ–çš„æœåŠ¡çŠ¶æ€å“åº”ï¼ŒåŒ…å«æœåŠ¡åŸºæœ¬ä¿¡æ¯ã€è¿è¡ŒçŠ¶æ€å’Œç»Ÿè®¡æ•°æ®
        """
        try:
            uptime_seconds = (datetime.now(timezone.utc) - self.start_time).total_seconds()

            # è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
            basic_stats = {}
            try:
                basic_stats = self._get_basic_stats()
            except Exception as e:
                self.logger.warning(f"è·å–åŸºç¡€ç»Ÿè®¡å¤±è´¥: {e}")
                basic_stats = {"error": "Stats temporarily unavailable"}

            status_data = {
                "service": "data-collector",
                "status": "running" if self.is_initialized else "initializing",
                "uptime_seconds": round(uptime_seconds, 2),
                "version": "1.0.0",
                "environment": "production",
                "features": {
                    "collector_initialized": self.public_collector is not None,
                    "orderbook_enabled": self.enable_orderbook,
                    "websocket_enabled": self.enable_websocket,
                    "normalizer_enabled": self.data_normalizer is not None
                },
                "supported_exchanges": self.supported_exchanges,
                "collection_stats": basic_stats
            }

            return self._create_success_response(status_data, "Service status retrieved successfully")

        except Exception as e:
            self.logger.error(f"è·å–æœåŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve service status: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR'],
                500
            )

    async def _get_collector_stats(self, request: web.Request) -> web.Response:
        """
        è·å–æ•°æ®æ”¶é›†ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŒ…å«æ”¶é›†å™¨ç»Ÿè®¡ã€æœåŠ¡ç»Ÿè®¡å’Œæ•°æ®æ‘˜è¦çš„æ ‡å‡†åŒ–å“åº”
        """
        try:
            if not self.public_collector:
                return self._create_error_response(
                    "Data collector not initialized. Service is running in degraded mode.",
                    self.ERROR_CODES['COLLECTOR_NOT_INITIALIZED'],
                    503
                )

            # è·å–æ”¶é›†å™¨ç»Ÿè®¡ä¿¡æ¯
            collector_stats = {}
            try:
                collector_stats = self.public_collector.get_stats()
                if not collector_stats:
                    collector_stats = {"warning": "No statistics available yet"}
            except Exception as e:
                self.logger.warning(f"è·å–æ”¶é›†å™¨ç»Ÿè®¡å¤±è´¥: {e}")
                collector_stats = {
                    "error": "Stats temporarily unavailable",
                    "error_details": str(e)
                }

            # è®¡ç®—è¿è¡Œæ—¶é—´
            uptime_seconds = (datetime.now(timezone.utc) - self.start_time).total_seconds()

            # ç»„åˆç»Ÿè®¡æ•°æ®
            stats_data = {
                "collection_stats": collector_stats,
                "service_stats": {
                    "uptime_seconds": round(uptime_seconds, 2),
                    "total_collections": self.collected_data['stats']['total_collections'],
                    "error_count": self.collected_data['stats']['error_count'],
                    "last_collection_time": self.collected_data['stats']['last_collection_time'],
                    "success_rate": self._calculate_success_rate()
                },
                "data_summary": {
                    "orderbooks_count": len(self.collected_data['orderbooks']),
                    "trades_count": len(self.collected_data['trades']),
                    "total_data_points": (
                        len(self.collected_data['orderbooks']) +
                        len(self.collected_data['trades'])
                    )
                },
                "performance_metrics": {
                    "collections_per_minute": self._calculate_collections_per_minute(uptime_seconds),
                    "memory_usage_mb": self._estimate_memory_usage()
                }
            }

            return self._create_success_response(stats_data, "Collection statistics retrieved successfully")

        except Exception as e:
            self.logger.error(f"è·å–æ”¶é›†ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve collection statistics: {str(e)}",
                self.ERROR_CODES['STATS_UNAVAILABLE'],
                500
            )

    async def _get_collector_status(self, request: web.Request) -> web.Response:
        """
        è·å–æ•°æ®æ”¶é›†å™¨è¯¦ç»†çŠ¶æ€

        Returns:
            åŒ…å«æœåŠ¡ä¿¡æ¯ã€åŠŸèƒ½çŠ¶æ€ã€æ”¶é›†å™¨ç»Ÿè®¡å’Œäº¤æ˜“æ‰€çŠ¶æ€çš„è¯¦ç»†å“åº”
        """
        try:
            # è·å–æ”¶é›†å™¨ç»Ÿè®¡ä¿¡æ¯
            collector_stats = {}
            if self.public_collector:
                try:
                    collector_stats = self.public_collector.get_stats()
                    if not collector_stats:
                        collector_stats = {"warning": "No statistics available yet"}
                except Exception as e:
                    self.logger.warning(f"è·å–æ”¶é›†å™¨ç»Ÿè®¡å¤±è´¥: {e}")
                    collector_stats = {
                        "error": "Stats temporarily unavailable",
                        "error_details": str(e)
                    }
            else:
                collector_stats = {"status": "not_initialized"}

            # è®¡ç®—è¿è¡Œæ—¶é—´
            uptime_seconds = (datetime.now(timezone.utc) - self.start_time).total_seconds()

            # æ„å»ºè¯¦ç»†çŠ¶æ€ä¿¡æ¯
            status_data = {
                "service_info": {
                    "name": "data-collector",
                    "version": "1.0.0",
                    "uptime_seconds": round(uptime_seconds, 2),
                    "initialized": self.is_initialized,
                    "start_time": self.start_time.isoformat(),
                    "environment": "production",
                    "process_id": os.getpid() if hasattr(os, 'getpid') else "unknown"
                },
                "feature_status": {
                    "collector_initialized": self.public_collector is not None,
                    "orderbook_enabled": self.enable_orderbook,
                    "websocket_enabled": self.enable_websocket,
                    "normalizer_enabled": self.data_normalizer is not None,
                    "orderbook_manager_active": self.orderbook_manager is not None
                },
                "collector_stats": collector_stats,
                "exchanges": self._get_exchange_status(),
                "data_summary": {
                    "orderbooks": len(self.collected_data['orderbooks']),
                    "trades": len(self.collected_data['trades']),
                    "total_data_points": (
                        len(self.collected_data['orderbooks']) +
                        len(self.collected_data['trades'])
                    )
                },
                "health_indicators": {
                    "overall_health": "healthy" if self.is_initialized else "degraded",
                    "data_flow_active": len(self.collected_data['orderbooks']) > 0 or len(self.collected_data['trades']) > 0,
                    "error_rate": self._calculate_error_rate(),
                    "last_activity": self.collected_data['stats']['last_collection_time']
                }
            }

            return self._create_success_response(status_data, "Detailed status retrieved successfully")

        except Exception as e:
            self.logger.error(f"è·å–è¯¦ç»†çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve detailed status: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR'],
                500
            )

    async def _get_exchanges_status(self, request: web.Request) -> web.Response:
        """
        è·å–äº¤æ˜“æ‰€è¿æ¥çŠ¶æ€

        Returns:
            åŒ…å«æ‰€æœ‰æ”¯æŒäº¤æ˜“æ‰€çš„è¿æ¥çŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯
        """
        try:
            exchanges_data = self._get_exchange_status()

            # æ·»åŠ æ±‡æ€»ä¿¡æ¯
            summary = {
                "total_exchanges": len(exchanges_data),
                "active_exchanges": sum(1 for ex in exchanges_data.values() if ex.get('status') == 'active'),
                "websocket_connections": sum(1 for ex in exchanges_data.values() if ex.get('websocket_connected')),
                "rest_api_available": sum(1 for ex in exchanges_data.values() if ex.get('rest_api_available'))
            }

            response_data = {
                "exchanges": exchanges_data,
                "summary": summary,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }

            return self._create_success_response(response_data, "Exchange status retrieved successfully")

        except Exception as e:
            self.logger.error(f"è·å–äº¤æ˜“æ‰€çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve exchange status: {str(e)}",
                self.ERROR_CODES['EXCHANGE_STATUS_ERROR'],
                500
            )

    async def _get_collected_data(self, request: web.Request) -> web.Response:
        """
        è·å–æ”¶é›†çš„æ•°æ®æ‘˜è¦

        Query Parameters:
            exchange: äº¤æ˜“æ‰€åç§° (all, binance, okx, deribit)
            type: æ•°æ®ç±»å‹ (all, orderbooks, trades)
            limit: è¿”å›è®°å½•æ•°é™åˆ¶ (1-100, é»˜è®¤10)

        Returns:
            åŒ…å«æ•°æ®æ‘˜è¦ã€æœ€è¿‘æ•°æ®å’ŒæŸ¥è¯¢å‚æ•°çš„æ ‡å‡†åŒ–å“åº”
        """
        try:
            # è·å–å’ŒéªŒè¯æŸ¥è¯¢å‚æ•°
            exchange = request.query.get('exchange', 'all').lower()
            data_type = request.query.get('type', 'all').lower()

            try:
                limit = int(request.query.get('limit', '10'))
                if limit < 1 or limit > 100:
                    return self._create_error_response(
                        "Limit parameter must be between 1 and 100",
                        self.ERROR_CODES['INVALID_PARAMETERS'],
                        400
                    )
            except ValueError:
                return self._create_error_response(
                    "Limit parameter must be a valid integer",
                    self.ERROR_CODES['INVALID_PARAMETERS'],
                    400
                )

            # éªŒè¯äº¤æ˜“æ‰€å‚æ•°
            valid_exchanges = ['all'] + self.supported_exchanges
            if exchange not in valid_exchanges:
                return self._create_error_response(
                    f"Invalid exchange parameter. Valid values: {', '.join(valid_exchanges)}",
                    self.ERROR_CODES['INVALID_PARAMETERS'],
                    400
                )

            # éªŒè¯æ•°æ®ç±»å‹å‚æ•°
            valid_types = ['all', 'orderbooks', 'trades']
            if data_type not in valid_types:
                return self._create_error_response(
                    f"Invalid type parameter. Valid values: {', '.join(valid_types)}",
                    self.ERROR_CODES['INVALID_PARAMETERS'],
                    400
                )

            # æ„å»ºæ•°æ®æ‘˜è¦
            data_summary = {
                "query_parameters": {
                    "exchange": exchange,
                    "type": data_type,
                    "limit": limit
                },
                "summary": {
                    "total_orderbooks": len(self.collected_data['orderbooks']),
                    "total_trades": len(self.collected_data['trades']),
                    "total_data_points": (
                        len(self.collected_data['orderbooks']) +
                        len(self.collected_data['trades'])
                    ),
                    "last_update": self.collected_data['stats']['last_collection_time'],
                    "collection_stats": {
                        "total_collections": self.collected_data['stats']['total_collections'],
                        "error_count": self.collected_data['stats']['error_count']
                    }
                },
                "recent_data": self._get_recent_data(exchange, data_type, limit),
                "metadata": {
                    "generated_at": datetime.now(timezone.utc).isoformat(),
                    "data_freshness_seconds": self._calculate_data_freshness()
                }
            }

            return self._create_success_response(data_summary, "Collected data retrieved successfully")

        except Exception as e:
            self.logger.error(f"è·å–æ”¶é›†æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve collected data: {str(e)}",
                self.ERROR_CODES['DATA_RETRIEVAL_ERROR'],
                500
            )

    def _get_exchange_status(self) -> Dict[str, Any]:
        """è·å–äº¤æ˜“æ‰€çŠ¶æ€ä¿¡æ¯"""
        current_time = datetime.now(timezone.utc).isoformat()

        return {
            "binance": {
                "enabled": True,
                "websocket_connected": self.enable_websocket,
                "rest_api_available": True,
                "last_update": current_time,
                "status": "active"
            },
            "okx": {
                "enabled": True,
                "websocket_connected": self.enable_websocket,
                "rest_api_available": True,
                "last_update": current_time,
                "status": "active"
            },
            "deribit": {
                "enabled": self.enable_orderbook,
                "websocket_connected": self.enable_websocket and self.enable_orderbook,
                "rest_api_available": True,
                "last_update": current_time,
                "status": "active" if self.enable_orderbook else "disabled"
            }
        }

    def _get_basic_stats(self) -> Dict[str, Any]:
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_collections": self.collected_data['stats']['total_collections'],
            "error_count": self.collected_data['stats']['error_count'],
            "last_collection_time": self.collected_data['stats']['last_collection_time'],
            "data_counts": {
                "orderbooks": len(self.collected_data['orderbooks']),
                "trades": len(self.collected_data['trades'])
            }
        }

    def _get_recent_data(self, exchange: str, data_type: str, limit: int) -> Dict[str, Any]:
        """è·å–æœ€è¿‘çš„æ•°æ®"""
        recent_data = {}

        if data_type in ['all', 'orderbooks'] and self.collected_data['orderbooks']:
            recent_orderbooks = dict(list(self.collected_data['orderbooks'].items())[-limit:])
            if exchange != 'all':
                recent_orderbooks = {k: v for k, v in recent_orderbooks.items() if exchange in k}
            recent_data['orderbooks'] = recent_orderbooks

        if data_type in ['all', 'trades'] and self.collected_data['trades']:
            recent_trades = dict(list(self.collected_data['trades'].items())[-limit:])
            if exchange != 'all':
                recent_trades = {k: v for k, v in recent_trades.items() if exchange in k}
            recent_data['trades'] = recent_trades

        return recent_data

    def _calculate_success_rate(self) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        total = self.collected_data['stats']['total_collections']
        errors = self.collected_data['stats']['error_count']
        if total == 0:
            return 100.0
        return round((total - errors) / total * 100, 2)

    def _calculate_error_rate(self) -> float:
        """è®¡ç®—é”™è¯¯ç‡"""
        total = self.collected_data['stats']['total_collections']
        errors = self.collected_data['stats']['error_count']
        if total == 0:
            return 0.0
        return round(errors / total * 100, 2)

    def _calculate_collections_per_minute(self, uptime_seconds: float) -> float:
        """è®¡ç®—æ¯åˆ†é’Ÿæ”¶é›†æ¬¡æ•°"""
        if uptime_seconds < 60:
            return 0.0
        minutes = uptime_seconds / 60
        return round(self.collected_data['stats']['total_collections'] / minutes, 2)

    def _estimate_memory_usage(self) -> float:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        try:
            import sys
            total_size = 0
            for data_category in ['orderbooks', 'trades']:
                total_size += sys.getsizeof(self.collected_data[data_category])
                for item in self.collected_data[data_category].values():
                    total_size += sys.getsizeof(item)
            return round(total_size / (1024 * 1024), 2)
        except Exception:
            return 0.0

    def _calculate_data_freshness(self) -> float:
        """è®¡ç®—æ•°æ®æ–°é²œåº¦ï¼ˆç§’ï¼‰"""
        last_update = self.collected_data['stats']['last_collection_time']
        if not last_update:
            return float('inf')
        try:
            last_update_dt = datetime.fromisoformat(last_update.replace('Z', '+00:00'))
            return (datetime.now(timezone.utc) - last_update_dt).total_seconds()
        except Exception:
            return float('inf')

    async def on_startup(self):
        """æœåŠ¡å¯åŠ¨åˆå§‹åŒ–"""
        try:
            self.logger.info("å¼€å§‹åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨æœåŠ¡...")

            # 1. åˆå§‹åŒ–NATSå®¢æˆ·ç«¯
            await self._init_nats_client()

            # 2. åˆå§‹åŒ–æ•°æ®æ ‡å‡†åŒ–å™¨
            await self._init_data_normalizer()

            # 3. åˆå§‹åŒ–å…¬å¼€æ•°æ®æ”¶é›†å™¨
            await self._init_public_collector()

            # 4. åˆå§‹åŒ–OrderBook Managerï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enable_orderbook:
                await self._init_orderbook_manager()

            # 5. å¯åŠ¨æ•°æ®æ”¶é›†ä»»åŠ¡
            await self._start_collection_tasks()

            # 6. æ ‡è®°æœåŠ¡å·²åˆå§‹åŒ–
            self.is_initialized = True

            self.logger.info("ğŸ‰ æ•°æ®æ”¶é›†å™¨æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            self.logger.info(f"   - NATSå®¢æˆ·ç«¯: {'âœ…' if self.nats_client else 'âŒ'}")
            self.logger.info(f"   - æ•°æ®æ”¶é›†å™¨: {'âœ…' if self.public_collector else 'âŒ'}")
            self.logger.info(f"   - æ•°æ®æ ‡å‡†åŒ–å™¨: {'âœ…' if self.data_normalizer else 'âŒ'}")
            self.logger.info(f"   - OrderBookç®¡ç†å™¨: {'âœ…' if self.orderbook_manager else 'âŒ'}")
            self.logger.info(f"   - æ”¯æŒçš„äº¤æ˜“æ‰€: {', '.join(self.supported_exchanges)}")

        except Exception as e:
            self.logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            self.is_initialized = False
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸æœåŠ¡ä»¥é™çº§æ¨¡å¼è¿è¡Œ
            self.logger.warning("æœåŠ¡å°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ")

    async def _init_data_normalizer(self):
        """åˆå§‹åŒ–æ•°æ®æ ‡å‡†åŒ–å™¨"""
        try:
            if DataNormalizer:
                self.data_normalizer = DataNormalizer()
                self.logger.info("âœ… æ•°æ®æ ‡å‡†åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.logger.warning("âš ï¸ æ•°æ®æ ‡å‡†åŒ–å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡åˆå§‹åŒ–")
        except Exception as e:
            self.logger.error(f"æ•°æ®æ ‡å‡†åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

    async def _init_nats_client(self):
        """åˆå§‹åŒ–NATSå®¢æˆ·ç«¯"""
        try:
            if not self.nats_config.get('enabled', True):
                self.logger.info("âš ï¸ NATSå®¢æˆ·ç«¯å·²ç¦ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return

            servers = self.nats_config.get('servers', ['nats://localhost:4222'])

            # ä½¿ç”¨æœ€ç®€å•çš„è¿æ¥æ–¹å¼ï¼Œé¿å…asyncioå…¼å®¹æ€§é—®é¢˜
            self.nats_client = await nats.connect(servers=servers)
            self.logger.info(f"âœ… NATSå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ: {servers}")

        except Exception as e:
            self.logger.error(f"âŒ NATSå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            # å°è¯•é™çº§åˆ°æ‰‹åŠ¨NATSæ¨é€
            self.logger.info("âš ï¸ å°†ä½¿ç”¨HTTP APIè¿›è¡ŒNATSæ¨é€")
            self.nats_client = None

    async def _init_public_collector(self):
        """åˆå§‹åŒ–å…¬å¼€æ•°æ®æ”¶é›†å™¨"""
        try:
            if not PublicDataCollector:
                self.logger.warning("âš ï¸ å…¬å¼€æ•°æ®æ”¶é›†å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return

            # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
            config_path = self._find_config_file("public_data_sources.yaml")

            if config_path and config_path.exists():
                self.public_collector = PublicDataCollector(str(config_path))
                self.logger.info(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨: {config_path}")
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                self.public_collector = PublicDataCollector(None)
                self.logger.warning("âš ï¸ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨")

            if self.public_collector:
                # æ·»åŠ æ•°æ®å›è°ƒ
                self.public_collector.add_data_callback(self._on_data_received)
                self.logger.info("âœ… æ•°æ®æ”¶é›†å™¨å›è°ƒè®¾ç½®å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å…¬å¼€æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.public_collector = None

    async def _start_collection_tasks(self):
        """å¯åŠ¨æ•°æ®æ”¶é›†ä»»åŠ¡"""
        try:
            if self.public_collector:
                # å¯åŠ¨æ•°æ®æ”¶é›†
                collection_task = asyncio.create_task(self.public_collector.start())
                self.logger.info("âœ… æ•°æ®æ”¶é›†ä»»åŠ¡å¯åŠ¨æˆåŠŸ")

                # å¯åŠ¨ç»Ÿè®¡æ›´æ–°ä»»åŠ¡
                stats_task = asyncio.create_task(self._update_stats_periodically())
                self.logger.info("âœ… ç»Ÿè®¡æ›´æ–°ä»»åŠ¡å¯åŠ¨æˆåŠŸ")

                # å¯åŠ¨Deribitä¸“é—¨æ•°æ®æ”¶é›†ä»»åŠ¡
                deribit_task = asyncio.create_task(self._start_deribit_collection())
                self.logger.info("âœ… Deribitæ•°æ®æ”¶é›†ä»»åŠ¡å¯åŠ¨æˆåŠŸ")

            else:
                self.logger.warning("âš ï¸ æ•°æ®æ”¶é›†å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å¯åŠ¨æ”¶é›†ä»»åŠ¡")

        except Exception as e:
            self.logger.error(f"å¯åŠ¨æ•°æ®æ”¶é›†ä»»åŠ¡å¤±è´¥: {e}")

    async def _start_deribit_collection(self):
        """å¯åŠ¨Deribitä¸“é—¨æ•°æ®æ”¶é›†"""
        try:
            # æš‚æ—¶ç¦ç”¨Deribitæ”¶é›†ï¼Œé¿å…å¯¼å…¥é—®é¢˜
            self.logger.info("âš ï¸ Deribitæ•°æ®æ”¶é›†æš‚æ—¶ç¦ç”¨ï¼ˆå¯¼å…¥é—®é¢˜ä¿®å¤ä¸­ï¼‰")
            return

            # TODO: ä¿®å¤Deribitå¯¼å…¥é—®é¢˜åé‡æ–°å¯ç”¨
            # ç®€åŒ–çš„Deribitæ•°æ®æ”¶é›†ä»»åŠ¡
            async def deribit_collection_task():
                """ç®€åŒ–çš„Deribitæ•°æ®æ”¶é›†ä»»åŠ¡"""
                while True:
                    try:
                        # æ¨¡æ‹ŸDeribitæ³¢åŠ¨ç‡æŒ‡æ•°æ”¶é›†
                        await asyncio.sleep(10)  # 10ç§’é—´éš”

                        # è¿™é‡Œåº”è¯¥è°ƒç”¨Deribit APIè·å–æ³¢åŠ¨ç‡æŒ‡æ•°
                        # æš‚æ—¶è·³è¿‡å®é™…APIè°ƒç”¨

                    except Exception as e:
                        self.logger.error("Deribitæ•°æ®æ”¶é›†é”™è¯¯", error=str(e))
                        await asyncio.sleep(30)  # é”™è¯¯åç­‰å¾…30ç§’

            # å¯åŠ¨Deribitæ”¶é›†ä»»åŠ¡
            deribit_task = asyncio.create_task(deribit_collection_task())

            # åˆ›å»ºDeribité€‚é…å™¨
            deribit_config = {
                'base_url': 'https://www.deribit.com',
                'rate_limit': 10,  # æ¯ç§’10ä¸ªè¯·æ±‚
                'timeout': 30
            }

            deribit_adapter = DeribitAdapter(deribit_config)

            # å®šæœŸæ”¶é›†æ³¢åŠ¨ç‡æŒ‡æ•°æ•°æ®
            while True:
                try:
                    # æ”¶é›†BTCæ³¢åŠ¨ç‡æŒ‡æ•°
                    btc_volatility = await deribit_adapter.get_volatility_index_data('BTC')
                    if btc_volatility and 'result' in btc_volatility and btc_volatility['result']:
                        latest_btc = btc_volatility['result'][-1]
                        normalized_btc = {
                            'exchange': 'deribit',
                            'currency': 'BTC',
                            'symbol': 'BTC_USD',
                            'volatility': latest_btc.get('volatility', 0),
                            'timestamp': datetime.now(timezone.utc).isoformat()
                        }
                        # NATSæ¨é€å·²ç§»è‡³æ–°çš„å¤šå¸‚åœºOrderBook Manager

                    # æ”¶é›†ETHæ³¢åŠ¨ç‡æŒ‡æ•°
                    eth_volatility = await deribit_adapter.get_volatility_index_data('ETH')
                    if eth_volatility and 'result' in eth_volatility and eth_volatility['result']:
                        latest_eth = eth_volatility['result'][-1]
                        normalized_eth = {
                            'exchange': 'deribit',
                            'currency': 'ETH',
                            'symbol': 'ETH_USD',
                            'volatility': latest_eth.get('volatility', 0),
                            'timestamp': datetime.now(timezone.utc).isoformat()
                        }
                        # NATSæ¨é€å·²ç§»è‡³æ–°çš„å¤šå¸‚åœºOrderBook Manager

                    self.logger.debug("âœ… Deribitæ³¢åŠ¨ç‡æŒ‡æ•°æ•°æ®æ”¶é›†å®Œæˆ")

                except Exception as e:
                    self.logger.error(f"âŒ Deribitæ•°æ®æ”¶é›†å¤±è´¥: {e}")

                # ç­‰å¾…10ç§’å†æ¬¡æ”¶é›†
                await asyncio.sleep(10)

        except Exception as e:
            self.logger.error(f"âŒ Deribitæ•°æ®æ”¶é›†ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")

    def _find_config_file(self, filename: str) -> Optional[Path]:
        """æŸ¥æ‰¾é…ç½®æ–‡ä»¶"""
        possible_paths = [
            project_root / "config" / filename,
            Path("/app/config") / filename,
            Path("./config") / filename,
            Path(f"./{filename}")
        ]

        for path in possible_paths:
            if path.exists():
                return path

        return None

    async def _init_orderbook_manager(self):
        """åˆå§‹åŒ–OrderBook Manager"""
        try:
            # æ£€æŸ¥ä¾èµ–æ¨¡å—
            if not Exchange or not ExchangeConfig:
                self.logger.warning("âš ï¸ OrderBookç›¸å…³æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡OrderBook Manageråˆå§‹åŒ–")
                return

            try:
                from .orderbook_manager import OrderBookManager
            except ImportError as e:
                self.logger.warning(f"âš ï¸ OrderBook Manageræ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡åˆå§‹åŒ–: {e}")
                return

            # åˆ›å»ºå¤šå¸‚åœºOrderBook Manageré…ç½®
            # æ¯ä¸ªsymboléœ€è¦4ä¸ªè®¢å•ç°¿ï¼šBinanceç°è´§/æ°¸ç»­ + OKXç°è´§/æ°¸ç»­
            orderbook_configs = [
                # Binanceç°è´§
                {
                    'exchange': Exchange.BINANCE,
                    'market_type': 'spot',
                    'base_url': 'https://api.binance.com',
                    'ws_url': 'wss://stream.binance.com:9443',
                    'symbols': ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']
                },
                # BinanceæœŸè´§
                {
                    'exchange': Exchange.BINANCE,
                    'market_type': 'futures',
                    'base_url': 'https://fapi.binance.com',
                    'ws_url': 'wss://fstream.binance.com',
                    'symbols': ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']
                },
                # OKXç°è´§
                {
                    'exchange': Exchange.OKX,
                    'market_type': 'spot',
                    'base_url': 'https://www.okx.com',
                    'ws_url': 'wss://ws.okx.com:8443/ws/v5/public',
                    'symbols': ['BTC-USDT', 'ETH-USDT', 'BNB-USDT']
                },
                # OKXæ°¸ç»­
                {
                    'exchange': Exchange.OKX,
                    'market_type': 'perpetual',
                    'base_url': 'https://www.okx.com',
                    'ws_url': 'wss://ws.okx.com:8443/ws/v5/public',
                    'symbols': ['BTC-USDT-SWAP', 'ETH-USDT-SWAP', 'BNB-USDT-SWAP']
                }
            ]

            # åˆ›å»ºå¤šä¸ªOrderBook Managerå®ä¾‹
            if self.data_normalizer:
                self.orderbook_managers = []

                for config in orderbook_configs:
                    # åˆ›å»ºExchangeConfigå¯¹è±¡
                    exchange_config = ExchangeConfig(
                        exchange=config['exchange'],
                        market_type=config['market_type'],
                        base_url=config['base_url'],
                        ws_url=config['ws_url'],
                        snapshot_interval=60,
                        symbols=config['symbols']
                    )

                    # åˆ›å»ºOrderBook Managerå®ä¾‹
                    manager = OrderBookManager(exchange_config, self.data_normalizer, self.nats_client)
                    self.orderbook_managers.append(manager)

                    # å¯åŠ¨OrderBook Manager
                    manager_name = f"{config['exchange'].value}_{config['market_type']}"
                    orderbook_task = asyncio.create_task(manager.start(config['symbols']))
                    self.logger.info(f"âœ… OrderBook Managerå¯åŠ¨æˆåŠŸ: {manager_name}")

                self.logger.info(f"ğŸ‰ æ‰€æœ‰OrderBook Managerå¯åŠ¨å®Œæˆï¼Œå…±{len(self.orderbook_managers)}ä¸ªå®ä¾‹")
            else:
                self.logger.warning("âš ï¸ æ•°æ®æ ‡å‡†åŒ–å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¯åŠ¨OrderBook Manager")

        except Exception as e:
            self.logger.error(f"OrderBook Managerå¯åŠ¨å¤±è´¥: {e}")
            self.orderbook_manager = None
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸æœåŠ¡ç»§ç»­è¿è¡Œ

    async def _register_orderbook_callbacks(self):
        """æ³¨å†ŒOrderBook Managerçš„å›è°ƒåˆ°WebSocketå®¢æˆ·ç«¯"""
        try:
            if not self.orderbook_manager:
                return

            # æ£€æŸ¥æ˜¯å¦æœ‰äº¤æ˜“æ‰€å®¢æˆ·ç«¯
            if hasattr(self, 'exchange_clients') and self.exchange_clients:
                # ä¸ºæ¯ä¸ªäº¤æ˜“æ‰€æ³¨å†Œæ·±åº¦æ•°æ®å›è°ƒ
                for exchange_name, exchange_client in self.exchange_clients.items():
                    if hasattr(exchange_client, 'add_raw_callback'):
                        # æ³¨å†Œæ·±åº¦æ•°æ®å›è°ƒ
                        exchange_client.add_raw_callback('depth', self._handle_raw_depth_data)
                        self.logger.info(f"âœ… å·²ä¸º{exchange_name}æ³¨å†ŒOrderBookå›è°ƒ")
                    else:
                        self.logger.warning(f"âš ï¸ {exchange_name}ä¸æ”¯æŒåŸå§‹æ•°æ®å›è°ƒ")
            else:
                self.logger.info("âš ï¸ æš‚æ—¶è·³è¿‡OrderBookå›è°ƒæ³¨å†Œï¼Œå°†åœ¨äº¤æ˜“æ‰€å®¢æˆ·ç«¯åˆ›å»ºåæ³¨å†Œ")

        except Exception as e:
            self.logger.error(f"æ³¨å†ŒOrderBookå›è°ƒå¤±è´¥: {e}")

    async def _handle_raw_depth_data(self, exchange: str, symbol: str, raw_data: Dict[str, Any]):
        """å¤„ç†æ¥è‡ªWebSocketçš„åŸå§‹æ·±åº¦æ•°æ®"""
        try:
            if self.orderbook_manager:
                # å°†åŸå§‹æ•°æ®ä¼ é€’ç»™OrderBook Manager
                await self.orderbook_manager.handle_update(symbol, raw_data)
        except Exception as e:
            self.logger.error(f"å¤„ç†åŸå§‹æ·±åº¦æ•°æ®å¤±è´¥: {e}",
                            exchange=exchange, symbol=symbol)

    async def _update_stats_periodically(self):
        """å®šæœŸæ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        while True:
            try:
                await asyncio.sleep(self.collection_interval)

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.collected_data['stats']['total_collections'] += 1
                self.collected_data['stats']['last_collection_time'] = datetime.now(timezone.utc).isoformat()

                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                if self.collected_data['stats']['total_collections'] % 10 == 0:
                    self.logger.info(f"æ•°æ®æ”¶é›†ç»Ÿè®¡: æ€»æ¬¡æ•°={self.collected_data['stats']['total_collections']}, "
                                   f"é”™è¯¯æ¬¡æ•°={self.collected_data['stats']['error_count']}")

            except Exception as e:
                self.logger.error(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                self.collected_data['stats']['error_count'] += 1
                await asyncio.sleep(5)  # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…

    async def _on_data_received(self, data_type: str, exchange: str, data: Dict[str, Any]):
        """
        æ•°æ®æ¥æ”¶å›è°ƒ - æ ‡å‡†åŒ–å¹¶æ¨é€åˆ°NATS

        Args:
            data_type: æ•°æ®ç±»å‹ (orderbook, trade)
            exchange: äº¤æ˜“æ‰€åç§°
            data: æ¥æ”¶åˆ°çš„åŸå§‹æ•°æ®
        """
        try:
            if not data:
                self.logger.warning("æ¥æ”¶åˆ°ç©ºæ•°æ®ï¼Œè·³è¿‡å¤„ç†")
                return

            # æ•°æ®æ ‡å‡†åŒ–
            normalized_data = self._normalize_data(data_type, exchange, data)

            # å­˜å‚¨æ•°æ®åˆ°å†…å­˜
            self._store_data(data_type, exchange, normalized_data)

            # æ³¨æ„ï¼šNATSæ¨é€å·²ç§»è‡³æ–°çš„å¤šå¸‚åœºOrderBook Managerï¼Œé¿å…é‡å¤æ¨é€

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.collected_data['stats']['total_collections'] += 1

        except Exception as e:
            self.logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {e}", exc_info=True)
            self.collected_data['stats']['error_count'] += 1

    def _normalize_data(self, data_type: str, exchange: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–æ•°æ®"""
        try:
            if self.data_normalizer:
                return self.data_normalizer.normalize(data, data_type, exchange)
            else:
                # åŸºç¡€æ ‡å‡†åŒ–
                return {
                    **data,
                    'data_type': data_type,
                    'exchange': exchange,
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'source': 'data-collector',
                    'normalized': False
                }
        except Exception as e:
            self.logger.warning(f"æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return {
                **data,
                'data_type': data_type,
                'exchange': exchange,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'source': 'data-collector',
                'normalized': False,
                'normalization_error': str(e)
            }

    def _store_data(self, data_type: str, exchange: str, normalized_data: Dict[str, Any]):
        """å­˜å‚¨æ•°æ®åˆ°å†…å­˜"""
        try:
            symbol = normalized_data.get('symbol', 'unknown')
            key = f"{exchange}:{symbol}"

            # æ ¹æ®æ•°æ®ç±»å‹å­˜å‚¨
            # æ ¹æ®æ•°æ®ç±»å‹å­˜å‚¨åˆ°å¯¹åº”çš„åˆ†ç±»ä¸­
            data_type_mapping = {
                'orderbook': 'orderbooks',
                'trade': 'trades',
                'kline': 'klines',
                'funding_rate': 'funding_rates',
                'open_interest': 'open_interest',
                'volatility_index': 'volatility_index',
                'top_trader_ratio': 'top_trader_ratio',
                'global_long_short_ratio': 'global_long_short_ratio',
                'liquidation': 'liquidations'
            }

            storage_key = data_type_mapping.get(data_type)
            if storage_key:
                self.collected_data[storage_key][key] = normalized_data
            else:
                # å¯¹äºæœªçŸ¥æ•°æ®ç±»å‹ï¼Œå­˜å‚¨åˆ°é€šç”¨ä½ç½®
                if 'other' not in self.collected_data:
                    self.collected_data['other'] = {}
                self.collected_data['other'][key] = normalized_data
                self.logger.debug(f"å­˜å‚¨æœªçŸ¥æ•°æ®ç±»å‹: {data_type}")

            # é™åˆ¶å†…å­˜ä½¿ç”¨ï¼Œä¿ç•™æœ€æ–°çš„1000æ¡è®°å½•
            data_categories = ['orderbooks', 'trades', 'klines', 'funding_rates',
                             'open_interest', 'volatility_index', 'top_trader_ratio',
                             'global_long_short_ratio', 'liquidations', 'other']

            for data_category in data_categories:
                if data_category in self.collected_data and len(self.collected_data[data_category]) > 1000:
                    # åˆ é™¤æœ€æ—§çš„è®°å½•
                    oldest_key = next(iter(self.collected_data[data_category]))
                    del self.collected_data[data_category][oldest_key]

        except Exception as e:
            self.logger.error(f"æ•°æ®å­˜å‚¨å¤±è´¥: {e}")



    async def on_shutdown(self):
        """æœåŠ¡å…³é—­æ¸…ç†"""
        self.logger.info("å¼€å§‹å…³é—­æ•°æ®æ”¶é›†å™¨æœåŠ¡...")

        shutdown_tasks = []

        try:
            # 1. åœæ­¢å…¬å¼€æ•°æ®æ”¶é›†å™¨
            if self.public_collector:
                try:
                    await asyncio.wait_for(self.public_collector.stop(), timeout=10.0)
                    self.logger.info("âœ… å…¬å¼€æ•°æ®æ”¶é›†å™¨å·²åœæ­¢")
                except asyncio.TimeoutError:
                    self.logger.warning("âš ï¸ å…¬å¼€æ•°æ®æ”¶é›†å™¨åœæ­¢è¶…æ—¶")
                except Exception as e:
                    self.logger.error(f"âŒ åœæ­¢å…¬å¼€æ•°æ®æ”¶é›†å™¨å¤±è´¥: {e}")

            # 2. åœæ­¢OrderBook Manager(s)
            if hasattr(self, 'orderbook_managers') and self.orderbook_managers:
                # æ–°çš„å¤šå®ä¾‹æ¶æ„
                for i, manager in enumerate(self.orderbook_managers):
                    try:
                        await asyncio.wait_for(manager.stop(), timeout=10.0)
                        self.logger.info(f"âœ… OrderBook Manager {i+1} å·²åœæ­¢")
                    except asyncio.TimeoutError:
                        self.logger.warning(f"âš ï¸ OrderBook Manager {i+1} åœæ­¢è¶…æ—¶")
                    except Exception as e:
                        self.logger.error(f"âŒ åœæ­¢OrderBook Manager {i+1} å¤±è´¥: {e}")
            elif hasattr(self, 'orderbook_manager') and self.orderbook_manager:
                # æ—§çš„å•å®ä¾‹æ¶æ„ï¼ˆå‘åå…¼å®¹ï¼‰
                try:
                    await asyncio.wait_for(self.orderbook_manager.stop(), timeout=10.0)
                    self.logger.info("âœ… OrderBook Managerå·²åœæ­¢")
                except asyncio.TimeoutError:
                    self.logger.warning("âš ï¸ OrderBook Manageråœæ­¢è¶…æ—¶")
                except Exception as e:
                    self.logger.error(f"âŒ åœæ­¢OrderBook Managerå¤±è´¥: {e}")

            # 3. å…³é—­NATSè¿æ¥
            if self.nats_client:
                try:
                    await self.nats_client.close()
                    self.logger.info("âœ… NATSå®¢æˆ·ç«¯å·²å…³é—­")
                except Exception as e:
                    self.logger.error(f"âŒ å…³é—­NATSå®¢æˆ·ç«¯å¤±è´¥: {e}")

            # 4. æ¸…ç†æ•°æ®
            self._cleanup_data()

            # 5. æ ‡è®°æœåŠ¡å·²å…³é—­
            self.is_initialized = False

        except Exception as e:
            self.logger.error(f"æœåŠ¡å…³é—­æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        finally:
            self.logger.info("ğŸ”š æ•°æ®æ”¶é›†å™¨æœåŠ¡å·²å…³é—­")

    def _cleanup_data(self):
        """æ¸…ç†æ•°æ®å’Œèµ„æº"""
        try:
            # æ¸…ç†å†…å­˜ä¸­çš„æ•°æ®
            self.collected_data = {
                'orderbooks': {},
                'trades': {},
                'stats': {
                    'total_collections': 0,
                    'last_collection_time': None,
                    'error_count': 0
                }
            }

            # é‡ç½®ç»„ä»¶å¼•ç”¨
            self.public_collector = None
            self.orderbook_manager = None

            self.logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")
