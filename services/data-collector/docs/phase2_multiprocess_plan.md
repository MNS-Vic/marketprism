# Phase 2 多进程改造开发计划

## 📋 项目概述

**目标**：将 data-collector 从单进程改造为多进程架构，按交易所拆分进程，降低 GIL 瓶颈和数据采集延迟

**背景**：
- Phase 1 优化（orjson + uvloop）已将 CPU 占用率从 97-100% 降低到 42-63%
- 但仍存在单核心瓶颈（某个核心周期性达到 100%），这是 Python GIL 的限制
- 多进程改造可以进一步降低延迟 20-30%，提高系统吞吐量

**预期收益**：
- ✅ **CPU 占用率**：103.86% → 80-90%（分布在 4 个核心上，单核心不再饱和）
- ✅ **单核心峰值**：100% → 60-70%（消除 GIL 瓶颈）
- ✅ **数据延迟**：降低 20-30%（OrderBook 0.30ms → 0.20-0.25ms，Trade 0.17ms → 0.12-0.15ms）
- ✅ **P99 延迟**：降低 40-50%（5-10ms → 2-5ms）
- ✅ **故障隔离**：单个交易所故障不影响其他交易所
- ✅ **可扩展性**：新增交易所时只需增加一个子进程

**代价**：
- ❌ **内存占用**：增加 72%（418.8MB → 720MB 硬限制）
- ❌ **复杂度**：调试和部署复杂度增加（但有完善的日志和监控）
- ❌ **指标聚合**：增加 1-5ms 延迟（但不影响数据采集主流程）

**投入产出比**：
- 开发时间：8 天
- 性能提升：CPU 降低 20%，延迟降低 20-30%
- 稳定性提升：故障隔离，单点故障不影响全局
- 可维护性：日志更清晰，问题定位更快

---

## 🏗️ 架构设计

### 进程拆分策略

按交易所拆分为 **5 个子进程**（基于实际资源需求优化）：

| 进程 ID | 交易所 | 数据类型 | 预期 CPU | 预期内存 | 优先级 | 说明 |
|---------|--------|----------|----------|----------|--------|------|
| 1 | okx_derivatives | orderbook, trade, funding_rate, open_interest, liquidation, LSR | 30-35% | 120-150MB | 🔴 最高 | OrderBook 更新频率最高 |
| 2 | okx_spot | orderbook, trade | 25-30% | 100-120MB | 🔴 高 | OrderBook 更新频率高 |
| 3 | binance_derivatives | orderbook, trade, funding_rate, open_interest, liquidation, LSR | 20-25% | 80-100MB | 🟡 中 | OrderBook 更新频率中等 |
| 4 | binance_spot | orderbook, trade | 15-20% | 60-80MB | 🟡 中 | OrderBook 更新频率中等 |
| 5 | deribit_derivatives | volatility_index | 5-10% | 40-60MB | 🟢 低 | 仅 REST API，低频数据 |

**资源分配原则**：
- **OKX 优先**：OKX 的 OrderBook 更新频率最高，分配更多 CPU 和内存资源
- **Binance 次之**：Binance 的 OrderBook 更新频率次之，分配中等资源
- **Deribit 最低**：Deribit 仅使用 REST API 采集低频数据，分配最少资源

**当前单进程资源使用**（基准）：
- CPU：103.86%（单核心饱和）
- 内存：418.8MB / 3GB（13.63%）
- 进程数：9 个线程

**主进程**：
- 启动和监控 5 个子进程
- 聚合指标和健康检查
- 提供统一的 HTTP 接口（8087/health, 9092/metrics）

### 进程间通信（IPC）

使用 `multiprocessing.Pipe` 实现双向通信：

```
主进程 <--Pipe--> 子进程 1 (binance_spot)
       <--Pipe--> 子进程 2 (binance_derivatives)
       <--Pipe--> 子进程 3 (okx_spot)
       <--Pipe--> 子进程 4 (okx_derivatives)
       <--Pipe--> 子进程 5 (deribit_derivatives)
```

**消息类型**：
1. **指标消息**（子进程 → 主进程）：CPU、内存、数据计数、错误计数
2. **健康检查消息**（子进程 → 主进程）：健康状态、最后成功时间
3. **控制消息**（主进程 → 子进程）：重启、停止、配置更新

### 故障隔离与自动重启

- **故障隔离**：每个子进程独立运行，崩溃不影响其他进程
- **自动重启**：主进程监控子进程状态，崩溃后自动重启
- **重启策略**：
  - 立即重启（第 1 次）
  - 延迟 5 秒重启（第 2-3 次）
  - 延迟 30 秒重启（第 4+ 次）
  - 超过 10 次重启则标记为永久失败，发送告警

### 资源限制策略

#### 内存限制（软限制 + 硬限制）

**设计原则**：
- 服务器专为 MarketPrism 服务，内存配额可适当放宽
- 设置软限制（警告阈值）和硬限制（强制重启阈值）
- 在达到系统 OOM 之前主动重启异常进程

| 进程 | 内存软限制 | 内存硬限制 | 说明 |
|------|-----------|-----------|------|
| okx_derivatives | 150MB | 200MB | 高频 OrderBook，需要更多缓冲 |
| okx_spot | 120MB | 160MB | 高频 OrderBook |
| binance_derivatives | 100MB | 140MB | 中频 OrderBook |
| binance_spot | 80MB | 120MB | 中频 OrderBook |
| deribit_derivatives | 60MB | 100MB | 低频 REST API |
| **总计** | **510MB** | **720MB** | 当前单进程：418.8MB |

**内存监控策略**：
- **软限制触发**：记录警告日志，发送告警通知
- **硬限制触发**：优雅停止进程，等待 5 秒后自动重启
- **OOM 预防**：硬限制总和（720MB）远低于 Docker 限制（4GB）

#### 动态资源调节（Phase 2.5 可选增强）

**设计思路**：
- 根据实际负载动态调整各子进程的 CPU/内存配额
- 高负载交易所（如 OKX）自动获得更多资源
- 低负载交易所（如 Deribit）自动释放资源

**实现方案**（可选，Phase 2 不包含）：
1. **监控指标**：
   - 每个子进程的 CPU 使用率、内存使用率
   - WebSocket 消息接收速率
   - NATS 发布速率

2. **调节策略**：
   - CPU 使用率 > 80% 持续 5 分钟 → 增加 CPU 配额 10%
   - 内存使用率 > 80% 持续 5 分钟 → 增加内存软限制 10%
   - CPU 使用率 < 30% 持续 10 分钟 → 减少 CPU 配额 10%

3. **约束条件**：
   - 总 CPU 配额不超过 4 核心
   - 总内存配额不超过 3GB
   - 单个进程 CPU 配额范围：0.2 - 1.5 核心
   - 单个进程内存配额范围：50MB - 300MB

**结论**：Phase 2 使用静态资源分配，Phase 2.5 可考虑动态调节

#### 其他资源限制

| 资源 | 单进程配额 | 总配额 | 说明 |
|------|-----------|--------|------|
| WebSocket 连接 | 10-20 | 80 | 按交易所数据类型数量分配 |
| NATS 连接 | 1 | 5 | 每个子进程独立连接 |
| 文件描述符 | 200 | 1000 | 包括日志文件、网络连接等 |
| CPU 配额 | 0.8 核心 | 4 核心 | 使用 Docker cpus 限制 |

### 向后兼容

通过配置开关支持单进程模式，作为降级选项：

```bash
# 多进程模式（默认）
python main.py

# 单进程模式（降级）
python main.py --single-process
```

---

## � 与现有架构的兼容性分析

### 端口分配（无冲突）

**README 规定的固定端口**：
- NATS: 4222（客户端）、8222（监控/健康）
- 热存储服务: 8085（/health）
- **采集器: 8087（/health）、9092（/metrics）** ← 本服务
- 冷存储服务: 8086（/health）
- ClickHouse: 8123（HOT HTTP）、8124（COLD HTTP 映射）

**多进程架构的端口使用**：
- ✅ **主进程**：继续使用 8087（健康检查）、9092（指标）
- ✅ **子进程**：不需要独立 HTTP 端口，通过 IPC 与主进程通信
- ✅ **对外接口**：完全不变，无需修改 README 或其他服务配置

**结论**：✅ **无端口冲突，无需修改 README 端口规定**

---

### Docker 配置（需小幅调整）

**当前配置**（`docker-compose.unified.yml`）：
```yaml
mem_limit: 3G
mem_reservation: 512M
# CPU 无限制
ports:
  - "8087:8087"  # 健康检查端口
  - "9092:9092"  # Prometheus metrics 端口
```

**多进程架构需要的调整**：
```yaml
mem_limit: 4G          # 3G → 4G（增加 1GB）
mem_reservation: 1G    # 512M → 1G（提高预留）
# CPU 无限制（保持不变，多进程可充分利用多核）
ports:
  - "8087:8087"  # 健康检查端口（不变）
  - "9092:9092"  # Prometheus metrics 端口（不变）
```

**调整理由**：
- 多进程内存硬限制总和：720MB
- 系统开销 + 临时峰值：~300MB
- 总需求：~1GB（当前单进程：418.8MB）
- 设置 4GB 留有 3GB 余量，足够安全

**结论**：✅ **仅需调整内存限制，其他配置保持不变**

---

### 配置文件（无需修改）

**当前配置文件**：
- `services/data-collector/config/collector/unified_data_collection.yaml`
- 包含所有交易所和数据类型的配置

**多进程架构的配置使用**：
- ✅ **主进程**：加载完整配置，按交易所拆分后分配给子进程
- ✅ **子进程**：只加载分配给自己的交易所配置
- ✅ **配置过滤**：在 main.py 中实现，根据 `--exchange` 参数过滤

**结论**：✅ **无需修改配置文件，保持唯一配置原则**

---

### 启动方式（向后兼容）

**当前启动方式**（单进程）：
```bash
# Docker 方式
docker compose -f docker-compose.unified.yml up -d

# 直接运行方式
python main.py --mode launcher
```

**多进程架构的启动方式**：
```bash
# Docker 方式（默认多进程）
docker compose -f docker-compose.unified.yml up -d

# 直接运行方式（默认多进程）
python main.py --mode launcher

# 降级到单进程（兼容模式）
python main.py --mode launcher --single-process
```

**结论**：✅ **完全向后兼容，默认启用多进程，支持降级到单进程**

---

### 监控和健康检查（接口不变）

**当前接口**：
- `http://localhost:8087/health` - 健康检查
- `http://localhost:9092/metrics` - Prometheus 指标

**多进程架构的接口**：
- ✅ **主进程**：聚合所有子进程的健康状态和指标
- ✅ **响应格式**：保持不变，增加子进程详情（可选）
- ✅ **兼容性**：现有监控系统无需修改

**健康检查响应示例**（多进程）：
```json
{
  "status": "healthy",
  "uptime_seconds": 3600,
  "mode": "multiprocess",
  "processes": {
    "okx_derivatives": {"status": "healthy", "cpu": 32.5, "memory_mb": 145},
    "okx_spot": {"status": "healthy", "cpu": 28.1, "memory_mb": 115},
    "binance_derivatives": {"status": "healthy", "cpu": 22.3, "memory_mb": 95},
    "binance_spot": {"status": "healthy", "cpu": 18.7, "memory_mb": 75},
    "deribit_derivatives": {"status": "healthy", "cpu": 8.2, "memory_mb": 55}
  },
  "services": { /* 现有格式保持不变 */ }
}
```

**结论**：✅ **接口完全兼容，增加子进程详情（可选）**

---

### 日志和调试（增强但兼容）

**当前日志**：
- 单一日志文件：`logs/unified-collector.log`

**多进程架构的日志**：
- ✅ **主进程日志**：`logs/collector_main.log`
- ✅ **子进程日志**：`logs/collector_<exchange>.log`（5 个文件）
- ✅ **聚合日志**：主进程日志包含所有子进程的关键事件
- ✅ **向后兼容**：保留 `logs/unified-collector.log` 作为主进程日志的软链接

**结论**：✅ **日志更详细，但保持向后兼容**

---

## �📅 开发计划

### 阶段 1：架构设计与技术调研（1 天）

- [x] 1.1 设计进程拆分策略
- [ ] 1.2 设计进程间通信机制
- [ ] 1.3 设计故障隔离与自动重启
- [ ] 1.4 设计资源限制策略
- [ ] 1.5 设计向后兼容方案
- [ ] 1.6 绘制架构图和流程图
- [ ] 1.7 风险评估与缓解方案

**交付物**：
- 架构设计文档（本文档）
- Mermaid 架构图
- 风险评估报告

---

### 阶段 2：核心组件开发（2 天）

- [ ] 2.1 开发进程管理器 ProcessManager
  - 子进程启动、监控、重启逻辑
  - 文件：`collector/process_manager.py`
  
- [ ] 2.2 开发指标聚合器 MetricsAggregator
  - 使用 multiprocessing.Pipe 收集子进程指标
  - 文件：`collector/metrics_aggregator.py`
  
- [ ] 2.3 开发健康检查聚合器 HealthAggregator
  - 从所有子进程收集健康状态
  - 文件：`collector/health_aggregator.py`
  
- [ ] 2.4 开发进程间通信协议
  - 定义消息格式：指标消息、健康检查消息、控制消息
  - 文件：`collector/ipc_protocol.py`
  
- [ ] 2.5 开发资源管理器 ResourceManager
  - 为每个子进程分配内存/连接数配额
  - 文件：`collector/resource_manager.py`

**交付物**：
- 5 个核心组件模块
- 单元测试（覆盖率 > 80%）

---

### 阶段 3：主进程改造（1.5 天）

- [ ] 3.1 修改 main.py 支持 --exchange 参数
  - 添加命令行参数，支持指定单个交易所运行（子进程模式）
  
- [ ] 3.2 实现主进程模式
  - 主进程启动 5 个子进程，每个子进程负责一个交易所
  
- [ ] 3.3 实现子进程模式
  - 子进程只加载指定交易所的配置和管理器
  
- [ ] 3.4 修改 HTTP 服务器
  - 主进程：聚合所有子进程的指标和健康状态
  - 子进程：只返回本进程数据
  
- [ ] 3.5 实现配置过滤逻辑
  - 根据 --exchange 参数过滤 unified_data_collection.yaml 配置
  
- [ ] 3.6 添加单进程模式开关
  - 添加 --single-process 参数，支持降级到单进程模式

**交付物**：
- 修改后的 main.py
- 修改后的 http_server.py
- 集成测试

---

### 阶段 4：测试与验证（2 天）

#### 单元测试
- [ ] 4.1 测试进程管理器（启动、监控、重启）
- [ ] 4.2 测试指标聚合器（指标收集和聚合）
- [ ] 4.3 测试健康检查聚合器（健康状态收集和聚合）

#### 集成测试
- [ ] 4.4 测试单交易所模式（单个子进程运行）
- [ ] 4.5 测试多进程模式（5 个子进程同时运行）

#### 故障测试
- [ ] 4.6 模拟子进程崩溃，验证自动重启机制
- [ ] 4.7 模拟进程间通信失败，验证容错机制

#### 压力测试
- [ ] 4.8 运行 24 小时，监控 CPU、内存、延迟、错误率
- [ ] 4.9 对比单进程 vs 多进程的性能指标

**交付物**：
- 测试报告
- 性能对比报告
- 稳定性报告

---

### 阶段 5：部署与监控（1.5 天）

- [ ] 5.1 更新 Dockerfile（支持多进程模式，调整资源限制）
- [ ] 5.2 更新 docker-compose.yml（内存限制 3GB → 4-5GB）
- [ ] 5.3 更新 README.md（添加 Phase 2 文档）
- [ ] 5.4 更新 Grafana 监控面板（按进程展示 CPU/内存/延迟）
- [ ] 5.5 灰度发布：单交易所测试（先只启动 1 个子进程）
- [ ] 5.6 灰度发布：多交易所测试（逐步增加到 5 个子进程）
- [ ] 5.7 全量发布（更新生产环境）
- [ ] 5.8 监控与告警（设置多进程相关的监控告警）

**交付物**：
- 更新后的 Docker 配置
- 更新后的文档
- 更新后的监控面板
- 发布报告

---

## ⏱️ 时间估算

| 阶段 | 预计时间 | 依赖 |
|------|---------|------|
| 阶段 1：架构设计与技术调研 | 1 天 | - |
| 阶段 2：核心组件开发 | 2 天 | 阶段 1 |
| 阶段 3：主进程改造 | 1.5 天 | 阶段 2 |
| 阶段 4：测试与验证 | 2 天 | 阶段 3 |
| 阶段 5：部署与监控 | 1.5 天 | 阶段 4 |
| **总计** | **8 天** | - |

---

## 🎯 里程碑

- **M1（Day 1）**：架构设计完成，技术方案确定
- **M2（Day 3）**：核心组件开发完成，单元测试通过
- **M3（Day 4.5）**：主进程改造完成，集成测试通过
- **M4（Day 6.5）**：测试与验证完成，性能对比报告完成
- **M5（Day 8）**：部署与监控完成，全量发布

---

## ⚠️ 风险与缓解

### 风险 1：内存占用增加导致 OOM

**影响**：高
**概率**：低（已优化）
**缓解方案**：
- ✅ 为每个子进程设置软限制（警告）和硬限制（强制重启）
- ✅ 硬限制总和（720MB）远低于 Docker 限制（3GB），留有 2.3GB 余量
- ✅ 使用 ResourceManager 实时监控内存使用
- ✅ 超过软限制时触发告警，超过硬限制时自动重启
- ✅ 主进程监控所有子进程，异常时自动重启

### 风险 2：端口冲突

**影响**：中
**概率**：低（已规避）
**现状分析**：
- ✅ README 明确规定：8087（健康检查）、9092（指标）为固定端口
- ✅ 多进程架构**不引入新端口**：主进程继续使用 8087/9092
- ✅ 子进程不需要独立 HTTP 端口，通过 IPC 与主进程通信
**缓解方案**：
- 主进程聚合所有子进程的指标和健康状态
- 子进程通过 Pipe 发送数据到主进程
- 保持对外接口不变，无需修改 README 端口规定

### 风险 3：调试复杂度增加

**影响**：中
**概率**：高
**缓解方案**：
- ✅ 每个子进程独立日志文件（`logs/collector_<exchange>.log`）
- ✅ 添加进程 ID 和交易所名称到所有日志
- ✅ 开发调试工具脚本（`scripts/debug_multiprocess.sh`）
- ✅ 主进程日志聚合所有子进程的关键事件

### 风险 4：部署复杂度增加

**影响**：中
**概率**：中
**缓解方案**：
- ✅ 保留单进程模式作为降级选项（`--single-process`）
- ✅ 灰度发布，逐步验证稳定性（先 1 个子进程，再 5 个）
- ✅ 完善文档和运维手册
- ✅ Docker 配置保持简单，只需调整内存限制（3GB → 4GB）

### 风险 5：IPC 通信成为新瓶颈

**影响**：低
**概率**：低
**缓解方案**：
- ✅ 使用高效的 multiprocessing.Pipe（内核级通信）
- ✅ 异步非阻塞通信，不影响数据采集主流程
- ✅ 批量发送指标数据（每 10 秒一次）
- ✅ 健康检查按需查询（仅在 HTTP 请求时触发）

### 风险 6：Docker 资源限制不足

**影响**：中
**概率**：低（已规避）
**现状分析**：
- 当前 Docker 配置：`mem_limit: 3G`，`mem_reservation: 512M`
- 多进程预期内存：720MB（硬限制总和）
- 余量：3GB - 720MB = 2.3GB（足够）
**缓解方案**：
- ✅ 调整 Docker 内存限制为 4GB（保守估计）
- ✅ 保留 1GB 余量用于系统开销和临时峰值
- ✅ 不需要调整 CPU 限制（当前无限制，多进程可充分利用多核）

---

## 📊 成功标准

- ✅ CPU 占用率降低到 20-30%
- ✅ 数据延迟降低 20-30%
- ✅ P99 延迟降低 40-50%
- ✅ 24 小时稳定性测试通过（无崩溃、无内存泄漏）
- ✅ 单元测试覆盖率 > 80%
- ✅ 集成测试通过率 100%
- ✅ 文档完整（架构图、使用方法、故障排查）

---

## 📝 下一步行动

1. **确认开发计划**：与团队 review 本计划，确认技术方案
2. **开始阶段 1**：完成架构设计和技术调研
3. **每日站会**：同步进度，识别风险
4. **里程碑 review**：每个阶段完成后进行 review

---

**创建时间**：2025-10-22
**创建人**：Augment Agent
**状态**：待确认

