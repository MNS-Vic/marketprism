#!/usr/bin/env python3
"""
MarketPrismåºåˆ—éªŒè¯åˆ†æå™¨
ä¸“é—¨åˆ†æè®¢å•ç°¿åºåˆ—IDéªŒè¯å’Œæ›´æ–°çš„æ•ˆæœ
"""

import asyncio
import sys
import os
from pathlib import Path
from datetime import datetime, timezone
import logging
import time
from collections import defaultdict, deque

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SequenceValidationAnalyzer:
    """åºåˆ—éªŒè¯åˆ†æå™¨"""
    
    def __init__(self):
        self.validation_stats = defaultdict(lambda: {
            'total_updates': 0,
            'successful_validations': 0,
            'failed_validations': 0,
            'sequence_gaps': 0,
            'checksum_failures': 0,
            'reconnections': 0,
            'last_update_id': None,
            'sequence_history': deque(maxlen=100)
        })
        
        self.start_time = None
        self.is_running = False
        
    async def start_analysis(self, duration_seconds=60):
        """å¯åŠ¨åºåˆ—éªŒè¯åˆ†æ"""
        try:
            logger.info(f"ğŸ” å¼€å§‹åºåˆ—éªŒè¯åˆ†æï¼ŒæŒç»­æ—¶é—´: {duration_seconds}ç§’")
            
            # å¯¼å…¥å¿…è¦æ¨¡å—
            from services.data_collector.collector.orderbook_manager import OrderBookManager
            from core.messaging.nats_publisher import NATSPublisher
            import yaml
            
            # åŠ è½½é…ç½®
            config_path = project_root / "config" / "collector" / "unified_data_collection.yaml"
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # åˆå§‹åŒ–NATS
            nats_config = config.get('nats', {})
            nats_servers = nats_config.get('servers', ['nats://localhost:4222'])
            nats_publisher = NATSPublisher(servers=nats_servers)
            await nats_publisher.connect()
            
            # åˆ›å»ºåˆ†æå›è°ƒå‡½æ•°
            def create_analysis_callback(exchange_name, market_type):
                def analysis_callback(symbol, data):
                    self._analyze_update(exchange_name, market_type, symbol, data)
                return analysis_callback
            
            # å¯åŠ¨å„äº¤æ˜“æ‰€çš„è®¢å•ç°¿ç®¡ç†å™¨
            managers = []
            exchanges_config = config.get('exchanges', {})
            
            for exchange_name, exchange_config in exchanges_config.items():
                if not exchange_config.get('enabled', True):
                    continue
                    
                try:
                    manager = OrderBookManager(
                        exchange_name=exchange_name,
                        market_type=exchange_config.get('market_type', 'spot'),
                        symbols=exchange_config.get('symbols', ['BTC-USDT'])[:1],  # åªåˆ†æä¸€ä¸ªsymbol
                        nats_publisher=nats_publisher,
                        config=exchange_config
                    )
                    
                    # è®¾ç½®åˆ†æå›è°ƒ
                    original_callback = manager.update_callback
                    analysis_callback = create_analysis_callback(exchange_name, exchange_config.get('market_type', 'spot'))
                    
                    def combined_callback(symbol, data):
                        analysis_callback(symbol, data)
                        if original_callback:
                            return original_callback(symbol, data)
                    
                    manager.update_callback = combined_callback
                    
                    success = await manager.start()
                    if success:
                        managers.append((exchange_name, manager))
                        logger.info(f"âœ… {exchange_name} åˆ†æå™¨å¯åŠ¨æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ {exchange_name} åˆ†æå™¨å¯åŠ¨å¤±è´¥")
                        
                except Exception as e:
                    logger.error(f"âŒ {exchange_name} åˆ†æå™¨å¯åŠ¨å¼‚å¸¸: {e}")
            
            if not managers:
                logger.error("âŒ æ²¡æœ‰æˆåŠŸå¯åŠ¨çš„åˆ†æå™¨")
                return
            
            # è¿è¡Œåˆ†æ
            self.start_time = datetime.now(timezone.utc)
            self.is_running = True
            
            logger.info(f"ğŸ¯ åºåˆ—éªŒè¯åˆ†æå¼€å§‹ï¼Œç›‘æ§ {len(managers)} ä¸ªäº¤æ˜“æ‰€")
            
            # å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            for i in range(duration_seconds):
                await asyncio.sleep(1)
                if (i + 1) % 10 == 0:  # æ¯10ç§’è¾“å‡ºä¸€æ¬¡
                    self._print_interim_stats(i + 1)
            
            # åœæ­¢æ‰€æœ‰ç®¡ç†å™¨
            for exchange_name, manager in managers:
                try:
                    await manager.stop()
                    logger.info(f"âœ… {exchange_name} åˆ†æå™¨å·²åœæ­¢")
                except Exception as e:
                    logger.error(f"åœæ­¢ {exchange_name} åˆ†æå™¨å¤±è´¥: {e}")
            
            # æ–­å¼€NATS
            await nats_publisher.disconnect()
            
            # è¾“å‡ºæœ€ç»ˆåˆ†ææŠ¥å‘Š
            self._print_final_report()
            
        except Exception as e:
            logger.error(f"âŒ åºåˆ—éªŒè¯åˆ†æå¤±è´¥: {e}", exc_info=True)
    
    def _analyze_update(self, exchange_name, market_type, symbol, data):
        """åˆ†æå•ä¸ªæ›´æ–°çš„åºåˆ—éªŒè¯æƒ…å†µ"""
        try:
            key = f"{exchange_name}_{market_type}_{symbol}"
            stats = self.validation_stats[key]
            stats['total_updates'] += 1
            
            # åˆ†æBinanceåºåˆ—éªŒè¯
            if 'binance' in exchange_name.lower():
                self._analyze_binance_sequence(stats, data)
            
            # åˆ†æOKXåºåˆ—éªŒè¯
            elif 'okx' in exchange_name.lower():
                self._analyze_okx_sequence(stats, data)
            
            # è®°å½•åºåˆ—å†å²
            current_time = datetime.now(timezone.utc)
            stats['sequence_history'].append({
                'timestamp': current_time,
                'update_id': self._extract_update_id(data),
                'data_type': self._get_data_type(data)
            })
            
        except Exception as e:
            logger.error(f"åˆ†ææ›´æ–°å¤±è´¥: {e}", exc_info=True)
    
    def _analyze_binance_sequence(self, stats, data):
        """åˆ†æBinanceåºåˆ—éªŒè¯"""
        try:
            # æå–Binanceåºåˆ—ID
            first_update_id = data.get('U')
            final_update_id = data.get('u')
            prev_update_id = data.get('pu')  # æ°¸ç»­åˆçº¦ç‰¹æœ‰
            
            if final_update_id is not None:
                if stats['last_update_id'] is not None:
                    # æ£€æŸ¥åºåˆ—è¿ç»­æ€§
                    if prev_update_id is not None:
                        # æ°¸ç»­åˆçº¦éªŒè¯
                        if prev_update_id == stats['last_update_id']:
                            stats['successful_validations'] += 1
                        else:
                            stats['failed_validations'] += 1
                            stats['sequence_gaps'] += 1
                    else:
                        # ç°è´§éªŒè¯
                        expected_first = stats['last_update_id'] + 1
                        if first_update_id is not None and first_update_id <= expected_first <= final_update_id:
                            stats['successful_validations'] += 1
                        else:
                            stats['failed_validations'] += 1
                            stats['sequence_gaps'] += 1
                else:
                    # é¦–æ¬¡æ›´æ–°
                    stats['successful_validations'] += 1
                
                stats['last_update_id'] = final_update_id
            
        except Exception as e:
            logger.error(f"Binanceåºåˆ—åˆ†æå¤±è´¥: {e}")
    
    def _analyze_okx_sequence(self, stats, data):
        """åˆ†æOKXåºåˆ—éªŒè¯"""
        try:
            # æå–OKXåºåˆ—ID
            seq_id = data.get('seqId')
            prev_seq_id = data.get('prevSeqId')
            checksum = data.get('checksum')
            
            if seq_id is not None and prev_seq_id is not None:
                if stats['last_update_id'] is not None:
                    # æ£€æŸ¥åºåˆ—è¿ç»­æ€§
                    if prev_seq_id == stats['last_update_id']:
                        stats['successful_validations'] += 1
                    elif prev_seq_id == -1:
                        # å¿«ç…§æ¶ˆæ¯
                        stats['successful_validations'] += 1
                    else:
                        stats['failed_validations'] += 1
                        stats['sequence_gaps'] += 1
                else:
                    # é¦–æ¬¡æ›´æ–°
                    stats['successful_validations'] += 1
                
                stats['last_update_id'] = seq_id
            
            # æ£€æŸ¥checksum
            if checksum is not None:
                # è¿™é‡Œå¯ä»¥æ·»åŠ checksuméªŒè¯é€»è¾‘
                pass
            
        except Exception as e:
            logger.error(f"OKXåºåˆ—åˆ†æå¤±è´¥: {e}")
    
    def _extract_update_id(self, data):
        """æå–æ›´æ–°ID"""
        return data.get('u') or data.get('seqId') or data.get('ts')
    
    def _get_data_type(self, data):
        """è·å–æ•°æ®ç±»å‹"""
        if 'e' in data and data.get('e') == 'depthUpdate':
            return 'binance_depth_update'
        elif 'seqId' in data:
            return 'okx_update'
        else:
            return 'unknown'
    
    def _print_interim_stats(self, elapsed_seconds):
        """è¾“å‡ºä¸­æœŸç»Ÿè®¡ä¿¡æ¯"""
        logger.info(f"ğŸ“Š åºåˆ—éªŒè¯ç»Ÿè®¡ ({elapsed_seconds}ç§’)")
        logger.info("-" * 60)
        
        for key, stats in self.validation_stats.items():
            if stats['total_updates'] > 0:
                success_rate = (stats['successful_validations'] / stats['total_updates']) * 100
                logger.info(f"{key}:")
                logger.info(f"  æ€»æ›´æ–°: {stats['total_updates']}")
                logger.info(f"  éªŒè¯æˆåŠŸ: {stats['successful_validations']} ({success_rate:.1f}%)")
                logger.info(f"  éªŒè¯å¤±è´¥: {stats['failed_validations']}")
                logger.info(f"  åºåˆ—è·³è·ƒ: {stats['sequence_gaps']}")
    
    def _print_final_report(self):
        """è¾“å‡ºæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
        logger.info("ğŸ¯ åºåˆ—éªŒè¯åˆ†ææŠ¥å‘Š")
        logger.info("=" * 80)
        
        total_updates = sum(stats['total_updates'] for stats in self.validation_stats.values())
        total_successful = sum(stats['successful_validations'] for stats in self.validation_stats.values())
        total_failed = sum(stats['failed_validations'] for stats in self.validation_stats.values())
        total_gaps = sum(stats['sequence_gaps'] for stats in self.validation_stats.values())
        
        if total_updates > 0:
            overall_success_rate = (total_successful / total_updates) * 100
            logger.info(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
            logger.info(f"  æ€»æ›´æ–°æ•°: {total_updates}")
            logger.info(f"  éªŒè¯æˆåŠŸ: {total_successful} ({overall_success_rate:.2f}%)")
            logger.info(f"  éªŒè¯å¤±è´¥: {total_failed}")
            logger.info(f"  åºåˆ—è·³è·ƒ: {total_gaps}")
            logger.info("")
            
            logger.info(f"ğŸ“Š å„äº¤æ˜“æ‰€è¯¦ç»†ç»Ÿè®¡:")
            for key, stats in self.validation_stats.items():
                if stats['total_updates'] > 0:
                    success_rate = (stats['successful_validations'] / stats['total_updates']) * 100
                    logger.info(f"  {key}:")
                    logger.info(f"    æ›´æ–°æ•°: {stats['total_updates']}")
                    logger.info(f"    æˆåŠŸç‡: {success_rate:.2f}%")
                    logger.info(f"    åºåˆ—è·³è·ƒ: {stats['sequence_gaps']}")
                    logger.info(f"    æœ€åæ›´æ–°ID: {stats['last_update_id']}")
        else:
            logger.warning("âŒ æ²¡æœ‰æ”¶åˆ°ä»»ä½•æ›´æ–°æ•°æ®")

async def main():
    """ä¸»å‡½æ•°"""
    analyzer = SequenceValidationAnalyzer()
    
    try:
        await analyzer.start_analysis(duration_seconds=60)
        return 0
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°é”®ç›˜ä¸­æ–­ï¼Œåœæ­¢åˆ†æ...")
        return 0
    except Exception as e:
        logger.error(f"åˆ†æå¼‚å¸¸: {e}", exc_info=True)
        return 1

if __name__ == "__main__":
    print("ğŸ” MarketPrismåºåˆ—éªŒè¯åˆ†æå™¨")
    print("ä¸“é—¨åˆ†æè®¢å•ç°¿åºåˆ—IDéªŒè¯å’Œæ›´æ–°çš„æ•ˆæœ")
    print("=" * 60)
    
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
