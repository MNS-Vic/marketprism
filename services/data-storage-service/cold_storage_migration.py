#!/usr/bin/env python3
"""
MarketPrism å†·å­˜å‚¨è¿ç§»æœåŠ¡
å®šæ—¶å°†çƒ­å­˜å‚¨æ•°æ®è¿ç§»åˆ°æ°¸ä¹…å­˜å‚¨ (NAS)

ğŸ”„ Dockeréƒ¨ç½²ç®€åŒ–æ”¹é€  (2025-08-02):
- âœ… æ”¯æŒ8ç§æ•°æ®ç±»å‹çš„è‡ªåŠ¨è¿ç§»
- âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯
- âœ… æ‰¹é‡è¿ç§»ä¼˜åŒ–
- âœ… é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- âœ… NASéƒ¨ç½²æ”¯æŒ
"""

import asyncio
import aiohttp
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import os
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class MigrationConfig:
    """è¿ç§»é…ç½®"""
    # çƒ­å­˜å‚¨é…ç½®
    hot_clickhouse_host: str = "localhost"
    hot_clickhouse_port: int = 8123
    hot_database: str = "marketprism_hot"
    
    # å†·å­˜å‚¨é…ç½® (NAS)
    cold_clickhouse_host: str = "nas.local"
    cold_clickhouse_port: int = 8123
    cold_database: str = "marketprism_cold"
    
    # è¿ç§»é…ç½®
    migration_age_days: int = 3  # è¿ç§»3å¤©å‰çš„æ•°æ®
    batch_size: int = 10000      # æ‰¹é‡å¤§å°
    verification_enabled: bool = True  # æ•°æ®éªŒè¯
    cleanup_after_migration: bool = True  # è¿ç§»åæ¸…ç†çƒ­å­˜å‚¨
    
    # é‡è¯•é…ç½®
    max_retries: int = 3
    retry_delay: float = 5.0

class ColdStorageMigration:
    """å†·å­˜å‚¨è¿ç§»æœåŠ¡"""
    
    def __init__(self, config: MigrationConfig):
        self.config = config
        self.stats = {
            "migrations_completed": 0,
            "migrations_failed": 0,
            "records_migrated": 0,
            "bytes_migrated": 0,
            "last_migration_time": None,
            "errors": []
        }
        
        # æ”¯æŒçš„æ•°æ®ç±»å‹
        self.data_types = [
            'orderbooks', 'trades', 'funding_rates', 'open_interests',
            'liquidations', 'lsr_top_positions', 'lsr_all_accounts', 'volatility_indices'
        ]
    
    async def check_cold_storage_connection(self) -> bool:
        """æ£€æŸ¥å†·å­˜å‚¨è¿æ¥"""
        try:
            async with aiohttp.ClientSession() as session:
                url = f"http://{self.config.cold_clickhouse_host}:{self.config.cold_clickhouse_port}/ping"
                async with session.get(url, timeout=10) as response:
                    if response.status == 200:
                        logger.info("âœ… å†·å­˜å‚¨è¿æ¥æ­£å¸¸")
                        return True
                    else:
                        logger.error(f"âŒ å†·å­˜å‚¨è¿æ¥å¤±è´¥: {response.status}")
                        return False
        except Exception as e:
            logger.error(f"âŒ å†·å­˜å‚¨è¿æ¥å¼‚å¸¸: {e}")
            return False
    
    async def ensure_cold_storage_schema(self) -> bool:
        """ç¡®ä¿å†·å­˜å‚¨æ•°æ®åº“å’Œè¡¨ç»“æ„å­˜åœ¨"""
        try:
            async with aiohttp.ClientSession() as session:
                base_url = f"http://{self.config.cold_clickhouse_host}:{self.config.cold_clickhouse_port}"
                
                # åˆ›å»ºæ•°æ®åº“
                create_db_sql = f"CREATE DATABASE IF NOT EXISTS {self.config.cold_database}"
                async with session.post(base_url, data=create_db_sql) as response:
                    if response.status != 200:
                        logger.error(f"åˆ›å»ºå†·å­˜å‚¨æ•°æ®åº“å¤±è´¥: {response.status}")
                        return False
                
                # ä¸ºæ¯ç§æ•°æ®ç±»å‹åˆ›å»ºè¡¨
                for table in self.data_types:
                    # è·å–çƒ­å­˜å‚¨è¡¨ç»“æ„
                    show_create_sql = f"SHOW CREATE TABLE {self.config.hot_database}.{table}"
                    async with aiohttp.ClientSession() as hot_session:
                        hot_url = f"http://{self.config.hot_clickhouse_host}:{self.config.hot_clickhouse_port}"
                        async with hot_session.post(hot_url, data=show_create_sql) as hot_response:
                            if hot_response.status == 200:
                                create_table_sql = await hot_response.text()
                                # ä¿®æ”¹è¡¨åå’ŒTTL
                                create_table_sql = create_table_sql.replace(
                                    f"CREATE TABLE {self.config.hot_database}.{table}",
                                    f"CREATE TABLE IF NOT EXISTS {self.config.cold_database}.{table}"
                                )
                                # ä¿®æ”¹TTLä¸º1å¹´
                                create_table_sql = create_table_sql.replace(
                                    "TTL timestamp + INTERVAL 3 DAY DELETE",
                                    "TTL timestamp + INTERVAL 365 DAY DELETE"
                                )
                                
                                # åˆ›å»ºå†·å­˜å‚¨è¡¨
                                async with session.post(base_url, data=create_table_sql) as response:
                                    if response.status == 200:
                                        logger.info(f"âœ… å†·å­˜å‚¨è¡¨åˆ›å»ºæˆåŠŸ: {table}")
                                    else:
                                        logger.error(f"âŒ å†·å­˜å‚¨è¡¨åˆ›å»ºå¤±è´¥: {table}")
                                        return False
                
                logger.info("âœ… å†·å­˜å‚¨æ•°æ®åº“ç»“æ„ç¡®ä¿å®Œæˆ")
                return True
                
        except Exception as e:
            logger.error(f"âŒ å†·å­˜å‚¨æ•°æ®åº“ç»“æ„åˆ›å»ºå¼‚å¸¸: {e}")
            return False
    
    async def get_migration_partitions(self, table: str) -> List[str]:
        """è·å–éœ€è¦è¿ç§»çš„åˆ†åŒº"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.config.migration_age_days)
            cutoff_month = cutoff_date.strftime('%Y%m')
            
            # æŸ¥è¯¢éœ€è¦è¿ç§»çš„åˆ†åŒº
            sql = f"""
            SELECT DISTINCT partition
            FROM system.parts 
            WHERE database = '{self.config.hot_database}' 
                AND table = '{table}'
                AND active = 1
                AND partition < '{cutoff_month}'
            ORDER BY partition
            """
            
            async with aiohttp.ClientSession() as session:
                url = f"http://{self.config.hot_clickhouse_host}:{self.config.hot_clickhouse_port}"
                async with session.post(url, data=sql) as response:
                    if response.status == 200:
                        result = await response.text()
                        partitions = [line.strip() for line in result.strip().split('\n') if line.strip()]
                        logger.info(f"ğŸ“‹ è¡¨ {table} éœ€è¦è¿ç§»çš„åˆ†åŒº: {partitions}")
                        return partitions
                    else:
                        logger.error(f"âŒ è·å–è¿ç§»åˆ†åŒºå¤±è´¥: {table}")
                        return []
                        
        except Exception as e:
            logger.error(f"âŒ è·å–è¿ç§»åˆ†åŒºå¼‚å¸¸: {table}, {e}")
            return []
    
    async def migrate_partition(self, table: str, partition: str) -> bool:
        """è¿ç§»å•ä¸ªåˆ†åŒº"""
        try:
            logger.info(f"ğŸ”„ å¼€å§‹è¿ç§»: {table}.{partition}")
            
            # 1. ä»çƒ­å­˜å‚¨è¯»å–æ•°æ®
            select_sql = f"""
            SELECT * FROM {self.config.hot_database}.{table}
            WHERE toYYYYMM(timestamp) = '{partition}'
            """
            
            async with aiohttp.ClientSession() as session:
                hot_url = f"http://{self.config.hot_clickhouse_host}:{self.config.hot_clickhouse_port}"
                
                # è·å–æ•°æ®
                async with session.post(hot_url, data=select_sql + " FORMAT JSONEachRow") as response:
                    if response.status != 200:
                        logger.error(f"âŒ è¯»å–çƒ­å­˜å‚¨æ•°æ®å¤±è´¥: {table}.{partition}")
                        return False
                    
                    data = await response.text()
                    if not data.strip():
                        logger.info(f"âš ï¸ åˆ†åŒºæ— æ•°æ®: {table}.{partition}")
                        return True
                    
                    # 2. å†™å…¥å†·å­˜å‚¨
                    insert_sql = f"INSERT INTO {self.config.cold_database}.{table} FORMAT JSONEachRow"
                    cold_url = f"http://{self.config.cold_clickhouse_host}:{self.config.cold_clickhouse_port}"
                    
                    async with session.post(cold_url, data=insert_sql + "\n" + data) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            logger.error(f"âŒ å†™å…¥å†·å­˜å‚¨å¤±è´¥: {table}.{partition}, {error_text}")
                            return False
                    
                    # 3. éªŒè¯æ•°æ®å®Œæ•´æ€§
                    if self.config.verification_enabled:
                        if not await self.verify_migration(table, partition):
                            logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {table}.{partition}")
                            return False
                    
                    # 4. æ¸…ç†çƒ­å­˜å‚¨æ•°æ®
                    if self.config.cleanup_after_migration:
                        delete_sql = f"""
                        ALTER TABLE {self.config.hot_database}.{table}
                        DROP PARTITION '{partition}'
                        """
                        async with session.post(hot_url, data=delete_sql) as response:
                            if response.status == 200:
                                logger.info(f"âœ… çƒ­å­˜å‚¨æ¸…ç†å®Œæˆ: {table}.{partition}")
                            else:
                                logger.warning(f"âš ï¸ çƒ­å­˜å‚¨æ¸…ç†å¤±è´¥: {table}.{partition}")
                    
                    # ç»Ÿè®¡æ›´æ–°
                    record_count = len(data.strip().split('\n'))
                    self.stats["records_migrated"] += record_count
                    self.stats["bytes_migrated"] += len(data.encode('utf-8'))
                    
                    logger.info(f"âœ… è¿ç§»å®Œæˆ: {table}.{partition}, {record_count} æ¡è®°å½•")
                    return True
                    
        except Exception as e:
            logger.error(f"âŒ è¿ç§»åˆ†åŒºå¼‚å¸¸: {table}.{partition}, {e}")
            return False
    
    async def verify_migration(self, table: str, partition: str) -> bool:
        """éªŒè¯è¿ç§»æ•°æ®å®Œæ•´æ€§"""
        try:
            # è·å–çƒ­å­˜å‚¨è®°å½•æ•°
            hot_count_sql = f"""
            SELECT count() FROM {self.config.hot_database}.{table}
            WHERE toYYYYMM(timestamp) = '{partition}'
            """
            
            # è·å–å†·å­˜å‚¨è®°å½•æ•°
            cold_count_sql = f"""
            SELECT count() FROM {self.config.cold_database}.{table}
            WHERE toYYYYMM(timestamp) = '{partition}'
            """
            
            async with aiohttp.ClientSession() as session:
                # æŸ¥è¯¢çƒ­å­˜å‚¨
                hot_url = f"http://{self.config.hot_clickhouse_host}:{self.config.hot_clickhouse_port}"
                async with session.post(hot_url, data=hot_count_sql) as response:
                    if response.status == 200:
                        hot_count = int((await response.text()).strip())
                    else:
                        logger.error(f"âŒ æŸ¥è¯¢çƒ­å­˜å‚¨è®°å½•æ•°å¤±è´¥: {table}.{partition}")
                        return False
                
                # æŸ¥è¯¢å†·å­˜å‚¨
                cold_url = f"http://{self.config.cold_clickhouse_host}:{self.config.cold_clickhouse_port}"
                async with session.post(cold_url, data=cold_count_sql) as response:
                    if response.status == 200:
                        cold_count = int((await response.text()).strip())
                    else:
                        logger.error(f"âŒ æŸ¥è¯¢å†·å­˜å‚¨è®°å½•æ•°å¤±è´¥: {table}.{partition}")
                        return False
                
                if hot_count == cold_count:
                    logger.info(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {table}.{partition}, {hot_count} æ¡è®°å½•")
                    return True
                else:
                    logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {table}.{partition}, çƒ­å­˜å‚¨:{hot_count}, å†·å­˜å‚¨:{cold_count}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ æ•°æ®éªŒè¯å¼‚å¸¸: {table}.{partition}, {e}")
            return False
    
    async def run_migration(self) -> bool:
        """æ‰§è¡Œè¿ç§»ä»»åŠ¡"""
        logger.info("ğŸš€ å¼€å§‹å†·å­˜å‚¨è¿ç§»ä»»åŠ¡")
        
        # æ£€æŸ¥å†·å­˜å‚¨è¿æ¥
        if not await self.check_cold_storage_connection():
            return False
        
        # ç¡®ä¿å†·å­˜å‚¨æ•°æ®åº“ç»“æ„
        if not await self.ensure_cold_storage_schema():
            return False
        
        migration_success = True
        
        # ä¸ºæ¯ç§æ•°æ®ç±»å‹æ‰§è¡Œè¿ç§»
        for table in self.data_types:
            try:
                logger.info(f"ğŸ“Š å¤„ç†è¡¨: {table}")
                
                # è·å–éœ€è¦è¿ç§»çš„åˆ†åŒº
                partitions = await self.get_migration_partitions(table)
                
                if not partitions:
                    logger.info(f"âš ï¸ è¡¨ {table} æ— éœ€è¿ç§»çš„åˆ†åŒº")
                    continue
                
                # è¿ç§»æ¯ä¸ªåˆ†åŒº
                for partition in partitions:
                    success = await self.migrate_partition(table, partition)
                    if success:
                        self.stats["migrations_completed"] += 1
                    else:
                        self.stats["migrations_failed"] += 1
                        migration_success = False
                        
            except Exception as e:
                logger.error(f"âŒ è¡¨è¿ç§»å¼‚å¸¸: {table}, {e}")
                self.stats["migrations_failed"] += 1
                migration_success = False
        
        self.stats["last_migration_time"] = datetime.now().isoformat()
        
        if migration_success:
            logger.info("ğŸ‰ å†·å­˜å‚¨è¿ç§»ä»»åŠ¡å®Œæˆ")
        else:
            logger.error("âŒ å†·å­˜å‚¨è¿ç§»ä»»åŠ¡éƒ¨åˆ†å¤±è´¥")
        
        return migration_success
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è¿ç§»ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()

async def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    config = MigrationConfig(
        hot_clickhouse_host=os.getenv("HOT_CLICKHOUSE_HOST", "localhost"),
        hot_clickhouse_port=int(os.getenv("HOT_CLICKHOUSE_PORT", "8123")),
        hot_database=os.getenv("HOT_DATABASE", "marketprism_hot"),
        cold_clickhouse_host=os.getenv("COLD_CLICKHOUSE_HOST", "nas.local"),
        cold_clickhouse_port=int(os.getenv("COLD_CLICKHOUSE_PORT", "8123")),
        cold_database=os.getenv("COLD_DATABASE", "marketprism_cold"),
        migration_age_days=int(os.getenv("MIGRATION_AGE_DAYS", "3")),
        batch_size=int(os.getenv("MIGRATION_BATCH_SIZE", "10000")),
        verification_enabled=os.getenv("MIGRATION_VERIFICATION", "true").lower() == "true",
        cleanup_after_migration=os.getenv("MIGRATION_CLEANUP", "true").lower() == "true"
    )
    
    migration_service = ColdStorageMigration(config)
    
    # æ‰§è¡Œè¿ç§»
    success = await migration_service.run_migration()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    stats = migration_service.get_stats()
    logger.info(f"ğŸ“Š è¿ç§»ç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
