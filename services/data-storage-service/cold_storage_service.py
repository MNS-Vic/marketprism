"""
MarketPrism å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡
å®šæ—¶ä»çƒ­ç«¯ClickHouseåŒæ­¥å†å²æ•°æ®åˆ°æœ¬åœ°NASè¿›è¡Œæ°¸ä¹…å­˜å‚¨
"""

import asyncio
import signal
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any
import structlog

from core.storage.tiered_storage_manager import TieredStorageManager, TierConfig, StorageTier
from core.observability.logging.unified_logger import UnifiedLogger


class ColdStorageService:
    """å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–å†·ç«¯å½’æ¡£æœåŠ¡
        
        Args:
            config: æœåŠ¡é…ç½®
        """
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = structlog.get_logger("services.data_storage.cold_storage")
        
        # é…ç½®
        self.config = config
        self.hot_storage_config = config.get('hot_storage', {})
        self.cold_storage_config = config.get('cold_storage', {})
        self.sync_config = config.get('sync', {})
        
        # åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
        self.storage_manager: Optional[TieredStorageManager] = None
        
        # åŒæ­¥ä»»åŠ¡é…ç½®
        self.sync_interval = self.sync_config.get('interval_hours', 6)  # é»˜è®¤6å°æ—¶åŒæ­¥ä¸€æ¬¡
        self.sync_batch_hours = self.sync_config.get('batch_hours', 24)  # é»˜è®¤æ¯æ¬¡åŒæ­¥24å°æ—¶æ•°æ®
        # ç¼“å†²æ—¶é—´ï¼Œé¿å…åŒæ­¥æ­£åœ¨å†™å…¥çš„æœ€æ–°æ•°æ®ï¼Œé»˜è®¤60åˆ†é’Ÿï¼Œå¯é€šè¿‡é…ç½®sync.buffer_minutesè°ƒæ•´
        self.sync_buffer_minutes = self.sync_config.get('buffer_minutes', 60)
        self.cleanup_enabled = self.sync_config.get('cleanup_enabled', True)
        self.cleanup_delay_hours = self.sync_config.get('cleanup_delay_hours', 48)  # åŒæ­¥å48å°æ—¶æ¸…ç†çƒ­ç«¯

        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.shutdown_event = asyncio.Event()
        self.sync_task: Optional[asyncio.Task] = None
        self.cleanup_task: Optional[asyncio.Task] = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "sync_cycles": 0,
            "successful_syncs": 0,
            "failed_syncs": 0,
            "last_sync_time": None,
            "last_sync_duration": None,
            "total_records_synced": 0,
            "cleanup_cycles": 0,
            "last_cleanup_time": None,
            "total_records_cleaned": 0,
            "data_types": {
                "orderbook": {"synced": 0, "failed": 0},
                "trade": {"synced": 0, "failed": 0},
                "funding_rate": {"synced": 0, "failed": 0},
                "open_interest": {"synced": 0, "failed": 0},
                "liquidation": {"synced": 0, "failed": 0},
                "lsr": {"synced": 0, "failed": 0},
                "volatility_index": {"synced": 0, "failed": 0}
            }
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–å†·ç«¯å½’æ¡£æœåŠ¡"""
        try:
            self.logger.info("ğŸš€ åˆå§‹åŒ–å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡")
            
            # åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
            await self._initialize_storage_manager()
            
            self.logger.info("âœ… å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error("âŒ å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡åˆå§‹åŒ–å¤±è´¥", error=str(e))
            raise
    
    async def _initialize_storage_manager(self):
        """åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨"""
        try:
            # åˆ›å»ºçƒ­ç«¯é…ç½®
            hot_config = TierConfig(
                tier=StorageTier.HOT,
                clickhouse_host=self.hot_storage_config.get('clickhouse_host', 'localhost'),
                clickhouse_port=self.hot_storage_config.get('clickhouse_http_port', 8123),
                clickhouse_user=self.hot_storage_config.get('clickhouse_user', 'default'),
                clickhouse_password=self.hot_storage_config.get('clickhouse_password', ''),
                clickhouse_database=self.hot_storage_config.get('clickhouse_database', 'marketprism_hot'),
                retention_days=self.hot_storage_config.get('retention_days', 3),
                batch_size=self.hot_storage_config.get('batch_size', 1000),
                flush_interval=self.hot_storage_config.get('flush_interval', 5)
            )
            
            # åˆ›å»ºå†·ç«¯é…ç½®
            cold_config = TierConfig(
                tier=StorageTier.COLD,
                clickhouse_host=self.cold_storage_config.get('clickhouse_host', 'localhost'),
                clickhouse_port=self.cold_storage_config.get('clickhouse_http_port', 8123),
                clickhouse_user=self.cold_storage_config.get('clickhouse_user', 'default'),
                clickhouse_password=self.cold_storage_config.get('clickhouse_password', ''),
                clickhouse_database=self.cold_storage_config.get('clickhouse_database', 'marketprism_cold'),
                retention_days=self.cold_storage_config.get('retention_days', 365),
                batch_size=self.cold_storage_config.get('batch_size', 5000),
                flush_interval=self.cold_storage_config.get('flush_interval', 30)
            )
            
            # åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
            self.storage_manager = TieredStorageManager(hot_config, cold_config)
            await self.storage_manager.initialize()
            
            self.logger.info("âœ… åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error("âŒ åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥", error=str(e))
            raise
    
    async def start(self):
        """å¯åŠ¨å†·ç«¯å½’æ¡£æœåŠ¡"""
        try:
            self.logger.info("ğŸš€ å¯åŠ¨å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡")
            
            self.is_running = True
            
            # è®¾ç½®ä¿¡å·å¤„ç†
            self._setup_signal_handlers()
            
            # å¯åŠ¨åŒæ­¥ä»»åŠ¡
            self.sync_task = asyncio.create_task(self._sync_worker())
            
            # å¯åŠ¨æ¸…ç†ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.cleanup_enabled:
                self.cleanup_task = asyncio.create_task(self._cleanup_worker())
            
            self.logger.info("âœ… å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å·²å¯åŠ¨",
                           sync_interval_hours=self.sync_interval,
                           cleanup_enabled=self.cleanup_enabled)
            
            # ç­‰å¾…å…³é—­ä¿¡å·
            await self.shutdown_event.wait()
            
        except Exception as e:
            self.logger.error("âŒ å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å¯åŠ¨å¤±è´¥", error=str(e))
            raise
    
    async def stop(self):
        """åœæ­¢å†·ç«¯å½’æ¡£æœåŠ¡"""
        try:
            self.logger.info("ğŸ›‘ åœæ­¢å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡")
            
            self.is_running = False
            
            # åœæ­¢åŒæ­¥ä»»åŠ¡
            if self.sync_task:
                self.sync_task.cancel()
                try:
                    await self.sync_task
                except asyncio.CancelledError:
                    pass
                self.logger.info("âœ… åŒæ­¥ä»»åŠ¡å·²åœæ­¢")
            
            # åœæ­¢æ¸…ç†ä»»åŠ¡
            if self.cleanup_task:
                self.cleanup_task.cancel()
                try:
                    await self.cleanup_task
                except asyncio.CancelledError:
                    pass
                self.logger.info("âœ… æ¸…ç†ä»»åŠ¡å·²åœæ­¢")
            
            # å…³é—­å­˜å‚¨ç®¡ç†å™¨
            if self.storage_manager:
                await self.storage_manager.close()
                self.logger.info("âœ… å­˜å‚¨ç®¡ç†å™¨å·²å…³é—­")
            
            # è®¾ç½®å…³é—­äº‹ä»¶
            self.shutdown_event.set()
            
            self.logger.info("âœ… å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å·²åœæ­¢")
            
        except Exception as e:
            self.logger.error("âŒ åœæ­¢å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å¤±è´¥", error=str(e))
    
    async def _sync_worker(self):
        """æ•°æ®åŒæ­¥å·¥ä½œå™¨"""
        self.logger.info("ğŸ”„ æ•°æ®åŒæ­¥å·¥ä½œå™¨å·²å¯åŠ¨", 
                        interval_hours=self.sync_interval)
        
        while self.is_running:
            try:
                # æ‰§è¡Œæ•°æ®åŒæ­¥
                await self._perform_sync_cycle()
                
                # ç­‰å¾…ä¸‹æ¬¡åŒæ­¥
                await asyncio.sleep(self.sync_interval * 3600)  # è½¬æ¢ä¸ºç§’
                
            except asyncio.CancelledError:
                self.logger.info("ğŸ›‘ æ•°æ®åŒæ­¥å·¥ä½œå™¨è¢«å–æ¶ˆ")
                break
            except Exception as e:
                self.logger.error("âŒ æ•°æ®åŒæ­¥å·¥ä½œå™¨å¼‚å¸¸", error=str(e))
                # é”™è¯¯æ—¶ç­‰å¾…è¾ƒçŸ­æ—¶é—´å†é‡è¯•
                await asyncio.sleep(300)  # 5åˆ†é’Ÿ
        
        self.logger.info("ğŸ›‘ æ•°æ®åŒæ­¥å·¥ä½œå™¨å·²åœæ­¢")
    
    async def _cleanup_worker(self):
        """æ•°æ®æ¸…ç†å·¥ä½œå™¨"""
        self.logger.info("ğŸ§¹ æ•°æ®æ¸…ç†å·¥ä½œå™¨å·²å¯åŠ¨")
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´åå¼€å§‹æ¸…ç†ï¼ˆé¿å…ä¸åŒæ­¥å†²çªï¼‰
        await asyncio.sleep(3600)  # 1å°æ—¶åå¼€å§‹
        
        while self.is_running:
            try:
                # æ‰§è¡Œæ•°æ®æ¸…ç†
                await self._perform_cleanup_cycle()
                
                # ç­‰å¾…ä¸‹æ¬¡æ¸…ç†ï¼ˆæ¯å¤©æ¸…ç†ä¸€æ¬¡ï¼‰
                await asyncio.sleep(24 * 3600)  # 24å°æ—¶
                
            except asyncio.CancelledError:
                self.logger.info("ğŸ›‘ æ•°æ®æ¸…ç†å·¥ä½œå™¨è¢«å–æ¶ˆ")
                break
            except Exception as e:
                self.logger.error("âŒ æ•°æ®æ¸…ç†å·¥ä½œå™¨å¼‚å¸¸", error=str(e))
                # é”™è¯¯æ—¶ç­‰å¾…è¾ƒçŸ­æ—¶é—´å†é‡è¯•
                await asyncio.sleep(3600)  # 1å°æ—¶
        
        self.logger.info("ğŸ›‘ æ•°æ®æ¸…ç†å·¥ä½œå™¨å·²åœæ­¢")
    
    async def _perform_sync_cycle(self):
        """æ‰§è¡Œä¸€æ¬¡æ•°æ®åŒæ­¥å‘¨æœŸ"""
        try:
            sync_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ”„ å¼€å§‹æ•°æ®åŒæ­¥å‘¨æœŸ")
            
            self.stats["sync_cycles"] += 1
            
            # è®¡ç®—åŒæ­¥æ—¶é—´èŒƒå›´
            end_time = sync_start - timedelta(minutes=self.sync_buffer_minutes)  # ç•™ç¼“å†²æ—¶é—´
            start_time = end_time - timedelta(hours=self.sync_batch_hours)

            # è·å–éœ€è¦åŒæ­¥çš„æ•°æ®ç±»å‹å’Œäº¤æ˜“æ‰€
            data_types = self.sync_config.get('data_types', [
                "orderbook", "trade", "funding_rate", "open_interest",
                "liquidation", "lsr", "volatility_index"
            ])
            
            exchanges = self.sync_config.get('exchanges', [
                "binance_spot", "binance_derivatives", "okx_spot",
                "okx_derivatives", "deribit_derivatives"
            ])
            
            # è°ƒåº¦ä¼ è¾“ä»»åŠ¡
            task_ids = []
            for data_type in data_types:
                for exchange in exchanges:
                    # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è·å–symbolåˆ—è¡¨
                    symbols = self._get_symbols_for_exchange(exchange)
                    
                    for symbol in symbols:
                        try:
                            task_id = await self.storage_manager.schedule_data_transfer(
                                data_type, exchange, symbol, start_time, end_time
                            )
                            task_ids.append(task_id)
                        except Exception as e:
                            self.logger.error("âŒ è°ƒåº¦ä¼ è¾“ä»»åŠ¡å¤±è´¥",
                                            data_type=data_type,
                                            exchange=exchange,
                                            symbol=symbol,
                                            error=str(e))
                            self.stats["data_types"][data_type]["failed"] += 1
            
            # ç­‰å¾…æ‰€æœ‰ä¼ è¾“ä»»åŠ¡å®Œæˆ
            await self._wait_for_transfer_completion(task_ids)
            
            # æ›´æ–°ç»Ÿè®¡
            sync_duration = (datetime.now(timezone.utc) - sync_start).total_seconds()
            self.stats["last_sync_time"] = sync_start
            self.stats["last_sync_duration"] = sync_duration
            self.stats["successful_syncs"] += 1
            
            self.logger.info("âœ… æ•°æ®åŒæ­¥å‘¨æœŸå®Œæˆ",
                           duration_seconds=sync_duration,
                           tasks_scheduled=len(task_ids))
            
        except Exception as e:
            self.stats["failed_syncs"] += 1
            self.logger.error("âŒ æ•°æ®åŒæ­¥å‘¨æœŸå¤±è´¥", error=str(e))
    
    async def _perform_cleanup_cycle(self):
        """æ‰§è¡Œä¸€æ¬¡æ•°æ®æ¸…ç†å‘¨æœŸ"""
        try:
            cleanup_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ§¹ å¼€å§‹æ•°æ®æ¸…ç†å‘¨æœŸ")
            
            self.stats["cleanup_cycles"] += 1
            
            # æ‰§è¡Œçƒ­ç«¯æ•°æ®æ¸…ç†
            cleanup_summary = await self.storage_manager.cleanup_expired_hot_data()
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["last_cleanup_time"] = cleanup_start
            self.stats["total_records_cleaned"] += cleanup_summary.get("total_records_deleted", 0)
            
            self.logger.info("âœ… æ•°æ®æ¸…ç†å‘¨æœŸå®Œæˆ",
                           records_deleted=cleanup_summary.get("total_records_deleted", 0))
            
        except Exception as e:
            self.logger.error("âŒ æ•°æ®æ¸…ç†å‘¨æœŸå¤±è´¥", error=str(e))
    
    def _get_symbols_for_exchange(self, exchange: str) -> List[str]:
        """è·å–äº¤æ˜“æ‰€çš„äº¤æ˜“å¯¹åˆ—è¡¨"""
        # è¿™é‡Œå¯ä»¥ä»é…ç½®æ–‡ä»¶æˆ–æ•°æ®åº“è·å–
        # æš‚æ—¶è¿”å›é»˜è®¤çš„ä¸»è¦äº¤æ˜“å¯¹
        return self.sync_config.get('symbols', {}).get(exchange, ["BTC-USDT"])
    
    async def _wait_for_transfer_completion(self, task_ids: List[str], timeout_minutes: int = 60):
        """ç­‰å¾…ä¼ è¾“ä»»åŠ¡å®Œæˆ"""
        try:
            timeout_seconds = timeout_minutes * 60
            start_time = datetime.now(timezone.utc)
            
            while (datetime.now(timezone.utc) - start_time).total_seconds() < timeout_seconds:
                # æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡çŠ¶æ€
                pending_tasks = []
                completed_tasks = 0
                failed_tasks = 0
                
                for task_id in task_ids:
                    status = self.storage_manager.get_transfer_task_status(task_id)
                    if status:
                        if status["status"] == "pending" or status["status"] == "running":
                            pending_tasks.append(task_id)
                        elif status["status"] == "completed":
                            completed_tasks += 1
                        elif status["status"] == "failed":
                            failed_tasks += 1
                
                # å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
                if not pending_tasks:
                    self.logger.info("âœ… æ‰€æœ‰ä¼ è¾“ä»»åŠ¡å·²å®Œæˆ",
                                   total_tasks=len(task_ids),
                                   completed=completed_tasks,
                                   failed=failed_tasks)
                    return
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
                await asyncio.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
            
            # è¶…æ—¶
            self.logger.warning("âš ï¸ ä¼ è¾“ä»»åŠ¡ç­‰å¾…è¶…æ—¶",
                              timeout_minutes=timeout_minutes,
                              pending_tasks=len(pending_tasks))
            
        except Exception as e:
            self.logger.error("âŒ ç­‰å¾…ä¼ è¾“ä»»åŠ¡å®Œæˆå¤±è´¥", error=str(e))
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            self.logger.info("ğŸ“¡ æ”¶åˆ°åœæ­¢ä¿¡å·", signal=signum)
            asyncio.create_task(self.stop())
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "service_status": {
                "is_running": self.is_running,
                "sync_task_active": self.sync_task is not None and not self.sync_task.done(),
                "cleanup_task_active": self.cleanup_task is not None and not self.cleanup_task.done()
            },
            "sync_stats": self.stats,
            "storage_stats": self.storage_manager.get_storage_stats() if self.storage_manager else None
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "components": {}
        }
        
        # æ£€æŸ¥å­˜å‚¨ç®¡ç†å™¨
        if self.storage_manager:
            storage_health = await self.storage_manager.health_check()
            health_status["components"]["storage"] = storage_health
            if storage_health["status"] != "healthy":
                health_status["status"] = "degraded"
        else:
            health_status["components"]["storage"] = {"status": "not_initialized"}
            health_status["status"] = "unhealthy"
        
        # æ£€æŸ¥åŒæ­¥ä»»åŠ¡
        if self.sync_task and not self.sync_task.done():
            health_status["components"]["sync_worker"] = {"status": "healthy"}
        else:
            health_status["components"]["sync_worker"] = {"status": "stopped"}
            if health_status["status"] == "healthy":
                health_status["status"] = "degraded"
        
        return health_status
