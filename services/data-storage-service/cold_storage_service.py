"""
MarketPrism å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡
å®šæ—¶ä»çƒ­ç«¯ClickHouseåŒæ­¥å†å²æ•°æ®åˆ°æœ¬åœ°NASè¿›è¡Œæ°¸ä¹…å­˜å‚¨
"""

import asyncio
import signal
import os
import fcntl
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any
import structlog

from core.storage.tiered_storage_manager import TieredStorageManager, TierConfig, StorageTier
from core.observability.logging.unified_logger import UnifiedLogger
from aiohttp import web



class ColdStorageService:
    """å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–å†·ç«¯å½’æ¡£æœåŠ¡

        Args:
            config: æœåŠ¡é…ç½®
        """
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = structlog.get_logger("services.data_storage.cold_storage")

        # é…ç½®
        self.config = config
        self.hot_storage_config = config.get('hot_storage', {})
        self.cold_storage_config = config.get('cold_storage', {})
        self.sync_config = config.get('sync', {})

        # åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
        self.storage_manager: Optional[TieredStorageManager] = None

        # åŒæ­¥ä»»åŠ¡é…ç½®
        self.sync_interval = self.sync_config.get('interval_hours', 6)  # é»˜è®¤6å°æ—¶åŒæ­¥ä¸€æ¬¡
        self.sync_batch_hours = self.sync_config.get('batch_hours', 24)  # é»˜è®¤æ¯æ¬¡åŒæ­¥24å°æ—¶æ•°æ®
        # ç¼“å†²æ—¶é—´ï¼Œé¿å…åŒæ­¥æ­£åœ¨å†™å…¥çš„æœ€æ–°æ•°æ®ï¼Œé»˜è®¤60åˆ†é’Ÿï¼Œå¯é€šè¿‡é…ç½®sync.buffer_minutesè°ƒæ•´
        self.sync_buffer_minutes = self.sync_config.get('buffer_minutes', 60)
        self.cleanup_enabled = self.sync_config.get('cleanup_enabled', True)
        self.cleanup_delay_hours = self.sync_config.get('cleanup_delay_hours', 48)  # åŒæ­¥å48å°æ—¶æ¸…ç†çƒ­ç«¯

        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.shutdown_event = asyncio.Event()

        # å®ä¾‹é”ï¼ˆé˜²æ­¢å¤šå®ä¾‹åŒæ—¶è¿è¡Œï¼‰
        self._lock_fd = None
        self._lock_path = None
        self.sync_task: Optional[asyncio.Task] = None
        # HTTP æœåŠ¡
        self.app = None
        self.http_runner = None
        # å†·ç«¯å¥åº·æ£€æŸ¥ç«¯å£ï¼ˆæ¥è‡ªé…ç½® cold_storage.http_portï¼Œé»˜è®¤ 8086ï¼‰
        self.http_port = self.cold_storage_config.get('http_port', 8086)

        self.cleanup_task: Optional[asyncio.Task] = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "sync_cycles": 0,
            "successful_syncs": 0,
            "failed_syncs": 0,
            "last_sync_time": None,
            "last_sync_duration": None,
            "total_records_synced": 0,
            "cleanup_cycles": 0,
            "last_cleanup_time": None,
            "total_records_cleaned": 0,
            "data_types": {
                "orderbook": {"synced": 0, "failed": 0},
                "trade": {"synced": 0, "failed": 0},
                "funding_rate": {"synced": 0, "failed": 0},
                "open_interest": {"synced": 0, "failed": 0},
                "liquidation": {"synced": 0, "failed": 0},
                "lsr_top_position": {"synced": 0, "failed": 0},
                "lsr_all_account": {"synced": 0, "failed": 0},
                "volatility_index": {"synced": 0, "failed": 0}
            }
        }

    async def initialize(self):
        """åˆå§‹åŒ–å†·ç«¯å½’æ¡£æœåŠ¡"""
        try:
            self.logger.info("ğŸš€ åˆå§‹åŒ–å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡")

            # åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
            await self._initialize_storage_manager()

            self.logger.info("âœ… å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            self.logger.error("âŒ å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡åˆå§‹åŒ–å¤±è´¥", error=str(e))
            raise

    async def _initialize_storage_manager(self):
        """åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨"""
        try:
            # åˆ›å»ºçƒ­ç«¯é…ç½®
            hot_config = TierConfig(
                tier=StorageTier.HOT,
                clickhouse_host=self.hot_storage_config.get('clickhouse_host', 'localhost'),
                clickhouse_port=self.hot_storage_config.get('clickhouse_http_port', 8123),
                clickhouse_user=self.hot_storage_config.get('clickhouse_user', 'default'),
                clickhouse_password=self.hot_storage_config.get('clickhouse_password', ''),
                clickhouse_database=self.hot_storage_config.get('clickhouse_database', 'marketprism_hot'),
                retention_days=self.hot_storage_config.get('retention_days', 3),
                batch_size=self.hot_storage_config.get('batch_size', 1000),
                flush_interval=self.hot_storage_config.get('flush_interval', 5)
            )

            # åˆ›å»ºå†·ç«¯é…ç½®
            cold_config = TierConfig(
                tier=StorageTier.COLD,
                clickhouse_host=self.cold_storage_config.get('clickhouse_host', 'localhost'),
                clickhouse_port=self.cold_storage_config.get('clickhouse_http_port', 8123),
                clickhouse_user=self.cold_storage_config.get('clickhouse_user', 'default'),
                clickhouse_password=self.cold_storage_config.get('clickhouse_password', ''),
                clickhouse_database=self.cold_storage_config.get('clickhouse_database', 'marketprism_cold'),
                retention_days=self.cold_storage_config.get('retention_days', 365),
                batch_size=self.cold_storage_config.get('batch_size', 5000),
                flush_interval=self.cold_storage_config.get('flush_interval', 30)
            )

            # åˆå§‹åŒ–åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨
            self.storage_manager = TieredStorageManager(hot_config, cold_config)
            await self.storage_manager.initialize()

            self.logger.info("âœ… åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            self.logger.error("âŒ åˆ†å±‚å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥", error=str(e))
            raise

    def _acquire_singleton_lock(self) -> bool:
        """è·å–å•å®ä¾‹æ–‡ä»¶é”ï¼Œé˜²æ­¢åŒæœºå¤šå¼€"""
        try:
            self._lock_path = os.getenv('MARKETPRISM_COLD_STORAGE_LOCK', '/tmp/marketprism_cold_storage.lock')
            self._lock_fd = os.open(self._lock_path, os.O_CREAT | os.O_RDWR, 0o644)
            # éé˜»å¡ç‹¬å é”
            fcntl.lockf(self._lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)

            # å†™å…¥PID
            try:
                os.ftruncate(self._lock_fd, 0)
                os.write(self._lock_fd, str(os.getpid()).encode('utf-8'))
            except Exception:
                pass

            self.logger.info("âœ… è·å–å†·ç«¯å­˜å‚¨æœåŠ¡å•å®ä¾‹é”æˆåŠŸ", lock_path=self._lock_path)
            return True

        except BlockingIOError:
            self.logger.warning("âš ï¸ æ£€æµ‹åˆ°å·²æœ‰å†·ç«¯å­˜å‚¨æœåŠ¡å®ä¾‹åœ¨è¿è¡Œï¼Œè·³è¿‡å¯åŠ¨", lock_path=self._lock_path)
            return False
        except Exception as e:
            self.logger.error("âŒ è·å–å†·ç«¯å­˜å‚¨æœåŠ¡å•å®ä¾‹é”å¤±è´¥", error=str(e))
            return False

    def _release_singleton_lock(self):
        """é‡Šæ”¾å•å®ä¾‹æ–‡ä»¶é”"""
        try:
            if self._lock_fd is not None:
                fcntl.lockf(self._lock_fd, fcntl.LOCK_UN)
                os.close(self._lock_fd)
                self._lock_fd = None
            if self._lock_path and os.path.exists(self._lock_path):
                os.unlink(self._lock_path)
                self._lock_path = None
            self.logger.info("âœ… å†·ç«¯å­˜å‚¨æœåŠ¡å•å®ä¾‹é”å·²é‡Šæ”¾")
        except Exception as e:
            self.logger.warning("âš ï¸ é‡Šæ”¾å•å®ä¾‹é”æ—¶å‡ºç°é—®é¢˜", error=str(e))

    async def start(self):
        """å¯åŠ¨å†·ç«¯å½’æ¡£æœåŠ¡"""
        try:
            self.logger.info("ğŸš€ å¯åŠ¨å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡")

            # è·å–å•å®ä¾‹é”
            if not self._acquire_singleton_lock():
                self.logger.error("âŒ æ— æ³•è·å–å†·ç«¯å­˜å‚¨æœåŠ¡å•å®ä¾‹é”ï¼Œé€€å‡º")
                return

            self.is_running = True

            # è®¾ç½®ä¿¡å·å¤„ç†
            # å¯åŠ¨HTTPå¥åº·æ£€æŸ¥æœåŠ¡
            await self.setup_http_server()

            self._setup_signal_handlers()

            # å¯åŠ¨åŒæ­¥ä»»åŠ¡
            self.sync_task = asyncio.create_task(self._sync_worker())

            # å¯åŠ¨æ¸…ç†ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.cleanup_enabled:
                self.cleanup_task = asyncio.create_task(self._cleanup_worker())

            self.logger.info("âœ… å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å·²å¯åŠ¨",
                           sync_interval_hours=self.sync_interval,
                           cleanup_enabled=self.cleanup_enabled)

            # ç­‰å¾…å…³é—­ä¿¡å·
            await self.shutdown_event.wait()

        except Exception as e:
            self.logger.error("âŒ å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å¯åŠ¨å¤±è´¥", error=str(e))
            raise

    async def stop(self):
        """åœæ­¢å†·ç«¯å½’æ¡£æœåŠ¡"""
        try:
            self.logger.info("ğŸ›‘ åœæ­¢å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡")

            self.is_running = False

            # åœæ­¢åŒæ­¥ä»»åŠ¡
            if self.sync_task:
                self.sync_task.cancel()
                try:
                    await self.sync_task
                except asyncio.CancelledError:
                    pass
                self.logger.info("âœ… åŒæ­¥ä»»åŠ¡å·²åœæ­¢")

            # åœæ­¢æ¸…ç†ä»»åŠ¡
            if self.cleanup_task:
                self.cleanup_task.cancel()
                try:
                    await self.cleanup_task
                except asyncio.CancelledError:
                    pass
                self.logger.info("âœ… æ¸…ç†ä»»åŠ¡å·²åœæ­¢")

            # å…³é—­HTTPæœåŠ¡
            try:
                if self.http_runner:
                    await self.http_runner.cleanup()
                    self.logger.info("âœ… HTTPæœåŠ¡å™¨å·²å…³é—­")
            except Exception as _e:
                self.logger.warning("âš ï¸ å…³é—­HTTPæœåŠ¡å™¨æ—¶å‡ºç°é—®é¢˜", error=str(_e))

            # å…³é—­å­˜å‚¨ç®¡ç†å™¨
            if self.storage_manager:
                await self.storage_manager.close()
                self.logger.info("âœ… å­˜å‚¨ç®¡ç†å™¨å·²å…³é—­")

            # é‡Šæ”¾å•å®ä¾‹é”
            self._release_singleton_lock()

            # è®¾ç½®å…³é—­äº‹ä»¶
            self.shutdown_event.set()

            self.logger.info("âœ… å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å·²åœæ­¢")

        except Exception as e:
            self.logger.error("âŒ åœæ­¢å†·ç«¯æ•°æ®å½’æ¡£æœåŠ¡å¤±è´¥", error=str(e))
            # ç¡®ä¿é‡Šæ”¾é”
            self._release_singleton_lock()

    async def _sync_worker(self):
        """æ•°æ®åŒæ­¥å·¥ä½œå™¨"""
        self.logger.info("ğŸ”„ æ•°æ®åŒæ­¥å·¥ä½œå™¨å·²å¯åŠ¨",
                        interval_hours=self.sync_interval)

        while self.is_running:
            try:
                # æ‰§è¡Œæ•°æ®åŒæ­¥
                await self._perform_sync_cycle()

                # ç­‰å¾…ä¸‹æ¬¡åŒæ­¥
                await asyncio.sleep(self.sync_interval * 3600)  # è½¬æ¢ä¸ºç§’

            except asyncio.CancelledError:
                self.logger.info("ğŸ›‘ æ•°æ®åŒæ­¥å·¥ä½œå™¨è¢«å–æ¶ˆ")
                break
            except Exception as e:
                self.logger.error("âŒ æ•°æ®åŒæ­¥å·¥ä½œå™¨å¼‚å¸¸", error=str(e))
                # é”™è¯¯æ—¶ç­‰å¾…è¾ƒçŸ­æ—¶é—´å†é‡è¯•
                await asyncio.sleep(300)  # 5åˆ†é’Ÿ

        self.logger.info("ğŸ›‘ æ•°æ®åŒæ­¥å·¥ä½œå™¨å·²åœæ­¢")

    async def _cleanup_worker(self):
        """æ•°æ®æ¸…ç†å·¥ä½œå™¨"""
        self.logger.info("ğŸ§¹ æ•°æ®æ¸…ç†å·¥ä½œå™¨å·²å¯åŠ¨")

        # ç­‰å¾…ä¸€æ®µæ—¶é—´åå¼€å§‹æ¸…ç†ï¼ˆé¿å…ä¸åŒæ­¥å†²çªï¼‰
        await asyncio.sleep(3600)  # 1å°æ—¶åå¼€å§‹

        while self.is_running:
            try:
                # æ‰§è¡Œæ•°æ®æ¸…ç†
                await self._perform_cleanup_cycle()

                # ç­‰å¾…ä¸‹æ¬¡æ¸…ç†ï¼ˆæ¯å¤©æ¸…ç†ä¸€æ¬¡ï¼‰
                await asyncio.sleep(24 * 3600)  # 24å°æ—¶

            except asyncio.CancelledError:
                self.logger.info("ğŸ›‘ æ•°æ®æ¸…ç†å·¥ä½œå™¨è¢«å–æ¶ˆ")
                break
            except Exception as e:
                self.logger.error("âŒ æ•°æ®æ¸…ç†å·¥ä½œå™¨å¼‚å¸¸", error=str(e))
                # é”™è¯¯æ—¶ç­‰å¾…è¾ƒçŸ­æ—¶é—´å†é‡è¯•
                await asyncio.sleep(3600)  # 1å°æ—¶

        self.logger.info("ğŸ›‘ æ•°æ®æ¸…ç†å·¥ä½œå™¨å·²åœæ­¢")

    async def _perform_sync_cycle(self):
        """æ‰§è¡Œä¸€æ¬¡æ•°æ®åŒæ­¥å‘¨æœŸ"""
        try:
            sync_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ”„ å¼€å§‹æ•°æ®åŒæ­¥å‘¨æœŸ")

            self.stats["sync_cycles"] += 1

            # è®¡ç®—åŒæ­¥æ—¶é—´èŒƒå›´
            end_time = sync_start - timedelta(minutes=self.sync_buffer_minutes)  # ç•™ç¼“å†²æ—¶é—´
            start_time = end_time - timedelta(hours=self.sync_batch_hours)

            # è·å–éœ€è¦åŒæ­¥çš„æ•°æ®ç±»å‹å’Œäº¤æ˜“æ‰€
            data_types = self.sync_config.get('data_types', [
                "orderbook", "trade", "funding_rate", "open_interest",
                "liquidation", "lsr_top_position", "lsr_all_account", "volatility_index"
            ])

            exchanges = self.sync_config.get('exchanges', [
                "binance_spot", "binance_derivatives", "okx_spot",
                "okx_derivatives", "deribit_derivatives"
            ])

            # è°ƒåº¦ä¼ è¾“ä»»åŠ¡
            task_ids = []
            for data_type in data_types:
                for exchange in exchanges:
                    # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è·å–symbolåˆ—è¡¨
                    symbols = self._get_symbols_for_exchange(exchange)

                    for symbol in symbols:
                        try:
                            task_id = await self.storage_manager.schedule_data_transfer(
                                data_type, exchange, symbol, start_time, end_time
                            )
                            task_ids.append(task_id)
                        except Exception as e:
                            self.logger.error("âŒ è°ƒåº¦ä¼ è¾“ä»»åŠ¡å¤±è´¥",
                                            data_type=data_type,
                                            exchange=exchange,
                                            symbol=symbol,
                                            error=str(e))
                            self.stats["data_types"][data_type]["failed"] += 1

            # ç­‰å¾…æ‰€æœ‰ä¼ è¾“ä»»åŠ¡å®Œæˆ
            await self._wait_for_transfer_completion(task_ids)

            # æ›´æ–°ç»Ÿè®¡
            sync_duration = (datetime.now(timezone.utc) - sync_start).total_seconds()
            self.stats["last_sync_time"] = sync_start
            self.stats["last_sync_duration"] = sync_duration
            self.stats["successful_syncs"] += 1

            self.logger.info("âœ… æ•°æ®åŒæ­¥å‘¨æœŸå®Œæˆ",
                           duration_seconds=sync_duration,
                           tasks_scheduled=len(task_ids))

        except Exception as e:
            self.stats["failed_syncs"] += 1
            self.logger.error("âŒ æ•°æ®åŒæ­¥å‘¨æœŸå¤±è´¥", error=str(e))

    async def _perform_cleanup_cycle(self):
        """æ‰§è¡Œä¸€æ¬¡æ•°æ®æ¸…ç†å‘¨æœŸ"""
        try:
            cleanup_start = datetime.now(timezone.utc)
            self.logger.info("ğŸ§¹ å¼€å§‹æ•°æ®æ¸…ç†å‘¨æœŸ")

            self.stats["cleanup_cycles"] += 1

            # æ‰§è¡Œçƒ­ç«¯æ•°æ®æ¸…ç†
            cleanup_summary = await self.storage_manager.cleanup_expired_hot_data()

            # æ›´æ–°ç»Ÿè®¡
            self.stats["last_cleanup_time"] = cleanup_start
            self.stats["total_records_cleaned"] += cleanup_summary.get("total_records_deleted", 0)

            self.logger.info("âœ… æ•°æ®æ¸…ç†å‘¨æœŸå®Œæˆ",
                           records_deleted=cleanup_summary.get("total_records_deleted", 0))

        except Exception as e:
            self.logger.error("âŒ æ•°æ®æ¸…ç†å‘¨æœŸå¤±è´¥", error=str(e))

    def _get_symbols_for_exchange(self, exchange: str) -> List[str]:
        """è·å–äº¤æ˜“æ‰€çš„äº¤æ˜“å¯¹åˆ—è¡¨"""
        # è¿™é‡Œå¯ä»¥ä»é…ç½®æ–‡ä»¶æˆ–æ•°æ®åº“è·å–
        # æš‚æ—¶è¿”å›é»˜è®¤çš„ä¸»è¦äº¤æ˜“å¯¹
        return self.sync_config.get('symbols', {}).get(exchange, ["BTC-USDT"])

    async def _wait_for_transfer_completion(self, task_ids: List[str], timeout_minutes: int = 60):
        """ç­‰å¾…ä¼ è¾“ä»»åŠ¡å®Œæˆ"""
        try:
            timeout_seconds = timeout_minutes * 60
            start_time = datetime.now(timezone.utc)

            while (datetime.now(timezone.utc) - start_time).total_seconds() < timeout_seconds:
                # æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡çŠ¶æ€
                pending_tasks = []
                completed_tasks = 0
                failed_tasks = 0

                for task_id in task_ids:
                    status = self.storage_manager.get_transfer_task_status(task_id)
                    if status:
                        if status["status"] == "pending" or status["status"] == "running":
                            pending_tasks.append(task_id)
                        elif status["status"] == "completed":
                            completed_tasks += 1
                        elif status["status"] == "failed":
                            failed_tasks += 1

                # å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
                if not pending_tasks:
                    self.logger.info("âœ… æ‰€æœ‰ä¼ è¾“ä»»åŠ¡å·²å®Œæˆ",
                                   total_tasks=len(task_ids),
                                   completed=completed_tasks,
                                   failed=failed_tasks)
                    return

                # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
                await asyncio.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡

            # è¶…æ—¶
            self.logger.warning("âš ï¸ ä¼ è¾“ä»»åŠ¡ç­‰å¾…è¶…æ—¶",
                              timeout_minutes=timeout_minutes,
                              pending_tasks=len(pending_tasks))

        except Exception as e:
            self.logger.error("âŒ ç­‰å¾…ä¼ è¾“ä»»åŠ¡å®Œæˆå¤±è´¥", error=str(e))

    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            self.logger.info("ğŸ“¡ æ”¶åˆ°åœæ­¢ä¿¡å·", signal=signum)
            asyncio.create_task(self.stop())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    async def setup_http_server(self):
        """è®¾ç½®å¹¶å¯åŠ¨HTTPæœåŠ¡å™¨ï¼ˆ/health, /statsï¼‰"""
        try:
            self.app = web.Application()
            self.app.router.add_get('/health', self.handle_health)
            self.app.router.add_get('/stats', self.handle_stats)
            runner = web.AppRunner(self.app)
            await runner.setup()
            site = web.TCPSite(runner, '0.0.0.0', self.http_port)
            await site.start()
            self.http_runner = runner
            self.logger.info(f"âœ… HTTPæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼Œç«¯å£: {self.http_port}")
        except Exception as e:
            self.logger.error("âŒ å¯åŠ¨HTTPæœåŠ¡å™¨å¤±è´¥", error=str(e))

    async def handle_health(self, request):
        health = await self.health_check()
        status = health.get("status", "unhealthy")
        code = 200 if status in ("healthy", "degraded") else 503
        return web.json_response(health, status=code)

    async def handle_stats(self, request):
        return web.json_response(self.get_stats(), status=200)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "service_status": {
                "is_running": self.is_running,
                "sync_task_active": self.sync_task is not None and not self.sync_task.done(),
                "cleanup_task_active": self.cleanup_task is not None and not self.cleanup_task.done()
            },
            "sync_stats": self.stats,
            "storage_stats": self.storage_manager.get_storage_stats() if self.storage_manager else None
        }

    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "components": {}
        }

        # æ£€æŸ¥å­˜å‚¨ç®¡ç†å™¨
        if self.storage_manager:
            storage_health = await self.storage_manager.health_check()
            health_status["components"]["storage"] = storage_health
            if storage_health["status"] != "healthy":
                health_status["status"] = "degraded"
        else:
            health_status["components"]["storage"] = {"status": "not_initialized"}
            health_status["status"] = "unhealthy"

        # æ£€æŸ¥åŒæ­¥ä»»åŠ¡
        if self.sync_task and not self.sync_task.done():
            health_status["components"]["sync_worker"] = {"status": "healthy"}
        else:
            health_status["components"]["sync_worker"] = {"status": "stopped"}
            if health_status["status"] == "healthy":
                health_status["status"] = "degraded"

        return health_status
