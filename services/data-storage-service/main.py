#!/usr/bin/env python3
"""
MarketPrism ç®€åŒ–çƒ­ç«¯æ•°æ®å­˜å‚¨æœåŠ¡ - Dockeréƒ¨ç½²ä¼˜åŒ–ç‰ˆ
ç›´æ¥å¤„ç†NATSæ¶ˆæ¯å¹¶å†™å…¥ClickHouse

ğŸ”„ Dockeréƒ¨ç½²ç®€åŒ–æ”¹é€  (2025-08-02):
- âœ… æ”¯æŒ8ç§æ•°æ®ç±»å‹: orderbook, trade, funding_rate, open_interest, liquidation, lsr_top_position, lsr_all_account, volatility_index
- âœ… ä¼˜åŒ–ClickHouseå»ºè¡¨è„šæœ¬: åˆ†ç¦»LSRæ•°æ®ç±»å‹ï¼Œä¼˜åŒ–åˆ†åŒºå’Œç´¢å¼•
- âœ… ç®€åŒ–NATSè®¢é˜…: ç»Ÿä¸€ä¸»é¢˜è®¢é˜…ï¼Œè‡ªåŠ¨æ•°æ®ç±»å‹è¯†åˆ«
- âœ… Dockeré›†æˆ: ä¸ç»Ÿä¸€NATSå®¹å™¨å®Œç¾é›†æˆ
- âœ… æ‰¹é‡å†™å…¥ä¼˜åŒ–: æé«˜å†™å…¥æ€§èƒ½ï¼Œå‡å°‘æ•°æ®åº“è´Ÿè½½

ç‰¹æ€§:
- ä»NATS JetStreamè®¢é˜…å¸‚åœºæ•°æ®
- å®æ—¶å†™å…¥ClickHouseçƒ­ç«¯æ•°æ®åº“
- æ”¯æŒ8ç§æ•°æ®ç±»å‹ï¼Œè‡ªåŠ¨è¡¨æ˜ å°„
- æ‰¹é‡å†™å…¥ä¼˜åŒ–ï¼Œæ€§èƒ½æå‡
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- å¥åº·æ£€æŸ¥å’Œç›‘æ§
- Dockerå®¹å™¨åŒ–éƒ¨ç½²
"""

import asyncio
import json
import os
import signal
import sys
import time
import logging
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union
import yaml
import nats
from nats.js import JetStreamContext
import aiohttp
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

# å¯¼å…¥ä¼˜åŒ–çš„ClickHouseå®¢æˆ·ç«¯
try:
    from services.data_storage_service.storage import get_clickhouse_client, close_clickhouse_client
except ImportError:
    # å¦‚æœæ¨¡å—è·¯å¾„ä¸å¯¹ï¼Œå°è¯•å…¶ä»–è·¯å¾„
    sys.path.append(str(Path(__file__).parent))
    from storage import get_clickhouse_client, close_clickhouse_client
from aiohttp import web
from pathlib import Path
from decimal import Decimal, InvalidOperation
import traceback

# å¯é€‰å¼•å…¥ clickhouse-driverï¼ˆä¼˜å…ˆä½¿ç”¨TCPé©±åŠ¨ï¼Œå¤±è´¥å›é€€HTTPï¼‰
try:
    from clickhouse_driver import Client as CHClient
except Exception:
    CHClient = None


class DataValidationError(Exception):
    """æ•°æ®éªŒè¯é”™è¯¯"""
    pass


class DataFormatValidator:
    """æ•°æ®æ ¼å¼éªŒè¯å™¨"""

    @staticmethod
    def validate_json_data(data: Any, field_name: str) -> str:
        """éªŒè¯å¹¶è½¬æ¢JSONæ•°æ®"""
        try:
            if data is None:
                return '[]'

            if isinstance(data, str):
                # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
                try:
                    json.loads(data)
                    return data
                except json.JSONDecodeError:
                    logging.warning(f"Invalid JSON string in {field_name}: {data[:100]}...")
                    return '[]'

            elif isinstance(data, (list, dict)):
                # è½¬æ¢ä¸ºæ ‡å‡†JSONæ ¼å¼
                return json.dumps(data, ensure_ascii=False, separators=(',', ':'))

            else:
                logging.warning(f"Unexpected data type for {field_name}: {type(data)}")
                return '[]'

        except Exception as e:
            logging.error(f"Error validating JSON data for {field_name}: {e}")
            return '[]'

    @staticmethod
    def validate_numeric(value: Any, field_name: str, default: Union[int, float] = 0) -> Union[int, float]:
        """éªŒè¯æ•°å€¼ç±»å‹"""
        try:
            if value is None:
                return default

            if isinstance(value, (int, float)):
                return value

            if isinstance(value, str):
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                    if '.' in value:
                        return float(value)
                    else:
                        return int(value)
                except ValueError:
                    logging.warning(f"Cannot convert {field_name} to number: {value}")
                    return default

            return default

        except Exception as e:
            logging.error(f"Error validating numeric value for {field_name}: {e}")
            return default

    @staticmethod
    def validate_timestamp(timestamp: Any, field_name: str) -> datetime:
        """éªŒè¯æ—¶é—´æˆ³æ ¼å¼ï¼Œè¿”å›æ— æ—¶åŒºçš„ UTC datetime å¯¹è±¡ä¾› ClickHouse ä½¿ç”¨"""
        try:
            # å…œåº•ï¼šå½“å‰UTCæ—¶é—´ï¼ˆæ— æ—¶åŒºï¼‰
            def now_utc_naive() -> datetime:
                return datetime.now(timezone.utc).replace(tzinfo=None)

            if timestamp is None:
                return now_utc_naive()

            if isinstance(timestamp, str):
                t = timestamp.strip()
                # å½’ä¸€ï¼šå»æ‰Zï¼Œæ›¿æ¢Tä¸ºç©ºæ ¼ï¼Œå»é™¤æ—¶åŒºåç¼€
                t = t.replace('Z', '').replace('T', ' ')
                if '+' in t:
                    t = t.split('+')[0]
                # å»æ‰æ¯«ç§’éƒ¨åˆ†ï¼Œåªä¿ç•™åˆ°ç§’
                if '.' in t:
                    t = t.split('.')[0]

                # å°è¯•è§£æä¸º datetimeï¼ˆæ— æ—¶åŒºï¼‰
                try:
                    dt = datetime.strptime(t, '%Y-%m-%d %H:%M:%S')
                    return dt  # è¿”å›æ— æ—¶åŒºçš„ datetime
                except ValueError:
                    logging.warning(f"Failed to parse timestamp string: {t}")
                    return now_utc_naive()

            if isinstance(timestamp, datetime):
                # è½¬æ¢ä¸º UTC å¹¶ç§»é™¤æ—¶åŒºä¿¡æ¯
                if timestamp.tzinfo is None:
                    return timestamp  # å·²ç»æ˜¯æ— æ—¶åŒºçš„
                else:
                    return timestamp.astimezone(timezone.utc).replace(tzinfo=None)

            logging.warning(f"Unexpected timestamp type for {field_name}: {type(timestamp)}")
            return now_utc_naive()

        except Exception as e:
            logging.error(f"Error validating timestamp for {field_name}: {e}")
            return datetime.now(timezone.utc).replace(tzinfo=None)


class SimpleHotStorageService:
    """ç®€åŒ–çš„çƒ­ç«¯æ•°æ®å­˜å‚¨æœåŠ¡"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æœåŠ¡

        Args:
            config: æœåŠ¡é…ç½®
        """
        self.config = self._validate_config(config)
        self.nats_config = self.config.get('nats', {})
        self.hot_storage_config = self.config.get('hot_storage', {})

        # è®¾ç½®æ—¥å¿—
        self._setup_logging()

        # æ•°æ®éªŒè¯å™¨
        self.validator = DataFormatValidator()

        # NATSè¿æ¥
        self.nats_client: Optional[nats.NATS] = None
        self.jetstream: Optional[JetStreamContext] = None

        # è®¢é˜…ç®¡ç†
        self.subscriptions: Dict[str, Any] = {}

        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.shutdown_event = asyncio.Event()

        # HTTPæœåŠ¡å™¨
        self.app = None
        self.http_server = None
        self.http_port = self.config.get('http_port', 8080)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "messages_received": 0,
            "messages_processed": 0,
            "messages_failed": 0,
            "validation_errors": 0,
            "retry_attempts": 0,
            "last_message_time": None,
            "last_error_time": None,
            "batch_inserts": 0,
            "batch_size_total": 0,
            "tcp_driver_hits": 0,
            "http_fallback_hits": 0
        }

        # ğŸ”§ æ‰¹é‡å†™å…¥ç¼“å†²åŒº
        self.batch_buffers = {}  # {data_type: [validated_data, ...]}
        self.batch_locks = {}    # {data_type: asyncio.Lock()}
        self.batch_tasks = {}    # {data_type: asyncio.Task}
        # NOTE(Phase2-Fix 2025-09-19):
        #   - ä¿®å¤ deliver_policy=LAST ç”Ÿæ•ˆåï¼Œå‘ç°é«˜é¢‘æ•°æ®ï¼ˆtrade/orderbookï¼‰ååç“¶é¢ˆä¸å¶å‘â€œæ‰¹é‡å¤„ç†åœæ»â€
        #   - å°†æ‰¹é‡å‚æ•°ä¸Šè°ƒï¼Œå¹¶ä¸º trade å¼•å…¥æ›´å¤§æ‰¹æ¬¡é˜ˆå€¼ï¼›é€‚åº¦å»¶é•¿ flush_interval ä»¥æå‡ ClickHouse å†™å…¥æ•ˆç‡
        #   - è¿™äº›å‚æ•°åœ¨ E2E éªŒè¯ä¸­å¸¦æ¥ç¨³å®šçš„æ‰¹é‡æ’å…¥ä¸è¾ƒä½é”™è¯¯ç‡ï¼ˆè¯¦è§ logs/e2e_report.txtï¼‰
        self.batch_config = {
            "max_batch_size": 100,      # æå‡æ‰¹é‡å¤§å°ä»¥æé«˜ååé‡
            "flush_interval": 1.0,      # é€‚åº¦å»¶é•¿é—´éš”ä»¥ç§¯ç´¯æ›´å¤šæ•°æ®
            "high_freq_types": {"orderbook", "trade"},  # é«˜é¢‘æ•°æ®ç±»å‹
            "low_freq_batch_size": 20,  # æå‡ä½é¢‘æ•°æ®æ‰¹é‡å¤§å°
            "orderbook_flush_interval": 0.8,  # è®¢å•ç°¿ç¨å¾®å»¶é•¿ä»¥ç§¯ç´¯æ›´å¤šæ•°æ®
            "trade_batch_size": 150,    # trade ä¸“ç”¨æ›´å¤§æ‰¹é‡
        }

        # ClickHouse é©±åŠ¨å®¢æˆ·ç«¯ï¼ˆæ‡’åˆå§‹åŒ–ï¼‰
        self._ch_client = None

        # é‡è¯•é…ç½®
        self.retry_config = {
            "max_retries": self.config.get('retry', {}).get('max_retries', 3),
            "retry_delay": self.config.get('retry', {}).get('delay_seconds', 1),
            "backoff_multiplier": self.config.get('retry', {}).get('backoff_multiplier', 2)
        }

    def _validate_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        try:
            # éªŒè¯å¿…éœ€çš„é…ç½®é¡¹
            required_sections = ['nats', 'hot_storage']
            for section in required_sections:
                if section not in config:
                    raise DataValidationError(f"Missing required config section: {section}")

            # éªŒè¯NATSé…ç½®ï¼ˆç»Ÿä¸€ä½¿ç”¨ servers åˆ—è¡¨ï¼Œå…¼å®¹å†å² url ä¸ç¯å¢ƒå˜é‡ï¼‰
            nats_config = config['nats']
            servers = nats_config.get('servers')
            if not servers:
                env_url = os.getenv('MARKETPRISM_NATS_URL') or os.getenv('NATS_URL') or nats_config.get('url', 'nats://localhost:4222')
                nats_config['servers'] = [env_url]

            # éªŒè¯ClickHouseé…ç½®
            ch_config = config['hot_storage']
            defaults = {
                'clickhouse_host': 'localhost',
                'clickhouse_http_port': 8123,
                'clickhouse_tcp_port': 9000,
                'clickhouse_database': 'marketprism_hot',
                'clickhouse_user': 'default',
                'clickhouse_password': '',
                'use_clickhouse_driver': True
            }

            for key, default_value in defaults.items():
                if key not in ch_config:
                    ch_config[key] = default_value

            # è®¾ç½®é»˜è®¤é‡è¯•é…ç½®
            if 'retry' not in config:
                config['retry'] = {
                    'max_retries': 3,
                    'delay_seconds': 1,
                    'backoff_multiplier': 2
                }

            return config

        except Exception as e:
            print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
            raise

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('/tmp/hot_storage_service.log')
            ]
        )
        self.logger = logging.getLogger('HotStorageService')

    async def start(self):
        """å¯åŠ¨æœåŠ¡"""
        try:
            print("ğŸš€ å¯åŠ¨ç®€åŒ–çƒ­ç«¯æ•°æ®å­˜å‚¨æœåŠ¡")

            # è¿æ¥NATS
            await self._connect_nats()

            # è®¾ç½®è®¢é˜…
            await self._setup_subscriptions()

            # å¯åŠ¨HTTPæœåŠ¡å™¨
            await self.setup_http_server()

            # è®¾ç½®ä¿¡å·å¤„ç†
            self._setup_signal_handlers()

            self.is_running = True
            self.start_time = time.time()
            print("âœ… ç®€åŒ–çƒ­ç«¯æ•°æ®å­˜å‚¨æœåŠ¡å·²å¯åŠ¨")

            # ç­‰å¾…å…³é—­ä¿¡å·
            await self.shutdown_event.wait()

        except Exception as e:
            print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
            raise

    async def _connect_nats(self):
        """è¿æ¥NATSæœåŠ¡å™¨"""
        try:
            # ç»Ÿä¸€è¯»å– serversï¼Œå…¼å®¹å†å² url ä¸ç¯å¢ƒå˜é‡
            env_url = os.getenv('MARKETPRISM_NATS_URL') or os.getenv('NATS_URL')
            servers = self.nats_config.get('servers') or ([env_url] if env_url else [self.nats_config.get('url', 'nats://localhost:4222')])

            # Define callback functions
            async def error_cb(e):
                print(f"NATS error: {e}")

            async def disconnected_cb():
                print("NATS disconnected")

            async def reconnected_cb():
                print("NATS reconnected")

            async def closed_cb():
                print("NATS closed")

            self.nats_client = await nats.connect(
                servers=servers,
                max_reconnect_attempts=10,
                reconnect_time_wait=2,
                error_cb=error_cb,
                disconnected_cb=disconnected_cb,
                reconnected_cb=reconnected_cb,
                closed_cb=closed_cb
            )

            # è·å–JetStreamä¸Šä¸‹æ–‡
            self.jetstream = self.nats_client.jetstream()

            print(f"âœ… NATS connection established: {', '.join(servers)}")

        except Exception as e:
            print(f"âŒ NATSè¿æ¥å¤±è´¥: {e}")
            raise

    async def _setup_subscriptions(self):
        """è®¾ç½®NATSè®¢é˜…"""
        try:
            # è®¢é˜…å„ç§æ•°æ®ç±»å‹ - 8ç§æ•°æ®ç±»å‹
            data_types = ["orderbook", "trade", "funding_rate", "open_interest",
                         "liquidation", "lsr_top_position", "lsr_all_account", "volatility_index"]

            for data_type in data_types:
                await self._subscribe_to_data_type(data_type)

            print(f"âœ… NATSè®¢é˜…è®¾ç½®å®Œæˆï¼ŒæˆåŠŸè®¢é˜…æ•°é‡: {len(self.subscriptions)}")

            # åªè¦æœ‰è‡³å°‘ä¸€ä¸ªè®¢é˜…æˆåŠŸå°±ç»§ç»­
            if len(self.subscriptions) == 0:
                raise Exception("æ²¡æœ‰æˆåŠŸåˆ›å»ºä»»ä½•è®¢é˜…")

        except Exception as e:
            print(f"âŒ NATSè®¢é˜…è®¾ç½®å¤±è´¥: {e}")
            print(traceback.format_exc())
            raise

    async def _subscribe_to_data_type(self, data_type: str):
        """è®¢é˜…ç‰¹å®šæ•°æ®ç±»å‹ - çº¯JetStream Pullæ¶ˆè´¹è€…æ¨¡å¼"""
        try:
            # æ„å»ºä¸»é¢˜æ¨¡å¼ - ä¸å‘å¸ƒç«¯ç»Ÿä¸€
            subject_mapping = {
                "funding_rate": "funding_rate.>",
                "open_interest": "open_interest.>",
                "lsr_top_position": "lsr_top_position.>",  # é¡¶çº§å¤§æˆ·å¤šç©ºæŒä»“æ¯”ä¾‹
                "lsr_all_account": "lsr_all_account.>",  # å…¨å¸‚åœºå¤šç©ºæŒä»“äººæ•°æ¯”ä¾‹
                "orderbook": "orderbook.>",  # è®¢å•ç°¿
                "trade": "trade.>",  # æˆäº¤æ•°æ®
                "liquidation": "liquidation.>",  # å¼ºå¹³æ•°æ®
                "volatility_index": "volatility_index.>",  # æ³¢åŠ¨ç‡æŒ‡æ•°
            }

            if data_type in subject_mapping:
                subject_pattern = subject_mapping[data_type]
            else:
                # å…¶ä»–ç±»å‹ç›´æ¥ä½¿ç”¨ä¸‹åˆ’çº¿å‘½å
                subject_pattern = f"{data_type}.>"

            # ç¡®å®šæµåç§° - è®¢å•ç°¿ä½¿ç”¨ç‹¬ç«‹ORDERBOOK_SNAPæµï¼Œå…¶ä»–ä½¿ç”¨MARKET_DATAæµ
            if data_type == "orderbook":
                stream_name = "ORDERBOOK_SNAP"
            else:
                stream_name = "MARKET_DATA"

            print(f"è®¾ç½®JetStreamè®¢é˜…: {data_type} -> {subject_pattern} (æµ: {stream_name})")

            # ç­‰å¾… JetStream Stream å¯ç”¨
            js_ready = False
            for attempt in range(10):  # æœ€é•¿é‡è¯• ~20s
                try:
                    await self.jetstream._jsm.stream_info(stream_name)
                    js_ready = True
                    print(f"âœ… æµ {stream_name} å¯ç”¨")
                    break
                except Exception as e:
                    print(f"â³ ç­‰å¾…æµ {stream_name} å¯ç”¨... (å°è¯• {attempt+1}/10)")
                    await asyncio.sleep(2)

            if not js_ready:
                raise Exception(f"æµ {stream_name} åœ¨20ç§’å†…æœªå°±ç»ª")

            # JetStreamè®¢é˜…ï¼ˆçº¯JetStreamæ¨¡å¼ï¼‰
            try:
                # å®šä¹‰åç¨‹å›è°ƒï¼Œç»‘å®šå½“å‰æ•°æ®ç±»å‹
                async def _cb(msg, _dt=data_type):
                    await self._handle_message(msg, _dt)

                # ä½¿ç”¨æ–°çš„ durable åç§°ä»¥é¿å…å¤ç”¨å†å²æ¶ˆè´¹ä½ç½®ï¼Œç¡®ä¿æœ¬æ¬¡å¯åŠ¨ä»â€œæ–°æ¶ˆæ¯â€å¼€å§‹
                new_durable = f"simple_hot_storage_realtime_{data_type}"

                # ğŸ”§ æ£€æŸ¥å¹¶åˆ é™¤ä¸ç¬¦åˆè¦æ±‚çš„å†å²consumerï¼Œç¡®ä¿ä½¿ç”¨LASTç­–ç•¥ï¼ˆæŒ‰å®é™…æµæ£€æŸ¥ï¼‰
                try:
                    existing_consumer = await self.jetstream._jsm.consumer_info(stream_name, new_durable)
                    existing_policy = existing_consumer.config.deliver_policy
                    existing_max_ack = existing_consumer.config.max_ack_pending

                    # å¦‚æœç°æœ‰consumerä¸æ˜¯LASTç­–ç•¥æˆ–max_ack_pendingä¸ç¬¦åˆé¢„æœŸï¼Œåˆ™åˆ é™¤é‡å»º
                    expected_max_ack = 5000 if data_type == "orderbook" else 2000
                    if (existing_policy != nats.js.api.DeliverPolicy.LAST or
                        existing_max_ack != expected_max_ack):
                        print(f"ğŸ§¹ åˆ é™¤ä¸ç¬¦åˆè¦æ±‚çš„consumer: {new_durable} (policy={existing_policy}, max_ack={existing_max_ack})")
                        await self.jetstream._jsm.delete_consumer(stream_name, new_durable)
                except nats.js.errors.NotFoundError:
                    # Consumerä¸å­˜åœ¨ï¼Œæ­£å¸¸æƒ…å†µ
                    pass
                except Exception as e:
                    print(f"âš ï¸ æ£€æŸ¥consumerçŠ¶æ€æ—¶å‡ºé”™: {e}")

                # ğŸ”§ æ˜ç¡®ç»‘å®šåˆ°æŒ‡å®šStreamå¹¶æ˜¾å¼åˆ›å»ºConsumerï¼Œç¡®ä¿ä½¿ç”¨LASTç­–ç•¥
                # ä¸è¦†ç›–å‰é¢æ ¹æ®æ•°æ®ç±»å‹ç¡®å®šçš„ stream_name

                # å…ˆåˆ é™¤å†å²ä¸ç¬¦åˆè¦æ±‚çš„consumerï¼ˆè‹¥ä»å­˜åœ¨ï¼‰
                try:
                    await self.jetstream._jsm.delete_consumer(stream_name, new_durable)
                except Exception:
                    pass

                # ä½¿ç”¨ push consumerï¼ˆæŒ‡å®š deliver_subjectï¼‰ä»¥æ”¯æŒå›è°ƒå¼æ¶ˆè´¹
                deliver_subject = f"_deliver.{new_durable}.{int(time.time())}"
                desired_config = nats.js.api.ConsumerConfig(
                    durable_name=new_durable,
                    deliver_policy=nats.js.api.DeliverPolicy.LAST,  # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹ï¼Œé¿å…å†å²å›æ”¾
                    ack_policy=nats.js.api.AckPolicy.EXPLICIT,
                    max_deliver=3,
                    ack_wait=60,    # æ”¾å®½ACKç­‰å¾…ï¼Œä¾¿äºæ‰¹å¤„ç†ä¸å¹¶å‘
                    max_ack_pending=(5000 if data_type == "orderbook" else 2000),
                    filter_subject=subject_pattern,  # å…³é”®ï¼šé™å®šåˆ°å¯¹åº”æ•°æ®ç±»å‹çš„ä¸»é¢˜
                    deliver_subject=deliver_subject,
                )

                # æ˜¾å¼åˆ›å»º/ç¡®ä¿å­˜åœ¨
                try:
                    await self.jetstream._jsm.add_consumer(stream_name, desired_config)
                except Exception:
                    # è‹¥å·²å­˜åœ¨åˆ™å¿½ç•¥
                    pass

                # ç»‘å®šåˆ°å·²åˆ›å»ºçš„consumerï¼Œæ˜¾å¼æŒ‡å®šstreamé¿å…è‡ªåŠ¨ç»‘å®šé€ æˆçš„é»˜è®¤ç­–ç•¥
                subscription = await self.jetstream.subscribe(
                    subject=subject_pattern,
                    cb=_cb,
                    durable=new_durable,
                    stream=stream_name
                )
                print(f"âœ… è®¢é˜…æˆåŠŸ(JS): {data_type} -> {subject_pattern} (durable={new_durable}, enforced_policy=LAST, max_ack_pending={(5000 if data_type == 'orderbook' else 2000)})")
                self.subscriptions[data_type] = subscription
                return
            except Exception as js_err:
                print(f"âŒ è®¢é˜…å¤±è´¥ {data_type} (JetStream): {js_err} â€” å°è¯•å›é€€åˆ° Core NATS")
                print(traceback.format_exc())

            # å›é€€åˆ° Core NATSï¼ˆä½¿ç”¨åç¨‹å›è°ƒï¼‰
            try:
                subscription = await self.nats_client.subscribe(
                    subject_pattern,
                    cb=_cb
                )
                self.subscriptions[data_type] = subscription
                print(f"âœ… è®¢é˜…æˆåŠŸ(Core): {data_type} -> {subject_pattern}")
            except Exception as core_err:
                print(f"âŒ Core subscription failed {data_type}: {core_err}")
                print(traceback.format_exc())
                # Don't raise exception, continue with other subscriptions
                pass

        except Exception as e:
            print(f"âŒ è®¢é˜… {data_type} å¤±è´¥: {e}")
            print(traceback.format_exc())

    async def _handle_message(self, msg, data_type: str):
        """å¤„ç†NATSæ¶ˆæ¯ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        try:
            # æ›´æ–°ç»Ÿè®¡
            self.stats["messages_received"] += 1
            # ç»Ÿä¸€ä¸º epoch ç§’ï¼Œä¾¿äº Prometheus æŒ‡æ ‡ç›´æ¥è¾“å‡º
            self.stats["last_message_time"] = time.time()

            # è§£ææ¶ˆæ¯
            try:
                data = json.loads(msg.data.decode())
            except json.JSONDecodeError as e:
                self.logger.error(f"æ¶ˆæ¯JSONè§£æå¤±è´¥ {data_type}: {e}")
                try:
                    await msg.nak()
                except Exception:
                    pass
                self.stats["messages_failed"] += 1
                self.stats["validation_errors"] += 1
                return

            # éªŒè¯æ•°æ®æ ¼å¼
            try:
                validated_data = self._validate_message_data(data, data_type)
            except DataValidationError as e:
                self.logger.error(f"æ•°æ®éªŒè¯å¤±è´¥ {data_type}: {e}")
                try:
                    await msg.nak()
                except Exception:
                    pass
                self.stats["validation_errors"] += 1
                return

            #   :       
            #    orderbook  trade  
            success = False
            if data_type in self.batch_config.get("high_freq_types", {"orderbook", "trade"}):
                enq = await self._store_to_batch_buffer(data_type, validated_data)
                if enq:
                    #  ->  
                    try:
                        await msg.ack()
                    except Exception:
                        pass
                    self.stats["messages_processed"] += 1
                    print(f"âœ… å·²å…¥é˜Ÿç­‰å¾…æ‰¹é‡: {data_type} -> {msg.subject}")
                    success = True
                else:
                    # æ‰¹é‡å…¥é˜Ÿå¤±è´¥åˆ™å›é€€ä¸ºå•æ¡å…¥åº“
                    success = await self._store_to_clickhouse_with_retry(data_type, validated_data)
                    if success:
                        try:
                            await msg.ack()
                        except Exception:
                            pass
                        self.stats["messages_processed"] += 1
                        print(f"âœ… æ¶ˆæ¯å¤„ç†æˆåŠŸ: {data_type} -> {msg.subject}")
            else:
                # ä½é¢‘ç±»å‹ï¼šå•æ¡å…¥åº“å¹¶æˆåŠŸåACK
                success = await self._store_to_clickhouse_with_retry(data_type, validated_data)
                if success:
                    try:
                        await msg.ack()
                    except Exception:
                        pass
                    self.stats["messages_processed"] += 1
                    print(f"âœ… æ¶ˆæ¯å¤„ç†æˆåŠŸ: {data_type} -> {msg.subject}")

            if success:
                pass
            else:
                #  
                try:
                    await msg.nak()
                except Exception:
                    pass
                self.stats["messages_failed"] += 1
                # ç»Ÿä¸€ä¸º epoch ç§’ï¼Œä¾¿äº Prometheus æŒ‡æ ‡è¾“å‡º
                self.stats["last_error_time"] = time.time()
                print(f"âŒ : {data_type} -> {msg.subject}")

        except Exception as e:
            # å¤„ç†å¼‚å¸¸ï¼Œæ‹’ç»æ¶ˆæ¯ï¼ˆä»… JetStream æ¶ˆæ¯æ”¯æŒ NAKï¼‰
            try:
                await msg.nak()
            except Exception:
                pass

            self.stats["messages_failed"] += 1
            self.stats["last_error_time"] = datetime.now(timezone.utc)
            self.logger.error(f"æ¶ˆæ¯å¤„ç†å¼‚å¸¸ {data_type}: {e}")
            print(f"âŒ æ¶ˆæ¯å¤„ç†å¼‚å¸¸ {data_type}: {e}")

    def _validate_message_data(self, data: Dict[str, Any], data_type: str) -> Dict[str, Any]:
        """éªŒè¯æ¶ˆæ¯æ•°æ®æ ¼å¼"""
        try:
            validated_data = {}

            # éªŒè¯åŸºç¡€å­—æ®µ
            validated_data['timestamp'] = self.validator.validate_timestamp(
                data.get('timestamp'), 'timestamp'
            )
            validated_data['exchange'] = str(data.get('exchange', ''))
            validated_data['market_type'] = str(data.get('market_type', ''))
            validated_data['symbol'] = str(data.get('symbol', ''))
            validated_data['data_source'] = str(data.get('data_source', 'simple_hot_storage'))

            # æ ¹æ®æ•°æ®ç±»å‹éªŒè¯ç‰¹å®šå­—æ®µ
            if data_type in ['orderbook']:
                validated_data['last_update_id'] = self.validator.validate_numeric(
                    data.get('last_update_id'), 'last_update_id', 0
                )

                # å¤„ç†è®¢å•ç°¿æ•°æ®å¹¶æå–æœ€ä¼˜ä»·æ ¼
                bids_data = data.get('bids', '[]')
                asks_data = data.get('asks', '[]')

                validated_data['bids'] = self.validator.validate_json_data(bids_data, 'bids')
                validated_data['asks'] = self.validator.validate_json_data(asks_data, 'asks')

                # æå–æœ€ä¼˜ä¹°å–ä»·
                try:
                    import json
                    bids_list = json.loads(bids_data) if isinstance(bids_data, str) else bids_data
                    asks_list = json.loads(asks_data) if isinstance(asks_data, str) else asks_data

                    # æå–æœ€ä¼˜ä¹°ä»·ï¼ˆbidsç¬¬ä¸€ä¸ªï¼‰
                    if bids_list and len(bids_list) > 0:
                        best_bid = bids_list[0]
                        if isinstance(best_bid, dict):
                            validated_data['best_bid_price'] = float(best_bid.get('price', 0))
                            validated_data['best_bid_quantity'] = float(best_bid.get('quantity', 0))
                        elif isinstance(best_bid, list) and len(best_bid) >= 2:
                            validated_data['best_bid_price'] = float(best_bid[0])
                            validated_data['best_bid_quantity'] = float(best_bid[1])
                        else:
                            validated_data['best_bid_price'] = 0
                            validated_data['best_bid_quantity'] = 0
                    else:
                        validated_data['best_bid_price'] = 0
                        validated_data['best_bid_quantity'] = 0

                    # æå–æœ€ä¼˜å–ä»·ï¼ˆasksç¬¬ä¸€ä¸ªï¼‰
                    if asks_list and len(asks_list) > 0:
                        best_ask = asks_list[0]
                        if isinstance(best_ask, dict):
                            validated_data['best_ask_price'] = float(best_ask.get('price', 0))
                            validated_data['best_ask_quantity'] = float(best_ask.get('quantity', 0))
                        elif isinstance(best_ask, list) and len(best_ask) >= 2:
                            validated_data['best_ask_price'] = float(best_ask[0])
                            validated_data['best_ask_quantity'] = float(best_ask[1])
                        else:
                            validated_data['best_ask_price'] = 0
                            validated_data['best_ask_quantity'] = 0
                    else:
                        validated_data['best_ask_price'] = 0
                        validated_data['best_ask_quantity'] = 0

                    # è®¡ç®—bidså’Œasksæ•°é‡
                    validated_data['bids_count'] = len(bids_list) if bids_list else 0
                    validated_data['asks_count'] = len(asks_list) if asks_list else 0

                except Exception as e:
                    print(f"âš ï¸ è®¢å•ç°¿ä»·æ ¼æå–å¤±è´¥: {e}")
                    validated_data['best_bid_price'] = 0
                    validated_data['best_ask_price'] = 0
                    validated_data['best_bid_quantity'] = 0
                    validated_data['best_ask_quantity'] = 0
                    validated_data['bids_count'] = 0
                    validated_data['asks_count'] = 0

            elif data_type in ['trade']:
                validated_data['trade_id'] = str(data.get('trade_id', ''))
                validated_data['price'] = self.validator.validate_numeric(
                    data.get('price'), 'price', 0.0
                )
                validated_data['quantity'] = self.validator.validate_numeric(
                    data.get('quantity'), 'quantity', 0.0
                )
                validated_data['side'] = str(data.get('side', ''))
                validated_data['is_maker'] = bool(data.get('is_maker', False))
                # å…¼å®¹è¡¨ç»“æ„ï¼šè‹¥æœªæä¾› trade_time åˆ™ä½¿ç”¨æ¶ˆæ¯ timestamp
                validated_data['trade_time'] = self.validator.validate_timestamp(
                    data.get('trade_time') or data.get('timestamp'), 'trade_time'
                )

            elif data_type in ['funding_rate']:
                # ğŸ”§ ä¿®å¤ï¼šä» current_funding_rate å­—æ®µè¯»å–æ•°æ®ï¼ˆä¸ Collector å‘å¸ƒçš„å­—æ®µåä¸€è‡´ï¼‰
                validated_data['funding_rate'] = self.validator.validate_numeric(
                    data.get('current_funding_rate'), 'current_funding_rate', 0.0
                )
                validated_data['funding_time'] = self.validator.validate_timestamp(
                    data.get('funding_time'), 'funding_time'
                )
                validated_data['next_funding_time'] = self.validator.validate_timestamp(
                    data.get('next_funding_time'), 'next_funding_time'
                )

            elif data_type in ['liquidation']:
                # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ  liquidation æ•°æ®éªŒè¯é€»è¾‘
                validated_data['side'] = str(data.get('side', ''))
                validated_data['price'] = self.validator.validate_numeric(
                    data.get('price'), 'price', 0.0
                )
                validated_data['quantity'] = self.validator.validate_numeric(
                    data.get('quantity'), 'quantity', 0.0
                )
                validated_data['liquidation_time'] = self.validator.validate_timestamp(
                    data.get('liquidation_time') or data.get('timestamp'), 'liquidation_time'
                )


            elif data_type in ['volatility_index']:
                # ğŸ”§ æ–°å¢ï¼šæ·»åŠ  volatility_index æ•°æ®éªŒè¯é€»è¾‘
                validated_data['volatility_index'] = self.validator.validate_numeric(
                    data.get('volatility_index'), 'volatility_index', 0.0
                )
                validated_data['index_value'] = self.validator.validate_numeric(
                    data.get('volatility_index'), 'volatility_index', 0.0  # å…¼å®¹å­—æ®µå
                )
                validated_data['underlying_asset'] = str(data.get('underlying_asset', ''))
                validated_data['maturity_date'] = self.validator.validate_timestamp(
                    data.get('maturity_date'), 'maturity_date'
                )

            elif data_type in ['open_interest']:
                # æ·»åŠ  open_interest æ•°æ®éªŒè¯é€»è¾‘
                validated_data['open_interest'] = self.validator.validate_numeric(
                    data.get('open_interest'), 'open_interest', 0.0
                )
                validated_data['open_interest_value'] = self.validator.validate_numeric(
                    data.get('open_interest_value'), 'open_interest_value', 0.0
                )

            elif data_type in ['lsr_top_position']:
                # æ·»åŠ  lsr_top_position æ•°æ®éªŒè¯é€»è¾‘
                validated_data['long_position_ratio'] = self.validator.validate_numeric(
                    data.get('long_position_ratio'), 'long_position_ratio', 0.0
                )
                validated_data['short_position_ratio'] = self.validator.validate_numeric(
                    data.get('short_position_ratio'), 'short_position_ratio', 0.0
                )
                validated_data['period'] = str(data.get('period', ''))

            elif data_type in ['lsr_all_account']:
                # æ·»åŠ  lsr_all_account æ•°æ®éªŒè¯é€»è¾‘
                validated_data['long_account_ratio'] = self.validator.validate_numeric(
                    data.get('long_account_ratio'), 'long_account_ratio', 0.0
                )
                validated_data['short_account_ratio'] = self.validator.validate_numeric(
                    data.get('short_account_ratio'), 'short_account_ratio', 0.0
                )
                validated_data['period'] = str(data.get('period', ''))

            # æ·»åŠ å…¶ä»–æ•°æ®ç±»å‹çš„éªŒè¯...

            return validated_data

        except Exception as e:
            raise DataValidationError(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")

    async def _store_to_clickhouse_with_retry(self, data_type: str, data: Dict[str, Any]) -> bool:
        """å¸¦é‡è¯•æœºåˆ¶çš„ClickHouseå­˜å‚¨"""
        max_retries = self.retry_config['max_retries']
        delay = self.retry_config['retry_delay']
        backoff = self.retry_config['backoff_multiplier']

        for attempt in range(max_retries + 1):
            try:
                success = await self._store_to_clickhouse(data_type, data)
                if success:
                    if attempt > 0:
                        self.logger.info(f"é‡è¯•æˆåŠŸ {data_type}ï¼Œå°è¯•æ¬¡æ•°: {attempt + 1}")
                    return True

                if attempt < max_retries:
                    self.stats["retry_attempts"] += 1
                    await asyncio.sleep(delay)
                    delay *= backoff


            except Exception as e:
                self.logger.error(f"å­˜å‚¨å°è¯• {attempt + 1} å¤±è´¥ {data_type}: {e}")
                if attempt < max_retries:
                    self.stats["retry_attempts"] += 1
                    await asyncio.sleep(delay)
                    delay *= backoff
                else:
                    self.logger.error(f"æ‰€æœ‰é‡è¯•å°è¯•å¤±è´¥ {data_type}")

        return False

    def _get_ch_client(self):
        """è·å–æˆ–åˆå§‹åŒ– ClickHouse TCP å®¢æˆ·ç«¯"""
        if getattr(self, "_ch_client", None) is not None:
            return self._ch_client
        if not CHClient or not self.hot_storage_config.get('use_clickhouse_driver', True):
            return None
        try:
            host = self.hot_storage_config.get('clickhouse_host', 'localhost')
            port = int(self.hot_storage_config.get('clickhouse_tcp_port', 9000))
            user = self.hot_storage_config.get('clickhouse_user', 'default')
            password = self.hot_storage_config.get('clickhouse_password', '')
            database = self.hot_storage_config.get('clickhouse_database', 'marketprism_hot')
            self._ch_client = CHClient(host=host, port=port, user=user, password=password, database=database)
            return self._ch_client
        except Exception as e:
            print(f"âš ï¸ åˆå§‹åŒ– ClickHouse é©±åŠ¨å¤±è´¥ï¼Œå°†å›é€€HTTP: {e}")
            self._ch_client = None
            return None

    async def _store_to_batch_buffer(self, data_type: str, data: Dict[str, Any]) -> bool:
        """å°†æ•°æ®æ·»åŠ åˆ°æ‰¹é‡ç¼“å†²åŒº"""
        try:
            # åˆå§‹åŒ–æ•°æ®ç±»å‹çš„ç¼“å†²åŒºå’Œé”
            if data_type not in self.batch_buffers:
                self.batch_buffers[data_type] = []
                self.batch_locks[data_type] = asyncio.Lock()

            async with self.batch_locks[data_type]:
                self.batch_buffers[data_type].append(data)

                # ç¡®å®šæ‰¹é‡å¤§å°é˜ˆå€¼ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
                if data_type == "trade":
                    batch_threshold = self.batch_config.get("trade_batch_size", 150)
                elif data_type in self.batch_config["high_freq_types"]:
                    batch_threshold = self.batch_config["max_batch_size"]
                else:
                    batch_threshold = self.batch_config["low_freq_batch_size"]

                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ·æ–°
                if len(self.batch_buffers[data_type]) >= batch_threshold:
                    await self._flush_batch_buffer(data_type)

                # å¯åŠ¨å®šæ—¶åˆ·æ–°ä»»åŠ¡ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
                if data_type not in self.batch_tasks or self.batch_tasks[data_type].done():
                    self.batch_tasks[data_type] = asyncio.create_task(
                        self._batch_flush_timer(data_type)
                    )

            return True

        except Exception as e:
            self.logger.error(f"æ‰¹é‡ç¼“å†²å¤±è´¥ {data_type}: {e}")
            # å›é€€åˆ°å•æ¡å­˜å‚¨
            return await self._store_to_clickhouse_with_retry(data_type, data)

    async def _batch_flush_timer(self, data_type: str):
        """æ‰¹é‡åˆ·æ–°å®šæ—¶å™¨"""
        try:
            while self.is_running:
                # è®¢å•ç°¿ä½¿ç”¨æ›´å¿«çš„åˆ·æ–°é—´éš”
                if data_type == "orderbook":
                    flush_interval = self.batch_config.get("orderbook_flush_interval", 0.5)
                else:
                    flush_interval = self.batch_config["flush_interval"]

                await asyncio.sleep(flush_interval)

                async with self.batch_locks[data_type]:
                    if self.batch_buffers[data_type]:
                        await self._flush_batch_buffer(data_type)

        except asyncio.CancelledError:
            # æœåŠ¡åœæ­¢æ—¶åˆ·æ–°å‰©ä½™æ•°æ®
            async with self.batch_locks[data_type]:
                if self.batch_buffers[data_type]:
                    await self._flush_batch_buffer(data_type)
        except Exception as e:
            self.logger.error(f"æ‰¹é‡åˆ·æ–°å®šæ—¶å™¨å¼‚å¸¸ {data_type}: {e}")

    async def _flush_batch_buffer(self, data_type: str):
        """åˆ·æ–°æ‰¹é‡ç¼“å†²åŒºåˆ°ClickHouse"""
        if not self.batch_buffers[data_type]:
            return

        batch_data = self.batch_buffers[data_type].copy()
        self.batch_buffers[data_type].clear()

        try:
            success = await self._batch_insert_to_clickhouse(data_type, batch_data)
            if success:
                self.stats["batch_inserts"] += 1
                self.stats["batch_size_total"] += len(batch_data)
                print(f"âœ… æ‰¹é‡æ’å…¥æˆåŠŸ: {data_type} -> {len(batch_data)} æ¡è®°å½•")
            else:
                # æ‰¹é‡æ’å…¥å¤±è´¥ï¼Œå›é€€åˆ°å•æ¡æ’å…¥
                print(f"âš ï¸ æ‰¹é‡æ’å…¥å¤±è´¥ï¼Œå›é€€åˆ°å•æ¡æ’å…¥: {data_type}")
                for data in batch_data:
                    await self._store_to_clickhouse_with_retry(data_type, data)

        except Exception as e:
            self.logger.error(f"æ‰¹é‡åˆ·æ–°å¤±è´¥ {data_type}: {e}")
            # å›é€€åˆ°å•æ¡æ’å…¥
            for data in batch_data:
                await self._store_to_clickhouse_with_retry(data_type, data)

    async def _store_to_clickhouse(self, data_type: str, data: Dict[str, Any]) -> bool:
        """å­˜å‚¨æ•°æ®åˆ°ClickHouseï¼ˆä¼˜å…ˆTCPé©±åŠ¨ï¼Œå¤±è´¥å›é€€HTTPï¼‰"""
        try:
            host = self.hot_storage_config.get('clickhouse_host', 'localhost')
            http_port = self.hot_storage_config.get('clickhouse_http_port', 8123)
            database = self.hot_storage_config.get('clickhouse_database', 'marketprism_hot')

            # è·å–è¡¨å - æ›´æ–°ä¸º8ç§æ•°æ®ç±»å‹çš„åˆ†ç¦»è¡¨
            table_mapping = {
                "orderbook": "orderbooks",
                "trade": "trades",
                "funding_rate": "funding_rates",
                "open_interest": "open_interests",
                "liquidation": "liquidations",
                "lsr_top_position": "lsr_top_positions",    # åˆ†ç¦»çš„LSRé¡¶çº§æŒä»“è¡¨
                "lsr_all_account": "lsr_all_accounts",      # åˆ†ç¦»çš„LSRå…¨è´¦æˆ·è¡¨
                "volatility_index": "volatility_indices"
            }
            table_name = table_mapping.get(data_type, data_type)

            # æ„å»ºæ’å…¥SQL
            insert_sql = self._build_insert_sql(table_name, data)

            # 1) å°è¯•ä½¿ç”¨ TCP é©±åŠ¨
            ch = self._get_ch_client()
            if ch:
                try:
                    ch.execute(insert_sql)
                    return True
                except Exception as e:
                    print(f"âš ï¸ ClickHouseé©±åŠ¨æ‰§è¡Œå¤±è´¥ï¼Œå›é€€HTTP: {e}")

            # 2) å›é€€åˆ° HTTP
            url = f"http://{host}:{http_port}/?database={database}"
            async with aiohttp.ClientSession() as session:
                async with session.post(url, data=insert_sql) as response:
                    if response.status == 200:
                        return True
                    else:
                        error_text = await response.text()
                        print(f"âŒ ClickHouseæ’å…¥å¤±è´¥: {error_text}")
                        return False

        except Exception as e:
            print(f"âŒ å­˜å‚¨åˆ°ClickHouseå¼‚å¸¸: {e}")
            return False

    async def _batch_insert_to_clickhouse(self, data_type: str, batch_data: List[Dict[str, Any]]) -> bool:
        """æ‰¹é‡æ’å…¥æ•°æ®åˆ°ClickHouseï¼ˆä¼˜å…ˆTCPé©±åŠ¨ï¼Œå¤±è´¥å›é€€HTTPï¼‰"""
        if not batch_data:
            return True

        try:
            host = self.hot_storage_config.get('clickhouse_host', 'localhost')
            http_port = self.hot_storage_config.get('clickhouse_http_port', 8123)
            database = self.hot_storage_config.get('clickhouse_database', 'marketprism_hot')

            # è·å–è¡¨å
            table_mapping = {
                "orderbook": "orderbooks",
                "trade": "trades",
                "funding_rate": "funding_rates",
                "open_interest": "open_interests",
                "liquidation": "liquidations",
                "lsr_top_position": "lsr_top_positions",
                "lsr_all_account": "lsr_all_accounts",
                "volatility_index": "volatility_indices"
            }
            table_name = table_mapping.get(data_type, data_type)

            # æ„å»ºæ‰¹é‡æ’å…¥SQL
            batch_sql = self._build_batch_insert_sql(table_name, batch_data)
            if not batch_sql:
                return False

            # 1) å…ˆå°è¯• TCP é©±åŠ¨
            ch = self._get_ch_client()
            if ch:
                try:
                    ch.execute(batch_sql)
                    self.stats["tcp_driver_hits"] += 1
                    if self.stats["tcp_driver_hits"] % 50 == 0:  # æ¯50æ¬¡æ‰“å°ä¸€æ¬¡ç»Ÿè®¡
                        tcp_total = self.stats["tcp_driver_hits"]
                        http_total = self.stats["http_fallback_hits"]
                        tcp_rate = tcp_total / (tcp_total + http_total) * 100 if (tcp_total + http_total) > 0 else 0
                        print(f"ğŸ“Š ClickHouseé©±åŠ¨ç»Ÿè®¡: TCP={tcp_total}, HTTP={http_total}, TCPå‘½ä¸­ç‡={tcp_rate:.1f}%")
                    return True
                except Exception as e:
                    print(f"âš ï¸ ClickHouseé©±åŠ¨æ‰¹é‡æ‰§è¡Œå¤±è´¥ï¼Œå›é€€HTTP: {e}")

            # 2) å›é€€åˆ° HTTP
            self.stats["http_fallback_hits"] += 1
            url = f"http://{host}:{http_port}/?database={database}"

            async with aiohttp.ClientSession() as session:
                async with session.post(url, data=batch_sql) as response:
                    if response.status == 200:
                        return True
                    else:
                        error_text = await response.text()
                        print(f"âŒ ClickHouseæ‰¹é‡æ’å…¥å¤±è´¥: {error_text}")
                        return False

        except Exception as e:
            print(f"âŒ æ‰¹é‡æ’å…¥åˆ°ClickHouseå¼‚å¸¸: {e}")
            return False

    def _build_batch_insert_sql(self, table_name: str, batch_data: List[Dict[str, Any]]) -> str:
        """æ„å»ºæ‰¹é‡æ’å…¥SQL"""
        if not batch_data:
            return ""

        try:
            # ä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•ç¡®å®šå­—æ®µç»“æ„
            first_record = batch_data[0]

            # åŸºç¡€å­—æ®µ
            fields = ['timestamp', 'exchange', 'market_type', 'symbol', 'data_source']

            # æ ¹æ®æ•°æ®ç±»å‹æ·»åŠ ç‰¹å®šå­—æ®µ
            if table_name == 'orderbooks':
                fields.extend([
                    'last_update_id', 'bids_count', 'asks_count',
                    'best_bid_price', 'best_ask_price', 'best_bid_quantity', 'best_ask_quantity',
                    'bids', 'asks'
                ])
            elif table_name == 'trades':
                fields.extend(['trade_id', 'price', 'quantity', 'side', 'is_maker', 'trade_time'])
            elif table_name == 'funding_rates':
                fields.extend(['funding_rate', 'funding_time', 'next_funding_time'])
            elif table_name == 'liquidations':
                fields.extend(['side', 'price', 'quantity', 'liquidation_time'])
            elif table_name == 'lsr_top_positions':
                fields.extend(['long_position_ratio', 'short_position_ratio', 'period'])
            elif table_name == 'lsr_all_accounts':
                fields.extend(['long_account_ratio', 'short_account_ratio', 'period'])

            # æ„å»ºVALUESå­å¥
            values_list = []
            for data in batch_data:
                values = self._build_values_for_record(table_name, data, fields)
                if values:
                    values_list.append(f"({', '.join(values)})")

            if not values_list:
                return ""

            # æ„å»ºå®Œæ•´SQL
            fields_str = ', '.join(fields)
            values_str = ',\n    '.join(values_list)

            sql = f"INSERT INTO {table_name} ({fields_str}) VALUES\n    {values_str}"
            return sql

        except Exception as e:
            print(f"âŒ æ„å»ºæ‰¹é‡SQLå¤±è´¥: {e}")
            return ""

    def _build_insert_sql(self, table_name: str, data: Dict[str, Any]) -> str:
        """æ„å»ºæ’å…¥SQLï¼ˆä½¿ç”¨å·²éªŒè¯çš„æ•°æ®ï¼‰"""
        try:
            # åŸºç¡€å­—æ®µï¼ˆæ•°æ®å·²ç»è¿‡éªŒè¯ï¼‰
            fields = ['timestamp', 'exchange', 'market_type', 'symbol', 'data_source']
            values = [
                f"'{data['timestamp']}'",
                f"'{data['exchange']}'",
                f"'{data['market_type']}'",
                f"'{data['symbol']}'",
                f"'{data['data_source']}'"
            ]

            # æ ¹æ®æ•°æ®ç±»å‹æ·»åŠ ç‰¹å®šå­—æ®µï¼ˆæ•°æ®å·²ç»è¿‡éªŒè¯å’Œæ ¼å¼åŒ–ï¼‰
            if table_name == 'orderbooks':
                # å†™å…¥å®Œæ•´çš„è®¢å•ç°¿æ•°æ®ï¼ŒåŒ…æ‹¬æœ€ä¼˜ä»·æ ¼
                fields.extend([
                    'last_update_id', 'bids_count', 'asks_count',
                    'best_bid_price', 'best_ask_price', 'best_bid_quantity', 'best_ask_quantity',
                    'bids', 'asks'
                ])
                values.extend([
                    str(data['last_update_id']),
                    str(data['bids_count']),
                    str(data['asks_count']),
                    str(data['best_bid_price']),
                    str(data['best_ask_price']),
                    str(data['best_bid_quantity']),
                    str(data['best_ask_quantity']),
                    f"'{data['bids']}'",  # å·²ç»æ˜¯æ ‡å‡†JSONæ ¼å¼
                    f"'{data['asks']}'"   # å·²ç»æ˜¯æ ‡å‡†JSONæ ¼å¼
                ])

            elif table_name == 'trades':
                fields.extend(['trade_id', 'price', 'quantity', 'side', 'is_maker', 'trade_time'])
                values.extend([
                    f"'{data['trade_id']}'",
                    str(data['price']),
                    str(data['quantity']),
                    f"'{data['side']}'",
                    str(data['is_maker']).lower(),
                    f"'{data.get('trade_time', data['timestamp'])}'"
                ])

            elif table_name == 'funding_rates':
                fields.extend(['funding_rate', 'funding_time', 'next_funding_time'])
                values.extend([
                    str(data['funding_rate']),
                    f"'{data['funding_time']}'",  # å·²ç»æ ¼å¼åŒ–
                    f"'{data['next_funding_time']}'"  # å·²ç»æ ¼å¼åŒ–
                ])

            elif table_name == 'liquidations':
                fields.extend(['side', 'price', 'quantity', 'liquidation_time'])
                values.extend([
                    f"'{data.get('side', '')}'",
                    str(data['price']),
                    str(data['quantity']),
                    f"'{data.get('liquidation_time', data['timestamp'])}'"
                ])

            elif table_name == 'lsr_top_positions':
                # å¤„ç†LSRé¡¶çº§æŒä»“æ¯”ä¾‹æ•°æ®
                fields.extend(['long_position_ratio', 'short_position_ratio', 'period'])
                values.extend([
                    str(data.get('long_position_ratio', 0)),
                    str(data.get('short_position_ratio', 0)),
                    f"'{data.get('period', '5m')}'"
                ])

            elif table_name == 'lsr_all_accounts':
                # å¤„ç†LSRå…¨è´¦æˆ·æ¯”ä¾‹æ•°æ®
                fields.extend(['long_account_ratio', 'short_account_ratio', 'period'])
                values.extend([
                    str(data.get('long_account_ratio', 0)),
                    str(data.get('short_account_ratio', 0)),
                    f"'{data.get('period', '5m')}'"
                ])

            # æ„å»ºSQL
            fields_str = ', '.join(fields)
            values_str = ', '.join(values)

            sql = f"INSERT INTO {table_name} ({fields_str}) VALUES ({values_str})"
            return sql

        except Exception as e:
            print(f"âŒ æ„å»ºSQLå¤±è´¥: {e}")
            return ""

    def _build_values_for_record(self, table_name: str, data: Dict[str, Any], fields: List[str]) -> List[str]:
        """ä¸ºå•æ¡è®°å½•æ„å»ºVALUES"""
        try:
            values = []

            for field in fields:
                if field == 'timestamp':
                    values.append(f"'{data['timestamp']}'")
                elif field == 'exchange':
                    values.append(f"'{data['exchange']}'")
                elif field == 'market_type':
                    values.append(f"'{data['market_type']}'")
                elif field == 'symbol':
                    values.append(f"'{data['symbol']}'")
                elif field == 'data_source':
                    values.append(f"'{data['data_source']}'")
                elif field in ['last_update_id', 'bids_count', 'asks_count']:
                    values.append(str(data.get(field, 0)))
                elif field in ['best_bid_price', 'best_ask_price', 'best_bid_quantity', 'best_ask_quantity']:
                    values.append(str(data.get(field, 0)))
                elif field in ['bids', 'asks']:
                    values.append(f"'{data.get(field, '[]')}'")
                elif field == 'trade_id':
                    values.append(f"'{data.get(field, '')}'")
                elif field in ['price', 'quantity']:
                    values.append(str(data.get(field, 0)))
                elif field == 'side':
                    values.append(f"'{data.get(field, '')}'")
                elif field == 'is_maker':
                    values.append(str(data.get(field, False)).lower())
                elif field == 'trade_time':
                    values.append(f"'{data.get(field, data.get('timestamp', ''))}'")
                elif field == 'funding_rate':
                    values.append(str(data.get(field, 0)))
                elif field in ['funding_time', 'next_funding_time']:
                    values.append(f"'{data.get(field, data.get('timestamp', ''))}'")
                elif field == 'liquidation_time':
                    values.append(f"'{data.get(field, data.get('timestamp', ''))}'")
                elif field in ['long_position_ratio', 'short_position_ratio', 'long_account_ratio', 'short_account_ratio']:
                    values.append(str(data.get(field, 0)))
                elif field == 'period':
                    values.append(f"'{data.get(field, '5m')}'")
                else:
                    values.append("''")  # é»˜è®¤ç©ºå­—ç¬¦ä¸²

            return values

        except Exception as e:
            print(f"âŒ æ„å»ºè®°å½•VALUESå¤±è´¥: {e}")
            return []

    async def stop(self):
        """åœæ­¢æœåŠ¡"""
        try:
            print("ğŸ›‘ åœæ­¢ç®€åŒ–çƒ­ç«¯æ•°æ®å­˜å‚¨æœåŠ¡")

            self.is_running = False

            # ğŸ”§ åˆ·æ–°æ‰€æœ‰æ‰¹é‡ç¼“å†²åŒº
            print("ğŸ”„ åˆ·æ–°æ‰¹é‡ç¼“å†²åŒº...")
            for data_type in list(self.batch_buffers.keys()):
                try:
                    if data_type in self.batch_locks:
                        async with self.batch_locks[data_type]:
                            if self.batch_buffers[data_type]:
                                await self._flush_batch_buffer(data_type)
                                print(f"âœ… å·²åˆ·æ–° {data_type} ç¼“å†²åŒº")
                except Exception as e:
                    print(f"âŒ åˆ·æ–°ç¼“å†²åŒºå¤±è´¥ {data_type}: {e}")

            # ğŸ”§ å–æ¶ˆæ‰¹é‡åˆ·æ–°ä»»åŠ¡
            for data_type, task in self.batch_tasks.items():
                try:
                    if not task.done():
                        task.cancel()
                        await task
                except asyncio.CancelledError:
                    pass
                except Exception as e:
                    print(f"âŒ å–æ¶ˆæ‰¹é‡ä»»åŠ¡å¤±è´¥ {data_type}: {e}")

            # å…³é—­è®¢é˜…
            for data_type, subscription in self.subscriptions.items():
                try:
                    await subscription.unsubscribe()
                    print(f"âœ… è®¢é˜…å·²å…³é—­: {data_type}")
                except Exception as e:
                    print(f"âŒ å…³é—­è®¢é˜…å¤±è´¥ {data_type}: {e}")

            # å…³é—­NATSè¿æ¥
            if self.nats_client:
                await self.nats_client.close()
                print("âœ… NATSè¿æ¥å·²å…³é—­")

            # è®¾ç½®å…³é—­äº‹ä»¶
            self.shutdown_event.set()

            print("âœ… ç®€åŒ–çƒ­ç«¯æ•°æ®å­˜å‚¨æœåŠ¡å·²åœæ­¢")

        except Exception as e:
            print(f"âŒ åœæ­¢æœåŠ¡å¤±è´¥: {e}")

    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            print(f"ğŸ“¡ æ”¶åˆ°åœæ­¢ä¿¡å·: {signum}")
            asyncio.create_task(self.stop())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "service_status": {
                "is_running": self.is_running,
                "subscriptions_count": len(self.subscriptions),
                "nats_connected": self.nats_client is not None and not self.nats_client.is_closed
            },
            "message_stats": self.stats,
            "health_check": {
                "status": "healthy" if self.is_running else "unhealthy",
                "nats_connected": self.nats_client is not None and not self.nats_client.is_closed,
                "subscriptions_active": len(self.subscriptions)
            }
        }

    def _get_health_status(self) -> Dict[str, Any]:
        """è·å–å¥åº·çŠ¶æ€"""
        now = datetime.now(timezone.utc)

        # æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ¶ˆæ¯å¤„ç†
        last_message_time = self.stats.get("last_message_time")
        message_lag = None
        if last_message_time:
            if isinstance(last_message_time, str):
                last_message_time = datetime.fromisoformat(last_message_time.replace('Z', '+00:00'))
            message_lag = (now - last_message_time).total_seconds()

        # è®¡ç®—é”™è¯¯ç‡
        total_messages = self.stats["messages_received"]
        failed_messages = self.stats["messages_failed"]
        error_rate = (failed_messages / total_messages * 100) if total_messages > 0 else 0

        # å¥åº·çŠ¶æ€è¯„ä¼°
        health_status = "healthy"
        issues = []

        if not self.is_running:
            health_status = "unhealthy"
            issues.append("Service not running")

        if message_lag and message_lag > 300:  # 5åˆ†é’Ÿæ²¡æœ‰æ¶ˆæ¯
            health_status = "degraded"
            issues.append(f"No messages for {message_lag:.0f} seconds")

        if error_rate > 10:  # é”™è¯¯ç‡è¶…è¿‡10%
            health_status = "degraded"
            issues.append(f"High error rate: {error_rate:.1f}%")

        if len(self.subscriptions) == 0:
            health_status = "unhealthy"
            issues.append("No active subscriptions")

        return {
            "status": health_status,
            "issues": issues,
            "metrics": {
                "message_lag_seconds": message_lag,
                "error_rate_percent": round(error_rate, 2),
                "active_subscriptions": len(self.subscriptions),
                "total_retries": self.stats["retry_attempts"]
            }
        }

    async def health_check(self) -> bool:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥NATSè¿æ¥
            if not self.nats_client or self.nats_client.is_closed:
                return False

            # æ£€æŸ¥ClickHouseè¿æ¥
            host = self.hot_storage_config.get('clickhouse_host', 'localhost')
            port = self.hot_storage_config.get('clickhouse_http_port', 8123)

            async with aiohttp.ClientSession() as session:
                async with session.get(f"http://{host}:{port}/ping", timeout=5) as response:
                    if response.status != 200:
                        return False

            return True

        except Exception as e:
            self.logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def setup_http_server(self):
        """è®¾ç½®HTTPæœåŠ¡å™¨"""
        self.app = web.Application()

        # æ·»åŠ è·¯ç”±
        self.app.router.add_get('/health', self.handle_health)
        self.app.router.add_get('/stats', self.handle_stats)
        self.app.router.add_get('/metrics', self.handle_metrics)

        # å¯åŠ¨HTTPæœåŠ¡å™¨
        runner = web.AppRunner(self.app)
        await runner.setup()

        site = web.TCPSite(runner, '0.0.0.0', self.http_port)
        await site.start()

        self.http_server = runner
        self.logger.info(f"âœ… HTTPæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼Œç«¯å£: {self.http_port}")

    async def handle_health(self, request):
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        is_healthy = await self.health_check()

        health_data = {
            "status": "healthy" if is_healthy else "unhealthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "service": "hot_storage",
            "version": "2.0.0-simplified",
            "uptime": time.time() - self.start_time if hasattr(self, 'start_time') else 0,
            "nats_connected": self.nats_client is not None and not self.nats_client.is_closed,
            "subscriptions": len(self.subscriptions),
            "is_running": self.is_running
        }

        status_code = 200 if is_healthy else 503
        return web.json_response(health_data, status=status_code)

    async def handle_stats(self, request):
        """ç»Ÿè®¡ä¿¡æ¯ç«¯ç‚¹"""
        stats_data = self.get_stats()
        return web.json_response(stats_data)

    async def handle_metrics(self, request):
        """Prometheusæ ¼å¼æŒ‡æ ‡ç«¯ç‚¹"""
        metrics = []

        # åŸºç¡€æŒ‡æ ‡
        metrics.append(f"hot_storage_messages_received_total {self.stats['messages_received']}")
        metrics.append(f"hot_storage_messages_processed_total {self.stats['messages_processed']}")
        metrics.append(f"hot_storage_messages_failed_total {self.stats['messages_failed']}")
        metrics.append(f"hot_storage_validation_errors_total {self.stats['validation_errors']}")
        metrics.append(f"hot_storage_subscriptions_active {len(self.subscriptions)}")
        metrics.append(f"hot_storage_is_running {1 if self.is_running else 0}")

        # ClickHouse å†™å…¥ç›¸å…³æŒ‡æ ‡
        metrics.append(f"hot_storage_batch_inserts_total {self.stats['batch_inserts']}")
        metrics.append(f"hot_storage_batch_size_total {self.stats['batch_size_total']}")
        avg_batch = (self.stats['batch_size_total'] / self.stats['batch_inserts']) if self.stats['batch_inserts'] > 0 else 0
        metrics.append(f"hot_storage_batch_size_avg {avg_batch:.2f}")
        metrics.append(f"hot_storage_clickhouse_tcp_hits_total {self.stats.get('tcp_driver_hits', 0)}")
        metrics.append(f"hot_storage_clickhouse_http_fallback_total {self.stats.get('http_fallback_hits', 0)}")

        # è®¡ç®—é”™è¯¯ç‡
        total_messages = self.stats["messages_received"]
        if total_messages > 0:
            error_rate = (self.stats["messages_failed"] / total_messages) * 100
            metrics.append(f"hot_storage_error_rate_percent {error_rate:.2f}")

        # æ—¶é—´ç±»æŒ‡æ ‡ï¼ˆç§’çº§ epochï¼‰
        if self.stats.get('last_message_time'):
            try:
                ts = self.stats['last_message_time']
                if isinstance(ts, (int, float)):
                    metrics.append(f"hot_storage_last_message_time_seconds {float(ts):.3f}")
            except Exception:
                pass
        if self.stats.get('last_error_time'):
            try:
                ts = self.stats['last_error_time']
                if isinstance(ts, (int, float)):
                    metrics.append(f"hot_storage_last_error_time_seconds {float(ts):.3f}")
            except Exception:
                pass

        metrics_text = "\n".join(metrics) + "\n"
        return web.Response(text=metrics_text, content_type="text/plain")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        # åŠ è½½é…ç½®
        config_path = Path(__file__).parent / "config" / "tiered_storage_config.yaml"

        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
        else:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {config_path}")
            config = {}

        # ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®
        if 'nats' not in config:
            config['nats'] = {}
        if 'hot_storage' not in config:
            config['hot_storage'] = {}

        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆMARKETPRISM_NATS_URL > NATS_URLï¼‰ï¼Œç»Ÿä¸€ servers åˆ—è¡¨
        env_url = os.getenv('MARKETPRISM_NATS_URL') or os.getenv('NATS_URL')
        if env_url:
            config['nats']['servers'] = [env_url]
        else:
            config['nats']['servers'] = config['nats'].get('servers') or [config['nats'].get('url', 'nats://localhost:4222')]
        # è¦†ç›– ClickHouse è¿æ¥ï¼ˆenv ä¼˜å…ˆï¼‰
        config['hot_storage']['clickhouse_host'] = os.getenv('CLICKHOUSE_HOST', config['hot_storage'].get('clickhouse_host', 'localhost'))
        config['hot_storage']['clickhouse_http_port'] = int(os.getenv('CLICKHOUSE_HTTP_PORT', str(config['hot_storage'].get('clickhouse_http_port', 8123))))
        config['hot_storage']['clickhouse_tcp_port'] = int(os.getenv('CLICKHOUSE_TCP_PORT', str(config['hot_storage'].get('clickhouse_tcp_port', 9000))))
        config['hot_storage']['clickhouse_database'] = os.getenv('CLICKHOUSE_DATABASE', config['hot_storage'].get('clickhouse_database', 'marketprism_hot'))
        use_driver_env = os.getenv('USE_CLICKHOUSE_DRIVER')
        if use_driver_env is not None:
            config['hot_storage']['use_clickhouse_driver'] = use_driver_env.lower() in ('1', 'true', 'yes')

        # è¦†ç›– HTTP ç«¯å£ï¼ˆenv ä¼˜å…ˆï¼‰ï¼šHOT_STORAGE_HTTP_PORT æˆ– MARKETPRISM_STORAGE_SERVICE_PORT
        try:
            config['http_port'] = int(os.getenv('HOT_STORAGE_HTTP_PORT', os.getenv('MARKETPRISM_STORAGE_SERVICE_PORT', str(config.get('http_port', 8080)))))
        except Exception:
            config['http_port'] = config.get('http_port', 8080)

        print(f"ğŸ”§ ä½¿ç”¨NATS Servers: {', '.join(config['nats']['servers'])}")
        print(f"ğŸ”§ ä½¿ç”¨ClickHouse: {config['hot_storage']['clickhouse_host']} (HTTP:{config['hot_storage']['clickhouse_http_port']}, TCP:{config['hot_storage']['clickhouse_tcp_port']})")
        print(f"ğŸ”§ HTTPç«¯å£: {config['http_port']}")



        # åˆ›å»ºå¹¶å¯åŠ¨æœåŠ¡
        service = SimpleHotStorageService(config)
        await service.start()

    except KeyboardInterrupt:
        print("ğŸ“¡ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    except Exception as e:
        print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    import argparse
    from pathlib import Path as _Path

    parser = argparse.ArgumentParser(description="MarketPrism Storage Service (hot/cold)")
    parser.add_argument("--mode", "-m", choices=["hot", "cold"], default=os.getenv("STORAGE_MODE", "hot"), help="Run mode: hot (subscribe+ingest) or cold (archive)")
    parser.add_argument("--config", "-c", type=str, default=str(_Path(__file__).resolve().parent / "config" / "tiered_storage_config.yaml"), help="Config file path (YAML), default: config/tiered_storage_config.yaml")
    args = parser.parse_args()

    def _load_yaml(path_str: str) -> Dict[str, Any]:
        p = _Path(path_str)
        with open(p, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f) or {}

    cfg = _load_yaml(args.config)

    if args.mode == "hot":
        mapped = {
            'nats': cfg.get('nats', {}) or {},
            # ä»é…ç½®æ–‡ä»¶è¯»å–HTTPç«¯å£ï¼Œé»˜è®¤8081ï¼ˆä¸é¡¹ç›®çº¦å®šä¸€è‡´ï¼‰
            'http_port': cfg.get('http_port', 8081),
            'hot_storage': {
                'clickhouse_host': (cfg.get('hot_storage', {}) or {}).get('clickhouse_host', 'localhost'),
                'clickhouse_http_port': (cfg.get('hot_storage', {}) or {}).get('clickhouse_http_port', 8123),
                # ä¿®å¤é”®åï¼šä» clickhouse_port -> clickhouse_tcp_port
                'clickhouse_tcp_port': (cfg.get('hot_storage', {}) or {}).get('clickhouse_tcp_port', 9000),
                'clickhouse_user': (cfg.get('hot_storage', {}) or {}).get('clickhouse_user', 'default'),
                'clickhouse_password': (cfg.get('hot_storage', {}) or {}).get('clickhouse_password', ''),
                'clickhouse_database': (cfg.get('hot_storage', {}) or {}).get('clickhouse_database', 'marketprism_hot'),
                'use_clickhouse_driver': True
            },
            'retry': cfg.get('retry', {'max_retries': 3, 'delay_seconds': 1, 'backoff_multiplier': 2})
        }
        _svc = SimpleHotStorageService(mapped)
        try:
            asyncio.run(_svc.start())
        except KeyboardInterrupt:
            try:
                asyncio.run(_svc.stop())
            except Exception:
                pass
        import sys as _sys
        _sys.exit(0)
    else:
        try:
            from cold_storage_service import ColdStorageService as _Cold
        except Exception:
            from .cold_storage_service import ColdStorageService as _Cold
        cold_cfg = {
            'hot_storage': cfg.get('hot_storage', {}) or {},
            'cold_storage': cfg.get('cold_storage', {}) or {},
            'sync': cfg.get('sync', {}) or {}
        }
        _svc = _Cold(cold_cfg)
        async def _cold_main():
            await _svc.initialize()
            await _svc.start()
        try:
            asyncio.run(_cold_main())
        except KeyboardInterrupt:
            try:
                asyncio.run(_svc.stop())
            except Exception:
                pass
        import sys as _sys
        _sys.exit(0)


