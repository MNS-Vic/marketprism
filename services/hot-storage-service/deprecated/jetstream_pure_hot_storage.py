#!/usr/bin/env python3
"""
MarketPrism çº¯JetStreamçƒ­ç«¯å­˜å‚¨æœåŠ¡
å®Œå…¨ç§»é™¤Core NATSå›é€€æœºåˆ¶ï¼Œä½¿ç”¨Pullæ¶ˆè´¹è€…æ¨¡å¼
é…ç½®ä¸€è‡´æ€§ï¼šä»ç¯å¢ƒå˜é‡è¯»å–LSRé…ç½®å‚æ•°
"""
import asyncio
import json
import os
import sys
import time
import traceback
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer
from datetime import datetime, timezone
from typing import Dict, Any, Optional, Union

import nats
import nats.js
import nats.js.api
from clickhouse_driver import Client as ClickHouseClient

# å…¨å±€æœåŠ¡å¼•ç”¨ï¼Œä¾›å¥åº·æ£€æŸ¥HTTPæœåŠ¡è®¿é—®
SERVICE_REF = None


class _HealthHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        global SERVICE_REF
        if self.path.startswith('/health'):
            status = 200
            resp = {
                "service": "jetstream_pure_hot_storage",
                "status": "healthy" if SERVICE_REF and SERVICE_REF.is_running else "starting",
                "nats_connected": bool(SERVICE_REF and SERVICE_REF.nats_client),
                "subscriptions": len(SERVICE_REF.subscriptions) if SERVICE_REF else 0,
            }
            body = json.dumps(resp).encode()
            self.send_response(status)
            self.send_header('Content-Type', 'application/json')
            self.send_header('Content-Length', str(len(body)))
            self.end_headers()
            self.wfile.write(body)
            return
        if self.path.startswith('/metrics'):
            processed = getattr(SERVICE_REF, 'messages_processed', 0) or 0
            failed = getattr(SERVICE_REF, 'messages_failed', 0) or 0
            total = processed + failed
            error_rate = (failed / total * 100.0) if total > 0 else 0.0

            # è®¡ç®—æ‘„å…¥å»¶è¿ŸæŒ‡æ ‡
            avg_ingest_lag = 0.0
            if SERVICE_REF and SERVICE_REF.ingest_lag_count > 0:
                avg_ingest_lag = SERVICE_REF.ingest_lag_sum / SERVICE_REF.ingest_lag_count

            # è®¡ç®—ClickHouseå†™å…¥è€—æ—¶æŒ‡æ ‡
            avg_insert_time = 0.0
            if SERVICE_REF and SERVICE_REF.clickhouse_insert_times:
                avg_insert_time = sum(SERVICE_REF.clickhouse_insert_times) / len(SERVICE_REF.clickhouse_insert_times)
                # ä¿ç•™æœ€è¿‘100æ¬¡è®°å½•
                if len(SERVICE_REF.clickhouse_insert_times) > 100:
                    SERVICE_REF.clickhouse_insert_times = SERVICE_REF.clickhouse_insert_times[-100:]

            text = (
                f"hot_storage_messages_processed_total {processed}\n"
                f"hot_storage_messages_failed_total {failed}\n"
                f"hot_storage_error_rate_percent {error_rate:.2f}\n"
                f"hot_storage_ingest_lag_seconds {avg_ingest_lag:.3f}\n"
                f"hot_storage_clickhouse_insert_seconds {avg_insert_time:.3f}\n"
            ).encode()

            self.send_response(200)
            self.send_header('Content-Type', 'text/plain; version=0.0.4')
            self.send_header('Content-Length', str(len(text)))
            self.end_headers()
            self.wfile.write(text)
            return
        self.send_response(404)
        self.end_headers()


class JetStreamPureHotStorage:
    """çº¯JetStreamçƒ­ç«¯å­˜å‚¨æœåŠ¡"""

    def __init__(self):
        self.nats_client = None
        self.jetstream = None
        self.clickhouse_client = None
        self.subscriptions = {}
        self.is_running = False
        self.start_time = time.time()

        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.nats_url = os.getenv("NATS_URL", "nats://localhost:4222")
        self.clickhouse_host = os.getenv("CLICKHOUSE_HOST", "localhost")
        self.clickhouse_port = int(os.getenv("CLICKHOUSE_PORT", "9000"))
        self.clickhouse_database = os.getenv("CLICKHOUSE_DATABASE", "marketprism_hot")

        # LSRé…ç½®å‚æ•°ï¼ˆç¡®ä¿é…ç½®ä¸€è‡´æ€§ï¼‰
        self.lsr_deliver_policy = os.getenv("LSR_DELIVER_POLICY", "last").lower()
        self.lsr_ack_policy = os.getenv("LSR_ACK_POLICY", "explicit").lower()
        self.lsr_ack_wait = int(os.getenv("LSR_ACK_WAIT", "60"))
        self.lsr_max_ack_pending = int(os.getenv("LSR_MAX_ACK_PENDING", "2000"))
        self.lsr_max_deliver = int(os.getenv("LSR_MAX_DELIVER", "3"))

        # Pullæ¨¡å¼è°ƒä¼˜å‚æ•°ï¼ˆå¯é…ç½®ï¼‰
        self.pull_batch_size = int(os.getenv("JS_PULL_BATCH_SIZE", "50"))       # é»˜è®¤50
        self.pull_concurrency = int(os.getenv("JS_PULL_CONCURRENCY", "2"))      # é»˜è®¤2

        # æ•°æ®ç±»å‹é…ç½®
        # æ¢å¤å®Œæ•´æ•°æ®ç±»å‹æ”¯æŒ
        self.data_types = [
            "funding_rate", "open_interest", "lsr_top_position", "lsr_all_account",
            "orderbook", "trade", "liquidation", "volatility_index"
        ]


        # è¿è¡Œæ—¶æŒ‡æ ‡ä¸HTTPå¥åº·æœåŠ¡
        self.messages_processed = 0
        self.messages_failed = 0
        self.ingest_lag_sum = 0.0
        self.ingest_lag_count = 0
        self.clickhouse_insert_times = []
        self.httpd = None
        self.http_port = int(os.getenv("MARKETPRISM_STORAGE_SERVICE_PORT", "8080"))

        print(f"ğŸš€ JetStreamçº¯çƒ­ç«¯å­˜å‚¨æœåŠ¡åˆå§‹åŒ–")
        print(f"NATS URL: {self.nats_url}")
        print(f"ClickHouse: {self.clickhouse_host}:{self.clickhouse_port}/{self.clickhouse_database}")
        print(f"LSRé…ç½®: policy={self.lsr_deliver_policy}, ack={self.lsr_ack_policy}, wait={self.lsr_ack_wait}s, pending={self.lsr_max_ack_pending}")

    def _start_http_server(self):
        """å¯åŠ¨å†…ç½®HTTPå¥åº·æ£€æŸ¥ä¸æŒ‡æ ‡æœåŠ¡"""
        global SERVICE_REF
        try:
            SERVICE_REF = self
            self.httpd = HTTPServer(('0.0.0.0', self.http_port), _HealthHandler)
            th = threading.Thread(target=self.httpd.serve_forever, daemon=True)
            th.start()
            print(f"âœ… å¥åº·æ£€æŸ¥HTTPæœåŠ¡å¯åŠ¨äº 0.0.0.0:{self.http_port}")
        except Exception as e:
            print(f"âš ï¸ å¥åº·æ£€æŸ¥HTTPæœåŠ¡å¯åŠ¨å¤±è´¥: {e}")


    async def connect(self):
        """è¿æ¥NATSå’ŒClickHouse"""
        try:
            # è¿æ¥NATS
            self.nats_client = await nats.connect(self.nats_url)
            self.jetstream = self.nats_client.jetstream()
            print("âœ… NATSè¿æ¥æˆåŠŸ")

            # è¿æ¥ClickHouse
            self.clickhouse_client = ClickHouseClient(
                host=self.clickhouse_host,
                port=self.clickhouse_port,
                database=self.clickhouse_database
            )
            # æµ‹è¯•è¿æ¥
            self.clickhouse_client.execute("SELECT 1")
            print("âœ… ClickHouseè¿æ¥æˆåŠŸ")

        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            raise

    async def subscribe_all_data_types(self):
        """è®¢é˜…æ‰€æœ‰æ•°æ®ç±»å‹"""
        print("ğŸ”„ å¼€å§‹è®¢é˜…æ‰€æœ‰æ•°æ®ç±»å‹...")

        for data_type in self.data_types:
            try:
                await self._subscribe_to_data_type(data_type)
                await asyncio.sleep(0.1)  # é¿å…è¿‡å¿«åˆ›å»ºæ¶ˆè´¹è€…
            except Exception as e:
                print(f"âŒ è®¢é˜… {data_type} å¤±è´¥: {e}")
                traceback.print_exc()

        print(f"âœ… å®Œæˆè®¢é˜…ï¼Œå…± {len(self.subscriptions)} ä¸ªæ•°æ®ç±»å‹")

    async def _subscribe_to_data_type(self, data_type: str):
        """è®¢é˜…ç‰¹å®šæ•°æ®ç±»å‹ - çº¯JetStream Pullæ¶ˆè´¹è€…æ¨¡å¼"""
        # æ„å»ºä¸»é¢˜æ¨¡å¼
        subject_mapping = {
            "funding_rate": "funding_rate.>",
            "open_interest": "open_interest.>",
            "lsr_top_position": "lsr_top_position.>",
            "lsr_all_account": "lsr_all_account.>",
            "orderbook": "orderbook.>",
            "trade": "trade.>",
            "liquidation": "liquidation.>",
            "volatility_index": "volatility_index.>"
        }

        subject_pattern = subject_mapping.get(data_type, f"{data_type}.>")

        # ç¡®å®šæµåç§° - è®¢å•ç°¿ä½¿ç”¨ç‹¬ç«‹ORDERBOOK_SNAPæµï¼Œå…¶ä»–ä½¿ç”¨MARKET_DATAæµ
        stream_name = "ORDERBOOK_SNAP" if data_type == "orderbook" else "MARKET_DATA"

        print(f"è®¾ç½®JetStreamè®¢é˜…: {data_type} -> {subject_pattern} (æµ: {stream_name})")

        # ç­‰å¾…æµå¯ç”¨
        for attempt in range(10):
            try:
                await self.jetstream._jsm.stream_info(stream_name)
                print(f"âœ… æµ {stream_name} å¯ç”¨")
                break
            except Exception:
                print(f"â³ ç­‰å¾…æµ {stream_name} å¯ç”¨... (å°è¯• {attempt+1}/10)")
                await asyncio.sleep(2)
        else:
            raise Exception(f"âŒ æµ {stream_name} åœ¨20ç§’å†…æœªå°±ç»ª")

        # åˆ›å»ºæ¶ˆè´¹è€…
        durable_name = f"simple_hot_storage_realtime_{data_type}"

        # åˆ é™¤æ—§æ¶ˆè´¹è€…ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            await self.jetstream._jsm.delete_consumer(stream_name, durable_name)
            print(f"ğŸ§¹ åˆ é™¤æ—§æ¶ˆè´¹è€…: {durable_name}")
        except Exception:
            pass

        # åˆ›å»ºæ¶ˆè´¹è€…é…ç½®
        consumer_config = nats.js.api.ConsumerConfig(
            durable_name=durable_name,
            deliver_policy=nats.js.api.DeliverPolicy.LAST if self.lsr_deliver_policy == "last" else nats.js.api.DeliverPolicy.NEW,
            ack_policy=nats.js.api.AckPolicy.EXPLICIT if self.lsr_ack_policy == "explicit" else nats.js.api.AckPolicy.NONE,
            max_deliver=self.lsr_max_deliver,
            ack_wait=self.lsr_ack_wait,
            max_ack_pending=self.lsr_max_ack_pending,
            filter_subject=subject_pattern
        )

        # åˆ›å»ºæ¶ˆè´¹è€…
        await self.jetstream._jsm.add_consumer(stream_name, consumer_config)
        print(f"âœ… æ¶ˆè´¹è€…åˆ›å»ºæˆåŠŸ: {durable_name}")

        # åˆ›å»ºpullè®¢é˜…
        consumer = await self.jetstream.pull_subscribe(
            subject=subject_pattern,
            durable=durable_name,
            stream=stream_name
        )

        # å¯åŠ¨æ¶ˆæ¯å¤„ç†ä»»åŠ¡ï¼ˆå¹¶å‘ï¼‰
        tasks = []
        for i in range(max(1, self.pull_concurrency)):
            task = asyncio.create_task(self._pull_message_handler(consumer, data_type))
            tasks.append(task)
        self.subscriptions[data_type] = {"consumer": consumer, "tasks": tasks}

        print(f"âœ… JetStream Pullè®¢é˜…æˆåŠŸ: {data_type} -> {subject_pattern}ï¼Œå¹¶å‘={self.pull_concurrency}ï¼Œbatch={self.pull_batch_size}")

    async def _pull_message_handler(self, consumer, data_type: str):
        """Pullæ¶ˆè´¹è€…æ¶ˆæ¯å¤„ç†å™¨"""
        print(f"ğŸ”„ å¯åŠ¨ {data_type} æ¶ˆæ¯å¤„ç†å™¨")

        while self.is_running:
            try:
                # æ‰¹é‡æ‹‰å–æ¶ˆæ¯ï¼ˆå¯é…ç½®æ‰¹é‡å¤§å°ï¼‰
                msgs = await consumer.fetch(batch=self.pull_batch_size, timeout=5.0)

                for msg in msgs:
                    try:
                        # è®¡ç®—æ‘„å…¥å»¶è¿Ÿ
                        data = json.loads(msg.data.decode())
                        msg_timestamp = self._parse_ts(data.get('timestamp'))
                        now = datetime.now(timezone.utc)
                        ingest_lag = (now - msg_timestamp).total_seconds()
                        self.ingest_lag_sum += ingest_lag
                        self.ingest_lag_count += 1

                        # è®°å½•ClickHouseå†™å…¥æ—¶é—´
                        start_time = time.time()
                        await self._handle_message(msg, data_type)
                        insert_time = time.time() - start_time
                        self.clickhouse_insert_times.append(insert_time)

                        await msg.ack()
                        self.messages_processed += 1
                    except Exception as e:
                        print(f"âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥ {data_type}: {e}")
                        self.messages_failed += 1
                        await msg.nak()

            except asyncio.TimeoutError:
                # æ­£å¸¸è¶…æ—¶ï¼Œç»§ç»­æ‹‰å–
                continue
            except Exception as e:
                print(f"âŒ Pullæ¶ˆæ¯å¤±è´¥ {data_type}: {e}")
                await asyncio.sleep(1)

    async def _handle_message(self, msg, data_type: str):
        """å¤„ç†å•æ¡æ¶ˆæ¯"""
        try:
            # è§£ææ¶ˆæ¯
            data = json.loads(msg.data.decode())

            # æ ¹æ®æ•°æ®ç±»å‹å†™å…¥å¯¹åº”è¡¨
            if data_type == "trade":
                await self._insert_trade(data)
            elif data_type == "orderbook":
                await self._insert_orderbook(data)
            elif data_type == "liquidation":
                await self._insert_liquidation(data)
            elif data_type == "funding_rate":
                await self._insert_funding_rate(data)
            elif data_type == "open_interest":
                await self._insert_open_interest(data)
            elif data_type in ["lsr_top_position", "lsr_all_account"]:
                await self._insert_lsr(data, data_type)
            elif data_type == "volatility_index":
                await self._insert_volatility_index(data)
            else:
                print(f"âš ï¸ æœªçŸ¥æ•°æ®ç±»å‹: {data_type}")

        except Exception as e:
            print(f"âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            raise

    def _parse_ts(self, ts: Union[str, int, float, datetime, None]) -> datetime:
        """å°†å„ç§æ—¶é—´æˆ³æ ¼å¼è½¬æ¢ä¸ºå¸¦UTCæ—¶åŒºçš„datetimeä¾›clickhouse-driverä½¿ç”¨"""
        if ts is None:
            return datetime.now(timezone.utc)
        if isinstance(ts, datetime):
            return ts if ts.tzinfo else ts.replace(tzinfo=timezone.utc)
        try:
            # æ¯«ç§’æˆ–ç§’
            if isinstance(ts, (int, float)):
                # è®¤ä¸º>= 10^11 ä¸ºæ¯«ç§’
                if ts > 1e11:
                    return datetime.fromtimestamp(ts / 1000.0, tz=timezone.utc)
                else:
                    return datetime.fromtimestamp(ts, tz=timezone.utc)
            if isinstance(ts, str):
                t = ts.strip()
                # å¤„ç†Zç»“å°¾ä¸Tåˆ†éš”
                t = t.replace('T', ' ')
                if t.endswith('Z'):
                    t = t[:-1]
                # æˆªæ–­åˆ°æ¯«ç§’
                if '.' in t:
                    left, right = t.split('.', 1)
                    ms = ''.join(ch for ch in right if ch.isdigit())[:3]
                    t = f"{left}.{ms}" if ms else left
                # å°è¯•ä¸åŒæ ¼å¼
                for fmt in ('%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S'):
                    try:
                        dt = datetime.strptime(t, fmt)
                        return dt.replace(tzinfo=timezone.utc)
                    except ValueError:
                        continue
        except Exception:
            pass
        # å…œåº•ï¼šå½“å‰æ—¶é—´
        return datetime.now(timezone.utc)

    async def _insert_trade(self, data: Dict[str, Any]):
        """æ’å…¥äº¤æ˜“æ•°æ®"""
        query = """
        INSERT INTO trades (
            timestamp, trade_time, exchange, market_type, symbol,
            trade_id, price, quantity, side, is_maker, data_source, created_at
        ) VALUES
        """

        values = [(
            self._parse_ts(data.get('timestamp')),
            self._parse_ts(data.get('trade_time', data.get('timestamp'))),
            data.get('exchange'),
            data.get('market_type'),
            data.get('symbol'),
            data.get('trade_id'),
            float(data.get('price', 0)),
            float(data.get('quantity', 0)),
            data.get('side'),
            data.get('is_maker', False),
            data.get('data_source', 'collector'),
            datetime.now(timezone.utc)
        )]

        self.clickhouse_client.execute(query, values)

    async def _insert_orderbook(self, data: Dict[str, Any]):
        """æ’å…¥è®¢å•ç°¿æ•°æ®"""
        query = """
        INSERT INTO orderbooks (
            timestamp, exchange, market_type, symbol, last_update_id,
            bids, asks, bids_count, asks_count,
            best_bid_price, best_bid_quantity, best_ask_price, best_ask_quantity,
            data_source, created_at
        ) VALUES
        """

        bids = data.get('bids', [])
        asks = data.get('asks', [])

        values = [(
            self._parse_ts(data.get('timestamp')),
            data.get('exchange'),
            data.get('market_type'),
            data.get('symbol'),
            data.get('last_update_id', 0),
            json.dumps(bids),
            json.dumps(asks),
            len(bids),
            len(asks),
            float(bids[0][0]) if bids else 0,
            float(bids[0][1]) if bids else 0,
            float(asks[0][0]) if asks else 0,
            float(asks[0][1]) if asks else 0,
            data.get('data_source', 'collector'),
            datetime.now(timezone.utc)
        )]

        self.clickhouse_client.execute(query, values)

    async def _insert_liquidation(self, data: Dict[str, Any]):
        """æ’å…¥å¼ºå¹³æ•°æ®"""
        query = """
        INSERT INTO liquidations (
            timestamp, liquidation_time, exchange, market_type, symbol,
            price, quantity, side, data_source, created_at
        ) VALUES
        """

        values = [(
            self._parse_ts(data.get('timestamp')),
            self._parse_ts(data.get('liquidation_time', data.get('timestamp'))),
            data.get('exchange'),
            data.get('market_type'),
            data.get('symbol'),
            float(data.get('price', 0)),
            float(data.get('quantity', 0)),
            data.get('side'),
            data.get('data_source', 'collector'),
            datetime.now(timezone.utc)
        )]

        self.clickhouse_client.execute(query, values)

    async def _insert_funding_rate(self, data: Dict[str, Any]):
        """æ’å…¥èµ„é‡‘è´¹ç‡æ•°æ®"""
        query = """
        INSERT INTO funding_rates (
            timestamp, exchange, market_type, symbol,
            funding_rate, funding_time, next_funding_time,
            mark_price, index_price, data_source, created_at
        ) VALUES
        """

        values = [(
            self._parse_ts(data.get('timestamp')),
            data.get('exchange'),
            data.get('market_type'),
            data.get('symbol'),
            float(data.get('funding_rate', 0)),
            self._parse_ts(data.get('funding_time', data.get('timestamp'))),
            self._parse_ts(data.get('next_funding_time')),
            float(data.get('mark_price', 0)),
            float(data.get('index_price', 0)),
            data.get('data_source', 'collector'),
            datetime.now(timezone.utc)
        )]

        self.clickhouse_client.execute(query, values)

    async def _insert_open_interest(self, data: Dict[str, Any]):
        """æ’å…¥æŒä»“é‡æ•°æ®"""
        query = """
        INSERT INTO open_interests (
            timestamp, exchange, market_type, symbol,
            open_interest, open_interest_value, count,
            data_source, created_at
        ) VALUES
        """

        values = [(
            self._parse_ts(data.get('timestamp')),
            data.get('exchange'),
            data.get('market_type'),
            data.get('symbol'),
            float(data.get('open_interest', 0)),
            float(data.get('open_interest_value', 0)),
            int(data.get('count', 0)),
            data.get('data_source', 'collector'),
            datetime.now(timezone.utc)
        )]

        self.clickhouse_client.execute(query, values)

    async def _insert_lsr(self, data: Dict[str, Any], data_type: str):
        """æ’å…¥LSRæ•°æ®"""
        if data_type == "lsr_top_position":
            query = """
            INSERT INTO lsr_top_positions (
                timestamp, exchange, market_type, symbol,
                long_position_ratio, short_position_ratio, period,
                data_source, created_at
            ) VALUES
            """

            values = [(
                self._parse_ts(data.get('timestamp')),
                data.get('exchange'),
                data.get('market_type'),
                data.get('symbol'),
                float(data.get('long_position_ratio', 0)),
                float(data.get('short_position_ratio', 0)),
                data.get('period', '5m'),
                data.get('data_source', 'collector'),
                datetime.now(timezone.utc)
            )]

        elif data_type == "lsr_all_account":
            query = """
            INSERT INTO lsr_all_accounts (
                timestamp, exchange, market_type, symbol,
                long_account_ratio, short_account_ratio, period,
                data_source, created_at
            ) VALUES
            """

            values = [(
                self._parse_ts(data.get('timestamp')),
                data.get('exchange'),
                data.get('market_type'),
                data.get('symbol'),
                float(data.get('long_account_ratio', 0)),
                float(data.get('short_account_ratio', 0)),
                data.get('period', '5m'),
                data.get('data_source', 'collector'),
                datetime.now(timezone.utc)
            )]
        else:
            print(f"âš ï¸ æœªçŸ¥LSRæ•°æ®ç±»å‹: {data_type}")
            return

        self.clickhouse_client.execute(query, values)

    async def _insert_volatility_index(self, data: Dict[str, Any]):
        """æ’å…¥æ³¢åŠ¨ç‡æŒ‡æ•°æ•°æ®"""
        query = """
        INSERT INTO volatility_indices (
            timestamp, exchange, market_type, symbol,
            index_value, underlying_asset, data_source, created_at
        ) VALUES
        """

        values = [(
            self._parse_ts(data.get('timestamp')),
            data.get('exchange'),
            data.get('market_type'),
            data.get('symbol'),
            float(data.get('volatility_index', data.get('index_value', 0))),
            data.get('underlying_asset', data.get('symbol', '')),
            data.get('data_source', 'collector'),
            datetime.now(timezone.utc)
        )]

        self.clickhouse_client.execute(query, values)

    async def start(self):
        """å¯åŠ¨æœåŠ¡"""
        self.is_running = True
        print("ğŸš€ å¯åŠ¨JetStreamçº¯çƒ­ç«¯å­˜å‚¨æœåŠ¡...")

        # å¯åŠ¨å¥åº·æ£€æŸ¥HTTPæœåŠ¡
        self._start_http_server()

        await self.connect()
        await self.subscribe_all_data_types()

        print("âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼Œå¼€å§‹å¤„ç†æ¶ˆæ¯...")

        # ä¿æŒè¿è¡Œ
        try:
            while self.is_running:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            print("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·")
        finally:
            await self.stop()

    async def stop(self):
        """åœæ­¢æœåŠ¡"""
        print("â¹ï¸ åœæ­¢æœåŠ¡...")
        self.is_running = False

        # åœæ­¢æ‰€æœ‰ä»»åŠ¡
        for data_type, sub_info in self.subscriptions.items():
            tasks = sub_info.get("tasks")
            if tasks:
                for t in tasks:
                    t.cancel()

        # åœæ­¢HTTPå¥åº·æœåŠ¡
        if self.httpd:
            try:
                self.httpd.shutdown()
                self.httpd.server_close()
            except Exception as e:
                print(f"âš ï¸ åœæ­¢HTTPæœåŠ¡æ—¶å‡ºç°é—®é¢˜: {e}")
            finally:
                self.httpd = None

        # å…³é—­è¿æ¥
        if self.nats_client:
            await self.nats_client.close()

        print("âœ… æœåŠ¡å·²åœæ­¢")


async def main():
    """ä¸»å‡½æ•°"""
    service = JetStreamPureHotStorage()
    await service.start()


if __name__ == "__main__":
    asyncio.run(main())
