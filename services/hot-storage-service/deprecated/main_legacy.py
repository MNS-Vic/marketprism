"""
MarketPrism æ•°æ®å­˜å‚¨æœåŠ¡
åŸºäºunified_storage_managerçš„å¾®æœåŠ¡åŒ–å­˜å‚¨æœåŠ¡
æä¾›çƒ­å†·æ•°æ®ç®¡ç†ã€æŸ¥è¯¢è·¯ç”±ã€æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
"""

import asyncio
import json
import signal
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from aiohttp import web
import aiohttp
import yaml
import os
import sys
from pathlib import Path
import traceback
import logging

from collections import defaultdict, deque
import time

# ğŸ”§ æ–°å¢ï¼šNATSè®¢é˜…æ”¯æŒ
import nats
from nats.js import JetStreamContext

# ç¡®ä¿èƒ½æ­£ç¡®æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•å¹¶æ·»åŠ åˆ°sys.path
project_root = Path(__file__).resolve().parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from core.service_framework import BaseService
from core.storage.unified_storage_manager import UnifiedStorageManager
from core.storage.types import NormalizedTrade, NormalizedTicker, NormalizedOrderBook

class DataStorageService(BaseService):
    """æ•°æ®å­˜å‚¨å¾®æœåŠ¡ - æ•´åˆNATSè®¢é˜…å’ŒHTTP API"""

    def __init__(self, config: Dict[str, Any]):
        super().__init__("data-storage-service", config)
        self.storage_manager: Optional[UnifiedStorageManager] = None

        # ğŸ”§ æ–°å¢ï¼šNATSè®¢é˜…æ”¯æŒ
        self.nats_client: Optional[nats.NATS] = None
        self.jetstream: Optional[JetStreamContext] = None
        self.subscriptions = []
        self.nats_enabled = config.get('nats', {}).get('enabled', True)

        # ç»Ÿè®¡ä¿¡æ¯
        self.nats_stats = {
            'messages_received': 0,
            'messages_stored': 0,
            'storage_errors': 0,
            'start_time': None
        }

        #     
        #   (production_cached_storage )
        self.batch_config: Dict[str, Dict[str, float]] = {
            # 
            'orderbook': {'batch_size': 1000, 'timeout': 2.0, 'max_queue': 10000},
            'trade': {'batch_size': 500, 'timeout': 1.5, 'max_queue': 5000},
            # 
            'funding_rate': {'batch_size': 10, 'timeout': 2.0, 'max_queue': 500},
            'open_interest': {'batch_size': 50, 'timeout': 10.0, 'max_queue': 500},
            # 
            'liquidation': {'batch_size': 5, 'timeout': 10.0, 'max_queue': 200},
            'volatility_index': {'batch_size': 1, 'timeout': 1.0, 'max_queue': 50},
            'lsr_top_position': {'batch_size': 1, 'timeout': 1.0, 'max_queue': 50},
            'lsr_all_account': {'batch_size': 1, 'timeout': 1.0, 'max_queue': 50},
        }
        # 
        self.data_queues: Dict[str, deque] = defaultdict(deque)
        self.last_flush_time: Dict[str, float] = defaultdict(float)
        self.flush_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)
        self._batch_task: Optional[asyncio.Task] = None


    def setup_routes(self):
        """è®¾ç½®APIè·¯ç”±"""
        # æ·»åŠ æ ‡å‡†çŠ¶æ€APIè·¯ç”±
        self.app.router.add_get('/api/v1/storage/status', self.get_storage_status)

        self.app.router.add_post('/api/v1/storage/hot/trades', self.store_hot_trade)
        self.app.router.add_post('/api/v1/storage/hot/tickers', self.store_hot_ticker)
        self.app.router.add_post('/api/v1/storage/hot/orderbooks', self.store_hot_orderbook)
        self.app.router.add_get('/api/v1/storage/hot/trades/{exchange}/{symbol}', self.get_hot_trades)
        self.app.router.add_get('/api/v1/storage/hot/tickers/{exchange}/{symbol}', self.get_hot_ticker)
        self.app.router.add_get('/api/v1/storage/hot/orderbooks/{exchange}/{symbol}', self.get_hot_orderbook)
        self.app.router.add_post('/api/v1/storage/cold/archive', self.archive_to_cold)
        self.app.router.add_get('/api/v1/storage/cold/trades/{exchange}/{symbol}', self.get_cold_trades)
        self.app.router.add_post('/api/v1/storage/lifecycle/cleanup', self.cleanup_expired_data)
        self.app.router.add_get('/api/v1/storage/stats', self.get_storage_stats)

    async def on_startup(self):
        """æœåŠ¡å¯åŠ¨åˆå§‹åŒ–"""
        try:
            # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆä»é…ç½®æ„å»ºï¼‰
            ch_cfg = (self.config.get('storage', {}) or {}).get('clickhouse', {}) or {}
            from core.storage.unified_storage_manager import UnifiedStorageConfig, UnifiedStorageManager
            storage_cfg = UnifiedStorageConfig(
                storage_type='hot',
                clickhouse_host=ch_cfg.get('host', 'localhost'),
                clickhouse_port=int(ch_cfg.get('port', 8123)) if str(ch_cfg.get('port', '8123')).isdigit() else 8123,
                clickhouse_user=ch_cfg.get('user', 'default'),
                clickhouse_password=ch_cfg.get('password', ''),
                clickhouse_database=ch_cfg.get('database', 'marketprism_hot'),
                redis_enabled=False,
            )
            self.storage_manager = UnifiedStorageManager(config=storage_cfg)
            await self.storage_manager.initialize()
            self.logger.info("âœ… UnifiedStorageManageråˆå§‹åŒ–æˆåŠŸ", db=storage_cfg.clickhouse_database, host=storage_cfg.clickhouse_host, port=storage_cfg.clickhouse_port)

            # ğŸ”§ æ–°å¢ï¼šåˆå§‹åŒ–NATSè®¢é˜…
            if self.nats_enabled:
                await self._initialize_nats_subscription()
            else:
                self.logger.info("ğŸ“¡ NATSè®¢é˜…å·²ç¦ç”¨ï¼Œä»…æä¾›HTTP APIæœåŠ¡")
            # å¯åŠ¨æ‰¹å¤„ç†ç»´æŠ¤ä»»åŠ¡
            if self._batch_task is None:
                self._batch_task = asyncio.create_task(self._periodic_batch_maintenance())


        except Exception as e:

            self.logger.warning(f"âš ï¸ å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¿è¡Œåœ¨é™çº§æ¨¡å¼: {e}")
            self.storage_manager = None


    async def on_shutdown(self):
        """æœåŠ¡åœæ­¢æ¸…ç†"""
        # ğŸ”§ æ–°å¢ï¼šæ¸…ç†NATSè®¢é˜…
        if self.subscriptions:
            for sub in self.subscriptions:
                await sub.unsubscribe()
            self.logger.info("ğŸ“¡ NATSè®¢é˜…å·²æ¸…ç†")

        if self.nats_client:
            await self.nats_client.close()
            self.logger.info("ğŸ“¡ NATSè¿æ¥å·²å…³é—­")

        #    
        if self._batch_task:
            self._batch_task.cancel()
            try:
                await self._batch_task
            except asyncio.CancelledError:
                pass


        if self.storage_manager and hasattr(self.storage_manager, 'close'):
            try:
                await self.storage_manager.close()
                self.logger.info("ğŸ’¾ å­˜å‚¨ç®¡ç†å™¨å·²å…³é—­")
            except Exception as e:
                self.logger.warning(f"âš ï¸ å­˜å‚¨ç®¡ç†å™¨å…³é—­å¤±è´¥: {e}")
        else:
            self.logger.info("ğŸ’¾ å­˜å‚¨æœåŠ¡å·²åœæ­¢ (é™çº§æ¨¡å¼)")

    # ==================== NATSè®¢é˜…æ–¹æ³• ====================

    async def _initialize_nats_subscription(self):
        """åˆå§‹åŒ–NATSè®¢é˜…"""
        try:
            nats_config = self.config.get('nats', {})
            # ç¯å¢ƒå˜é‡è¦†ç›–ä¼˜å…ˆï¼šMARKETPRISM_NATS_URL > NATS_URL > YAML
            env_url = os.getenv('MARKETPRISM_NATS_URL') or os.getenv('NATS_URL')
            servers = [env_url] if env_url else nats_config.get('servers', ['nats://localhost:4222'])

            # è¿æ¥NATS
            self.nats_client = await nats.connect(
                servers=servers,
                name="data-storage-service",
                error_cb=self._nats_error_handler,
                closed_cb=self._nats_closed_handler,
                reconnected_cb=self._nats_reconnected_handler
            )

            # è·å–JetStreamä¸Šä¸‹æ–‡
            self.jetstream = self.nats_client.jetstream()
            self.logger.info("âœ… NATS JetStreamè¿æ¥æˆåŠŸ", servers=servers)

            # è®¢é˜…æ•°æ®æµ
            await self._subscribe_to_data_streams()

            self.nats_stats['start_time'] = datetime.now()
            self.logger.info("âœ… NATSæ•°æ®æµè®¢é˜…å®Œæˆ")

        except Exception as e:
            self.logger.error("âŒ NATSè®¢é˜…åˆå§‹åŒ–å¤±è´¥", error=str(e))
            self.nats_enabled = False

    def _load_subjects_from_collector_config(self) -> Tuple[List[str], Dict[str, str]]:
        """
        ä» collector çš„ unified_data_collection.yaml åŠ è½½ streams æ˜ å°„ï¼Œå¹¶ç”Ÿæˆè®¢é˜…ä¸»é¢˜åˆ—è¡¨
        è¿”å› (subjects, streams_map)
        subjects ä¸ºå„æ¨¡æ¿çš„å‰ç¼€åŠ é€šé…ç¬¦ï¼ˆä¾‹å¦‚ trade.{exchange}.{market_type}.>ï¼‰
        """
        try:
            project_root = Path(__file__).resolve().parents[2]
            collector_cfg = project_root / 'services' / 'data-collector' / 'config' / 'collector' / 'unified_data_collection.yaml'
            with open(collector_cfg, 'r', encoding='utf-8') as f:
                cfg = yaml.safe_load(f) or {}
            streams_map: Dict[str, str] = (cfg.get('nats') or {}).get('streams') or {}
            subjects: List[str] = []
            for key, template in streams_map.items():
                # æ¨¡æ¿å¦‚: "trade.{exchange}.{market_type}.{symbol}"
                # è½¬æ¢ä¸º: "trade.{exchange}.{market_type}.>" ä½œä¸ºè®¢é˜…å‰ç¼€
                base = template.rsplit('.', 1)[0]
                subjects.append(base + '.>')
            return subjects, streams_map
        except Exception:
            # å›é€€åˆ°å†…ç½®é»˜è®¤
            default_subjects = [
                'orderbook.>', 'trade.>', 'funding_rate.>', 'open_interest.>',
                'liquidation.>', 'volatility_index.>', 'lsr_top_position.>', 'lsr_all_account.>'
            ]
            return default_subjects, {}


    async def _subscribe_to_data_streams(self):
        """è®¢é˜…æ•°æ®æµ
        å¯¹é½collectorå‘å¸ƒçš„ä¸»é¢˜æ¨¡æ¿ï¼Œä½¿ç”¨â€œæ—  -data åç¼€â€çš„æ–°å‘½åã€‚
        """
        try:
            # ä» collector é…ç½®åŠ¨æ€ç”Ÿæˆè®¢é˜…ä¸»é¢˜ï¼ˆä¸å‘å¸ƒæ¨¡æ¿ä¸¥æ ¼å¯¹é½ï¼‰
            subjects, streams_map = self._load_subjects_from_collector_config()

            common_cfg = nats.js.api.ConsumerConfig(
                deliver_policy=nats.js.api.DeliverPolicy.LAST,
                ack_policy=nats.js.api.AckPolicy.EXPLICIT,
                max_ack_pending=2000,
                ack_wait=60
            )

            for subject in subjects:
                # é’ˆå¯¹ä¸åŒä¸»é¢˜ä½¿ç”¨ä¸åŒå¤„ç†å™¨
                # ç”Ÿæˆ durable åç§°ï¼šå…è®¸é€šè¿‡ç¯å¢ƒå˜é‡å‰ç¼€è¦†ç›–
                durable_prefix = os.getenv("STORAGE_DURABLE_PREFIX", "storage-service")

                if subject.startswith("orderbook"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_orderbook_message,
                        durable=f"{durable_prefix}-orderbook-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("trade"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_trade_message,
                        durable=f"{durable_prefix}-trade-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("volatility_index"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_volatility_index_message,
                        durable=f"{durable_prefix}-volatility-index-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("funding_rate"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_funding_rate_message,
                        durable=f"{durable_prefix}-funding-rate-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("open_interest"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_open_interest_message,
                        durable=f"{durable_prefix}-open-interest-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("liquidation"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_liquidation_message,
                        durable=f"{durable_prefix}-liquidation-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("lsr_top_position"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_lsr_top_position_message,
                        durable=f"{durable_prefix}-lsr-top-position-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                elif subject.startswith("lsr_all_account"):
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_lsr_all_account_message,
                        durable=f"{durable_prefix}-lsr-all-account-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                else:
                    sub = await self.jetstream.subscribe(
                        subject,
                        cb=self._handle_generic_message,
                        durable=f"{durable_prefix}-{subject.split('.')[0]}-consumer",
                        stream="MARKET_DATA",
                        config=common_cfg
                    )
                self.subscriptions.append(sub)

            self.logger.info("ğŸ“¡ æ•°æ®æµè®¢é˜…æˆåŠŸ", subscriptions=len(self.subscriptions))

        except Exception as e:
            self.logger.error("âŒ æ•°æ®æµè®¢é˜…å¤±è´¥", error=str(e))

    async def _handle_orderbook_message(self, msg):
        """å¤„ç†è®¢å•ç°¿æ¶ˆæ¯"""
        try:
            if not self.storage_manager:
                await msg.ack()  # é™çº§æ¨¡å¼ä¸‹ç›´æ¥ç¡®è®¤
                return

            # è§£ææ¶ˆæ¯
            data = json.loads(msg.data.decode())

            # å…¥é˜Ÿç­‰å¾…æ‰¹å¤„ç†
            self._enqueue_data('orderbook', data)

            # ç¡®è®¤æ¶ˆæ¯
            await msg.ack()

            # æ›´æ–°ç»Ÿè®¡ï¼ˆä»…è®¡å…¥æ”¶åˆ°ï¼ŒçœŸæ­£å†™å…¥åœ¨æ‰¹å¤„ç†åç»Ÿè®¡ï¼‰
            self.nats_stats['messages_received'] += 1

            self.logger.debug("ğŸ“Š è®¢å•ç°¿æ•°æ®å·²å…¥é˜Ÿ",
                            exchange=data.get('exchange'),
                            symbol=data.get('symbol'))

        except Exception as e:
            self.logger.error("âŒ è®¢å•ç°¿æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1
            # ä¸ç¡®è®¤æ¶ˆæ¯ï¼Œè®©å®ƒé‡æ–°æŠ•é€’

    async def _handle_trade_message(self, msg):
        """å¤„ç†äº¤æ˜“æ¶ˆæ¯"""
        try:
            if not self.storage_manager:
                await msg.ack()  # é™çº§æ¨¡å¼ä¸‹ç›´æ¥ç¡®è®¤
                return

            # è§£ææ¶ˆæ¯
            data = json.loads(msg.data.decode())

            # å…¥é˜Ÿç­‰å¾…æ‰¹å¤„ç†
            self._enqueue_data('trade', data)

            # ç¡®è®¤æ¶ˆæ¯
            await msg.ack()

            # æ›´æ–°ç»Ÿè®¡ï¼ˆä»…è®¡å…¥æ”¶åˆ°ï¼‰
            self.nats_stats['messages_received'] += 1

            self.logger.debug("ğŸ’° äº¤æ˜“æ•°æ®å·²å…¥é˜Ÿ",
                            exchange=data.get('exchange'),
                            symbol=data.get('symbol'),
                            price=data.get('price'))

        except Exception as e:
            self.logger.error("âŒ äº¤æ˜“æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    async def _handle_generic_message(self, msg):
        """å¤„ç†é€šç”¨æ¶ˆæ¯"""
        try:
            data = json.loads(msg.data.decode())
            subject = msg.subject

            if "funding_rate" in subject:
                # TODO
                pass
            elif "open_interest" in subject:
                # TODO
                pass
            else:
                # å…¶ä»–æš‚æœªåˆ†ç±»çš„æ•°æ®ç±»å‹ï¼Œå…ˆè®°å½•æ—¥å¿—
                self.logger.debug("ğŸ“¥ æ”¶åˆ°é€šç”¨æ¶ˆæ¯", subject=subject)

            await msg.ack()
        except Exception as e:
            self.logger.error("âŒ é€šç”¨æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    def _enqueue_data(self, data_type: str, data: Dict[str, Any]):
        """å…¥é˜Ÿæ•°æ®ï¼Œç­‰å¾…æ‰¹å¤„ç†åˆ·æ–°"""
        self.data_queues[data_type].append(data)
        if self.last_flush_time.get(data_type, 0) == 0:
            self.last_flush_time[data_type] = time.time()

    async def _periodic_batch_maintenance(self):
        """æ‰¹å¤„ç†ç»´æŠ¤ä»»åŠ¡ï¼šæŒ‰æ‰¹å¤§å°/è¶…æ—¶ç­–ç•¥è§¦å‘åˆ·æ–°"""
        try:
            while True:
                now = time.time()
                for dt, queue in list(self.data_queues.items()):
                    cfg = self.batch_config.get(dt, {'batch_size': 100, 'timeout': 5.0, 'max_queue': 1000})
                    last = self.last_flush_time.get(dt, 0)
                    should = (len(queue) >= cfg['batch_size']) or (len(queue) > 0 and now - last >= cfg['timeout']) or (len(queue) >= cfg['max_queue'])
                    if should and not self.flush_locks[dt].locked():
                        asyncio.create_task(self._flush_batch(dt))
                await asyncio.sleep(0.5)
        except asyncio.CancelledError:
            for dt in list(self.data_queues.keys()):
                if self.data_queues[dt]:
                    await self._flush_batch(dt)
            raise
        except Exception as e:
            self.logger.error("æ‰¹å¤„ç†ç»´æŠ¤ä»»åŠ¡å¼‚å¸¸", error=str(e))

    async def _flush_batch(self, data_type: str):
        async with self.flush_locks[data_type]:
            queue = self.data_queues[data_type]
            if not queue:
                return
            cfg = self.batch_config.get(data_type, {'batch_size': 100})
            batch = []
            take = min(len(queue), int(cfg.get('batch_size', 100)))
            for _ in range(take):
                if queue:
                    batch.append(queue.popleft())
            if not batch:
                return
            if not self.storage_manager:
                self.nats_stats['messages_stored'] += len(batch)
                self.last_flush_time[data_type] = time.time()
                return
            try:
                for item in batch:
                    if data_type == 'trade':
                        await self.storage_manager.store_trade(item)
                    elif data_type == 'orderbook':
                        await self.storage_manager.store_orderbook(item)
                    elif data_type == 'volatility_index':
                        await self.storage_manager.store_volatility_index(item)
                    elif data_type == 'funding_rate':
                        await self.storage_manager.store_funding_rate(item)
                    elif data_type == 'open_interest':
                        await self.storage_manager.store_open_interest(item)
                    elif data_type == 'liquidation':
                        await self.storage_manager.store_liquidation(item)
                    elif data_type == 'lsr_top_position':
                        await self.storage_manager.store_lsr_top_position(item)
                    elif data_type == 'lsr_all_account':
                        await self.storage_manager.store_lsr_all_account(item)
                self.nats_stats['messages_stored'] += len(batch)
            except Exception as e:
                self.logger.error("æ‰¹é‡å†™å…¥å¤±è´¥", data_type=data_type, error=str(e))
                for item in reversed(batch):
                    queue.appendleft(item)
                self.nats_stats['storage_errors'] += 1
            finally:
                self.last_flush_time[data_type] = time.time()

            self.nats_stats['messages_received'] += 1


    async def _handle_volatility_index_message(self, msg):
        """å¤„ç†æ³¢åŠ¨ç‡æŒ‡æ•°æ¶ˆæ¯ï¼Œå†™å…¥ ClickHouse"""
        try:
            if not self.storage_manager:
                await msg.ack()
                return

            data = json.loads(msg.data.decode())

            # ç»Ÿä¸€å­—æ®µæ˜ å°„ï¼šå¸‚åœºç±»å‹é»˜è®¤ options
            if 'market_type' not in data:
                data['market_type'] = 'options'
            if 'vol_index' not in data and 'volatility_index' in data:
                data['vol_index'] = data['volatility_index']

            # å…¥é˜Ÿï¼Œä½é¢‘æ•°æ®ç«‹å³è§¦å‘æ‰¹å¤„ç†ä¹Ÿå¯
            self._enqueue_data('volatility_index', data)
            await msg.ack()

            self.nats_stats['messages_received'] += 1
            self.logger.debug("ğŸ“ˆ VI å·²å…¥é˜Ÿ", subject=msg.subject, index_value=str(data.get('vol_index')))

        except Exception as e:
            self.logger.error("âŒ æ³¢åŠ¨ç‡æŒ‡æ•°æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1


    async def _handle_funding_rate_message(self, msg):
        try:
            data = json.loads(msg.data.decode())
            # å­—æ®µå…œåº•ï¼šç»Ÿä¸€å­—æ®µå
            if 'funding_rate' not in data and 'current_funding_rate' in data:
                data['funding_rate'] = data['current_funding_rate']
            self._enqueue_data('funding_rate', data)
            await msg.ack()
            self.nats_stats['messages_received'] += 1
            self.logger.debug(" èµ„é‡‘è´¹ç‡å·²å…¥é˜Ÿ", subject=msg.subject)
        except Exception as e:
            self.logger.error("âŒ èµ„é‡‘è´¹ç‡æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    async def _handle_open_interest_message(self, msg):
        try:
            data = json.loads(msg.data.decode())
            self._enqueue_data('open_interest', data)
            await msg.ack()
            self.nats_stats['messages_received'] += 1
            self.logger.debug(" æœªå¹³ä»“é‡å·²å…¥é˜Ÿ", subject=msg.subject)
        except Exception as e:
            self.logger.error("âŒ æœªå¹³ä»“é‡æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    async def _handle_liquidation_message(self, msg):
        try:
            data = json.loads(msg.data.decode())
            self._enqueue_data('liquidation', data)
            await msg.ack()
            self.nats_stats['messages_received'] += 1
            self.logger.debug(" å¼ºå¹³å·²å…¥é˜Ÿ", subject=msg.subject)
        except Exception as e:
            self.logger.error("âŒ å¼ºå¹³æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    async def _handle_lsr_top_position_message(self, msg):
        try:
            data = json.loads(msg.data.decode())
            self._enqueue_data('lsr_top_position', data)
            await msg.ack()
            self.nats_stats['messages_received'] += 1
            self.logger.debug(" LSRé¡¶çº§æŒä»“å·²å…¥é˜Ÿ", subject=msg.subject)
        except Exception as e:
            self.logger.error("âŒ LSRé¡¶çº§æŒä»“æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    async def _handle_lsr_all_account_message(self, msg):
        try:
            data = json.loads(msg.data.decode())
            self._enqueue_data('lsr_all_account', data)
            await msg.ack()
            self.nats_stats['messages_received'] += 1
            self.logger.debug(" LSRå…¨è´¦æˆ·å·²å…¥é˜Ÿ", subject=msg.subject)
        except Exception as e:
            self.logger.error("âŒ LSRå…¨è´¦æˆ·æ¶ˆæ¯å¤„ç†å¤±è´¥", error=str(e))
            self.nats_stats['storage_errors'] += 1

    async def _nats_error_handler(self, e):
        """NATSé”™è¯¯å¤„ç†"""
        self.logger.error("ğŸ“¡ NATSé”™è¯¯", error=str(e))

    async def _nats_closed_handler(self):
        """NATSè¿æ¥å…³é—­å¤„ç†"""
        self.logger.warning("ğŸ“¡ NATSè¿æ¥å·²å…³é—­")

    async def _nats_reconnected_handler(self):
        """NATSé‡è¿å¤„ç†"""
        self.logger.info("ğŸ“¡ NATSé‡è¿æˆåŠŸ")

    # ==================== API Handlers ====================

    async def store_hot_trade(self, request: web.Request) -> web.Response:
        """å­˜å‚¨çƒ­äº¤æ˜“æ•°æ®"""
        if not self.storage_manager:
            return web.json_response({"status": "degraded", "message": "Storage service running in degraded mode"}, status=503)
        try:
            data = await request.json()
            trade = NormalizedTrade(**data)
            await self.storage_manager.store_trade(trade)
            return web.json_response({"status": "success", "message": "Trade stored successfully"})
        except Exception as e:
            self.logger.error(f"Failed to store hot trade: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def store_hot_ticker(self, request: web.Request) -> web.Response:
        """å­˜å‚¨çƒ­è¡Œæƒ…æ•°æ®"""
        try:
            data = await request.json()
            ticker = NormalizedTicker(**data)
            await self.storage_manager.store_ticker(ticker)
            return web.json_response({"status": "success", "message": "Ticker stored successfully"})
        except Exception as e:
            self.logger.error(f"Failed to store hot ticker: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def store_hot_orderbook(self, request: web.Request) -> web.Response:
        """å­˜å‚¨çƒ­è®¢å•ç°¿æ•°æ®"""
        try:
            data = await request.json()
            orderbook = NormalizedOrderBook(**data)
            await self.storage_manager.store_orderbook(orderbook)
            return web.json_response({"status": "success", "message": "Orderbook stored successfully"})
        except Exception as e:
            self.logger.error(f"Failed to store hot orderbook: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def get_hot_trades(self, request: web.Request) -> web.Response:
        """æŸ¥è¯¢çƒ­äº¤æ˜“æ•°æ®"""
        try:
            exchange = request.match_info['exchange']
            symbol = request.match_info['symbol']
            limit = int(request.query.get('limit', '100'))
            trades = await self.storage_manager.get_recent_trades(exchange, symbol, limit)
            return web.json_response([trade.dict() for trade in trades])
        except Exception as e:
            self.logger.error(f"Failed to query hot trades for {exchange}:{symbol}: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def get_hot_ticker(self, request: web.Request) -> web.Response:
        """æŸ¥è¯¢çƒ­è¡Œæƒ…æ•°æ®"""
        try:
            exchange = request.match_info['exchange']
            symbol = request.match_info['symbol']
            ticker = await self.storage_manager.get_latest_ticker(exchange, symbol)
            if ticker:
                return web.json_response(ticker.dict())
            return web.json_response({"status": "not_found"}, status=404)
        except Exception as e:
            self.logger.error(f"Failed to query hot ticker for {exchange}:{symbol}: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def get_hot_orderbook(self, request: web.Request) -> web.Response:
        """æŸ¥è¯¢çƒ­è®¢å•ç°¿æ•°æ®"""
        try:
            exchange = request.match_info['exchange']
            symbol = request.match_info['symbol']
            orderbook = await self.storage_manager.get_latest_orderbook(exchange, symbol)
            if orderbook:
                return web.json_response(orderbook.dict())
            return web.json_response({"status": "not_found"}, status=404)
        except Exception as e:
            self.logger.error(f"Failed to query hot orderbook for {exchange}:{symbol}: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def archive_to_cold(self, request: web.Request) -> web.Response:
        """å°†çƒ­æ•°æ®å½’æ¡£åˆ°å†·å­˜å‚¨"""
        try:
            # è¿™é‡Œçš„å…·ä½“é€»è¾‘å¯ä»¥æ ¹æ®éœ€æ±‚å®ç°ï¼Œä¾‹å¦‚æŒ‰æ—¶é—´èŒƒå›´å½’æ¡£
            cutoff_days = int(request.query.get('days', '30'))
            cutoff_date = datetime.now() - timedelta(days=cutoff_days)
            summary = await self.storage_manager.archive_data(cutoff_date)
            return web.json_response({"status": "success", "summary": summary})
        except Exception as e:
            self.logger.error(f"Failed to archive data: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def get_cold_trades(self, request: web.Request) -> web.Response:
        # å®é™…çš„å†·æ•°æ®æŸ¥è¯¢é€»è¾‘ä¼šæ›´å¤æ‚ï¼Œè¿™é‡Œä»…ä¸ºç¤ºä¾‹
        return web.json_response({"status": "error", "message": "Not implemented"}, status=501)

    async def cleanup_expired_data(self, request: web.Request) -> web.Response:
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            summary = await self.storage_manager.cleanup_data()
            return web.json_response({"status": "success", "summary": summary})
        except Exception as e:
            self.logger.error(f"Failed to cleanup data: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def get_storage_status(self, request: web.Request) -> web.Response:
        """è·å–å­˜å‚¨æœåŠ¡çŠ¶æ€"""
        try:
            status_info = {
                "status": "success",
                "service": "data-storage-service",
                "timestamp": datetime.now().isoformat(),
                "storage_manager": {
                    "initialized": self.storage_manager is not None,
                    "mode": "normal" if self.storage_manager else "degraded"
                },
                # ğŸ”§ æ–°å¢ï¼šNATSè®¢é˜…çŠ¶æ€
                "nats_subscription": {
                    "enabled": self.nats_enabled,
                    "connected": self.nats_client is not None and not self.nats_client.is_closed,
                    "subscriptions": len(self.subscriptions),
                    "stats": self.nats_stats.copy()
                }
            }

            if self.storage_manager:
                try:
                    # å°è¯•è·å–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                    stats = await self.storage_manager.get_stats()
                    status_info["storage_stats"] = stats
                except Exception as e:
                    status_info["storage_stats"] = {"error": str(e)}

            return web.json_response(status_info)
        except Exception as e:
            self.logger.error(f"Failed to get storage status: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)

    async def get_storage_stats(self, request: web.Request) -> web.Response:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        if not self.storage_manager:
            return web.json_response({
                "status": "degraded",
                "mode": "degraded",
                "message": "Storage service running in degraded mode",
                "hot_storage": {"status": "unavailable"},
                "cold_storage": {"status": "unavailable"}
            })
        try:
            stats = await self.storage_manager.get_stats()
            return web.json_response(stats)
        except Exception as e:
            self.logger.error(f"Failed to get storage stats: {e}", exc_info=True)
            return web.json_response({"status": "error", "message": str(e)}, status=500)


async def main():
    """æœåŠ¡ä¸»å…¥å£ç‚¹"""
    try:
        project_root = Path(__file__).resolve().parents[2]
        config_path = project_root / 'config' / 'services.yaml'

        with open(config_path, 'r', encoding='utf-8') as f:
            # å¦‚æœæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆï¼Œåˆ™è§†ä¸ºç©ºå­—å…¸
            full_config = yaml.safe_load(f) or {}

        # è·å–æœ¬æœåŠ¡çš„ç‰¹å®šé…ç½®, å¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—å…¸
        service_config = full_config.get('services', {}).get('data-storage-service', {})

        service = DataStorageService(config=service_config)
        await service.run()

    except Exception:
        # å¼ºåˆ¶å°†å®Œæ•´çš„å †æ ˆè·Ÿè¸ªæ‰“å°åˆ°stderrï¼Œä»¥ä¾¿è°ƒè¯•
        logging.basicConfig()
        logging.critical("Data Storage Service failed to start", exc_info=True)
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())