#!/usr/bin/env python3
"""
MarketPrismç»Ÿä¸€NATSå®¹å™¨ - å¢å¼ºçš„JetStreamåˆå§‹åŒ–è„šæœ¬

ğŸ¯ åŠŸèƒ½è¯´æ˜ï¼š
- æ”¯æŒæ‰€æœ‰7ç§æ•°æ®ç±»å‹çš„JetStreamæµåˆå§‹åŒ–
- ä¸unified_data_collection.yamlå®Œå…¨å…¼å®¹
- ç¯å¢ƒå˜é‡é©±åŠ¨çš„é…ç½®ç®¡ç†
- è‡ªåŠ¨æµåˆ›å»ºå’Œæ›´æ–°

ğŸ“Š æ”¯æŒçš„æ•°æ®ç±»å‹ï¼š
- orderbook: è®¢å•ç°¿æ•°æ®ï¼ˆæ‰€æœ‰äº¤æ˜“æ‰€ï¼‰
- trade: äº¤æ˜“æ•°æ®ï¼ˆæ‰€æœ‰äº¤æ˜“æ‰€ï¼‰
- funding_rate: èµ„é‡‘è´¹ç‡ï¼ˆè¡ç”Ÿå“äº¤æ˜“æ‰€ï¼‰
- open_interest: æœªå¹³ä»“é‡ï¼ˆè¡ç”Ÿå“äº¤æ˜“æ‰€ï¼‰
- lsr_top_position: LSRé¡¶çº§æŒä»“ï¼ˆè¡ç”Ÿå“äº¤æ˜“æ‰€ï¼‰
- lsr_all_account: LSRå…¨è´¦æˆ·ï¼ˆè¡ç”Ÿå“äº¤æ˜“æ‰€ï¼‰
- volatility_index: æ³¢åŠ¨ç‡æŒ‡æ•°ï¼ˆDeribitï¼‰

ğŸ”§ è®¾è®¡ç†å¿µï¼š
- ç®€åŒ–Message BrokeråŠŸèƒ½åˆ°NATSå®¹å™¨
- ä¿æŒä¸Data Collectorçš„å®Œå…¨å…¼å®¹æ€§
- æ”¯æŒç¯å¢ƒå˜é‡é…ç½®è¦†ç›–
- æä¾›è¯¦ç»†çš„åˆå§‹åŒ–æ—¥å¿—
"""

import asyncio
import os
import sys
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import argparse

# å°è¯•å¯¼å…¥NATSå®¢æˆ·ç«¯
try:
    import nats
    from nats.js import JetStreamContext
    from nats.js.api import StreamConfig, RetentionPolicy, DiscardPolicy, StorageType
    NATS_AVAILABLE = True
except ImportError:
    print("âŒ NATSå®¢æˆ·ç«¯åº“æœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install nats-py")
    NATS_AVAILABLE = False
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger('EnhancedJetStreamInit')


class EnhancedJetStreamInitializer:
    """
    å¢å¼ºçš„JetStreamåˆå§‹åŒ–å™¨
    
    ä¸“é—¨ä¸ºMarketPrismç»Ÿä¸€NATSå®¹å™¨è®¾è®¡ï¼Œæ”¯æŒæ‰€æœ‰æ•°æ®ç±»å‹çš„æµåˆå§‹åŒ–
    """
    
    def __init__(self, nats_url: str = None):
        """
        åˆå§‹åŒ–JetStreamåˆå§‹åŒ–å™¨
        
        Args:
            nats_url: NATSæœåŠ¡å™¨è¿æ¥URLï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è·å–
        """
        self.nats_url = nats_url or os.getenv('NATS_URL', 'nats://localhost:4222')
        self.nc = None
        self.js = None
        
        # æ”¯æŒçš„æ•°æ®ç±»å‹ä¸»é¢˜æ¨¡å¼ï¼ˆä¸unified_data_collection.yamlå…¼å®¹ï¼‰
        self.supported_subjects = [
            "orderbook-data.>",           # è®¢å•ç°¿æ•°æ®ï¼šæ‰€æœ‰äº¤æ˜“æ‰€
            "trade-data.>",               # äº¤æ˜“æ•°æ®ï¼šæ‰€æœ‰äº¤æ˜“æ‰€
            "funding-rate-data.>",        # èµ„é‡‘è´¹ç‡ï¼šè¡ç”Ÿå“äº¤æ˜“æ‰€
            "open-interest-data.>",       # æœªå¹³ä»“é‡ï¼šè¡ç”Ÿå“äº¤æ˜“æ‰€
            "lsr-top-position-data.>",    # LSRé¡¶çº§æŒä»“ï¼šè¡ç”Ÿå“äº¤æ˜“æ‰€
            "lsr-all-account-data.>",     # LSRå…¨è´¦æˆ·ï¼šè¡ç”Ÿå“äº¤æ˜“æ‰€
            "volatility_index-data.>",    # æ³¢åŠ¨ç‡æŒ‡æ•°ï¼šDeribit
            "liquidation-data.>"          # å¼ºå¹³è®¢å•æ•°æ®ï¼šè¡ç”Ÿå“äº¤æ˜“æ‰€
        ]
        
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        self.config = self._load_config_from_env()
        
        logger.info("å¢å¼ºçš„JetStreamåˆå§‹åŒ–å™¨å·²åˆ›å»º")
        logger.info(f"NATS URL: {self.nats_url}")
        logger.info(f"æ”¯æŒçš„æ•°æ®ç±»å‹: {len(self.supported_subjects)} ç§")
    
    def _load_config_from_env(self) -> Dict[str, Any]:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        return {
            # æµåŸºç¡€é…ç½®
            'stream_name': os.getenv('STREAM_NAME', 'MARKET_DATA'),
            'retention_policy': os.getenv('RETENTION_POLICY', 'limits'),
            'discard_policy': os.getenv('DISCARD_POLICY', 'old'),
            'storage_type': os.getenv('STORAGE_TYPE', 'file'),
            
            # æµå®¹é‡é…ç½®
            'max_consumers': int(os.getenv('STREAM_MAX_CONSUMERS', '50')),
            'max_msgs': int(os.getenv('STREAM_MAX_MSGS', '1000000')),
            'max_bytes': int(os.getenv('STREAM_MAX_BYTES', '1073741824')),  # 1GB
            'max_age': int(os.getenv('STREAM_MAX_AGE', '7200')),  # 2å°æ—¶
            'num_replicas': int(os.getenv('STREAM_REPLICAS', '1')),
            'duplicate_window': int(os.getenv('STREAM_DUPLICATE_WINDOW', '300')),  # 5åˆ†é’Ÿ
            
            # è¿æ¥é…ç½®
            'connect_timeout': int(os.getenv('NATS_CONNECT_TIMEOUT', '10')),
            'max_reconnect_attempts': int(os.getenv('NATS_MAX_RECONNECT', '10')),
        }
    
    async def connect(self) -> bool:
        """è¿æ¥åˆ°NATSæœåŠ¡å™¨"""
        try:
            logger.info(f"è¿æ¥åˆ°NATSæœåŠ¡å™¨: {self.nats_url}")
            
            self.nc = await nats.connect(
                servers=[self.nats_url],
                connect_timeout=self.config['connect_timeout'],
                max_reconnect_attempts=self.config['max_reconnect_attempts']
            )
            
            self.js = self.nc.jetstream()
            
            logger.info("âœ… NATSè¿æ¥æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ NATSè¿æ¥å¤±è´¥: {e}")
            return False
    
    async def disconnect(self):
        """æ–­å¼€NATSè¿æ¥"""
        try:
            if self.nc and not self.nc.is_closed:
                await self.nc.close()
                logger.info("âœ… NATSè¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"âŒ å…³é—­NATSè¿æ¥å¤±è´¥: {e}")
    
    async def initialize_market_data_stream(self) -> bool:
        """
        åˆå§‹åŒ–MARKET_DATAæµ
        
        æ”¯æŒæ‰€æœ‰7ç§æ•°æ®ç±»å‹ï¼Œä¸Data Collectorå®Œå…¨å…¼å®¹
        """
        try:
            stream_name = self.config['stream_name']
            
            logger.info(f"ğŸ”„ åˆå§‹åŒ–JetStreamæµ: {stream_name}")
            logger.info(f"ğŸ“Š æ”¯æŒçš„ä¸»é¢˜æ•°é‡: {len(self.supported_subjects)}")
            
            # æ˜¾ç¤ºæ”¯æŒçš„æ•°æ®ç±»å‹
            for i, subject in enumerate(self.supported_subjects, 1):
                data_type = subject.replace('-data.>', '').replace('_', ' ').title()
                logger.info(f"  {i}. {data_type}: {subject}")
            
            # åˆ›å»ºæµé…ç½®
            stream_config = StreamConfig(
                name=stream_name,
                subjects=self.supported_subjects,
                retention=self._get_retention_policy(),
                discard=self._get_discard_policy(),
                storage=self._get_storage_type(),
                max_consumers=self.config['max_consumers'],
                max_msgs=self.config['max_msgs'],
                max_bytes=self.config['max_bytes'],
                max_age=self.config['max_age'],
                num_replicas=self.config['num_replicas'],
                duplicate_window=self.config['duplicate_window']
            )
            
            # æ£€æŸ¥æµæ˜¯å¦å·²å­˜åœ¨
            try:
                existing_stream = await self.js.stream_info(stream_name)
                logger.info(f"ğŸ“Š æµå·²å­˜åœ¨: {stream_name}")
                logger.info(f"   æ¶ˆæ¯æ•°: {existing_stream.state.messages:,}")
                logger.info(f"   å­—èŠ‚æ•°: {existing_stream.state.bytes:,}")
                logger.info(f"   æ¶ˆè´¹è€…æ•°: {existing_stream.state.consumer_count}")
                
                # æ›´æ–°æµé…ç½®
                await self.js.update_stream(stream_config)
                logger.info(f"ğŸ”„ æµé…ç½®å·²æ›´æ–°: {stream_name}")
                
            except Exception as e:
                if "stream not found" in str(e).lower():
                    # åˆ›å»ºæ–°æµ
                    logger.info(f"ğŸ†• åˆ›å»ºæ–°æµ: {stream_name}")
                    await self.js.add_stream(stream_config)
                    logger.info(f"âœ… æµåˆ›å»ºæˆåŠŸ: {stream_name}")
                else:
                    raise e
            
            # éªŒè¯æµé…ç½®
            await self._verify_stream_config(stream_name)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–æµå¤±è´¥: {e}")
            return False
    
    def _get_retention_policy(self) -> RetentionPolicy:
        """è·å–ä¿ç•™ç­–ç•¥"""
        policy_map = {
            'limits': RetentionPolicy.LIMITS,
            'interest': RetentionPolicy.INTEREST
        }
        return policy_map.get(self.config['retention_policy'], RetentionPolicy.LIMITS)
    
    def _get_discard_policy(self) -> DiscardPolicy:
        """è·å–ä¸¢å¼ƒç­–ç•¥"""
        policy_map = {
            'old': DiscardPolicy.OLD,
            'new': DiscardPolicy.NEW
        }
        return policy_map.get(self.config['discard_policy'], DiscardPolicy.OLD)
    
    def _get_storage_type(self) -> StorageType:
        """è·å–å­˜å‚¨ç±»å‹"""
        type_map = {
            'file': StorageType.FILE,
            'memory': StorageType.MEMORY
        }
        return type_map.get(self.config['storage_type'], StorageType.FILE)
    
    async def _verify_stream_config(self, stream_name: str):
        """éªŒè¯æµé…ç½®"""
        try:
            stream_info = await self.js.stream_info(stream_name)
            config = stream_info.config
            
            logger.info(f"ğŸ“‹ æµé…ç½®éªŒè¯: {stream_name}")
            logger.info(f"   ä¿ç•™ç­–ç•¥: {config.retention}")
            logger.info(f"   å­˜å‚¨ç±»å‹: {config.storage}")
            logger.info(f"   æœ€å¤§æ¶ˆæ¯æ•°: {config.max_msgs:,}")
            logger.info(f"   æœ€å¤§å­—èŠ‚æ•°: {config.max_bytes:,}")
            logger.info(f"   æœ€å¤§æ¶ˆè´¹è€…æ•°: {config.max_consumers}")
            logger.info(f"   æ¶ˆæ¯ä¿ç•™æ—¶é—´: {config.max_age}ç§’")
            
            # éªŒè¯ä¸»é¢˜é…ç½®
            missing_subjects = set(self.supported_subjects) - set(config.subjects)
            if missing_subjects:
                logger.warning(f"âš ï¸ ç¼ºå°‘ä¸»é¢˜: {missing_subjects}")
            else:
                logger.info("âœ… æ‰€æœ‰æ•°æ®ç±»å‹ä¸»é¢˜å·²é…ç½®")
                
        except Exception as e:
            logger.error(f"âŒ æµé…ç½®éªŒè¯å¤±è´¥: {e}")
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            if not self.js:
                logger.error("âŒ JetStreamæœªåˆå§‹åŒ–")
                return False
            
            stream_name = self.config['stream_name']
            stream_info = await self.js.stream_info(stream_name)
            
            logger.info(f"âœ… æµå¥åº·æ£€æŸ¥é€šè¿‡: {stream_name}")
            logger.info(f"   çŠ¶æ€: æ­£å¸¸")
            logger.info(f"   æ¶ˆæ¯æ•°: {stream_info.state.messages:,}")
            logger.info(f"   æ¶ˆè´¹è€…æ•°: {stream_info.state.consumer_count}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def get_stream_stats(self) -> Dict[str, Any]:
        """è·å–æµç»Ÿè®¡ä¿¡æ¯"""
        try:
            stream_name = self.config['stream_name']
            stream_info = await self.js.stream_info(stream_name)
            
            return {
                'stream_name': stream_name,
                'messages': stream_info.state.messages,
                'bytes': stream_info.state.bytes,
                'first_seq': stream_info.state.first_seq,
                'last_seq': stream_info.state.last_seq,
                'consumer_count': stream_info.state.consumer_count,
                'subjects': len(stream_info.config.subjects),
                'max_msgs': stream_info.config.max_msgs,
                'max_bytes': stream_info.config.max_bytes,
                'max_age': stream_info.config.max_age,
                'storage': str(stream_info.config.storage),
                'retention': str(stream_info.config.retention)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æµç»Ÿè®¡å¤±è´¥: {e}")
            return {}


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MarketPrismå¢å¼ºJetStreamåˆå§‹åŒ–å™¨')
    parser.add_argument('--nats-url', default=None, help='NATSæœåŠ¡å™¨URL')
    parser.add_argument('--wait', action='store_true', help='ç­‰å¾…NATSæœåŠ¡å™¨å¯åŠ¨')
    parser.add_argument('--health-check', action='store_true', help='æ‰§è¡Œå¥åº·æ£€æŸ¥')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºæµç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--timeout', type=int, default=30, help='æ“ä½œè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ å¯åŠ¨MarketPrismå¢å¼ºJetStreamåˆå§‹åŒ–å™¨")
    logger.info(f"â° å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åˆ›å»ºåˆå§‹åŒ–å™¨
    initializer = EnhancedJetStreamInitializer(args.nats_url)
    
    try:
        # ç­‰å¾…NATSæœåŠ¡å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.wait:
            logger.info("â³ ç­‰å¾…NATSæœåŠ¡å™¨å¯åŠ¨...")
            for i in range(args.timeout):
                if await initializer.connect():
                    await initializer.disconnect()
                    break
                await asyncio.sleep(1)
            else:
                logger.error("âŒ ç­‰å¾…NATSæœåŠ¡å™¨è¶…æ—¶")
                return 1
        
        # è¿æ¥NATS
        if not await initializer.connect():
            logger.error("âŒ æ— æ³•è¿æ¥åˆ°NATSæœåŠ¡å™¨")
            return 1
        
        # æ‰§è¡Œæ“ä½œ
        if args.health_check:
            success = await initializer.health_check()
            if not success:
                return 1
        elif args.stats:
            stats = await initializer.get_stream_stats()
            if stats:
                print(json.dumps(stats, indent=2, ensure_ascii=False))
            else:
                return 1
        else:
            # é»˜è®¤ï¼šåˆå§‹åŒ–æµ
            success = await initializer.initialize_market_data_stream()
            if not success:
                return 1
        
        logger.info("âœ… æ“ä½œå®Œæˆ")
        return 0
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"âŒ æ“ä½œå¼‚å¸¸: {e}")
        return 1
    finally:
        await initializer.disconnect()


if __name__ == "__main__":
    exit(asyncio.run(main()))
