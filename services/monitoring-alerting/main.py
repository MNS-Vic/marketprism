"""
MarketPrism ç›‘æ§å‘Šè­¦æœåŠ¡ - BaseServiceé‡æ„ç‰ˆæœ¬

åŸºäºBaseServiceæ¡†æ¶çš„ç›‘æ§å‘Šè­¦æœåŠ¡ï¼Œæä¾›ï¼š
- ç»Ÿä¸€çš„APIå“åº”æ ¼å¼
- æ ‡å‡†åŒ–çš„é”™è¯¯å¤„ç†æœºåˆ¶
- å®Œæ•´çš„æœåŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†
- å‘Šè­¦è§„åˆ™å’ŒæŒ‡æ ‡ç®¡ç†åŠŸèƒ½
"""

import asyncio
import sys
import json
import os
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime, timezone
import structlog
from aiohttp import web

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•ã€å½“å‰æ¨¡å—ç›®å½•ä¸ src ç›®å½•åˆ°Pythonè·¯å¾„ï¼ˆé¿å…é‡å¤æ’å…¥ï¼‰
project_root = str(Path(__file__).parent.parent.parent)
module_dir = str(Path(__file__).parent)
src_dir = str(Path(__file__).parent / 'src')
if project_root not in sys.path:
    sys.path.insert(0, project_root)
if module_dir not in sys.path:
    sys.path.insert(0, module_dir)
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)

# å¯¼å…¥BaseServiceæ¡†æ¶
from core.service_framework import BaseService

logger = structlog.get_logger(__name__)


class MonitoringAlertingService(BaseService):
    """
    MarketPrism ç›‘æ§å‘Šè­¦æœåŠ¡ - BaseServiceé‡æ„ç‰ˆæœ¬

    åŸºäºBaseServiceæ¡†æ¶ï¼Œæä¾›ï¼š
    - ç»Ÿä¸€çš„æœåŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†
    - æ ‡å‡†åŒ–çš„APIå“åº”æ ¼å¼
    - å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶
    - å‘Šè­¦è§„åˆ™å’ŒæŒ‡æ ‡ç®¡ç†åŠŸèƒ½
    - PrometheusæŒ‡æ ‡é›†æˆ
    """

    def __init__(self, config: Dict[str, Any]):
        super().__init__("monitoring-alerting", config)

        # æœåŠ¡çŠ¶æ€
        self.start_time = datetime.now(timezone.utc)
        self.is_initialized = False

        # å‘Šè­¦ç›¸å…³æ•°æ®
        self.alert_rules = []
        self.alerts = []
        self.component_health = {}
        self.metrics_data = {}

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_alerts': 0,
            'active_alerts': 0,
            'alert_rules_count': 0,
            'last_alert_time': None,
            'request_count': 0
        }

        logger.info("ğŸ‰ ç›‘æ§å‘Šè­¦æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def setup_routes(self):
        """è®¾ç½®APIè·¯ç”±"""
        # å¯é€‰ä¸­é—´ä»¶æ¥å…¥ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡å¼€å…³ï¼Œé»˜è®¤å…³é—­ï¼‰
        enable_auth = os.getenv('MARKETPRISM_ENABLE_AUTH', 'false').lower() == 'true'
        enable_validation = os.getenv('MARKETPRISM_ENABLE_VALIDATION', 'false').lower() == 'true'

        if enable_auth:
            try:
                from src.auth import create_auth_middleware
                self.app.middlewares.append(create_auth_middleware())
                logger.info("è®¤è¯ä¸­é—´ä»¶å·²å¯ç”¨ï¼ˆMARKETPRISM_ENABLE_AUTH=trueï¼‰")
            except Exception as e:
                logger.error(f"åŠ è½½è®¤è¯ä¸­é—´ä»¶å¤±è´¥: {e}")

        if enable_validation:
            try:
                from src.validation import create_validation_middleware
                self.app.middlewares.append(create_validation_middleware())
                logger.info("éªŒè¯ä¸­é—´ä»¶å·²å¯ç”¨ï¼ˆMARKETPRISM_ENABLE_VALIDATION=trueï¼‰")
            except Exception as e:
                logger.error(f"åŠ è½½éªŒè¯ä¸­é—´ä»¶å¤±è´¥: {e}")

        # åŸºç¡€è·¯ç”±å·²åœ¨BaseServiceä¸­è®¾ç½®ï¼Œè¿™é‡Œæ·»åŠ monitoring-alertingç‰¹å®šçš„APIç«¯ç‚¹
        self.app.router.add_get("/api/v1/status", self._get_service_status)
        self.app.router.add_get("/api/v1/alerts", self._get_alerts)
        self.app.router.add_post("/api/v1/alerts", self._create_alert)
        self.app.router.add_get("/api/v1/alerts/rules", self._get_alert_rules)
        self.app.router.add_post("/api/v1/alerts/rules", self._create_alert_rule)
        self.app.router.add_get("/api/v1/metrics", self._get_metrics)
        self.app.router.add_get("/api/v1/health/components", self._get_component_health)

        # ç™»å½•ç«¯ç‚¹ï¼ˆå…¬å¼€ï¼‰ï¼Œç”¨äºè·å– Bearer Token
        try:
            from src.auth import login_handler
            self.app.router.add_post("/login", login_handler)
        except Exception as e:
            logger.error(f"æ³¨å†Œ /login ç«¯ç‚¹å¤±è´¥: {e}")


    def _create_success_response(self, data: Any, message: str = "Success") -> web.Response:
        """
        åˆ›å»ºæ ‡å‡†åŒ–æˆåŠŸå“åº”

        Args:
            data: å“åº”æ•°æ®
            message: æˆåŠŸæ¶ˆæ¯

        Returns:
            æ ‡å‡†åŒ–çš„æˆåŠŸå“åº”
        """
        return web.json_response({
            "status": "success",
            "message": message,
            "data": data,
            "timestamp": datetime.now(timezone.utc).isoformat()
        })

    def _create_error_response(self, message: str, error_code: str = "INTERNAL_ERROR",
                              status_code: int = 500) -> web.Response:
        """
        åˆ›å»ºæ ‡å‡†åŒ–é”™è¯¯å“åº”

        Args:
            message: é”™è¯¯æè¿°ä¿¡æ¯
            error_code: æ ‡å‡†åŒ–é”™è¯¯ä»£ç 
            status_code: HTTPçŠ¶æ€ç 

        Returns:
            æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”
        """
        return web.json_response({
            "status": "error",
            "error_code": error_code,
            "message": message,
            "data": None,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }, status=status_code)

    # æ ‡å‡†åŒ–é”™è¯¯ä»£ç å¸¸é‡
    ERROR_CODES = {
        'ALERT_NOT_FOUND': 'ALERT_NOT_FOUND',
        'RULE_NOT_FOUND': 'RULE_NOT_FOUND',
        'INVALID_ALERT_DATA': 'INVALID_ALERT_DATA',
        'INVALID_RULE_DATA': 'INVALID_RULE_DATA',
        'METRICS_UNAVAILABLE': 'METRICS_UNAVAILABLE',
        'COMPONENT_HEALTH_ERROR': 'COMPONENT_HEALTH_ERROR',
        'INVALID_PARAMETERS': 'INVALID_PARAMETERS',
        'SERVICE_UNAVAILABLE': 'SERVICE_UNAVAILABLE',
        'INTERNAL_ERROR': 'INTERNAL_ERROR'
    }

    async def on_startup(self):
        """æœåŠ¡å¯åŠ¨åˆå§‹åŒ–"""
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–ç›‘æ§å‘Šè­¦æœåŠ¡...")

            # 1. åˆå§‹åŒ–å‘Šè­¦æ•°æ®
            self._initialize_alert_data()

            # 2. åˆå§‹åŒ–ç»„ä»¶å¥åº·çŠ¶æ€
            self._initialize_component_health()

            # 3. åˆå§‹åŒ–æŒ‡æ ‡æ•°æ®
            self._initialize_metrics_data()

            # 4. æ ‡è®°æœåŠ¡å·²åˆå§‹åŒ–
            self.is_initialized = True

            logger.info("ğŸ‰ ç›‘æ§å‘Šè­¦æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"   - å‘Šè­¦è§„åˆ™: {len(self.alert_rules)}ä¸ª")
            logger.info(f"   - æ´»è·ƒå‘Šè­¦: {len(self.alerts)}ä¸ª")
            logger.info(f"   - ç›‘æ§ç»„ä»¶: {len(self.component_health)}ä¸ª")

        except Exception as e:
            logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            self.is_initialized = False
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸æœåŠ¡ä»¥é™çº§æ¨¡å¼è¿è¡Œ
            logger.warning("æœåŠ¡å°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ")

    def _initialize_alert_data(self):
        """åˆå§‹åŒ–å‘Šè­¦æ•°æ®"""
        # å‘Šè­¦è§„åˆ™æ•°æ®
        self.alert_rules = [
            {
                'id': 'rule-001',
                'name': 'CPUä½¿ç”¨ç‡è¿‡é«˜',
                'description': 'CPUä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼å‘Šè­¦',
                'severity': 'high',
                'category': 'system',
                'enabled': True,
                'conditions': [
                    {
                        'metric_name': 'cpu_usage_percent',
                        'operator': 'greater_than',
                        'threshold': 80.0,
                        'duration': 300
                    }
                ],
                'created_at': '2025-06-27T20:00:00Z',
                'updated_at': '2025-06-27T20:00:00Z'
            },
            {
                'id': 'rule-002',
                'name': 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜',
                'description': 'å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼å‘Šè­¦',
                'severity': 'medium',
                'category': 'system',
                'enabled': True,
                'conditions': [
                    {
                        'metric_name': 'memory_usage_percent',
                        'operator': 'greater_than',
                        'threshold': 85.0,
                        'duration': 300
                    }
                ],
                'created_at': '2025-06-27T20:00:00Z',
                'updated_at': '2025-06-27T20:00:00Z'
            },
            {
                'id': 'rule-003',
                'name': 'APIé”™è¯¯ç‡è¿‡é«˜',
                'description': 'APIé”™è¯¯ç‡è¶…è¿‡5%',
                'severity': 'high',
                'category': 'business',
                'enabled': True,
                'conditions': [
                    {
                        'metric_name': 'api_error_rate',
                        'operator': 'greater_than',
                        'threshold': 0.05,
                        'duration': 180
                    }
                ],
                'created_at': '2025-06-27T20:00:00Z',
                'updated_at': '2025-06-27T20:00:00Z'
            }
        ]

        # ç¤ºä¾‹å‘Šè­¦æ•°æ®
        self.alerts = [
            {
                'id': 'alert-001',
                'rule_id': 'rule-001',
                'name': 'CPUä½¿ç”¨ç‡è¿‡é«˜',
                'severity': 'high',
                'status': 'active',
                'category': 'system',
                'timestamp': '2025-06-27T20:30:00Z',
                'description': 'marketprism-node-01 CPUä½¿ç”¨ç‡è¾¾åˆ°85%',
                'source': 'marketprism-node-01',
                'labels': {
                    'instance': 'marketprism-node-01',
                    'service': 'data-collector'
                }
            },
            {
                'id': 'alert-002',
                'rule_id': 'rule-002',
                'name': 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜',
                'severity': 'medium',
                'status': 'acknowledged',
                'category': 'system',
                'timestamp': '2025-06-27T20:25:00Z',
                'description': 'marketprism-node-02 å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ°87%',
                'source': 'marketprism-node-02',
                'labels': {
                    'instance': 'marketprism-node-02',
                    'service': 'api-gateway'
                }
            }
        ]

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats['alert_rules_count'] = len(self.alert_rules)
        self.stats['total_alerts'] = len(self.alerts)
        self.stats['active_alerts'] = len([a for a in self.alerts if a['status'] == 'active'])

        logger.info(f"âœ… å‘Šè­¦æ•°æ®åˆå§‹åŒ–å®Œæˆ: {len(self.alert_rules)}ä¸ªè§„åˆ™, {len(self.alerts)}ä¸ªå‘Šè­¦")

    def _initialize_component_health(self):
        """åˆå§‹åŒ–ç»„ä»¶å¥åº·çŠ¶æ€"""
        # ç»„ä»¶å¥åº·çŠ¶æ€
        self.component_health = {
            'alert_manager': {
                'status': 'healthy',
                'last_check': datetime.now(timezone.utc).isoformat(),
                'uptime_seconds': 0,
                'version': '2.0.0'
            },
            'rule_engine': {
                'status': 'healthy',
                'last_check': datetime.now(timezone.utc).isoformat(),
                'rules_loaded': len(self.alert_rules),
                'version': '2.0.0'
            },
            'data_collector': {
                'status': 'healthy',
                'last_check': datetime.now(timezone.utc).isoformat(),
                'endpoint': 'http://marketprism-data-collector:8084',
                'version': '1.0.0'
            },
            'message_broker': {
                'status': 'healthy',
                'last_check': datetime.now(timezone.utc).isoformat(),
                'endpoint': 'http://marketprism-message-broker:8086',
                'version': '1.0.0'
            },
            'task_worker': {
                'status': 'healthy',
                'last_check': datetime.now(timezone.utc).isoformat(),
                'endpoint': 'http://marketprism-task-worker:8090',
                'version': '1.0.0'
            },
            'prometheus': {
                'status': 'healthy',
                'last_check': datetime.now(timezone.utc).isoformat(),
                'endpoint': 'http://marketprism-prometheus:9090',
                'version': 'latest'
            }
        }

        logger.info(f"âœ… ç»„ä»¶å¥åº·çŠ¶æ€åˆå§‹åŒ–å®Œæˆ: {len(self.component_health)}ä¸ªç»„ä»¶")

    def _initialize_metrics_data(self):
        """åˆå§‹åŒ–æŒ‡æ ‡æ•°æ®"""
        self.metrics_data = {
            'system_metrics': {
                'cpu_usage_percent': 45.2,
                'memory_usage_percent': 67.8,
                'disk_usage_percent': 34.1,
                'network_io_bytes': 1024000,
                'last_updated': datetime.now(timezone.utc).isoformat()
            },
            'service_metrics': {
                'api_requests_total': 15420,
                'api_requests_per_second': 12.5,
                'api_error_rate': 0.02,
                'response_time_ms': 145.6,
                'last_updated': datetime.now(timezone.utc).isoformat()
            },
            'business_metrics': {
                'active_connections': 234,
                'data_points_processed': 98765,
                'alerts_triggered_today': 8,
                'last_updated': datetime.now(timezone.utc).isoformat()
            }
        }

        logger.info("âœ… æŒ‡æ ‡æ•°æ®åˆå§‹åŒ–å®Œæˆ")

    async def _get_service_status(self, request: web.Request) -> web.Response:
        """è·å–æœåŠ¡çŠ¶æ€ - æ ‡å‡†åŒ–APIç«¯ç‚¹"""
        try:
            self.stats['request_count'] += 1

            # è®¡ç®—è¿è¡Œæ—¶é—´
            uptime_seconds = (datetime.now(timezone.utc) - self.start_time).total_seconds()

            status_data = {
                "service": "monitoring-alerting",
                "status": "running" if self.is_initialized else "initializing",
                "uptime_seconds": round(uptime_seconds, 2),
                "version": "2.0.0",
                "environment": self.config.get('environment', 'production'),
                "port": self.config.get('port', 8082),
                "features": {
                    "alert_management": True,
                    "rule_engine": True,
                    "metrics_collection": True,
                    "prometheus_integration": True,
                    "grafana_support": True
                },
                "statistics": {
                    "total_alerts": self.stats['total_alerts'],
                    "active_alerts": self.stats['active_alerts'],
                    "alert_rules_count": self.stats['alert_rules_count'],
                    "request_count": self.stats['request_count'],
                    "last_alert_time": self.stats['last_alert_time']
                },
                "component_health": {
                    name: comp['status'] for name, comp in self.component_health.items()
                }
            }

            return self._create_success_response(status_data, "Service status retrieved successfully")

        except Exception as e:
            logger.error(f"è·å–æœåŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve service status: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR']
            )

    async def _get_alerts(self, request: web.Request) -> web.Response:
        """è·å–å‘Šè­¦åˆ—è¡¨"""
        try:
            self.stats['request_count'] += 1

            # è·å–æŸ¥è¯¢å‚æ•°
            status = request.query.get('status')
            severity = request.query.get('severity')
            category = request.query.get('category')
            limit = int(request.query.get('limit', 100))

            # è¿‡æ»¤å‘Šè­¦
            filtered_alerts = self.alerts.copy()

            if status:
                filtered_alerts = [a for a in filtered_alerts if a['status'] == status]
            if severity:
                filtered_alerts = [a for a in filtered_alerts if a['severity'] == severity]
            if category:
                filtered_alerts = [a for a in filtered_alerts if a['category'] == category]

            # é™åˆ¶è¿”å›æ•°é‡
            filtered_alerts = filtered_alerts[:limit]

            return self._create_success_response({
                "alerts": filtered_alerts,
                "total_count": len(self.alerts),
                "filtered_count": len(filtered_alerts),
                "filters_applied": {
                    "status": status,
                    "severity": severity,
                    "category": category,
                    "limit": limit
                }
            }, "Alerts retrieved successfully")

        except ValueError as e:
            return self._create_error_response(
                f"Invalid parameters: {str(e)}",
                self.ERROR_CODES['INVALID_PARAMETERS'],
                400
            )
        except Exception as e:
            logger.error(f"è·å–å‘Šè­¦åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve alerts: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR']
            )

    async def _create_alert(self, request: web.Request) -> web.Response:
        """åˆ›å»ºæ–°å‘Šè­¦"""
        try:
            self.stats['request_count'] += 1

            # è§£æè¯·æ±‚æ•°æ®
            data = await request.json()

            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['name', 'severity', 'description', 'source']
            for field in required_fields:
                if field not in data:
                    return self._create_error_response(
                        f"Missing required field: {field}",
                        self.ERROR_CODES['INVALID_ALERT_DATA'],
                        400
                    )

            # åˆ›å»ºæ–°å‘Šè­¦
            new_alert = {
                'id': f"alert-{len(self.alerts) + 1:03d}",
                'rule_id': data.get('rule_id'),
                'name': data['name'],
                'severity': data['severity'],
                'status': data.get('status', 'active'),
                'category': data.get('category', 'custom'),
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'description': data['description'],
                'source': data['source'],
                'labels': data.get('labels', {})
            }

            # æ·»åŠ åˆ°å‘Šè­¦åˆ—è¡¨
            self.alerts.append(new_alert)

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['total_alerts'] = len(self.alerts)
            self.stats['active_alerts'] = len([a for a in self.alerts if a['status'] == 'active'])
            self.stats['last_alert_time'] = new_alert['timestamp']

            return self._create_success_response(new_alert, "Alert created successfully")

        except json.JSONDecodeError:
            return self._create_error_response(
                "Invalid JSON data",
                self.ERROR_CODES['INVALID_ALERT_DATA'],
                400
            )
        except Exception as e:
            logger.error(f"åˆ›å»ºå‘Šè­¦å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to create alert: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR']
            )

    async def _get_alert_rules(self, request: web.Request) -> web.Response:
        """è·å–å‘Šè­¦è§„åˆ™åˆ—è¡¨"""
        try:
            self.stats['request_count'] += 1

            # è·å–æŸ¥è¯¢å‚æ•°
            enabled = request.query.get('enabled')
            category = request.query.get('category')
            severity = request.query.get('severity')

            # è¿‡æ»¤è§„åˆ™
            filtered_rules = self.alert_rules.copy()

            if enabled is not None:
                enabled_bool = enabled.lower() == 'true'
                filtered_rules = [r for r in filtered_rules if r['enabled'] == enabled_bool]
            if category:
                filtered_rules = [r for r in filtered_rules if r['category'] == category]
            if severity:
                filtered_rules = [r for r in filtered_rules if r['severity'] == severity]

            return self._create_success_response({
                "rules": filtered_rules,
                "total_count": len(self.alert_rules),
                "filtered_count": len(filtered_rules),
                "filters_applied": {
                    "enabled": enabled,
                    "category": category,
                    "severity": severity
                }
            }, "Alert rules retrieved successfully")

        except Exception as e:
            logger.error(f"è·å–å‘Šè­¦è§„åˆ™å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve alert rules: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR']
            )

    async def _create_alert_rule(self, request: web.Request) -> web.Response:
        """åˆ›å»ºæ–°å‘Šè­¦è§„åˆ™"""
        try:
            self.stats['request_count'] += 1

            # è§£æè¯·æ±‚æ•°æ®
            data = await request.json()

            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['name', 'description', 'severity', 'conditions']
            for field in required_fields:
                if field not in data:
                    return self._create_error_response(
                        f"Missing required field: {field}",
                        self.ERROR_CODES['INVALID_RULE_DATA'],
                        400
                    )

            # éªŒè¯æ¡ä»¶æ ¼å¼
            if not isinstance(data['conditions'], list) or not data['conditions']:
                return self._create_error_response(
                    "Conditions must be a non-empty list",
                    self.ERROR_CODES['INVALID_RULE_DATA'],
                    400
                )

            # åˆ›å»ºæ–°è§„åˆ™
            new_rule = {
                'id': f"rule-{len(self.alert_rules) + 1:03d}",
                'name': data['name'],
                'description': data['description'],
                'severity': data['severity'],
                'category': data.get('category', 'custom'),
                'enabled': data.get('enabled', True),
                'conditions': data['conditions'],
                'created_at': datetime.now(timezone.utc).isoformat(),
                'updated_at': datetime.now(timezone.utc).isoformat()
            }

            # æ·»åŠ åˆ°è§„åˆ™åˆ—è¡¨
            self.alert_rules.append(new_rule)

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['alert_rules_count'] = len(self.alert_rules)

            return self._create_success_response(new_rule, "Alert rule created successfully")

        except json.JSONDecodeError:
            return self._create_error_response(
                "Invalid JSON data",
                self.ERROR_CODES['INVALID_RULE_DATA'],
                400
            )
        except Exception as e:
            logger.error(f"åˆ›å»ºå‘Šè­¦è§„åˆ™å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to create alert rule: {str(e)}",
                self.ERROR_CODES['INTERNAL_ERROR']
            )

    async def _get_metrics(self, request: web.Request) -> web.Response:
        """è·å–ç›‘æ§æŒ‡æ ‡"""
        try:
            self.stats['request_count'] += 1

            # è·å–æŸ¥è¯¢å‚æ•°
            category = request.query.get('category')  # system, service, business
            format_type = request.query.get('format', 'json')  # json, prometheus

            # è¿‡æ»¤æŒ‡æ ‡
            if category and category in self.metrics_data:
                metrics = {category: self.metrics_data[category]}
            else:
                metrics = self.metrics_data

            # å¦‚æœè¯·æ±‚Prometheusæ ¼å¼
            if format_type == 'prometheus':
                prometheus_metrics = self._format_prometheus_metrics(metrics)
                return web.Response(text=prometheus_metrics, content_type='text/plain')

            return self._create_success_response({
                "metrics": metrics,
                "available_categories": list(self.metrics_data.keys()),
                "last_updated": datetime.now(timezone.utc).isoformat()
            }, "Metrics retrieved successfully")

        except Exception as e:
            logger.error(f"è·å–æŒ‡æ ‡å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve metrics: {str(e)}",
                self.ERROR_CODES['METRICS_UNAVAILABLE']
            )

    async def _get_component_health(self, request: web.Request) -> web.Response:
        """è·å–ç»„ä»¶å¥åº·çŠ¶æ€"""
        try:
            self.stats['request_count'] += 1

            # æ›´æ–°ç»„ä»¶å¥åº·çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿå®æ—¶æ£€æŸ¥ï¼‰
            self._update_component_health()

            # è®¡ç®—æ€»ä½“å¥åº·çŠ¶æ€
            healthy_count = sum(1 for comp in self.component_health.values()
                              if comp['status'] == 'healthy')
            total_count = len(self.component_health)
            overall_health = 'healthy' if healthy_count == total_count else 'degraded'

            return self._create_success_response({
                "overall_health": overall_health,
                "healthy_components": healthy_count,
                "total_components": total_count,
                "components": self.component_health,
                "last_check": datetime.now(timezone.utc).isoformat()
            }, "Component health retrieved successfully")

        except Exception as e:
            logger.error(f"è·å–ç»„ä»¶å¥åº·çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return self._create_error_response(
                f"Failed to retrieve component health: {str(e)}",
                self.ERROR_CODES['COMPONENT_HEALTH_ERROR']
            )

    def _format_prometheus_metrics(self, metrics: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸ºPrometheusæŒ‡æ ‡æ ¼å¼"""
        prometheus_lines = []

        for category, category_metrics in metrics.items():
            for metric_name, value in category_metrics.items():
                if metric_name == 'last_updated':
                    continue

                if isinstance(value, (int, float)):
                    prometheus_lines.append(f"marketprism_{category}_{metric_name} {value}")

        return '\n'.join(prometheus_lines) + '\n'

    def _update_component_health(self):
        """æ›´æ–°ç»„ä»¶å¥åº·çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        current_time = datetime.now(timezone.utc).isoformat()

        for component_name, component_info in self.component_health.items():
            # æ¨¡æ‹Ÿå¥åº·æ£€æŸ¥
            component_info['last_check'] = current_time
            # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè¿›è¡ŒçœŸå®çš„å¥åº·æ£€æŸ¥

    async def on_shutdown(self):
        """æœåŠ¡å…³é—­æ¸…ç†"""
        try:
            logger.info("å¼€å§‹å…³é—­ç›‘æ§å‘Šè­¦æœåŠ¡...")

            # æ¸…ç†èµ„æº
            self.is_initialized = False

            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦æŒä¹…åŒ–ï¼‰
            logger.info(f"æœåŠ¡è¿è¡Œç»Ÿè®¡:")
            logger.info(f"  - å¤„ç†è¯·æ±‚: {self.stats['request_count']}ä¸ª")
            logger.info(f"  - å‘Šè­¦è§„åˆ™: {self.stats['alert_rules_count']}ä¸ª")
            logger.info(f"  - æ€»å‘Šè­¦æ•°: {self.stats['total_alerts']}ä¸ª")

            logger.info("ğŸ‰ ç›‘æ§å‘Šè­¦æœåŠ¡å·²å®‰å…¨å…³é—­")

        except Exception as e:
            logger.error(f"æœåŠ¡å…³é—­æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


async def create_app(config: Dict[str, Any]) -> web.Application:
    """åˆ›å»ºåº”ç”¨å®ä¾‹"""
    service = MonitoringAlertingService(config)
    return service.app


async def main():
    """ä¸»å‡½æ•°"""
    # é»˜è®¤é…ç½®
    config = {
        'environment': 'production',
        'port': 8082,
        'host': '0.0.0.0',
        'log_level': 'INFO'
    }

    # åˆ›å»ºæœåŠ¡å®ä¾‹
    service = MonitoringAlertingService(config)

    try:
        # å¯åŠ¨æœåŠ¡ - ä½¿ç”¨BaseServiceçš„runæ–¹æ³•
        # run() æ–¹æ³•åŒ…å«å®Œæ•´çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼š
        # 1. åˆ›å»ºåº”ç”¨å’Œè·¯ç”±
        # 2. è°ƒç”¨ on_startup()
        # 3. å¯åŠ¨ HTTP æœåŠ¡å™¨
        # 4. ç­‰å¾…åœæ­¢ä¿¡å·ï¼ˆSIGINT/SIGTERMï¼‰
        # 5. è°ƒç”¨ on_shutdown()
        # 6. æ¸…ç†èµ„æº
        await service.run()

    except KeyboardInterrupt:
        # run() æ–¹æ³•å·²ç»å¤„ç†äº† SIGINTï¼Œè¿™é‡Œé€šå¸¸ä¸ä¼šåˆ°è¾¾
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    except Exception as e:
        logger.error(f"æœåŠ¡è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # è¿è¡ŒæœåŠ¡
    asyncio.run(main())
