#!/usr/bin/env python3
"""
æ·±åº¦åŠŸèƒ½é—®é¢˜æ£€æŸ¥ - æ£€æŸ¥å®é™…åŠŸèƒ½å±‚é¢çš„é—®é¢˜
åŸºç¡€è®¾æ–½è™½ç„¶å°±ç»ªï¼Œä½†åŠŸèƒ½å±‚é¢å¯èƒ½è¿˜æœ‰é—®é¢˜
"""

from datetime import datetime, timezone
import asyncio
import aiohttp
import logging
import sys
import os
import importlib.util
import yaml
import subprocess
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

logger = logging.getLogger(__name__)

class DeepFunctionalIssuesTest:
    """æ·±åº¦åŠŸèƒ½é—®é¢˜æ£€æŸ¥"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.core_dir = self.project_root / "core"
        self.services_dir = self.project_root / "services"
        self.config_dir = self.project_root / "config"
        self.issues_found = []
        
    async def test_core_components_actual_functionality(self):
        """æµ‹è¯•æ ¸å¿ƒç»„ä»¶çš„å®é™…åŠŸèƒ½å¯ç”¨æ€§"""
        logger.info("ğŸ” æ·±åº¦æ£€æŸ¥æ ¸å¿ƒç»„ä»¶å®é™…åŠŸèƒ½...")
        
        component_issues = []
        
        # 1. æ£€æŸ¥ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨çš„å®é™…å¯¼å…¥é—®é¢˜
        try:
            storage_manager_path = self.core_dir / 'storage' / 'unified_storage_manager.py'
            if storage_manager_path.exists():
                # å°è¯•å®é™…å¯¼å…¥
                spec = importlib.util.spec_from_file_location("unified_storage_manager", storage_manager_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                logger.info("âœ… ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å¯ä»¥æ­£å¸¸å¯¼å…¥")
            else:
                component_issues.append("ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            component_issues.append(f"ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
            logger.error(f"âŒ ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
        
        # 2. æ£€æŸ¥ç½‘ç»œç»„ä»¶çš„å¯¼å…¥é—®é¢˜
        try:
            networking_dir = self.core_dir / 'networking'
            if networking_dir.exists():
                session_manager_path = networking_dir / 'unified_session_manager.py'
                if session_manager_path.exists():
                    spec = importlib.util.spec_from_file_location("unified_session_manager", session_manager_path)
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)
                    logger.info("âœ… ç»Ÿä¸€ä¼šè¯ç®¡ç†å™¨å¯ä»¥æ­£å¸¸å¯¼å…¥")
                else:
                    component_issues.append("ç»Ÿä¸€ä¼šè¯ç®¡ç†å™¨æ–‡ä»¶ä¸å­˜åœ¨")
            else:
                component_issues.append("networkingç›®å½•ä¸å­˜åœ¨")
        except Exception as e:
            component_issues.append(f"ç»Ÿä¸€ä¼šè¯ç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
            logger.error(f"âŒ ç»Ÿä¸€ä¼šè¯ç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
        
        # 3. æ£€æŸ¥ç›‘æ§ç»„ä»¶
        try:
            monitoring_dir = self.core_dir / 'monitoring'
            if monitoring_dir.exists():
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»è¦çš„ç›‘æ§æ¨¡å—
                monitoring_files = list(monitoring_dir.glob('*.py'))
                if len(monitoring_files) > 0:
                    logger.info(f"âœ… ç›‘æ§ç»„ä»¶åŒ…å« {len(monitoring_files)} ä¸ªPythonæ–‡ä»¶")
                else:
                    component_issues.append("ç›‘æ§ç»„ä»¶ç¼ºå°‘Pythonå®ç°æ–‡ä»¶")
            else:
                component_issues.append("ç›‘æ§ç›®å½•ä¸å­˜åœ¨")
        except Exception as e:
            component_issues.append(f"ç›‘æ§ç»„ä»¶æ£€æŸ¥å¤±è´¥: {e}")
        
        if component_issues:
            self.issues_found.extend([f"æ ¸å¿ƒç»„ä»¶é—®é¢˜: {issue}" for issue in component_issues])
            return False
        return True
    
    async def test_services_actual_functionality(self):
        """æµ‹è¯•æœåŠ¡çš„å®é™…åŠŸèƒ½å¯ç”¨æ€§"""
        logger.info("ğŸ” æ·±åº¦æ£€æŸ¥æœåŠ¡å®é™…åŠŸèƒ½...")
        
        service_issues = []
        
        # æ£€æŸ¥æ¯ä¸ªæœåŠ¡æ˜¯å¦æœ‰å¯æ‰§è¡Œçš„å…¥å£
        services = [
            'data-storage-service',
            'api-gateway-service', 
            'scheduler-service',
            'monitoring-service',
            'message-broker-service',
            'market-data-collector'
        ]
        
        for service in services:
            service_path = self.services_dir / service
            if service_path.exists():
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»å…¥å£æ–‡ä»¶
                main_files = ['main.py', 'app.py', 'run.py', '__main__.py']
                has_main = any((service_path / main_file).exists() for main_file in main_files)
                
                if has_main:
                    # å°è¯•è¯­æ³•æ£€æŸ¥
                    for main_file in main_files:
                        main_path = service_path / main_file
                        if main_path.exists():
                            try:
                                with open(main_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    # åŸºæœ¬çš„è¯­æ³•æ£€æŸ¥
                                    compile(content, str(main_path), 'exec')
                                logger.info(f"âœ… æœåŠ¡ {service} è¯­æ³•æ­£ç¡®")
                                break
                            except SyntaxError as e:
                                service_issues.append(f"æœåŠ¡ {service} è¯­æ³•é”™è¯¯: {e}")
                                logger.error(f"âŒ æœåŠ¡ {service} è¯­æ³•é”™è¯¯: {e}")
                            except Exception as e:
                                service_issues.append(f"æœåŠ¡ {service} æ£€æŸ¥å¤±è´¥: {e}")
                else:
                    service_issues.append(f"æœåŠ¡ {service} ç¼ºå°‘ä¸»å…¥å£æ–‡ä»¶")
                    logger.warning(f"âš ï¸ æœåŠ¡ {service} ç¼ºå°‘ä¸»å…¥å£æ–‡ä»¶")
            else:
                service_issues.append(f"æœåŠ¡ {service} ç›®å½•ä¸å­˜åœ¨")
        
        if service_issues:
            self.issues_found.extend([f"æœåŠ¡é—®é¢˜: {issue}" for issue in service_issues])
            return False
        return True
    
    async def test_configuration_actual_validity(self):
        """æµ‹è¯•é…ç½®çš„å®é™…æœ‰æ•ˆæ€§"""
        logger.info("ğŸ” æ·±åº¦æ£€æŸ¥é…ç½®å®é™…æœ‰æ•ˆæ€§...")
        
        config_issues = []
        
        # æ£€æŸ¥å…³é”®é…ç½®æ–‡ä»¶çš„å†…å®¹æœ‰æ•ˆæ€§
        critical_configs = {
            'services.yaml': ['services'],
            'collector_config.yaml': ['exchanges', 'proxy'],
            'hot_storage_config.yaml': ['hot_storage']
        }
        
        for config_file, required_keys in critical_configs.items():
            config_path = self.config_dir / config_file
            if config_path.exists():
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config_data = yaml.safe_load(f)
                    
                    if config_data:
                        # æ£€æŸ¥å¿…éœ€çš„é”®æ˜¯å¦å­˜åœ¨
                        missing_keys = [key for key in required_keys if key not in config_data]
                        if missing_keys:
                            config_issues.append(f"{config_file} ç¼ºå°‘å¿…éœ€é…ç½®: {missing_keys}")
                        else:
                            logger.info(f"âœ… é…ç½®æ–‡ä»¶ {config_file} ç»“æ„æœ‰æ•ˆ")
                    else:
                        config_issues.append(f"{config_file} é…ç½®ä¸ºç©º")
                        
                except yaml.YAMLError as e:
                    config_issues.append(f"{config_file} YAMLæ ¼å¼é”™è¯¯: {e}")
                except Exception as e:
                    config_issues.append(f"{config_file} è¯»å–å¤±è´¥: {e}")
            else:
                config_issues.append(f"å…³é”®é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨")
        
        if config_issues:
            self.issues_found.extend([f"é…ç½®é—®é¢˜: {issue}" for issue in config_issues])
            return False
        return True
    
    async def test_real_exchange_api_functionality(self):
        """æµ‹è¯•çœŸå®äº¤æ˜“æ‰€APIåŠŸèƒ½"""
        logger.info("ğŸ” æ·±åº¦æ£€æŸ¥çœŸå®äº¤æ˜“æ‰€APIåŠŸèƒ½...")
        
        api_issues = []
        
        # æ›´ä¸¥æ ¼çš„äº¤æ˜“æ‰€APIæµ‹è¯•
        exchanges_detailed_test = [
            {
                'name': 'Binance',
                'ping_url': 'https://api.binance.com/api/v3/ping',
                'time_url': 'https://api.binance.com/api/v3/time',
                'info_url': 'https://api.binance.com/api/v3/exchangeInfo'
            },
            {
                'name': 'OKX', 
                'time_url': 'https://www.okx.com/api/v5/public/time',
                'instruments_url': 'https://www.okx.com/api/v5/public/instruments?instType=SPOT'
            }
        ]
        
        # è®¾ç½®ä»£ç†
        proxy = None
        for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'ALL_PROXY']:
            if os.environ.get(proxy_var):
                proxy = os.environ.get(proxy_var)
                break
        
        if not proxy:
            api_issues.append("æœªå‘ç°ä»£ç†é…ç½®ï¼Œå¯èƒ½æ— æ³•è®¿é—®å¤–éƒ¨API")
            logger.warning("âš ï¸ æœªå‘ç°ä»£ç†é…ç½®")
        
        successful_exchanges = 0
        
        try:
            timeout = aiohttp.ClientTimeout(total=20)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                
                for exchange in exchanges_detailed_test:
                    exchange_success = 0
                    exchange_total = 0
                    
                    for key, url in exchange.items():
                        if key == 'name':
                            continue
                        
                        exchange_total += 1
                        try:
                            logger.info(f"ğŸ”— æµ‹è¯• {exchange['name']} {key}...")
                            start_time = time.time()
                            
                            async with session.get(url, proxy=proxy) as response:
                                response_time = (time.time() - start_time) * 1000
                                
                                if response.status == 200:
                                    # å°è¯•è§£æJSONå“åº”
                                    try:
                                        data = await response.json()
                                        if data:
                                            exchange_success += 1
                                            logger.info(f"âœ… {exchange['name']} {key} æˆåŠŸ ({response_time:.0f}ms)")
                                        else:
                                            logger.warning(f"âš ï¸ {exchange['name']} {key} å“åº”ä¸ºç©º")
                                    except Exception as e:
                                        logger.warning(f"âš ï¸ {exchange['name']} {key} JSONè§£æå¤±è´¥: {e}")
                                else:
                                    logger.warning(f"âš ï¸ {exchange['name']} {key} HTTPçŠ¶æ€: {response.status}")
                                    
                        except Exception as e:
                            logger.warning(f"âš ï¸ {exchange['name']} {key} è¿æ¥å¤±è´¥: {e}")
                    
                    # è®¡ç®—äº¤æ˜“æ‰€æˆåŠŸç‡
                    exchange_success_rate = exchange_success / exchange_total if exchange_total > 0 else 0
                    if exchange_success_rate >= 0.5:  # è‡³å°‘50%æ¥å£æˆåŠŸ
                        successful_exchanges += 1
                        logger.info(f"âœ… {exchange['name']} æ•´ä½“å¯ç”¨ ({exchange_success_rate:.1%})")
                    else:
                        api_issues.append(f"{exchange['name']} APIåŠŸèƒ½ä¸å®Œæ•´ ({exchange_success_rate:.1%})")
                        logger.warning(f"âš ï¸ {exchange['name']} APIåŠŸèƒ½ä¸å®Œæ•´")
                        
        except Exception as e:
            api_issues.append(f"äº¤æ˜“æ‰€APIæµ‹è¯•æ¡†æ¶å¤±è´¥: {e}")
            logger.error(f"âŒ äº¤æ˜“æ‰€APIæµ‹è¯•æ¡†æ¶å¤±è´¥: {e}")
        
        # è¯„ä¼°ç»“æœ
        if successful_exchanges == 0:
            api_issues.append("æ‰€æœ‰äº¤æ˜“æ‰€APIå‡ä¸å¯ç”¨")
        elif successful_exchanges < len(exchanges_detailed_test):
            api_issues.append(f"ä»…æœ‰ {successful_exchanges}/{len(exchanges_detailed_test)} ä¸ªäº¤æ˜“æ‰€APIå¯ç”¨")
        
        if api_issues:
            self.issues_found.extend([f"APIé—®é¢˜: {issue}" for issue in api_issues])
            return successful_exchanges > 0  # è‡³å°‘ä¸€ä¸ªäº¤æ˜“æ‰€å¯ç”¨å°±ç®—éƒ¨åˆ†æˆåŠŸ
        
        return True
    
    async def test_dependency_completeness(self):
        """æµ‹è¯•ä¾èµ–å®Œæ•´æ€§"""
        logger.info("ğŸ” æ·±åº¦æ£€æŸ¥ä¾èµ–å®Œæ•´æ€§...")
        
        dependency_issues = []
        
        # æ£€æŸ¥requirements.txtä¸­çš„ä¾èµ–æ˜¯å¦éƒ½å·²å®‰è£…
        requirements_file = self.project_root / 'requirements.txt'
        if requirements_file.exists():
            try:
                with open(requirements_file, 'r', encoding='utf-8') as f:
                    requirements = f.read().strip().split('\n')
                
                missing_deps = []
                for req in requirements:
                    if req.strip() and not req.strip().startswith('#'):
                        # æå–åŒ…åï¼ˆå¿½ç•¥ç‰ˆæœ¬å·ï¼‰
                        package_name = req.split('==')[0].split('>=')[0].split('<=')[0].split('~=')[0].strip()
                        try:
                            __import__(package_name)
                        except ImportError:
                            try:
                                # å°è¯•ä¸€äº›å¸¸è§çš„åŒ…åæ˜ å°„
                                name_mappings = {
                                    'pyyaml': 'yaml',
                                    'pillow': 'PIL',
                                    'beautifulsoup4': 'bs4',
                                    'aiohttp-socks': 'aiohttp_socks',
                                    'python-socks': 'python_socks',
                                    'nats-py': 'nats',
                                    'clickhouse-driver': 'clickhouse_driver',
                                    'prometheus-client': 'prometheus_client',
                                    'python-dotenv': 'dotenv'
                                }
                                mapped_name = name_mappings.get(package_name.lower(), package_name)
                                __import__(mapped_name)
                            except ImportError:
                                missing_deps.append(package_name)
                
                if missing_deps:
                    dependency_issues.append(f"ç¼ºå°‘ä¾èµ–åŒ…: {missing_deps}")
                    logger.warning(f"âš ï¸ ç¼ºå°‘ä¾èµ–åŒ…: {missing_deps}")
                else:
                    logger.info("âœ… æ‰€æœ‰requirements.txtä¸­çš„ä¾èµ–éƒ½å·²å®‰è£…")
                    
            except Exception as e:
                dependency_issues.append(f"requirements.txtæ£€æŸ¥å¤±è´¥: {e}")
        else:
            dependency_issues.append("requirements.txtæ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥ç‰¹å®šçš„å…³é”®ä¾èµ–
        critical_deps = [
            'redis',
            'aiohttp', 
            'yaml',
            'psutil',
            'docker'
        ]
        
        missing_critical = []
        for dep in critical_deps:
            try:
                if dep == 'yaml':
                    import yaml
                else:
                    __import__(dep)
            except ImportError:
                missing_critical.append(dep)
        
        if missing_critical:
            dependency_issues.append(f"ç¼ºå°‘å…³é”®ä¾èµ–: {missing_critical}")
            logger.error(f"âŒ ç¼ºå°‘å…³é”®ä¾èµ–: {missing_critical}")
        else:
            logger.info("âœ… æ‰€æœ‰å…³é”®ä¾èµ–éƒ½å¯ç”¨")
        
        if dependency_issues:
            self.issues_found.extend([f"ä¾èµ–é—®é¢˜: {issue}" for issue in dependency_issues])
            return False
        return True
    
    async def test_docker_services_health(self):
        """æµ‹è¯•DockeræœåŠ¡å¥åº·çŠ¶æ€"""
        logger.info("ğŸ” æ·±åº¦æ£€æŸ¥DockeræœåŠ¡å¥åº·çŠ¶æ€...")
        
        docker_issues = []
        
        # æ£€æŸ¥Dockerå®¹å™¨çš„è¯¦ç»†å¥åº·çŠ¶æ€
        try:
            # æ£€æŸ¥ClickHouseå¥åº·çŠ¶æ€
            result = subprocess.run([
                'docker', 'exec', 'clickhouse-server', 
                'clickhouse-client', '--query', 'SELECT 1'
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and '1' in result.stdout:
                logger.info("âœ… ClickHouseæ•°æ®åº“æŸ¥è¯¢åŠŸèƒ½æ­£å¸¸")
            else:
                docker_issues.append(f"ClickHouseæŸ¥è¯¢åŠŸèƒ½å¼‚å¸¸: {result.stderr}")
                logger.error(f"âŒ ClickHouseæŸ¥è¯¢åŠŸèƒ½å¼‚å¸¸: {result.stderr}")
                
        except Exception as e:
            docker_issues.append(f"ClickHouseå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        
        # æ£€æŸ¥NATSå¥åº·çŠ¶æ€ï¼ˆç®€å•çš„è¿æ¥æµ‹è¯•ï¼‰
        try:
            import socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex(('localhost', 4222))
            sock.close()
            
            if result == 0:
                logger.info("âœ… NATSç«¯å£è¿æ¥æ­£å¸¸")
            else:
                docker_issues.append("NATSç«¯å£è¿æ¥å¤±è´¥")
        except Exception as e:
            docker_issues.append(f"NATSå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        
        if docker_issues:
            self.issues_found.extend([f"DockeræœåŠ¡é—®é¢˜: {issue}" for issue in docker_issues])
            return False
        return True

class DeepIssuesTestRunner:
    """æ·±åº¦é—®é¢˜æµ‹è¯•æ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.test_instance = DeepFunctionalIssuesTest()
        self.results = {}
    
    async def run_deep_functional_tests(self):
        """è¿è¡Œæ·±åº¦åŠŸèƒ½æµ‹è¯•"""
        logger.info("ğŸ”§ å¼€å§‹æ·±åº¦åŠŸèƒ½é—®é¢˜æ£€æŸ¥...")
        
        test_methods = [
            ('æ ¸å¿ƒç»„ä»¶åŠŸèƒ½', self.test_instance.test_core_components_actual_functionality),
            ('æœåŠ¡åŠŸèƒ½', self.test_instance.test_services_actual_functionality),
            ('é…ç½®æœ‰æ•ˆæ€§', self.test_instance.test_configuration_actual_validity),
            ('äº¤æ˜“æ‰€APIåŠŸèƒ½', self.test_instance.test_real_exchange_api_functionality),
            ('ä¾èµ–å®Œæ•´æ€§', self.test_instance.test_dependency_completeness),
            ('DockeræœåŠ¡å¥åº·', self.test_instance.test_docker_services_health)
        ]
        
        total_tests = len(test_methods)
        passed_tests = 0
        
        for test_name, test_method in test_methods:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ§ª æ·±åº¦æ£€æŸ¥: {test_name}")
            logger.info(f"{'='*60}")
            
            try:
                result = await test_method()
                self.results[test_name] = result
                
                if result:
                    passed_tests += 1
                    logger.info(f"âœ… {test_name} æ·±åº¦æ£€æŸ¥é€šè¿‡")
                else:
                    logger.warning(f"âš ï¸ {test_name} æ·±åº¦æ£€æŸ¥å‘ç°é—®é¢˜")
                    
            except Exception as e:
                logger.error(f"âŒ {test_name} æ·±åº¦æ£€æŸ¥å¼‚å¸¸: {e}")
                self.results[test_name] = False
        
        # æ·±åº¦æ£€æŸ¥æ€»ç»“
        deep_success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ¯ MarketPrism æ·±åº¦åŠŸèƒ½é—®é¢˜æ£€æŸ¥æ€»ç»“")
        logger.info(f"{'='*70}")
        logger.info(f"æ·±åº¦æ£€æŸ¥é¡¹ç›®: {total_tests}")
        logger.info(f"é€šè¿‡é¡¹ç›®: {passed_tests}")
        logger.info(f"å‘ç°é—®é¢˜é¡¹ç›®: {total_tests - passed_tests}")
        logger.info(f"åŠŸèƒ½å¥åº·åº¦: {deep_success_rate:.1f}%")
        
        # å±•ç¤ºå‘ç°çš„å…·ä½“é—®é¢˜
        if self.test_instance.issues_found:
            logger.info(f"\nğŸš¨ å‘ç°çš„å…·ä½“é—®é¢˜:")
            for i, issue in enumerate(self.test_instance.issues_found, 1):
                logger.info(f"   {i}. {issue}")
        
        # æ·±åº¦è¯„ä¼°
        if deep_success_rate == 100:
            logger.info("ğŸ‰ æ·±åº¦åŠŸèƒ½æ£€æŸ¥å®Œç¾é€šè¿‡ï¼Œç³»ç»Ÿå®Œå…¨å°±ç»ª")
        elif deep_success_rate >= 80:
            logger.info("ğŸ‘ æ·±åº¦åŠŸèƒ½æ£€æŸ¥è‰¯å¥½ï¼Œå°‘é‡é—®é¢˜éœ€è¦ä¿®å¤")
        elif deep_success_rate >= 60:
            logger.info("âš ï¸ æ·±åº¦åŠŸèƒ½æ£€æŸ¥å‘ç°é‡è¦é—®é¢˜ï¼Œéœ€è¦ä¿®å¤")
        else:
            logger.info("ğŸš¨ æ·±åº¦åŠŸèƒ½æ£€æŸ¥å‘ç°ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦å¤§é‡ä¿®å¤å·¥ä½œ")
        
        return self.results, self.test_instance.issues_found

# å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    async def main():
        runner = DeepIssuesTestRunner()
        results, issues = await runner.run_deep_functional_tests()
        return results, issues
    
    # è¿è¡Œæ·±åº¦åŠŸèƒ½æµ‹è¯•
    asyncio.run(main())