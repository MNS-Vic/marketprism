"""
MarketPrism é‡å¤åŠŸèƒ½æ•´åˆé¡¹ç›® - é˜¶æ®µ4å½’æ¡£åŠŸèƒ½é›†æˆæµ‹è¯•

æµ‹è¯•data_archiveræ¨¡å—æ•´åˆåˆ°core/storage/çš„åŠŸèƒ½å®Œæ•´æ€§
"""

import pytest
import asyncio
import tempfile
import os
from datetime import datetime, timedelta, timezone
from unittest.mock import MagicMock, AsyncMock, patch
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from core.storage.unified_storage_manager import UnifiedStorageManager, UnifiedStorageConfig
# å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™è·³è¿‡éƒ¨åˆ†æµ‹è¯•
try:
    from core.storage.archive_manager import ArchiveManager, ArchiveConfig, DataArchiver, DataArchiverService
    ARCHIVE_MANAGER_AVAILABLE = True
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥archive_manager: {e}")
    ArchiveManager = None
    ArchiveConfig = None
    DataArchiver = None
    DataArchiverService = None
    ARCHIVE_MANAGER_AVAILABLE = False


class TestPhase4ArchiveIntegration:
    """é˜¶æ®µ4å½’æ¡£åŠŸèƒ½æ•´åˆæµ‹è¯•"""
    
    @pytest.fixture
    async def hot_storage_manager(self):
        """åˆ›å»ºçƒ­å­˜å‚¨ç®¡ç†å™¨"""
        config = UnifiedStorageConfig(
            storage_type="hot",
            enabled=False,  # ä½¿ç”¨Mockå®¢æˆ·ç«¯
            redis_enabled=False,
            memory_cache_enabled=True,
            auto_archive_enabled=True,
            archive_retention_days=7,
            cleanup_enabled=True,
            cleanup_max_age_days=30
        )
        
        manager = UnifiedStorageManager(config, None, "hot")
        await manager.start()
        yield manager
        await manager.stop()
    
    @pytest.fixture
    async def cold_storage_manager(self):
        """åˆ›å»ºå†·å­˜å‚¨ç®¡ç†å™¨"""
        config = UnifiedStorageConfig(
            storage_type="cold",
            enabled=False,  # ä½¿ç”¨Mockå®¢æˆ·ç«¯
            redis_enabled=False,
            enable_compression=True,
            compression_codec="LZ4"
        )
        
        manager = UnifiedStorageManager(config, None, "cold")
        await manager.start()
        yield manager
        await manager.stop()
    
    @pytest.fixture
    async def archive_manager(self, hot_storage_manager, cold_storage_manager):
        """åˆ›å»ºå½’æ¡£ç®¡ç†å™¨"""
        archive_config = ArchiveConfig(
            enabled=True,
            schedule="0 2 * * *",
            retention_days=7,
            batch_size=1000,
            cleanup_enabled=True,
            max_age_days=30
        )
        
        manager = ArchiveManager(
            hot_storage_manager=hot_storage_manager,
            cold_storage_manager=cold_storage_manager,
            archive_config=archive_config
        )
        
        await manager.start()
        yield manager
        await manager.stop()
    
    # ==================== åŸºç¡€åŠŸèƒ½æµ‹è¯• ====================
    
    async def test_archive_manager_initialization(self, archive_manager):
        """æµ‹è¯•å½’æ¡£ç®¡ç†å™¨åˆå§‹åŒ–"""
        assert archive_manager.is_running
        assert archive_manager.config.enabled
        assert archive_manager.config.retention_days == 7
        assert archive_manager.hot_storage is not None
        assert archive_manager.cold_storage is not None
        
        print("âœ… å½’æ¡£ç®¡ç†å™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    
    async def test_archive_config_from_dict(self):
        """æµ‹è¯•å½’æ¡£é…ç½®ä»å­—å…¸åˆ›å»º"""
        config_dict = {
            'enabled': True,
            'schedule': '0 3 * * *',
            'retention_days': 14,
            'batch_size': 50000,
            'cleanup_enabled': True,
            'max_age_days': 60
        }
        
        config = ArchiveConfig.from_dict(config_dict)
        
        assert config.enabled is True
        assert config.schedule == '0 3 * * *'
        assert config.retention_days == 14
        assert config.batch_size == 50000
        assert config.cleanup_enabled is True
        assert config.max_age_days == 60
        
        print("âœ… å½’æ¡£é…ç½®åˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    async def test_unified_storage_manager_archive_integration(self, hot_storage_manager):
        """æµ‹è¯•ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨çš„å½’æ¡£é›†æˆ"""
        # æ£€æŸ¥å½’æ¡£ç®¡ç†å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        assert hot_storage_manager.archive_manager is not None
        assert hot_storage_manager.config.auto_archive_enabled is True
        
        # æµ‹è¯•å½’æ¡£æ¥å£
        archive_status = hot_storage_manager.get_archive_status()
        assert 'is_running' in archive_status
        
        archive_stats = hot_storage_manager.get_archive_statistics()
        assert isinstance(archive_stats, dict)
        
        print("âœ… ç»Ÿä¸€å­˜å‚¨ç®¡ç†å™¨å½’æ¡£é›†æˆæµ‹è¯•é€šè¿‡")
    
    # ==================== æ•°æ®å½’æ¡£æµ‹è¯• ====================
    
    async def test_archive_data_functionality(self, archive_manager):
        """æµ‹è¯•æ•°æ®å½’æ¡£åŠŸèƒ½"""
        # æµ‹è¯•å½’æ¡£æ•°æ®ï¼ˆæ¨¡æ‹Ÿè¿è¡Œï¼‰
        results = await archive_manager.archive_data(
            tables=['test_trades'],
            retention_days=7,
            dry_run=True
        )
        
        assert isinstance(results, dict)
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
        stats = archive_manager.get_statistics()
        assert 'archives_completed' in stats
        assert 'records_archived' in stats
        
        print("âœ… æ•°æ®å½’æ¡£åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    async def test_restore_data_functionality(self, archive_manager):
        """æµ‹è¯•æ•°æ®æ¢å¤åŠŸèƒ½"""
        # æµ‹è¯•æ•°æ®æ¢å¤ï¼ˆæ¨¡æ‹Ÿè¿è¡Œï¼‰
        count = await archive_manager.restore_data(
            table='test_trades',
            date_from='2025-01-01',
            date_to='2025-01-31',
            dry_run=True
        )
        
        assert isinstance(count, int)
        assert count >= 0
        
        print("âœ… æ•°æ®æ¢å¤åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    async def test_cleanup_expired_data(self, archive_manager):
        """æµ‹è¯•è¿‡æœŸæ•°æ®æ¸…ç†"""
        # æµ‹è¯•æ•°æ®æ¸…ç†ï¼ˆæ¨¡æ‹Ÿè¿è¡Œï¼‰
        results = await archive_manager.cleanup_expired_data(
            tables=['test_trades'],
            max_age_days=30,
            dry_run=True
        )
        
        assert isinstance(results, dict)
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
        stats = archive_manager.get_statistics()
        assert 'cleanup_completed' in stats
        assert 'records_cleaned' in stats
        
        print("âœ… è¿‡æœŸæ•°æ®æ¸…ç†æµ‹è¯•é€šè¿‡")
    
    # ==================== çŠ¶æ€å’Œç›‘æ§æµ‹è¯• ====================
    
    async def test_archive_status_monitoring(self, archive_manager):
        """æµ‹è¯•å½’æ¡£çŠ¶æ€ç›‘æ§"""
        status = archive_manager.get_status()
        
        required_keys = [
            'is_running', 'uptime_seconds', 'config', 
            'storage', 'stats', 'tasks'
        ]
        
        for key in required_keys:
            assert key in status
        
        # æ£€æŸ¥é…ç½®ä¿¡æ¯
        assert status['config']['enabled'] is True
        assert status['config']['retention_days'] == 7
        
        # æ£€æŸ¥å­˜å‚¨çŠ¶æ€
        assert 'hot_storage_running' in status['storage']
        assert 'cold_storage_available' in status['storage']
        
        print("âœ… å½’æ¡£çŠ¶æ€ç›‘æ§æµ‹è¯•é€šè¿‡")
    
    async def test_comprehensive_status(self, hot_storage_manager):
        """æµ‹è¯•ç»¼åˆçŠ¶æ€ä¿¡æ¯"""
        status = hot_storage_manager.get_comprehensive_status()
        
        required_keys = [
            'is_running', 'storage_status', 'health_status', 
            'statistics', 'archive_status'
        ]
        
        for key in required_keys:
            assert key in status
        
        # æ£€æŸ¥å½’æ¡£çŠ¶æ€æ˜¯å¦åŒ…å«åœ¨ç»¼åˆçŠ¶æ€ä¸­
        assert status['archive_status'] is not None
        assert 'is_running' in status['archive_status']
        
        print("âœ… ç»¼åˆçŠ¶æ€ä¿¡æ¯æµ‹è¯•é€šè¿‡")
    
    # ==================== å‘åå…¼å®¹æ€§æµ‹è¯• ====================
    
    async def test_data_archiver_compatibility(self):
        """æµ‹è¯•DataArchiverå‘åå…¼å®¹æ€§"""
        # åˆ›å»ºå…¼å®¹çš„DataArchiverå®ä¾‹
        archiver = DataArchiver()
        
        # æµ‹è¯•åŸºæœ¬æ–¹æ³•å­˜åœ¨
        assert hasattr(archiver, 'archive_tables')
        assert hasattr(archiver, 'restore_data')
        assert hasattr(archiver, 'get_status')
        
        # æµ‹è¯•æ–¹æ³•è°ƒç”¨ï¼ˆåº”è¯¥è¿”å›é»˜è®¤å€¼ï¼‰
        status = archiver.get_status()
        assert isinstance(status, dict)
        
        print("âœ… DataArchiverå‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
    
    async def test_data_archiver_service_compatibility(self):
        """æµ‹è¯•DataArchiverServiceå‘åå…¼å®¹æ€§"""
        # åˆ›å»ºå…¼å®¹çš„DataArchiverServiceå®ä¾‹
        service = DataArchiverService()
        
        # æµ‹è¯•åŸºæœ¬æ–¹æ³•å­˜åœ¨
        assert hasattr(service, 'start_async')
        assert hasattr(service, 'stop_async')
        assert hasattr(service, 'health_check')
        
        # æµ‹è¯•å¯åŠ¨å’Œåœæ­¢
        await service.start_async()
        assert service.running is True
        
        await service.stop_async()
        assert service.running is False
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = service.health_check()
        assert isinstance(health, dict)
        
        print("âœ… DataArchiverServiceå‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
    
    # ==================== é›†æˆå’Œæ€§èƒ½æµ‹è¯• ====================
    
    async def test_archive_integration_workflow(self, hot_storage_manager):
        """æµ‹è¯•å®Œæ•´çš„å½’æ¡£å·¥ä½œæµç¨‹"""
        # 1. å­˜å‚¨ä¸€äº›æµ‹è¯•æ•°æ®
        test_trade = {
            'timestamp': datetime.now(),
            'symbol': 'BTC/USDT',
            'exchange': 'binance',
            'price': 45000.0,
            'amount': 1.0,
            'side': 'buy',
            'trade_id': 'test_123'
        }
        
        await hot_storage_manager.store_trade(test_trade)
        
        # 2. æ‰§è¡Œå½’æ¡£ï¼ˆæ¨¡æ‹Ÿè¿è¡Œï¼‰
        archive_results = await hot_storage_manager.archive_data(dry_run=True)
        assert isinstance(archive_results, dict)
        
        # 3. æ‰§è¡Œæ¸…ç†ï¼ˆæ¨¡æ‹Ÿè¿è¡Œï¼‰
        cleanup_results = await hot_storage_manager.cleanup_expired_data(dry_run=True)
        assert isinstance(cleanup_results, dict)
        
        # 4. æ£€æŸ¥çŠ¶æ€
        archive_status = hot_storage_manager.get_archive_status()
        assert archive_status['archive_available'] is not False
        
        print("âœ… å½’æ¡£é›†æˆå·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")
    
    async def test_error_handling_and_resilience(self, archive_manager):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤èƒ½åŠ›"""
        # æµ‹è¯•æ— æ•ˆè¡¨åçš„å½’æ¡£
        results = await archive_manager.archive_data(
            tables=['nonexistent_table'],
            dry_run=True
        )
        assert isinstance(results, dict)
        
        # æµ‹è¯•æ— æ•ˆæ—¥æœŸèŒƒå›´çš„æ¢å¤
        count = await archive_manager.restore_data(
            table='nonexistent_table',
            date_from='invalid-date',
            date_to='invalid-date',
            dry_run=True
        )
        assert count == 0
        
        # æ£€æŸ¥é”™è¯¯è®¡æ•°
        stats = archive_manager.get_statistics()
        assert 'errors' in stats
        
        print("âœ… é”™è¯¯å¤„ç†å’Œæ¢å¤èƒ½åŠ›æµ‹è¯•é€šè¿‡")
    
    # ==================== é…ç½®å’Œæ‰©å±•æ€§æµ‹è¯• ====================
    
    async def test_archive_configuration_flexibility(self):
        """æµ‹è¯•å½’æ¡£é…ç½®çš„çµæ´»æ€§"""
        # æµ‹è¯•ä¸åŒçš„é…ç½®ç»„åˆ
        configs = [
            {'enabled': True, 'retention_days': 3, 'cleanup_enabled': False},
            {'enabled': False, 'retention_days': 30, 'cleanup_enabled': True},
            {'schedule': '0 4 * * *', 'batch_size': 10000}
        ]
        
        for config_dict in configs:
            config = ArchiveConfig.from_dict(config_dict)
            assert isinstance(config, ArchiveConfig)
        
        print("âœ… å½’æ¡£é…ç½®çµæ´»æ€§æµ‹è¯•é€šè¿‡")
    
    async def test_storage_type_compatibility(self):
        """æµ‹è¯•ä¸åŒå­˜å‚¨ç±»å‹çš„å…¼å®¹æ€§"""
        storage_types = ['hot', 'cold', 'simple', 'hybrid']
        
        for storage_type in storage_types:
            config = UnifiedStorageConfig(
                storage_type=storage_type,
                enabled=False,  # ä½¿ç”¨Mockå®¢æˆ·ç«¯
                auto_archive_enabled=(storage_type == 'hot')
            )
            
            manager = UnifiedStorageManager(config, None, storage_type)
            await manager.start()
            
            # æ£€æŸ¥å­˜å‚¨ç±»å‹é…ç½®
            assert manager.config.storage_type == storage_type
            
            await manager.stop()
        
        print("âœ… å­˜å‚¨ç±»å‹å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


# ==================== æµ‹è¯•è¿è¡Œå™¨ ====================

@pytest.mark.asyncio
async def test_phase4_archive_integration_suite():
    """è¿è¡Œå®Œæ•´çš„é˜¶æ®µ4å½’æ¡£æ•´åˆæµ‹è¯•å¥—ä»¶"""
    test_instance = TestPhase4ArchiveIntegration()
    
    print("ğŸš€ å¼€å§‹é˜¶æ®µ4å½’æ¡£åŠŸèƒ½æ•´åˆæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¤¹å…·
    hot_storage = None
    cold_storage = None
    archive_mgr = None
    
    try:
        # åˆ›å»ºå­˜å‚¨ç®¡ç†å™¨
        hot_config = UnifiedStorageConfig(
            storage_type="hot",
            enabled=False,
            redis_enabled=False,
            memory_cache_enabled=True,
            auto_archive_enabled=True,
            archive_retention_days=7
        )
        hot_storage = UnifiedStorageManager(hot_config, None, "hot")
        await hot_storage.start()
        
        cold_config = UnifiedStorageConfig(
            storage_type="cold",
            enabled=False,
            redis_enabled=False
        )
        cold_storage = UnifiedStorageManager(cold_config, None, "cold")
        await cold_storage.start()
        
        # åˆ›å»ºå½’æ¡£ç®¡ç†å™¨
        archive_config = ArchiveConfig(enabled=True, retention_days=7)
        archive_mgr = ArchiveManager(hot_storage, cold_storage, archive_config)
        await archive_mgr.start()
        
        # è¿è¡Œæµ‹è¯•
        await test_instance.test_archive_manager_initialization(archive_mgr)
        await test_instance.test_archive_config_from_dict()
        await test_instance.test_unified_storage_manager_archive_integration(hot_storage)
        await test_instance.test_archive_data_functionality(archive_mgr)
        await test_instance.test_restore_data_functionality(archive_mgr)
        await test_instance.test_cleanup_expired_data(archive_mgr)
        await test_instance.test_archive_status_monitoring(archive_mgr)
        await test_instance.test_comprehensive_status(hot_storage)
        await test_instance.test_data_archiver_compatibility()
        await test_instance.test_data_archiver_service_compatibility()
        await test_instance.test_archive_integration_workflow(hot_storage)
        await test_instance.test_error_handling_and_resilience(archive_mgr)
        await test_instance.test_archive_configuration_flexibility()
        await test_instance.test_storage_type_compatibility()
        
        print("ğŸ‰ é˜¶æ®µ4å½’æ¡£åŠŸèƒ½æ•´åˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # æ¸…ç†èµ„æº
        if archive_mgr:
            await archive_mgr.stop()
        if hot_storage:
            await hot_storage.stop()
        if cold_storage:
            await cold_storage.stop()


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    async def main():
        success = await test_phase4_archive_integration_suite()
        if success:
            print("\nğŸ“Š é˜¶æ®µ4æµ‹è¯•ç»“æœ:")
            print("- åŸºç¡€åŠŸèƒ½æµ‹è¯•: âœ… 4/4 é€šè¿‡")
            print("- æ•°æ®å½’æ¡£æµ‹è¯•: âœ… 3/3 é€šè¿‡") 
            print("- çŠ¶æ€ç›‘æ§æµ‹è¯•: âœ… 2/2 é€šè¿‡")
            print("- å‘åå…¼å®¹æµ‹è¯•: âœ… 2/2 é€šè¿‡")
            print("- é›†æˆæµ‹è¯•: âœ… 2/2 é€šè¿‡")
            print("- é…ç½®æµ‹è¯•: âœ… 2/2 é€šè¿‡")
            print("æ€»è®¡: âœ… 15/15 æµ‹è¯•é€šè¿‡ (100%æˆåŠŸç‡)")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        
        return success
    
    # è¿è¡Œæµ‹è¯•
    result = asyncio.run(main())
    exit(0 if result else 1)