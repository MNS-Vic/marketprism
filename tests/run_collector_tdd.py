#!/usr/bin/env python3
"""
MarketPrism Collector TDD æµ‹è¯•æ‰§è¡Œè„šæœ¬

æŒ‰ç…§TDDè®¡åˆ’åˆ†é˜¶æ®µæ‰§è¡Œæµ‹è¯•ï¼Œç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
"""

import os
import sys
import subprocess
import time
import json
from datetime import datetime
from pathlib import Path
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class TDDTestRunner:
    """TDDæµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.project_root = project_root
        self.test_results = {}
        self.start_time = datetime.now()
        
    def run_phase(self, phase_name: str, test_patterns: list, description: str = ""):
        """è¿è¡Œæµ‹è¯•é˜¶æ®µ"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æ‰§è¡Œæµ‹è¯•é˜¶æ®µ: {phase_name}")
        print(f"ğŸ“ æè¿°: {description}")
        print(f"{'='*60}")
        
        phase_start = time.time()
        phase_results = {
            'description': description,
            'start_time': datetime.now().isoformat(),
            'test_files': {},
            'summary': {}
        }
        
        total_tests = 0
        total_passed = 0
        total_failed = 0
        total_skipped = 0
        
        for pattern in test_patterns:
            print(f"\nğŸ“ è¿è¡Œæµ‹è¯•æ¨¡å¼: {pattern}")
            
            # æ„å»ºpytestå‘½ä»¤
            cmd = [
                sys.executable, "-m", "pytest",
                pattern,
                "-v",
                "--tb=short",
                "--json-report",
                f"--json-report-file={self.project_root}/tests/reports/{phase_name}_{pattern.replace('/', '_').replace('*', 'all')}.json",
                "--html={}/tests/reports/{}_report.html".format(self.project_root, phase_name),
                "--self-contained-html",
                "--cov=services.python_collector.src.marketprism_collector",
                f"--cov-report=html:{self.project_root}/tests/reports/{phase_name}_coverage",
                "--cov-report=json",
                "--timeout=120"
            ]
            
            try:
                result = subprocess.run(
                    cmd,
                    cwd=self.project_root,
                    capture_output=True,
                    text=True,
                    timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
                )
                
                # è§£æç»“æœ
                if result.returncode == 0:
                    status = "âœ… PASSED"
                    print(f"   {status}")
                elif result.returncode == 5:  # pytestæ²¡æœ‰æ‰¾åˆ°æµ‹è¯•
                    status = "âš ï¸ NO TESTS"
                    print(f"   {status} - æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
                else:
                    status = "âŒ FAILED"
                    print(f"   {status}")
                    print(f"   é”™è¯¯è¾“å‡º: {result.stderr[:500]}")
                
                # å°è¯•è¯»å–JSONæŠ¥å‘Š
                json_report_path = f"{self.project_root}/tests/reports/{phase_name}_{pattern.replace('/', '_').replace('*', 'all')}.json"
                test_stats = self._parse_json_report(json_report_path)
                
                phase_results['test_files'][pattern] = {
                    'status': status,
                    'return_code': result.returncode,
                    'stdout': result.stdout[-1000:] if result.stdout else "",
                    'stderr': result.stderr[-500:] if result.stderr else "",
                    'stats': test_stats
                }
                
                # ç´¯è®¡ç»Ÿè®¡
                if test_stats:
                    total_tests += test_stats.get('total', 0)
                    total_passed += test_stats.get('passed', 0)
                    total_failed += test_stats.get('failed', 0)
                    total_skipped += test_stats.get('skipped', 0)
                
            except subprocess.TimeoutExpired:
                print(f"   â° TIMEOUT - æµ‹è¯•è¶…æ—¶")
                phase_results['test_files'][pattern] = {
                    'status': 'TIMEOUT',
                    'return_code': -1,
                    'error': 'Test execution timeout'
                }
            except Exception as e:
                print(f"   ğŸ’¥ ERROR - {e}")
                phase_results['test_files'][pattern] = {
                    'status': 'ERROR',
                    'return_code': -1,
                    'error': str(e)
                }
        
        phase_end = time.time()
        phase_duration = phase_end - phase_start
        
        # é˜¶æ®µæ€»ç»“
        phase_results['summary'] = {
            'total_tests': total_tests,
            'passed': total_passed,
            'failed': total_failed,
            'skipped': total_skipped,
            'duration_seconds': phase_duration,
            'success_rate': (total_passed / total_tests * 100) if total_tests > 0 else 0
        }
        
        phase_results['end_time'] = datetime.now().isoformat()
        
        # æ˜¾ç¤ºé˜¶æ®µæ€»ç»“
        print(f"\nğŸ“Š é˜¶æ®µ {phase_name} æ€»ç»“:")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   é€šè¿‡: {total_passed}")
        print(f"   å¤±è´¥: {total_failed}")
        print(f"   è·³è¿‡: {total_skipped}")
        print(f"   æˆåŠŸç‡: {phase_results['summary']['success_rate']:.1f}%")
        print(f"   è€—æ—¶: {phase_duration:.1f}ç§’")
        
        self.test_results[phase_name] = phase_results
        return phase_results
    
    def _parse_json_report(self, json_path: str) -> dict:
        """è§£æpytest JSONæŠ¥å‘Š"""
        try:
            if os.path.exists(json_path):
                with open(json_path, 'r') as f:
                    data = json.load(f)
                
                summary = data.get('summary', {})
                return {
                    'total': summary.get('total', 0),
                    'passed': summary.get('passed', 0),
                    'failed': summary.get('failed', 0),
                    'skipped': summary.get('skipped', 0),
                    'error': summary.get('error', 0)
                }
        except Exception as e:
            print(f"   è§£æJSONæŠ¥å‘Šå¤±è´¥: {e}")
        
        return {}
    
    def run_all_phases(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•é˜¶æ®µ"""
        print(f"ğŸš€ å¼€å§‹ MarketPrism Collector TDD æµ‹è¯•")
        print(f"â° å¼€å§‹æ—¶é—´: {self.start_time}")
        
        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        os.makedirs(f"{self.project_root}/tests/reports", exist_ok=True)
        
        # Phase 1: å•å…ƒæµ‹è¯•
        self.run_phase(
            "phase1_unit",
            [
                "tests/unit/collector/test_core_integration.py",
                "tests/unit/collector/*.py"
            ],
            "éªŒè¯å„ä¸ªç»„ä»¶çš„ç‹¬ç«‹åŠŸèƒ½å’ŒCoreæ¨¡å—é›†æˆ"
        )
        
        # Phase 2: é›†æˆæµ‹è¯•
        self.run_phase(
            "phase2_integration", 
            [
                "tests/integration/collector/test_exchange_adapters.py",
                "tests/integration/collector/*.py"
            ],
            "éªŒè¯ç»„ä»¶é—´çš„äº¤äº’å’Œäº¤æ˜“æ‰€è¿æ¥"
        )
        
        # Phase 3: ç«¯åˆ°ç«¯æµ‹è¯•
        self.run_phase(
            "phase3_e2e",
            [
                "tests/e2e/collector/test_real_data_collection.py"
            ],
            "éªŒè¯å®Œæ•´çš„æ•°æ®æ”¶é›†æµç¨‹"
        )
        
        # Phase 4: æ€§èƒ½å’Œç¨³å®šæ€§æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
        if self._should_run_performance_tests():
            self.run_phase(
                "phase4_performance",
                [
                    "tests/performance/collector/*.py"
                ],
                "éªŒè¯ç³»ç»Ÿåœ¨é«˜è´Ÿè½½ä¸‹çš„è¡¨ç°"
            )
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.generate_final_report()
    
    def _should_run_performance_tests(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        # å¦‚æœå‰é¢çš„æµ‹è¯•é€šè¿‡ç‡ä½äº80%ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•
        overall_success_rate = self._calculate_overall_success_rate()
        return overall_success_rate >= 80.0
    
    def _calculate_overall_success_rate(self) -> float:
        """è®¡ç®—æ•´ä½“æˆåŠŸç‡"""
        total_tests = 0
        total_passed = 0
        
        for phase_result in self.test_results.values():
            summary = phase_result.get('summary', {})
            total_tests += summary.get('total_tests', 0)
            total_passed += summary.get('passed', 0)
        
        return (total_passed / total_tests * 100) if total_tests > 0 else 0
    
    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
        end_time = datetime.now()
        total_duration = (end_time - self.start_time).total_seconds()
        
        overall_success_rate = self._calculate_overall_success_rate()
        
        final_report = {
            'test_run_info': {
                'start_time': self.start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'total_duration_seconds': total_duration,
                'overall_success_rate': overall_success_rate
            },
            'phases': self.test_results,
            'recommendations': self._generate_recommendations()
        }
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = f"{self.project_root}/tests/reports/tdd_final_report.json"
        with open(report_path, 'w') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        # æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“
        print(f"\n{'='*80}")
        print(f"ğŸ¯ MarketPrism Collector TDD æµ‹è¯•å®Œæˆ")
        print(f"{'='*80}")
        print(f"â° æ€»è€—æ—¶: {total_duration:.1f}ç§’")
        print(f"ğŸ“Š æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%")
        
        # æ˜¾ç¤ºå„é˜¶æ®µç»“æœ
        for phase_name, phase_result in self.test_results.items():
            summary = phase_result['summary']
            status_emoji = "âœ…" if summary['success_rate'] >= 80 else "âš ï¸" if summary['success_rate'] >= 60 else "âŒ"
            print(f"{status_emoji} {phase_name}: {summary['success_rate']:.1f}% ({summary['passed']}/{summary['total_tests']})")
        
        # æ˜¾ç¤ºå»ºè®®
        recommendations = final_report['recommendations']
        if recommendations:
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        
        # è¿”å›æˆåŠŸçŠ¶æ€
        return overall_success_rate >= 80.0
    
    def _generate_recommendations(self) -> list:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        overall_success_rate = self._calculate_overall_success_rate()
        
        if overall_success_rate < 60:
            recommendations.append("æ•´ä½“æµ‹è¯•é€šè¿‡ç‡è¿‡ä½ï¼Œéœ€è¦é‡ç‚¹æ£€æŸ¥æ ¸å¿ƒåŠŸèƒ½å®ç°")
        elif overall_success_rate < 80:
            recommendations.append("éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®ä¼˜å…ˆä¿®å¤å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹")
        
        # åˆ†æå„é˜¶æ®µ
        for phase_name, phase_result in self.test_results.items():
            summary = phase_result['summary']
            if summary['success_rate'] < 60:
                recommendations.append(f"{phase_name} é˜¶æ®µé—®é¢˜ä¸¥é‡ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨")
            elif summary['failed'] > 0:
                recommendations.append(f"{phase_name} é˜¶æ®µæœ‰ {summary['failed']} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        
        # æ£€æŸ¥è·³è¿‡çš„æµ‹è¯•
        total_skipped = sum(phase['summary']['skipped'] for phase in self.test_results.values())
        if total_skipped > 10:
            recommendations.append(f"æœ‰ {total_skipped} ä¸ªæµ‹è¯•è¢«è·³è¿‡ï¼Œå¯èƒ½éœ€è¦è§£å†³ç¯å¢ƒä¾èµ–é—®é¢˜")
        
        return recommendations


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MarketPrism Collector TDD æµ‹è¯•æ‰§è¡Œå™¨")
    parser.add_argument("--phase", choices=["unit", "integration", "e2e", "performance", "all"], 
                       default="all", help="æŒ‡å®šè¦è¿è¡Œçš„æµ‹è¯•é˜¶æ®µ")
    parser.add_argument("--fast", action="store_true", help="å¿«é€Ÿæ¨¡å¼ï¼Œè·³è¿‡è€—æ—¶çš„æµ‹è¯•")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    runner = TDDTestRunner()
    
    if args.phase == "all":
        success = runner.run_all_phases()
    else:
        # è¿è¡ŒæŒ‡å®šé˜¶æ®µ
        phase_map = {
            "unit": ("phase1_unit", ["tests/unit/collector/*.py"], "å•å…ƒæµ‹è¯•"),
            "integration": ("phase2_integration", ["tests/integration/collector/*.py"], "é›†æˆæµ‹è¯•"),
            "e2e": ("phase3_e2e", ["tests/e2e/collector/*.py"], "ç«¯åˆ°ç«¯æµ‹è¯•"),
            "performance": ("phase4_performance", ["tests/performance/collector/*.py"], "æ€§èƒ½æµ‹è¯•")
        }
        
        if args.phase in phase_map:
            phase_name, patterns, description = phase_map[args.phase]
            result = runner.run_phase(phase_name, patterns, description)
            success = result['summary']['success_rate'] >= 80.0
        else:
            print(f"æœªçŸ¥çš„æµ‹è¯•é˜¶æ®µ: {args.phase}")
            return 1
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())