#!/usr/bin/env python3
"""
MarketPrism ä»£ç è´¨é‡æ£€æµ‹å™¨
æ·±åº¦æ£€æµ‹å†—ä½™ã€é‡å¤ã€å†²çªçš„ä»£ç å’Œé…ç½®
"""

from datetime import datetime, timezone
import os
import sys
import ast
import json
import yaml
import hashlib
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict, Counter
import re
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CodeQualityChecker:
    """ä»£ç è´¨é‡æ£€æµ‹å™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.results = {
            'unused_imports': {},
            'duplicate_functions': {},
            'redundant_configs': {},
            'unused_files': [],
            'port_conflicts': {},
            'duplicate_dependencies': {},
            'dead_code': {},
            'complexity_hotspots': {},
            'naming_inconsistencies': {}
        }
    
    def run_all_checks(self) -> Dict:
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        logger.info("ğŸ” å¼€å§‹ä»£ç è´¨é‡æ£€æµ‹...")
        
        # 1. æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥
        self.check_unused_imports()
        
        # 2. æ£€æŸ¥é‡å¤å‡½æ•°
        self.check_duplicate_functions()
        
        # 3. æ£€æŸ¥å†—ä½™é…ç½®
        self.check_redundant_configs()
        
        # 4. æ£€æŸ¥æœªä½¿ç”¨çš„æ–‡ä»¶
        self.check_unused_files()
        
        # 5. æ£€æŸ¥ç«¯å£å†²çª
        self.check_port_conflicts()
        
        # 6. æ£€æŸ¥é‡å¤ä¾èµ–
        self.check_duplicate_dependencies()
        
        # 7. æ£€æŸ¥æ­»ä»£ç 
        self.check_dead_code()
        
        # 8. æ£€æŸ¥å¤æ‚åº¦çƒ­ç‚¹
        self.check_complexity_hotspots()
        
        # 9. æ£€æŸ¥å‘½åä¸ä¸€è‡´
        self.check_naming_inconsistencies()
        
        return self.results
    
    def check_unused_imports(self):
        """æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥"""
        logger.info("ğŸ” æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥...")
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æAST
                tree = ast.parse(content)
                
                # æ”¶é›†æ‰€æœ‰å¯¼å…¥
                imports = []
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.append(alias.name.split('.')[0])
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            imports.append(node.module.split('.')[0])
                        for alias in node.names:
                            imports.append(alias.name)
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨
                unused = []
                for imp in imports:
                    if imp not in content or content.count(imp) == 1:  # åªå‡ºç°åœ¨importè¡Œ
                        unused.append(imp)
                
                if unused:
                    self.results['unused_imports'][str(py_file.relative_to(self.project_root))] = unused
                    
            except Exception as e:
                logger.warning(f"æ£€æŸ¥å¯¼å…¥æ—¶å‡ºé”™ {py_file}: {e}")
    
    def check_duplicate_functions(self):
        """æ£€æŸ¥é‡å¤å‡½æ•°"""
        logger.info("ğŸ” æ£€æŸ¥é‡å¤å‡½æ•°...")
        
        function_hashes = defaultdict(list)
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # è·å–å‡½æ•°ä½“çš„å“ˆå¸Œå€¼
                        func_body = ast.dump(node.body[0] if node.body else ast.Pass())
                        func_hash = hashlib.md5(func_body.encode()).hexdigest()
                        
                        function_hashes[func_hash].append({
                            'file': str(py_file.relative_to(self.project_root)),
                            'function': node.name,
                            'line': node.lineno
                        })
                        
            except Exception as e:
                logger.warning(f"æ£€æŸ¥å‡½æ•°æ—¶å‡ºé”™ {py_file}: {e}")
        
        # æ‰¾å‡ºé‡å¤çš„å‡½æ•°
        for func_hash, functions in function_hashes.items():
            if len(functions) > 1:
                self.results['duplicate_functions'][func_hash] = functions
    
    def check_redundant_configs(self):
        """æ£€æŸ¥å†—ä½™é…ç½®"""
        logger.info("ğŸ” æ£€æŸ¥å†—ä½™é…ç½®...")
        
        config_files = []
        config_files.extend(self.project_root.rglob("*.yaml"))
        config_files.extend(self.project_root.rglob("*.yml"))
        config_files.extend(self.project_root.rglob("*.json"))
        config_files.extend(self.project_root.rglob("*.toml"))
        
        config_contents = {}
        
        for config_file in config_files:
            if self._should_skip_file(config_file):
                continue
            
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    if config_file.suffix in ['.yaml', '.yml']:
                        content = yaml.safe_load(f)
                    elif config_file.suffix == '.json':
                        content = json.load(f)
                    else:
                        content = f.read()
                
                config_contents[str(config_file.relative_to(self.project_root))] = content
                
            except Exception as e:
                logger.warning(f"è¯»å–é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ {config_file}: {e}")
        
        # æ£€æŸ¥é‡å¤çš„é…ç½®å†…å®¹
        content_hashes = defaultdict(list)
        for file_path, content in config_contents.items():
            content_hash = hashlib.md5(str(content).encode()).hexdigest()
            content_hashes[content_hash].append(file_path)
        
        for content_hash, files in content_hashes.items():
            if len(files) > 1:
                self.results['redundant_configs'][content_hash] = files
    
    def check_unused_files(self):
        """æ£€æŸ¥æœªä½¿ç”¨çš„æ–‡ä»¶"""
        logger.info("ğŸ” æ£€æŸ¥æœªä½¿ç”¨çš„æ–‡ä»¶...")
        
        # å¯èƒ½æœªä½¿ç”¨çš„æ–‡ä»¶ç±»å‹
        suspicious_patterns = [
            '*.pyc', '*.pyo', '*.pyd',
            '*.log', '*.tmp', '*.bak', '*.old',
            '*~', '*.orig', '*.rej',
            '.DS_Store', 'Thumbs.db'
        ]
        
        for pattern in suspicious_patterns:
            for file_path in self.project_root.rglob(pattern):
                if file_path.is_file():
                    self.results['unused_files'].append(str(file_path.relative_to(self.project_root)))
        
        # æ£€æŸ¥å¯èƒ½çš„å­¤å„¿æ–‡ä»¶
        python_files = set()
        imported_modules = set()
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            python_files.add(str(py_file.relative_to(self.project_root)))
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾æœ¬åœ°å¯¼å…¥
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.ImportFrom):
                        if node.module and node.module.startswith('.'):
                            # ç›¸å¯¹å¯¼å…¥
                            module_path = self._resolve_relative_import(py_file, node.module)
                            if module_path:
                                imported_modules.add(module_path)
                        elif node.module and not node.module.startswith(('sys', 'os', 'json', 'yaml', 'asyncio')):
                            # å¯èƒ½çš„æœ¬åœ°å¯¼å…¥
                            module_file = f"{node.module.replace('.', '/')}.py"
                            if (self.project_root / module_file).exists():
                                imported_modules.add(module_file)
                                
            except Exception as e:
                logger.warning(f"åˆ†æå¯¼å…¥æ—¶å‡ºé”™ {py_file}: {e}")
        
        # æ‰¾å‡ºå¯èƒ½æœªè¢«å¯¼å…¥çš„Pythonæ–‡ä»¶
        orphan_files = python_files - imported_modules
        for orphan in orphan_files:
            if not any(x in orphan for x in ['__main__', 'main.py', 'start-', 'test_']):
                self.results['unused_files'].append(f"å¯èƒ½å­¤å„¿æ–‡ä»¶: {orphan}")
    
    def check_port_conflicts(self):
        """æ£€æŸ¥ç«¯å£å†²çª"""
        logger.info("ğŸ” æ£€æŸ¥ç«¯å£å†²çª...")
        
        port_usage = defaultdict(list)
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„ç«¯å£
        for config_file in self.project_root.rglob("*.yaml"):
            if self._should_skip_file(config_file):
                continue
            
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    content = yaml.safe_load(f)
                
                ports = self._extract_ports_from_config(content)
                for port in ports:
                    port_usage[port].append(str(config_file.relative_to(self.project_root)))
                    
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ç«¯å£é…ç½®æ—¶å‡ºé”™ {config_file}: {e}")
        
        # æ£€æŸ¥Pythonä»£ç ä¸­çš„ç«¯å£
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾ç«¯å£å·
                port_pattern = r'(?:port\s*[=:]\s*|:)(\d{4,5})'
                ports = re.findall(port_pattern, content, re.IGNORECASE)
                
                for port in ports:
                    if 1000 <= int(port) <= 65535:
                        port_usage[int(port)].append(str(py_file.relative_to(self.project_root)))
                        
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ç«¯å£ä½¿ç”¨æ—¶å‡ºé”™ {py_file}: {e}")
        
        # æ‰¾å‡ºå†²çªçš„ç«¯å£
        for port, files in port_usage.items():
            if len(files) > 1:
                self.results['port_conflicts'][port] = files
    
    def check_duplicate_dependencies(self):
        """æ£€æŸ¥é‡å¤ä¾èµ–"""
        logger.info("ğŸ” æ£€æŸ¥é‡å¤ä¾èµ–...")
        
        requirement_files = []
        requirement_files.extend(self.project_root.rglob("requirements*.txt"))
        requirement_files.extend(self.project_root.rglob("setup.py"))
        requirement_files.extend(self.project_root.rglob("pyproject.toml"))
        
        dependencies = defaultdict(list)
        
        for req_file in requirement_files:
            try:
                with open(req_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if req_file.name.startswith('requirements'):
                    # requirements.txtæ ¼å¼
                    for line in content.split('\n'):
                        line = line.strip()
                        if line and not line.startswith('#'):
                            pkg_name = line.split('=')[0].split('>')[0].split('<')[0].strip()
                            dependencies[pkg_name].append(str(req_file.relative_to(self.project_root)))
                            
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ä¾èµ–æ—¶å‡ºé”™ {req_file}: {e}")
        
        # æ‰¾å‡ºé‡å¤çš„ä¾èµ–
        for pkg, files in dependencies.items():
            if len(files) > 1:
                self.results['duplicate_dependencies'][pkg] = files
    
    def check_dead_code(self):
        """æ£€æŸ¥æ­»ä»£ç """
        logger.info("ğŸ” æ£€æŸ¥æ­»ä»£ç ...")
        
        defined_functions = set()
        called_functions = set()
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                # æ”¶é›†å®šä¹‰çš„å‡½æ•°
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        defined_functions.add(node.name)
                    elif isinstance(node, ast.Call):
                        if isinstance(node.func, ast.Name):
                            called_functions.add(node.func.id)
                        elif isinstance(node.func, ast.Attribute):
                            called_functions.add(node.func.attr)
                            
            except Exception as e:
                logger.warning(f"æ£€æŸ¥æ­»ä»£ç æ—¶å‡ºé”™ {py_file}: {e}")
        
        # æ‰¾å‡ºå¯èƒ½çš„æ­»å‡½æ•°
        dead_functions = defined_functions - called_functions
        # è¿‡æ»¤æ‰å¸¸è§çš„å…¥å£å‡½æ•°
        dead_functions = {f for f in dead_functions if f not in ['main', '__init__', 'run', 'start']}
        
        self.results['dead_code']['unused_functions'] = list(dead_functions)
    
    def check_complexity_hotspots(self):
        """æ£€æŸ¥å¤æ‚åº¦çƒ­ç‚¹"""
        logger.info("ğŸ” æ£€æŸ¥å¤æ‚åº¦çƒ­ç‚¹...")
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç®€å•çš„å¤æ‚åº¦æŒ‡æ ‡
                lines = len(content.split('\n'))
                functions = content.count('def ')
                classes = content.count('class ')
                nested_loops = len(re.findall(r'for.*for', content))
                nested_ifs = len(re.findall(r'if.*if', content))
                
                complexity_score = (
                    lines * 0.1 +
                    functions * 5 +
                    classes * 10 +
                    nested_loops * 15 +
                    nested_ifs * 10
                )
                
                if complexity_score > 100:  # é«˜å¤æ‚åº¦æ–‡ä»¶
                    self.results['complexity_hotspots'][str(py_file.relative_to(self.project_root))] = {
                        'score': complexity_score,
                        'lines': lines,
                        'functions': functions,
                        'classes': classes,
                        'nested_complexity': nested_loops + nested_ifs
                    }
                    
            except Exception as e:
                logger.warning(f"æ£€æŸ¥å¤æ‚åº¦æ—¶å‡ºé”™ {py_file}: {e}")
    
    def check_naming_inconsistencies(self):
        """æ£€æŸ¥å‘½åä¸ä¸€è‡´"""
        logger.info("ğŸ” æ£€æŸ¥å‘½åä¸ä¸€è‡´...")
        
        naming_patterns = {
            'snake_case': re.compile(r'^[a-z_][a-z0-9_]*$'),
            'camelCase': re.compile(r'^[a-z][a-zA-Z0-9]*$'),
            'PascalCase': re.compile(r'^[A-Z][a-zA-Z0-9]*$'),
            'UPPER_CASE': re.compile(r'^[A-Z_][A-Z0-9_]*$')
        }
        
        function_names = []
        class_names = []
        variable_names = []
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        function_names.append(node.name)
                    elif isinstance(node, ast.ClassDef):
                        class_names.append(node.name)
                    elif isinstance(node, ast.Name):
                        variable_names.append(node.id)
                        
            except Exception as e:
                logger.warning(f"æ£€æŸ¥å‘½åæ—¶å‡ºé”™ {py_file}: {e}")
        
        # åˆ†æå‘½åæ¨¡å¼
        inconsistencies = {}
        
        # æ£€æŸ¥å‡½æ•°å‘½å
        function_patterns = Counter()
        for name in function_names:
            for pattern_name, pattern in naming_patterns.items():
                if pattern.match(name):
                    function_patterns[pattern_name] += 1
                    break
        
        if len(function_patterns) > 1:
            inconsistencies['functions'] = dict(function_patterns)
        
        # æ£€æŸ¥ç±»å‘½å
        class_patterns = Counter()
        for name in class_names:
            for pattern_name, pattern in naming_patterns.items():
                if pattern.match(name):
                    class_patterns[pattern_name] += 1
                    break
        
        if len(class_patterns) > 1:
            inconsistencies['classes'] = dict(class_patterns)
        
        self.results['naming_inconsistencies'] = inconsistencies
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            'venv', '__pycache__', '.git', '.pytest_cache',
            'node_modules', '.tox', 'build', 'dist'
        ]
        
        return any(pattern in str(file_path) for pattern in skip_patterns)
    
    def _extract_ports_from_config(self, config: dict, ports: List[int] = None) -> List[int]:
        """ä»é…ç½®ä¸­æå–ç«¯å£å·"""
        if ports is None:
            ports = []
        
        if isinstance(config, dict):
            for key, value in config.items():
                if 'port' in str(key).lower() and isinstance(value, int):
                    if 1000 <= value <= 65535:
                        ports.append(value)
                elif isinstance(value, (dict, list)):
                    self._extract_ports_from_config(value, ports)
        elif isinstance(config, list):
            for item in config:
                self._extract_ports_from_config(item, ports)
        
        return ports
    
    def _resolve_relative_import(self, file_path: Path, module: str) -> str:
        """è§£æç›¸å¯¹å¯¼å…¥çš„æ¨¡å—è·¯å¾„"""
        try:
            # ç®€åŒ–çš„ç›¸å¯¹å¯¼å…¥è§£æ
            file_dir = file_path.parent
            parts = module.split('.')
            
            for part in parts:
                if part == '':
                    file_dir = file_dir.parent
                else:
                    file_dir = file_dir / part
            
            module_file = file_dir.with_suffix('.py')
            if module_file.exists():
                return str(module_file.relative_to(self.project_root))
        except:
            pass
        
        return None

def main():
    """ä¸»å‡½æ•°"""
    project_root = Path(__file__).parent.parent.parent
    
    checker = CodeQualityChecker(str(project_root))
    results = checker.run_all_checks()
    
    # ä¿å­˜ç»“æœ
    results_file = project_root / 'tests' / 'startup' / 'code_quality_results.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æ±‡æ€»
    print("\n" + "="*60)
    print("ğŸ” MarketPrism ä»£ç è´¨é‡æ£€æµ‹æŠ¥å‘Š")
    print("="*60)
    
    issues_count = 0
    
    for category, data in results.items():
        if data:
            count = len(data)
            issues_count += count
            print(f"ğŸ“‹ {category}: {count} ä¸ªé—®é¢˜")
    
    print(f"\nğŸ“Š æ€»è®¡å‘ç° {issues_count} ä¸ªæ½œåœ¨é—®é¢˜")
    
    if issues_count == 0:
        print("ğŸ‰ æ­å–œï¼ä»£ç è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°æ˜æ˜¾é—®é¢˜")
    elif issues_count < 10:
        print("ğŸ‘ ä»£ç è´¨é‡è¾ƒå¥½ï¼Œæœ‰å°‘é‡æ”¹è¿›ç©ºé—´")
    elif issues_count < 30:
        print("âš ï¸  ä»£ç è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®é‡æ„éƒ¨åˆ†ä»£ç ")
    else:
        print("âŒ ä»£ç è´¨é‡éœ€è¦æ”¹è¿›ï¼Œå»ºè®®è¿›è¡Œå¤§è§„æ¨¡é‡æ„")
    
    print(f"\nğŸ“ è¯¦ç»†ç»“æœä¿å­˜åœ¨: {results_file}")
    print("="*60)

if __name__ == "__main__":
    main()